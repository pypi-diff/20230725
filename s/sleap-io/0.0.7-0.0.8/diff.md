# Comparing `tmp/sleap_io-0.0.7-py3-none-any.whl.zip` & `tmp/sleap_io-0.0.8-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,21 +1,21 @@
-Zip file size: 36143 bytes, number of entries: 19
--rw-r--r--  2.0 unx      642 b- defN 23-Jun-29 22:41 sleap_io/__init__.py
--rw-r--r--  2.0 unx       86 b- defN 23-Jun-29 22:41 sleap_io/io/__init__.py
--rw-r--r--  2.0 unx    11647 b- defN 23-Jun-29 22:41 sleap_io/io/labelstudio.py
--rw-r--r--  2.0 unx     2177 b- defN 23-Jun-29 22:41 sleap_io/io/main.py
--rw-r--r--  2.0 unx    17498 b- defN 23-Jun-29 22:41 sleap_io/io/nwb.py
--rw-r--r--  2.0 unx     9888 b- defN 23-Jun-29 22:41 sleap_io/io/slp.py
--rw-r--r--  2.0 unx     7773 b- defN 23-Jun-29 22:41 sleap_io/io/utils.py
--rw-r--r--  2.0 unx    21686 b- defN 23-Jun-29 22:41 sleap_io/io/video.py
--rw-r--r--  2.0 unx       54 b- defN 23-Jun-29 22:41 sleap_io/model/__init__.py
--rw-r--r--  2.0 unx    14128 b- defN 23-Jun-29 22:41 sleap_io/model/instance.py
--rw-r--r--  2.0 unx     3907 b- defN 23-Jun-29 22:41 sleap_io/model/labeled_frame.py
--rw-r--r--  2.0 unx     9454 b- defN 23-Jun-29 22:41 sleap_io/model/labels.py
--rw-r--r--  2.0 unx     6376 b- defN 23-Jun-29 22:41 sleap_io/model/skeleton.py
--rw-r--r--  2.0 unx     4067 b- defN 23-Jun-29 22:41 sleap_io/model/video.py
--rw-r--r--  2.0 unx     1517 b- defN 23-Jun-29 22:42 sleap_io-0.0.7.dist-info/LICENSE
--rw-r--r--  2.0 unx     3266 b- defN 23-Jun-29 22:42 sleap_io-0.0.7.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-29 22:42 sleap_io-0.0.7.dist-info/WHEEL
--rw-r--r--  2.0 unx        9 b- defN 23-Jun-29 22:42 sleap_io-0.0.7.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1507 b- defN 23-Jun-29 22:42 sleap_io-0.0.7.dist-info/RECORD
-19 files, 115774 bytes uncompressed, 33709 bytes compressed:  70.9%
+Zip file size: 39477 bytes, number of entries: 19
+-rw-r--r--  2.0 unx      656 b- defN 23-Jul-25 08:59 sleap_io/__init__.py
+-rw-r--r--  2.0 unx       86 b- defN 23-Jul-25 08:59 sleap_io/io/__init__.py
+-rw-r--r--  2.0 unx    11647 b- defN 23-Jul-25 08:59 sleap_io/io/labelstudio.py
+-rw-r--r--  2.0 unx     2454 b- defN 23-Jul-25 08:59 sleap_io/io/main.py
+-rw-r--r--  2.0 unx    17498 b- defN 23-Jul-25 08:59 sleap_io/io/nwb.py
+-rw-r--r--  2.0 unx    22909 b- defN 23-Jul-25 08:59 sleap_io/io/slp.py
+-rw-r--r--  2.0 unx     7909 b- defN 23-Jul-25 08:59 sleap_io/io/utils.py
+-rw-r--r--  2.0 unx    21858 b- defN 23-Jul-25 08:59 sleap_io/io/video.py
+-rw-r--r--  2.0 unx       54 b- defN 23-Jul-25 08:59 sleap_io/model/__init__.py
+-rw-r--r--  2.0 unx    14128 b- defN 23-Jul-25 08:59 sleap_io/model/instance.py
+-rw-r--r--  2.0 unx     3915 b- defN 23-Jul-25 08:59 sleap_io/model/labeled_frame.py
+-rw-r--r--  2.0 unx     9988 b- defN 23-Jul-25 08:59 sleap_io/model/labels.py
+-rw-r--r--  2.0 unx     7222 b- defN 23-Jul-25 08:59 sleap_io/model/skeleton.py
+-rw-r--r--  2.0 unx     4386 b- defN 23-Jul-25 08:59 sleap_io/model/video.py
+-rw-r--r--  2.0 unx     1517 b- defN 23-Jul-25 09:00 sleap_io-0.0.8.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3266 b- defN 23-Jul-25 09:00 sleap_io-0.0.8.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-25 09:00 sleap_io-0.0.8.dist-info/WHEEL
+-rw-r--r--  2.0 unx        9 b- defN 23-Jul-25 09:00 sleap_io-0.0.8.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1508 b- defN 23-Jul-25 09:00 sleap_io-0.0.8.dist-info/RECORD
+19 files, 131102 bytes uncompressed, 37043 bytes compressed:  71.7%
```

## zipnote {}

```diff
@@ -36,23 +36,23 @@
 
 Filename: sleap_io/model/skeleton.py
 Comment: 
 
 Filename: sleap_io/model/video.py
 Comment: 
 
-Filename: sleap_io-0.0.7.dist-info/LICENSE
+Filename: sleap_io-0.0.8.dist-info/LICENSE
 Comment: 
 
-Filename: sleap_io-0.0.7.dist-info/METADATA
+Filename: sleap_io-0.0.8.dist-info/METADATA
 Comment: 
 
-Filename: sleap_io-0.0.7.dist-info/WHEEL
+Filename: sleap_io-0.0.8.dist-info/WHEEL
 Comment: 
 
-Filename: sleap_io-0.0.7.dist-info/top_level.txt
+Filename: sleap_io-0.0.8.dist-info/top_level.txt
 Comment: 
 
-Filename: sleap_io-0.0.7.dist-info/RECORD
+Filename: sleap_io-0.0.8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## sleap_io/__init__.py

```diff
@@ -1,24 +1,25 @@
 """This module exposes all high level APIs for sleap-io."""
 
 # Define package version.
 # This is read dynamically by setuptools in pyproject.toml to determine the release version.
-__version__ = "0.0.7"
+__version__ = "0.0.8"
 
 from sleap_io.model.skeleton import Node, Edge, Skeleton, Symmetry
 from sleap_io.model.video import Video
 from sleap_io.model.instance import (
     Point,
     PredictedPoint,
     Track,
     Instance,
     PredictedInstance,
 )
 from sleap_io.model.labeled_frame import LabeledFrame
 from sleap_io.model.labels import Labels
 from sleap_io.io.main import (
     load_slp,
+    save_slp,
     load_nwb,
     save_nwb,
     load_labelstudio,
     save_labelstudio,
 )
```

## sleap_io/io/main.py

```diff
@@ -15,14 +15,24 @@
 
     Returns:
         The dataset as a `Labels` object.
     """
     return slp.read_labels(filename)
 
 
+def save_slp(labels: Labels, filename: str):
+    """Save a SLEAP dataset to a `.slp` file.
+
+    Args:
+        labels: A SLEAP `Labels` object (see `load_slp`).
+        filename: Path to save labels to ending with `.slp`.
+    """
+    return slp.write_labels(filename, labels)
+
+
 def load_nwb(filename: str) -> Labels:
     """Load an NWB dataset as a SLEAP `Labels` object.
 
     Args:
         filename: Path to a NWB file (`.nwb`).
 
     Returns:
```

## sleap_io/io/slp.py

```diff
@@ -1,27 +1,36 @@
 """This module handles direct I/O operations for working with .slp files."""
 
 from __future__ import annotations
 import numpy as np
+import h5py
 import simplejson as json
 from typing import Union
 from sleap_io import (
     Video,
     Skeleton,
     Edge,
+    Symmetry,
     Node,
     Track,
     Point,
     PredictedPoint,
     Instance,
     PredictedInstance,
     LabeledFrame,
     Labels,
 )
-from sleap_io.io.utils import read_hdf5_attrs, read_hdf5_dataset
+from sleap_io.io.video import MediaVideo, HDF5Video
+from sleap_io.io.utils import (
+    read_hdf5_attrs,
+    read_hdf5_dataset,
+    write_hdf5_dataset,
+    write_hdf5_group,
+    write_hdf5_attrs,
+)
 from sleap_io.io.video import VideoBackend
 from enum import IntEnum
 from pathlib import Path
 
 
 class InstanceType(IntEnum):
     """Enumeration of instance types to integers."""
@@ -30,15 +39,15 @@
     PREDICTED = 1
 
 
 def read_videos(labels_path: str) -> list[Video]:
     """Read `Video` dataset in a SLEAP labels file.
 
     Args:
-        labels_path: A string that contains the path to the labels file
+        labels_path: A string path to the SLEAP labels file.
 
     Returns:
         A list of `Video` objects.
     """
     # TODO (DS) - Find shape of video
     videos = [json.loads(x) for x in read_hdf5_dataset(labels_path, "videos_json")]
     video_objects = []
@@ -71,41 +80,101 @@
             )
         except ValueError:
             backend = None
         video_objects.append(Video(filename=video_path.as_posix(), backend=backend))
     return video_objects
 
 
+def write_videos(labels_path: str, videos: list[Video]):
+    """Write video metadata to a SLEAP labels file.
+
+    Args:
+        labels_path: A string path to the SLEAP labels file.
+        videos: A list of `Video` objects to store the metadata for.
+    """
+    video_jsons = []
+    for video in videos:
+        if type(video.backend) == MediaVideo:
+            video_json = {
+                "backend": {
+                    "filename": video.filename,
+                    "grayscale": video.backend.grayscale,
+                    "bgr": True,
+                    "dataset": "",
+                    "input_format": "",
+                }
+            }
+
+        elif type(video.backend) == HDF5Video:
+            video_json = {
+                "backend": {
+                    "filename": "."
+                    if video.backend.has_embedded_images
+                    else video.filename,
+                    "dataset": video.backend.dataset,
+                    "input_format": video.backend.input_format,
+                    "convert_range": False,
+                }
+            }
+            # TODO: Handle saving embedded images or restoring source video.
+            # Ref: https://github.com/talmolab/sleap/blob/fb61b6ce7a9ac9613d99303111f3daafaffc299b/sleap/io/format/hdf5.py#L246-L273
+
+        else:
+            raise NotImplementedError(
+                f"Cannot serialize video backend for video: {video}"
+            )
+        video_jsons.append(np.string_(json.dumps(video_json, separators=(",", ":"))))
+
+        with h5py.File(labels_path, "a") as f:
+            f.create_dataset("videos_json", data=video_jsons, maxshape=(None,))
+
+
 def read_tracks(labels_path: str) -> list[Track]:
     """Read `Track` dataset in a SLEAP labels file.
 
     Args:
-        labels_path: A string that contains the path to the labels file
+        labels_path: A string path to the SLEAP labels file.
 
     Returns:
         A list of `Track` objects.
     """
     tracks = [json.loads(x) for x in read_hdf5_dataset(labels_path, "tracks_json")]
     track_objects = []
     for track in tracks:
         track_objects.append(Track(name=track[1]))
     return track_objects
 
 
+def write_tracks(labels_path: str, tracks: list[Track]):
+    """Write track metadata to a SLEAP labels file.
+
+    Args:
+        labels_path: A string path to the SLEAP labels file.
+        tracks: A list of `Track` objects to store the metadata for.
+    """
+    # TODO: Add support for track metadata like spawned on frame.
+    SPAWNED_ON = 0
+    tracks_json = [
+        np.string_(json.dumps([SPAWNED_ON, track.name], separators=(",", ":")))
+        for track in tracks
+    ]
+    with h5py.File(labels_path, "a") as f:
+        f.create_dataset("tracks_json", data=tracks_json, maxshape=(None,))
+
+
 def read_metadata(labels_path: str) -> dict:
     """Read metadata from a SLEAP labels file.
 
     Args:
-        labels_path: A string that contains the path to the labels file
+        labels_path: A string path to the SLEAP labels file.
 
     Returns:
         A dict containing the metadata from a SLEAP labels file.
     """
     md = read_hdf5_attrs(labels_path, "metadata", "json")
-    assert type(md) == np.bytes_
     return json.loads(md.decode())
 
 
 def read_skeletons(labels_path: str) -> list[Skeleton]:
     """Read `Skeleton` dataset from a SLEAP labels file.
 
     Args:
@@ -119,47 +188,203 @@
     # Get node names. This is a superset of all nodes across all skeletons. Note that
     # node ordering is specific to each skeleton, so we'll need to fix this afterwards.
     node_names = [x["name"] for x in metadata["nodes"]]
 
     skeleton_objects = []
     for skel in metadata["skeletons"]:
         # Parse out the cattr-based serialization stuff from the skeleton links.
-        edge_inds = []
+        edge_inds, symmetry_inds = [], []
         for link in skel["links"]:
             if "py/reduce" in link["type"]:
                 edge_type = link["type"]["py/reduce"][1]["py/tuple"][0]
             else:
                 edge_type = link["type"]["py/id"]
 
             if edge_type == 1:  # 1 -> real edge, 2 -> symmetry edge
                 edge_inds.append((link["source"], link["target"]))
 
+            elif edge_type == 2:
+                symmetry_inds.append((link["source"], link["target"]))
+
         # Re-index correctly.
         skeleton_node_inds = [node["id"] for node in skel["nodes"]]
         node_names = [node_names[i] for i in skeleton_node_inds]
+
+        # Create nodes.
+        nodes = []
+        for name in node_names:
+            nodes.append(Node(name=name))
+
+        # Create edges.
         edge_inds = [
             (skeleton_node_inds.index(s), skeleton_node_inds.index(d))
             for s, d in edge_inds
         ]
-        nodes = []
-        for name in node_names:
-            nodes.append(Node(name=name))
         edges = []
         for edge in edge_inds:
             edges.append(Edge(source=nodes[edge[0]], destination=nodes[edge[1]]))
-        skel = Skeleton(nodes=nodes, edges=edges, name=skel["graph"]["name"])
+
+        # Create symmetries.
+        symmetry_inds = [
+            (skeleton_node_inds.index(s), skeleton_node_inds.index(d))
+            for s, d in symmetry_inds
+        ]
+        symmetries = []
+        for symmetry in symmetry_inds:
+            symmetries.append(Symmetry([nodes[symmetry[0]], nodes[symmetry[1]]]))
+
+        # Create the full skeleton.
+        skel = Skeleton(
+            nodes=nodes, edges=edges, symmetries=symmetries, name=skel["graph"]["name"]
+        )
         skeleton_objects.append(skel)
     return skeleton_objects
 
 
+def serialize_skeletons(skeletons: list[Skeleton]) -> tuple[list[dict], list[dict]]:
+    """Serialize a list of `Skeleton` objects to JSON-compatible dicts.
+
+    Args:
+        skeletons: A list of `Skeleton` objects.
+
+    Returns:
+        A tuple of `nodes_dicts, skeletons_dicts`.
+
+        `nodes_dicts` is a list of dicts containing the nodes in all the skeletons.
+
+        `skeletons_dicts` is a list of dicts containing the skeletons.
+
+    Notes:
+        This function attempts to replicate the serialization of skeletons in legacy
+        SLEAP which relies on a combination of networkx's graph serialization and our
+        own metadata used to store nodes and edges independent of the graph structure.
+
+        However, because sleap-io does not currently load in the legacy metadata, this
+        function will not produce byte-level compatible serialization with legacy
+        formats, even though the ordering and all attributes of nodes and edges should
+        match up.
+    """
+    # Create global list of nodes with all nodes from all skeletons.
+    nodes_dicts = []
+    node_to_id = {}
+    for skeleton in skeletons:
+        for node in skeleton.nodes:
+            if node not in node_to_id:
+                # Note: This ID is not the same as the node index in the skeleton in
+                # legacy SLEAP, but we do not retain this information in the labels, so
+                # IDs will be different.
+                #
+                # The weight is also kept fixed here, but technically this is not
+                # modified or used in legacy SLEAP either.
+                #
+                # TODO: Store legacy metadata in labels to get byte-level compatibility?
+                node_to_id[node] = len(node_to_id)
+                nodes_dicts.append({"name": node.name, "weight": 1.0})
+
+    skeletons_dicts = []
+    for skeleton in skeletons:
+        # Build links dicts for normal edges.
+        edges_dicts = []
+        for edge_ind, edge in enumerate(skeleton.edges):
+            if edge_ind == 0:
+                edge_type = {
+                    "py/reduce": [
+                        {"py/type": "sleap.skeleton.EdgeType"},
+                        {"py/tuple": [1]},  # 1 = real edge, 2 = symmetry edge
+                    ]
+                }
+            else:
+                edge_type = {"py/id": 1}
+
+            edges_dicts.append(
+                {
+                    # Note: Insert idx is not the same as the edge index in the skeleton
+                    # in legacy SLEAP.
+                    "edge_insert_idx": edge_ind,
+                    "key": 0,  # Always 0.
+                    "source": node_to_id[edge.source],
+                    "target": node_to_id[edge.destination],
+                    "type": edge_type,
+                }
+            )
+
+        # Build links dicts for symmetry edges.
+        for symmetry_ind, symmetry in enumerate(skeleton.symmetries):
+            if symmetry_ind == 0:
+                edge_type = {
+                    "py/reduce": [
+                        {"py/type": "sleap.skeleton.EdgeType"},
+                        {"py/tuple": [2]},  # 1 = real edge, 2 = symmetry edge
+                    ]
+                }
+            else:
+                edge_type = {"py/id": 2}
+
+            src, dst = tuple(symmetry.nodes)
+            edges_dicts.append(
+                {
+                    "key": 0,
+                    "source": node_to_id[src],
+                    "target": node_to_id[dst],
+                    "type": edge_type,
+                }
+            )
+
+        # Create skeleton dict.
+        skeletons_dicts.append(
+            {
+                "directed": True,
+                "graph": {
+                    "name": skeleton.name,
+                    "num_edges_inserted": len(skeleton.edges),
+                },
+                "links": edges_dicts,
+                "multigraph": True,
+                # In the order in Skeleton.nodes and must match up with nodes_dicts.
+                "nodes": [{"id": node_to_id[node]} for node in skeleton.nodes],
+            }
+        )
+
+    return skeletons_dicts, nodes_dicts
+
+
+def write_metadata(labels_path: str, labels: Labels):
+    """Write metadata to a SLEAP labels file.
+
+    This function will write the skeletons and provenance for the labels.
+
+    Args:
+        labels_path: A string path to the SLEAP labels file.
+        labels: A `Labels` object to store the metadata for.
+
+    See also: serialize_skeletons
+    """
+    skeletons_dicts, nodes_dicts = serialize_skeletons(labels.skeletons)
+
+    md = {
+        "version": "2.0.0",
+        "skeletons": skeletons_dicts,
+        "nodes": nodes_dicts,
+        "videos": [],
+        "tracks": [],
+        "suggestions": [],  # TODO: Handle suggestions metadata.
+        "negative_anchors": [],
+        "provenance": labels.provenance,
+    }
+    with h5py.File(labels_path, "a") as f:
+        grp = f.require_group("metadata")
+        grp.attrs["format_id"] = 1.2
+        grp.attrs["json"] = np.string_(json.dumps(md, separators=(",", ":")))
+
+
 def read_points(labels_path: str) -> list[Point]:
     """Read `Point` dataset from a SLEAP labels file.
 
     Args:
-        labels_path: A string that contains the path to the labels file.
+        labels_path: A string path to the SLEAP labels file.
 
     Returns:
         A list of `Point` objects.
     """
     pts = read_hdf5_dataset(labels_path, "points")
     return [
         Point(x=x, y=y, visible=visible, complete=complete)
@@ -167,15 +392,15 @@
     ]
 
 
 def read_pred_points(labels_path: str) -> list[PredictedPoint]:
     """Read `PredictedPoint` dataset from a SLEAP labels file.
 
     Args:
-        labels_path: A string that contains the path to the labels file
+        labels_path: A string path to the SLEAP labels file.
 
     Returns:
         A list of `PredictedPoint` objects.
     """
     pred_pts = read_hdf5_dataset(labels_path, "pred_points")
     return [
         PredictedPoint(x=x, y=y, visible=visible, complete=complete, score=score)
@@ -190,15 +415,15 @@
     points: list[Point],
     pred_points: list[PredictedPoint],
     format_id: float,
 ) -> list[Union[Instance, PredictedInstance]]:
     """Read `Instance` dataset in a SLEAP labels file.
 
     Args:
-        labels_path: A string that contains the path to the labels file
+        labels_path: A string path to the SLEAP labels file.
         skeletons: A list of `Skeleton` objects (see `read_skeletons`).
         tracks: A list of `Track` objects (see `read_tracks`).
         points: A list of `Point` objects (see `read_points`).
         pred_points: A list of `PredictedPoint` objects (see `read_pred_points`).
         format_id: The format version identifier used to specify the format of the input
             file.
 
@@ -260,30 +485,171 @@
 
     # Convert instances back to list.
     instances = list(instances.values())
 
     return instances
 
 
+def write_lfs(labels_path: str, labels: Labels):
+    """Write labeled frames, instances and points to a SLEAP labels file.
+
+    Args:
+        labels_path: A string path to the SLEAP labels file.
+        labels: A `Labels` object to store the metadata for.
+    """
+    # We store the data in structured arrays for performance, so we first define the
+    # dtype fields.
+    instance_dtype = np.dtype(
+        [
+            ("instance_id", "i8"),
+            ("instance_type", "u1"),
+            ("frame_id", "u8"),
+            ("skeleton", "u4"),
+            ("track", "i4"),
+            ("from_predicted", "i8"),
+            ("score", "f4"),
+            ("point_id_start", "u8"),
+            ("point_id_end", "u8"),
+            ("tracking_score", "f4"),  # FORMAT_ID >= 1.2
+        ]
+    )
+    frame_dtype = np.dtype(
+        [
+            ("frame_id", "u8"),
+            ("video", "u4"),
+            ("frame_idx", "u8"),
+            ("instance_id_start", "u8"),
+            ("instance_id_end", "u8"),
+        ]
+    )
+    point_dtype = np.dtype(
+        [("x", "f8"), ("y", "f8"), ("visible", "?"), ("complete", "?")]
+    )
+    predicted_point_dtype = np.dtype(
+        [("x", "f8"), ("y", "f8"), ("visible", "?"), ("complete", "?"), ("score", "f8")]
+    )
+
+    # Next, we extract the data from the labels object into lists with the same fields.
+    frames, instances, points, predicted_points, to_link = [], [], [], [], []
+    inst_to_id = {}
+    for lf in labels:
+        frame_id = len(frames)
+        instance_id_start = len(instances)
+        for inst in lf:
+            instance_id = len(instances)
+            inst_to_id[id(inst)] = instance_id
+            skeleton_id = labels.skeletons.index(inst.skeleton)
+            track = labels.tracks.index(inst.track) if inst.track else -1
+            from_predicted = -1
+            if inst.from_predicted:
+                to_link.append((instance_id, inst.from_predicted))
+
+            if type(inst) == Instance:
+                instance_type = InstanceType.USER
+                score = np.nan
+                tracking_score = np.nan
+                point_id_start = len(points)
+
+                for node in inst.skeleton.nodes:
+                    pt = inst.points[node]
+                    points.append([pt.x, pt.y, pt.visible, pt.complete])
+
+                point_id_end = len(points)
+
+            elif type(inst) == PredictedInstance:
+                instance_type = InstanceType.PREDICTED
+                score = inst.score
+                tracking_score = inst.tracking_score
+                point_id_start = len(predicted_points)
+
+                for node in inst.skeleton.nodes:
+                    pt = inst.points[node]
+                    predicted_points.append(
+                        [pt.x, pt.y, pt.visible, pt.complete, pt.score]
+                    )
+
+                point_id_end = len(predicted_points)
+
+            else:
+                raise ValueError(f"Unknown instance type: {type(inst)}")
+
+            instances.append(
+                [
+                    instance_id,
+                    int(instance_type),
+                    frame_id,
+                    skeleton_id,
+                    track,
+                    from_predicted,
+                    score,
+                    point_id_start,
+                    point_id_end,
+                    tracking_score,
+                ]
+            )
+
+        instance_id_end = len(instances)
+
+        frames.append(
+            [
+                frame_id,
+                labels.videos.index(lf.video),
+                lf.frame_idx,
+                instance_id_start,
+                instance_id_end,
+            ]
+        )
+
+    # Link instances based on from_predicted field.
+    for instance_id, from_predicted in to_link:
+        instances[instance_id][5] = inst_to_id[id(from_predicted)]
+
+    # Create structured arrays.
+    points = np.array([tuple(x) for x in points], dtype=point_dtype)
+    predicted_points = np.array(
+        [tuple(x) for x in predicted_points], dtype=predicted_point_dtype
+    )
+    instances = np.array([tuple(x) for x in instances], dtype=instance_dtype)
+    frames = np.array([tuple(x) for x in frames], dtype=frame_dtype)
+
+    # Write to file.
+    with h5py.File(labels_path, "a") as f:
+        f.create_dataset("points", data=points, dtype=points.dtype)
+        f.create_dataset(
+            "pred_points",
+            data=predicted_points,
+            dtype=predicted_points.dtype,
+        )
+        f.create_dataset(
+            "instances",
+            data=instances,
+            dtype=instances.dtype,
+        )
+        f.create_dataset(
+            "frames",
+            data=frames,
+            dtype=frames.dtype,
+        )
+
+
 def read_labels(labels_path: str) -> Labels:
     """Read a SLEAP labels file.
 
     Args:
-        labels_path: Path to a SLEAP-formatted labels file (.slp).
+        labels_path: A string path to the SLEAP labels file.
 
     Returns:
         The processed `Labels` object.
     """
     tracks = read_tracks(labels_path)
     videos = read_videos(labels_path)
     skeletons = read_skeletons(labels_path)
     points = read_points(labels_path)
     pred_points = read_pred_points(labels_path)
     format_id = read_hdf5_attrs(labels_path, "metadata", "format_id")
-    assert isinstance(format_id, float)
     instances = read_instances(
         labels_path, skeletons, tracks, points, pred_points, format_id
     )
     metadata = read_metadata(labels_path)
     provenance = metadata.get("provenance", dict())
 
     frames = read_hdf5_dataset(labels_path, "frames")
@@ -302,7 +668,22 @@
         videos=videos,
         skeletons=skeletons,
         tracks=tracks,
         provenance=provenance,
     )
 
     return labels
+
+
+def write_labels(labels_path: str, labels: Labels):
+    """Write a SLEAP labels file.
+
+    Args:
+        labels_path: A string path to the SLEAP labels file to save.
+        labels: A `Labels` object to save.
+    """
+    if Path(labels_path).exists():
+        Path(labels_path).unlink()
+    write_videos(labels_path, labels.videos)
+    write_tracks(labels_path, labels.tracks)
+    write_metadata(labels_path, labels)
+    write_lfs(labels_path, labels)
```

## sleap_io/io/utils.py

```diff
@@ -37,22 +37,22 @@
         del f[dataset]
     except KeyError:
         pass
     f.create_dataset(dataset, data=data)
 
 
 def write_hdf5_dataset(filename: str, dataset: str, data: np.ndarray):
-    """Write data from an HDF5 file.
+    """Write data to an HDF5 file.
 
     Args:
         filename: Path to an HDF5 file.
         dataset: Path to a dataset.
         data: Data to write to dataset.
     """
-    with h5py.File(filename, "r+") as f:
+    with h5py.File(filename, "a") as f:  # "a": read/write if exists, create otherwise
         _overwrite_hdf5_dataset(f, dataset, data)
 
 
 def read_hdf5_group(filename: str, group: str = "/") -> dict[str, np.ndarray]:
     """Read an entire group from an HDF5 file.
 
     Args:
@@ -112,15 +112,15 @@
                 write_group(group, dataset_or_group)  # Recall with new parent
             else:
                 # Create dataset if dataset_or_group is a dataset
                 _overwrite_hdf5_dataset(
                     f=parent_group, dataset=name, data=dataset_or_group
                 )
 
-    with h5py.File(filename, "r+") as f:
+    with h5py.File(filename, "a") as f:  # "a": read/write if exists, create otherwise
         write_group(f, data)
 
 
 def read_hdf5_attrs(
     filename, dataset: str = "/", attribute: Optional[str] = None
 ) -> Union[Any, dict[str, Any]]:
     """Read attributes from an HDF5 dataset.
@@ -165,15 +165,15 @@
         """
         try:
             del group_or_dataset.attrs[attr_name]
         except KeyError:
             pass
         group_or_dataset.attrs.create(attr_name, data)
 
-    with h5py.File(filename, "r+") as f:
+    with h5py.File(filename, "a") as f:  # "a": read/write if exists, create otherwise
         ds = f[dataset]
         for attr_name, attr_value in attributes.items():
             _overwrite_hdf5_attr(ds, attr_name, attr_value)
 
 
 def convert_predictions_to_dataframe(labels: Labels) -> pd.DataFrame:
     """Convert predictions data to a Pandas dataframe.
```

## sleap_io/io/video.py

```diff
@@ -72,17 +72,14 @@
             filename = str(filename)
 
         if filename.endswith(MediaVideo.EXTS):
             return MediaVideo(
                 filename, grayscale=grayscale, **_get_valid_kwargs(MediaVideo, kwargs)
             )
         elif filename.endswith(HDF5Video.EXTS):
-            valid_kwargs = {
-                k: v for k, v in kwargs.items() if k in MediaVideo.__attrs_attrs__
-            }
             return HDF5Video(
                 filename,
                 dataset=dataset,
                 grayscale=grayscale,
                 **_get_valid_kwargs(HDF5Video, kwargs),
             )
         else:
@@ -347,14 +344,15 @@
             reader = cv2.VideoCapture(self.filename)
             reader.set(cv2.CAP_PROP_POS_FRAMES, frame_inds[0])
             imgs = []
             for idx in frame_inds:
                 if reader.get(cv2.CAP_PROP_POS_FRAMES) != idx:
                     reader.set(cv2.CAP_PROP_POS_FRAMES, idx)
                 _, img = reader.read()
+                img = img[..., ::-1]  # BGR -> RGB
                 imgs.append(img)
             imgs = np.stack(imgs, axis=0)
 
         else:
             with iio.imopen(self.filename, "r", plugin=self.plugin) as vid:
                 imgs = np.stack([vid.read(index=idx) for idx in frame_inds], axis=0)
         return imgs
@@ -490,14 +488,21 @@
         """Read a single frame from the video to test for grayscale."""
         if self.frame_map:
             frame_idx = list(self.frame_map.keys())[0]
         else:
             frame_idx = 0
         return self.read_frame(frame_idx)
 
+    @property
+    def has_embedded_images(self) -> bool:
+        """Return True if the dataset contains embedded images."""
+        with h5py.File(self.filename, "r") as f:
+            ds = f[self.dataset]
+            return "format" in ds.attrs
+
     def decode_embedded(self, img_string: np.ndarray, format: str) -> np.ndarray:
         """Decode an embedded image string into a numpy array.
 
         Args:
             img_string: Binary string of the image as a `int8` numpy vector with the
                 bytes as values corresponding to the format-encoded image.
             format: Image format (e.g., "png" or "jpg").
```

## sleap_io/model/labeled_frame.py

```diff
@@ -40,15 +40,15 @@
     @property
     def user_instances(self) -> list[Instance]:
         """Frame instances that are user-labeled (`Instance` objects)."""
         return [inst for inst in self.instances if type(inst) == Instance]
 
     @property
     def predicted_instances(self) -> list[Instance]:
-        """Frame instances that are user-labeled (`PredictedInstance` objects)."""
+        """Frame instances that are predicted by a model (`PredictedInstance` objects)."""
         return [inst for inst in self.instances if type(inst) == PredictedInstance]
 
     def numpy(self) -> np.ndarray:
         """Return all instances in the frame as a numpy array.
 
         Returns:
             Points as a numpy array of shape `(n_instances, n_nodes, 2)`.
```

## sleap_io/model/labels.py

```diff
@@ -186,14 +186,27 @@
             return self.videos[0]
         else:
             raise ValueError(
                 "Labels.video can only be used when there is only a single video saved "
                 "in the labels. Use Labels.videos instead."
             )
 
+    @property
+    def skeleton(self) -> Skeleton:
+        """Return the skeleton if there is only a single skeleton in the labels."""
+        if len(self.skeletons) == 0:
+            raise ValueError("There are no skeletons in the labels.")
+        elif len(self.skeletons) == 1:
+            return self.skeletons[0]
+        else:
+            raise ValueError(
+                "Labels.skeleton can only be used when there is only a single skeleton "
+                "saved in the labels. Use Labels.skeletons instead."
+            )
+
     def find(
         self,
         video: Video,
         frame_idx: int | list[int] | None = None,
         return_new: bool = False,
     ) -> list[LabeledFrame]:
         """Search for labeled frames given video and/or frame index.
```

## sleap_io/model/skeleton.py

```diff
@@ -56,14 +56,24 @@
 
     Attributes:
         nodes: A set of two `Node`s.
     """
 
     nodes: set[Node] = field(converter=set, validator=lambda _, __, val: len(val) == 2)
 
+    def __iter__(self):
+        """Iterate over the symmetric nodes."""
+        return iter(self.nodes)
+
+    def __getitem__(self, idx) -> Node:
+        """Return the first node."""
+        for i, node in enumerate(self.nodes):
+            if i == idx:
+                return node
+
 
 @define
 class Skeleton:
     """A description of a set of landmark types and connections between them.
 
     Skeletons are represented by a directed graph composed of a set of `Node`s (landmark
     types such as body parts) and `Edge`s (connections between parts).
@@ -82,15 +92,15 @@
     """
 
     def _update_node_map(self, attr, nodes):
         """Callback for maintaining node name/index to `Node` map."""
         self._node_name_map = {node.name: node for node in nodes}
         self._node_ind_map = {node: i for i, node in enumerate(nodes)}
 
-    nodes: list[Node] = field(on_setattr=_update_node_map)
+    nodes: list[Node] = field(factory=list, on_setattr=_update_node_map)
     edges: list[Edge] = field(factory=list)
     symmetries: list[Symmetry] = field(factory=list)
     name: Optional[str] = None
     _node_name_map: dict[str, Node] = field(init=False, repr=False, eq=False)
     _node_ind_map: dict[Node, int] = field(init=False, repr=False, eq=False)
 
     def __attrs_post_init__(self):
@@ -151,14 +161,28 @@
     def edge_inds(self) -> list[Tuple[int, int]]:
         """Edges indices as a list of 2-tuples."""
         return [
             (self.nodes.index(edge.source), self.nodes.index(edge.destination))
             for edge in self.edges
         ]
 
+    @property
+    def flipped_node_inds(self) -> list[int]:
+        """Returns node indices that should be switched when horizontally flipping."""
+        flip_idx = np.arange(len(self.nodes))
+        if len(self.symmetries) > 0:
+            symmetry_inds = np.array(
+                [(self.index(a), self.index(b)) for a, b in self.symmetries]
+            )
+            flip_idx[symmetry_inds[:, 0]] = symmetry_inds[:, 1]
+            flip_idx[symmetry_inds[:, 1]] = symmetry_inds[:, 0]
+
+        flip_idx = flip_idx.tolist()
+        return flip_idx
+
     def __len__(self) -> int:
         """Return the number of nodes in the skeleton."""
         return len(self.nodes)
 
     def index(self, node: Union[Node, str]) -> int:
         """Return the index of a node specified as a `Node` or string name."""
         if type(node) == str:
```

## sleap_io/model/video.py

```diff
@@ -5,14 +5,15 @@
 """
 
 from __future__ import annotations
 from attrs import define
 from typing import Tuple, Optional, Optional
 import numpy as np
 from sleap_io.io.video import VideoBackend
+from pathlib import Path
 
 
 @define
 class Video:
     """`Video` class used by sleap to represent videos and data associated with them.
 
     This class is used to store information regarding a video and its components.
@@ -28,14 +29,21 @@
 
     See also: VideoBackend
     """
 
     filename: str
     backend: Optional[VideoBackend] = None
 
+    def __attrs_post_init__(self):
+        """Set the video backend if not already set."""
+        if self.backend is None:
+            if Path(self.filename).exists():
+                # TODO: Automatic path resolution?
+                self.backend = VideoBackend.from_filename(self.filename)
+
     @classmethod
     def from_filename(
         cls,
         filename: str,
         dataset: Optional[str] = None,
         grayscale: Optional[str] = None,
         **kwargs,
```

## Comparing `sleap_io-0.0.7.dist-info/LICENSE` & `sleap_io-0.0.8.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `sleap_io-0.0.7.dist-info/METADATA` & `sleap_io-0.0.8.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: sleap-io
-Version: 0.0.7
+Version: 0.0.8
 Summary: Standalone utilities for working with pose data from SLEAP and other tools.
 Author-email: Liezl Maree <lmaree@salk.edu>, David Samy <davidasamy@gmail.com>, Talmo Pereira <talmo@salk.edu>
 License: BSD-3-Clause
 Project-URL: Homepage, https://sleap.ai
 Project-URL: Repository, https://github.com/talmolab/sleap-io
 Keywords: sleap,pose tracking,pose estimation,behavior
 Classifier: Programming Language :: Python :: 3.7
```

## Comparing `sleap_io-0.0.7.dist-info/RECORD` & `sleap_io-0.0.8.dist-info/RECORD`

 * *Files 20% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-sleap_io/__init__.py,sha256=CCMYdaR4dv4CFm1dOt74IQgM0yRCaL3YLjXKt6wB5xE,642
+sleap_io/__init__.py,sha256=ySwW6EiL7LjuHtoDNra9oLHI9wFRm_mgWXm7j-m7GCM,656
 sleap_io/io/__init__.py,sha256=NK3cO6qGcLTDCTPDaPzZ9Wzq70E_i4P763POgvKCSVA,86
 sleap_io/io/labelstudio.py,sha256=WN2pGyJhlRqGMJXflvEXETwHlFE925jYB_tZZzEqFiI,11647
-sleap_io/io/main.py,sha256=nRFbRt71XZIKndgq4rY9cfWsmWAOZWhvIPmxr8i0s_A,2177
+sleap_io/io/main.py,sha256=m7LzYAreSaGmRo39QK6in4iBcYT9P13SduACT-3Frvo,2454
 sleap_io/io/nwb.py,sha256=edqUq7wuUIYGCgwJD9JFP4wDTOePY8UvyZ6XGatzqOY,17498
-sleap_io/io/slp.py,sha256=n5C35FVUgbjB3Quwi7aRzpCoREFEJ8f92Ip3277tl8Y,9888
-sleap_io/io/utils.py,sha256=Ze3BCnTcsIx9ll9JB3c8yg_eM1n8B7IH3DP03FbQ9gE,7773
-sleap_io/io/video.py,sha256=-3g18altkNM07UJDnjQycy_jPgAt_hvH6MfH_ZOogXY,21686
+sleap_io/io/slp.py,sha256=9kE0WTBrEgBo4XCPtdH__5LkOl2G8TxWC3jzZRVuV2Q,22909
+sleap_io/io/utils.py,sha256=_F0uvhWbJCAAubCO4SOgmekjrjPhqF65p-zD4Dhu2h4,7909
+sleap_io/io/video.py,sha256=iqquI-j-vW1YPAkzlaHgHaPfEOyIZ_feXh-ZFsPN9mY,21858
 sleap_io/model/__init__.py,sha256=uXw3XtLUp_0eJSXBTZ19TcYPQiLbG8A3Pl8Ba52aoVk,54
 sleap_io/model/instance.py,sha256=FXfu9UzPs_qRPYCoSLiyalYxwRaRi5w_YRcu25frxPE,14128
-sleap_io/model/labeled_frame.py,sha256=BmJnIcHkjacphSpBXluslxpqU8D6fMha7IaOFUEQxHU,3907
-sleap_io/model/labels.py,sha256=rf1mGI2xvUvaQ9XOnwEAQQZyWRZSHduU-yu6SYoR96w,9454
-sleap_io/model/skeleton.py,sha256=MSo4eAx4H3Rqps9VXAuSy78GYe1NbGI35ebVZrrYKm4,6376
-sleap_io/model/video.py,sha256=ReBs5Py1LEow-7o-Ku1KlbuEKZCnRWi29FMLN3kpLtE,4067
-sleap_io-0.0.7.dist-info/LICENSE,sha256=J9iJdbsnfTn19yshe4TQ3dGGj7_oNpLGbTy8fK8b7mw,1517
-sleap_io-0.0.7.dist-info/METADATA,sha256=CVJ6xfNuwkcuZf1CKY-GdGOxwMmYIjiIIlvskiWrnlo,3266
-sleap_io-0.0.7.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-sleap_io-0.0.7.dist-info/top_level.txt,sha256=lIPfP4U6Vp5BMtjr2oC7XQEMuLE9RCHEMEHgpNNwsD4,9
-sleap_io-0.0.7.dist-info/RECORD,,
+sleap_io/model/labeled_frame.py,sha256=yBUO70JNIuEQt6P-eWXNDd3VvGJrZA80cmpO2fcojdU,3915
+sleap_io/model/labels.py,sha256=jnDMYbLCARPLB6Rwq9IjqPF1wnLxE4I_arALXwoHQEQ,9988
+sleap_io/model/skeleton.py,sha256=SoW7de4i-jplfWX2OiCmHEZopcNP27igh_ONQQxy26k,7222
+sleap_io/model/video.py,sha256=_Dy7LrS6fv48QODEQaDv8nnhZOHPfeCuwxy0ncYczHo,4386
+sleap_io-0.0.8.dist-info/LICENSE,sha256=J9iJdbsnfTn19yshe4TQ3dGGj7_oNpLGbTy8fK8b7mw,1517
+sleap_io-0.0.8.dist-info/METADATA,sha256=LeOtn4-kblREdk2ukpHgvgPoyFdcz6ZL3cc56B1PXWw,3266
+sleap_io-0.0.8.dist-info/WHEEL,sha256=AtBG6SXL3KF_v0NxLf0ehyVOh0cold-JbJYXNGorC6Q,92
+sleap_io-0.0.8.dist-info/top_level.txt,sha256=lIPfP4U6Vp5BMtjr2oC7XQEMuLE9RCHEMEHgpNNwsD4,9
+sleap_io-0.0.8.dist-info/RECORD,,
```

