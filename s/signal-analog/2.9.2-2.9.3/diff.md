# Comparing `tmp/signal_analog-2.9.2-py3.7.egg` & `tmp/signal_analog-2.9.3-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,37 +1,22 @@
-Zip file size: 117509 bytes, number of entries: 35
--rw-r--r--  2.0 unx    44597 b- defN 19-Nov-12 08:48 EGG-INFO/PKG-INFO
--rw-r--r--  2.0 unx     3576 b- defN 19-Nov-12 08:48 EGG-INFO/SOURCES.txt
--rw-r--r--  2.0 unx        1 b- defN 19-Nov-12 08:48 EGG-INFO/dependency_links.txt
--rw-r--r--  2.0 unx        1 b- defN 19-Nov-12 08:48 EGG-INFO/not-zip-safe
--rw-r--r--  2.0 unx       70 b- defN 19-Nov-12 08:48 EGG-INFO/requires.txt
--rw-r--r--  2.0 unx       14 b- defN 19-Nov-12 08:48 EGG-INFO/top_level.txt
--rw-r--r--  2.0 unx      672 b- defN 19-Nov-12 08:48 signal_analog/__init__.py
--rw-r--r--  2.0 unx    28726 b- defN 19-Oct-30 14:56 signal_analog/charts.py
--rw-r--r--  2.0 unx     3368 b- defN 18-Oct-30 10:14 signal_analog/cli.py
--rw-r--r--  2.0 unx     3265 b- defN 18-Oct-30 10:14 signal_analog/combinators.py
--rw-r--r--  2.0 unx    26213 b- defN 19-Jun-19 15:17 signal_analog/dashboards.py
--rw-r--r--  2.0 unx    21137 b- defN 19-Oct-30 14:56 signal_analog/detectors.py
--rw-r--r--  2.0 unx     2069 b- defN 19-Oct-30 12:32 signal_analog/errors.py
--rw-r--r--  2.0 unx     4339 b- defN 19-Jun-19 15:17 signal_analog/eventoverlays.py
--rw-r--r--  2.0 unx    13217 b- defN 19-May-10 11:44 signal_analog/filters.py
--rw-r--r--  2.0 unx    62782 b- defN 19-Nov-12 08:47 signal_analog/flow.py
--rw-r--r--  2.0 unx      454 b- defN 18-Jun-04 13:15 signal_analog/logging.yaml
--rw-r--r--  2.0 unx    14463 b- defN 19-Oct-30 14:56 signal_analog/resources.py
--rw-r--r--  2.0 unx     3156 b- defN 18-Oct-30 10:14 signal_analog/util.py
--rw-r--r--  2.0 unx      803 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/__init__.cpython-37.pyc
--rw-r--r--  2.0 unx    30763 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/charts.cpython-37.pyc
--rw-r--r--  2.0 unx     3659 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/cli.cpython-37.pyc
--rw-r--r--  2.0 unx     5427 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/combinators.cpython-37.pyc
--rw-r--r--  2.0 unx    18543 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/dashboards.cpython-37.pyc
--rw-r--r--  2.0 unx    23371 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/detectors.cpython-37.pyc
--rw-r--r--  2.0 unx     2920 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/errors.cpython-37.pyc
--rw-r--r--  2.0 unx     5020 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/eventoverlays.cpython-37.pyc
--rw-r--r--  2.0 unx    10924 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/filters.cpython-37.pyc
--rw-r--r--  2.0 unx    69951 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/flow.cpython-37.pyc
--rw-r--r--  2.0 unx    13305 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/resources.cpython-37.pyc
--rw-r--r--  2.0 unx     3899 b- defN 19-Nov-12 08:48 signal_analog/__pycache__/util.cpython-37.pyc
--rw-r--r--  2.0 unx        0 b- defN 19-Oct-30 14:56 signal_analog/error/__init__.py
--rw-r--r--  2.0 unx      932 b- defN 19-Oct-30 14:56 signal_analog/error/signalfx.py
--rw-r--r--  2.0 unx      154 b- defN 19-Nov-12 08:48 signal_analog/error/__pycache__/__init__.cpython-37.pyc
--rw-r--r--  2.0 unx     1503 b- defN 19-Nov-12 08:48 signal_analog/error/__pycache__/signalfx.cpython-37.pyc
-35 files, 423294 bytes uncompressed, 112419 bytes compressed:  73.4%
+Zip file size: 57872 bytes, number of entries: 20
+-rw-r--r--  2.0 unx      672 b- defN 20-Mar-26 19:12 signal_analog/__init__.py
+-rw-r--r--  2.0 unx    28726 b- defN 20-Mar-26 19:05 signal_analog/charts.py
+-rw-r--r--  2.0 unx     3368 b- defN 18-Sep-10 22:01 signal_analog/cli.py
+-rw-r--r--  2.0 unx     3265 b- defN 18-Sep-10 22:01 signal_analog/combinators.py
+-rw-r--r--  2.0 unx    26413 b- defN 20-Mar-26 19:05 signal_analog/dashboards.py
+-rw-r--r--  2.0 unx    21137 b- defN 20-Mar-26 19:05 signal_analog/detectors.py
+-rw-r--r--  2.0 unx     2069 b- defN 18-Sep-10 22:01 signal_analog/errors.py
+-rw-r--r--  2.0 unx     4339 b- defN 18-Sep-10 22:01 signal_analog/eventoverlays.py
+-rw-r--r--  2.0 unx    13217 b- defN 19-Apr-22 17:29 signal_analog/filters.py
+-rw-r--r--  2.0 unx    63596 b- defN 20-Mar-26 19:05 signal_analog/flow.py
+-rw-r--r--  2.0 unx      454 b- defN 18-Mar-26 21:30 signal_analog/logging.yaml
+-rw-r--r--  2.0 unx    14463 b- defN 20-Mar-26 19:05 signal_analog/resources.py
+-rw-r--r--  2.0 unx     3156 b- defN 18-Sep-10 22:01 signal_analog/util.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Mar-26 19:05 signal_analog/error/__init__.py
+-rw-r--r--  2.0 unx      932 b- defN 20-Mar-26 19:05 signal_analog/error/signalfx.py
+-rw-r--r--  2.0 unx     1517 b- defN 20-Mar-26 19:49 signal_analog-2.9.3.dist-info/LICENSE
+-rw-r--r--  2.0 unx    38141 b- defN 20-Mar-26 19:49 signal_analog-2.9.3.dist-info/METADATA
+-rw-r--r--  2.0 unx      110 b- defN 20-Mar-26 19:49 signal_analog-2.9.3.dist-info/WHEEL
+-rw-r--r--  2.0 unx       14 b- defN 20-Mar-26 19:49 signal_analog-2.9.3.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     1655 b- defN 20-Mar-26 19:49 signal_analog-2.9.3.dist-info/RECORD
+20 files, 227244 bytes uncompressed, 55188 bytes compressed:  75.7%
```

## zipnote «TEMP»/diffoscope_68artau3_/tmp488hh_01_.zip

```diff
@@ -1,25 +1,7 @@
-Filename: EGG-INFO/PKG-INFO
-Comment: 
-
-Filename: EGG-INFO/SOURCES.txt
-Comment: 
-
-Filename: EGG-INFO/dependency_links.txt
-Comment: 
-
-Filename: EGG-INFO/not-zip-safe
-Comment: 
-
-Filename: EGG-INFO/requires.txt
-Comment: 
-
-Filename: EGG-INFO/top_level.txt
-Comment: 
-
 Filename: signal_analog/__init__.py
 Comment: 
 
 Filename: signal_analog/charts.py
 Comment: 
 
 Filename: signal_analog/cli.py
@@ -51,56 +33,29 @@
 
 Filename: signal_analog/resources.py
 Comment: 
 
 Filename: signal_analog/util.py
 Comment: 
 
-Filename: signal_analog/__pycache__/__init__.cpython-37.pyc
-Comment: 
-
-Filename: signal_analog/__pycache__/charts.cpython-37.pyc
-Comment: 
-
-Filename: signal_analog/__pycache__/cli.cpython-37.pyc
-Comment: 
-
-Filename: signal_analog/__pycache__/combinators.cpython-37.pyc
-Comment: 
-
-Filename: signal_analog/__pycache__/dashboards.cpython-37.pyc
-Comment: 
-
-Filename: signal_analog/__pycache__/detectors.cpython-37.pyc
-Comment: 
-
-Filename: signal_analog/__pycache__/errors.cpython-37.pyc
-Comment: 
-
-Filename: signal_analog/__pycache__/eventoverlays.cpython-37.pyc
-Comment: 
-
-Filename: signal_analog/__pycache__/filters.cpython-37.pyc
-Comment: 
-
-Filename: signal_analog/__pycache__/flow.cpython-37.pyc
+Filename: signal_analog/error/__init__.py
 Comment: 
 
-Filename: signal_analog/__pycache__/resources.cpython-37.pyc
+Filename: signal_analog/error/signalfx.py
 Comment: 
 
-Filename: signal_analog/__pycache__/util.cpython-37.pyc
+Filename: signal_analog-2.9.3.dist-info/LICENSE
 Comment: 
 
-Filename: signal_analog/error/__init__.py
+Filename: signal_analog-2.9.3.dist-info/METADATA
 Comment: 
 
-Filename: signal_analog/error/signalfx.py
+Filename: signal_analog-2.9.3.dist-info/WHEEL
 Comment: 
 
-Filename: signal_analog/error/__pycache__/__init__.cpython-37.pyc
+Filename: signal_analog-2.9.3.dist-info/top_level.txt
 Comment: 
 
-Filename: signal_analog/error/__pycache__/signalfx.cpython-37.pyc
+Filename: signal_analog-2.9.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## signal_analog/__init__.py

```diff
@@ -5,15 +5,15 @@
 import logging.config
 import pkg_resources
 import yaml
 import os
 
 __author__ = """Fernando Freire"""
 __email__ = 'Lst-nike.plus.platform.sharedinfrastructure@nike.com'
-__version__ = '2.9.2'
+__version__ = '2.9.3'
 
 logging_config = pkg_resources.resource_string(
     __name__, 'logging.yaml').decode('utf-8')
 
 # Fix for yaml loader according to https://github.com/yaml/pyyaml/wiki/PyYAML-yaml.load(input)-Deprecation
 logging.config.dictConfig(yaml.load(logging_config, Loader=yaml.SafeLoader))
```

## signal_analog/dashboards.py

```diff
@@ -174,15 +174,18 @@
             dry_run: Boolean to test a dry run
 
         See: https://developers.signalfx.com/dashboard_groups_reference.html#tag/Update-Single-Dashboard-Group
         """
 
         if 'id' in self.options or resource_id:
             dashboard_group = super(DashboardGroup, self).read(resource_id=resource_id)
+            # Preserving the teams configuration since the options gets overwritten when the dashboards are updated.
+            teams = self.options['teams']
             self.options = self.__update_dashboard_resources__(dashboard_group)
+            self.options['teams'] = teams
             return super(DashboardGroup, self).update(name=name, description=description, resource_id=resource_id)
         else:
             query_result = self.__find_existing_resources__()
 
             try:
                 self.__find_existing_match__(query_result)
 
@@ -190,15 +193,15 @@
                 self.options = self.__update_dashboard_resources__(self.__filter_matches__(query_result))
 
                 if dry_run:
                     click.echo(
                         "Updates the Dashboard Group named: \"{0}\". If it doesn't exist, will create a new one.  "
                         "API call being executed: \n"
                         "PUT {1} \nRequest Body: \n {2}".format(self.options['name'], (
-                                self.base_url + self.endpoint + '/' + self.options['id']), self.options))
+                            self.base_url + self.endpoint + '/' + self.options['id']), self.options))
                     return None
 
                 return super(DashboardGroup, self)\
                     .update(name=name, description=description, resource_id=resource_id, info_only=True)
 
             except ResourceMatchNotFoundError:
                 return self.create(dry_run=dry_run)
@@ -493,15 +496,15 @@
                 # Our implementation makes it exceptionally inconvenient to special
                 # case delete behavior. Let's check back in a bit to see what
                 # API changes SignalFx makes.
                 if dry_run:
                     click.echo("Updates the Dashboard named: \"{0}\". If it doesn't exist, will create a new one.  "
                                "API call being executed: \n"
                                "PUT {1} \nRequest Body: \n {2}".format(self.options['name'], (
-                                self.base_url + self.endpoint + '/' + dashboard['id']), dashboard))
+                                   self.base_url + self.endpoint + '/' + dashboard['id']), dashboard))
                     return None
 
                 try:
                     return self.__action__('put', '/dashboard/' + dashboard['id'], lambda x: dashboard)
                 except RuntimeError:
                     msg = """
 WARNING: signal_analog has caught a potentially fatal runtime error when
```

## signal_analog/flow.py

```diff
@@ -94,16 +94,16 @@
         """Type check the provided statement.
 
         Arguments:
             stmt: the statement to validate
         """
         if not stmt or (not issubclass(stmt.__class__, Function) and not issubclass(stmt.__class__, Plot)):
             msg = "Attempted to build a program with something other than " +\
-                   "SignalFlow statements. Received '{0}' but expected a " +\
-                   "{1} or {2}"
+                "SignalFlow statements. Received '{0}' but expected a " +\
+                "{1} or {2}"
             raise ValueError(msg.format(
                 stmt.__class__.__name__, Function.__name__, Plot.__name__))
 
     def add_statements(self, *statements):
         """Add a statement to this program.
 
         Arguments:
@@ -1675,7 +1675,26 @@
 
     def __init__(self, aliases=None, renames=None):
         super(Dimensions, self).__init__("dimensions")
         if not aliases and not renames:
             raise ValueError("Either aliases or renames must be defined, but not both.")
 
         self.args = [KWArg("aliases", aliases), KWArg("renames", renames)]
+
+
+class Alerts(Function):
+
+    def __init__(self, detector_id):
+        """The Alerts() function is used to create a stream of data generated by a detector
+           including notifications that an alert has been triggered or that an alert
+           has been turned off. Once published in a chart, it will link the chart to the
+           detector in the web UI. This code will not validate that the decector_id is valid.
+
+        Usage:  prog = Program(Data('some.metric').publish())
+                prog.statements.append(Alerts(detector_id).publish())
+
+        Arguments:
+            detector_id: String the value assigned to a Detector by SignalFx. Can be obtained in the web UI
+        """
+        super(Alerts, self).__init__("alerts")
+        self.args = [KWArg("detector_id", detector_id)]
+        print(self)
```

## Comparing `EGG-INFO/PKG-INFO` & `signal_analog-2.9.3.dist-info/METADATA`

 * *Files 15% similar despite different names*

```diff
@@ -1,1065 +1,1112 @@
 Metadata-Version: 2.1
 Name: signal-analog
-Version: 2.9.2
+Version: 2.9.3
 Summary: A troposphere-like library for managing SignalFxCharts, Dashboards, and Detectors.
 Home-page: https://github.com/Nike-inc/signal_analog
 Author: Fernando Freire
 Author-email: fernando.freire@nike.com
 License: BSD 3-Clause License
-Description: [![CircleCI](https://circleci.com/gh/Nike-Inc/signal_analog.svg?style=svg)](https://circleci.com/gh/Nike-Inc/signal_analog)
-        # signal_analog
-        
-        A [`troposphere`](https://github.com/cloudtools/troposphere)-inspired library
-        for programmatic, declarative definition and management of SignalFx Charts,
-        Dashboards, and Detectors.
-        
-        This library assumes a basic familiarity with resources in SignalFx. For a
-        good overview of the SignalFx API consult the [upstream documentation][sfxdocs].
-        
-        ## TOC
-        
-          - [Features](#features)
-          - [Installation](#installation)
-          - [Usage](#usage)
-              - [Building Charts](#building-charts)
-              - [Building Dashboards](#building-dashboards)
-              - [Updating Dashboards](#updating-dashboards)
-              - [Dashboard Filters](#providing-dashboard-filters)
-              - [Dashboard Event Overlays](#dashboard-event-overlays-and-selected-event-overlays)
-              - [Creating Detectors](#creating-detectors)
-                  - [Detectors That Combine Data Streams](#detectors-that-combine-data-streams)
-                  - [Building Detectors from Existing Charts](#building-detectors-from-existing-charts)
-              - [Using Flow and Combinator Functions In Formulas](#using-flow-and-combinator-functions-in-formulas)
-              - [Building Dashboard Groups](#building-dashboard-groups)
-              - [Updating Dashboard Group](#updating-dashboard-groups)
-              - [Talking to the SignalFlow API Directly](#talking-to-the-signalflow-api-directly)
-              - [General `Resource` Guidelines](#general-resource-guidelines)
-              - [Creating a CLI for your resources](#creating-a-cli-for-your-resources)
-          - [Documentation](#documentation)
-          - [Example Code](#example-code)
-          - [Contributing](#contributing)
-        
-        ## Features
-        
-          - Provides bindings for the SignalFlow DSL
-          - Provides abstractions for:
-              - Charts
-              - Dashboards, DashboardGroups
-              - Detectors
-          - A CLI builder to wrap resource definitions (useful for automation)
-        
-        ## Installation
-        
-        Add `signal_analog` to the requirements file in your project:
-        
-        ```
-        # requirements.txt
-        # ... your other dependencies
-        signal_analog
-        ```
-        
-        Then run the following command to update your environment:
-        
-        ```
-        pip install -r requirements.txt
-        ```
-        
-        ## Usage
-        
-        `signal_analog` provides two kinds of abstractions, one for building resources
-        in the SignalFx API and the other for describing metric timeseries through the
-        [Signal Flow DSL][signalflow].
-        
-        The following sections describe how to use `Resource` abstractions in
-        conjunction with the [Signal Flow DSL][signalflow].
-        
-        ### Building Charts
-        
-        `signal_analog` provides constructs for building charts in the
-        `signal_analog.charts` module.
-        
-        Consult the [upstream documentation][charts] for more information Charts.
-        
-        Let's consider an example where we would like to build a chart to monitor
-        memory utilization for a single applicaton in a single environment.
-        
-        This assumes a service reports metrics for application name as `app` and
-        environment as `env` with memory utilization reporting via the
-        `memory.utilization` metric name.
-        
-        In a timeseries chart, all data displayed on the screen comes from at least one
-        `data` definition in the SignalFlow language. Let's begin by defining our
-        timeseries:
-        
-        ```python
-        from signal_analog.flow import Data
-        
-        ts = Data('memory.utilization')
-        ```
-        
-        In SignalFlow parlance a timeseries is only displayed on a chart if it has been
-        "published". All stream functions in SignalFlow have a `publish` method that
-        may be called at the _end_ of all timeseries transformations.
-        
-        ```python
-        ts = Data('memory.utilization').publish()
-        ```
-        
-        As a convenience, all transformations on stream functions return the callee,
-        so in the above example `ts` remains bound to an instance of `Data`.
-        
-        Now, this timeseries isn't very useful by itself; if we attached this program
-        to a chart we would see _all_ timeseries for _all_ [Riposte] applications
-        reporting to SignalFx!
-        
-        We can restrict our view of the data by adding a filter on application name:
-        
-        ```python
-        from signal_analog.flow import Data, Filter
-        
-        app_filter = Filter('app', 'foo')
-        
-        ts = Data('memory.utilization', filter=app_filter).publish()
-        ```
-        
-        Now if we created a chart with this program we would only be looking at metrics
-        that relate to the `foo` application. Much better, but we're still
-        looking at instance of `foo` _regardless_ of the environment it
-        lives in.
-        
-        What we'll want to do is combine our `app_filter` with another filter for the
-        environment. The `signal_analog.combinators` module provides some helpful
-        constructs for achieving this goal:
-        
-        ```python
-        from signal_analog.combinators import And
-        
-        env_filter = Filter('env', 'prod')
-        
-        all_filters = And(app_filter, env_filter)
-        
-        ts = Data('memory.utilization', filter=all_filters).publish()
-        ```
-        
-        Excellent! We're now ready to create our chart.
-        
-        First, let's give our chart a name:
-        
-        ```python
-        from signal_analog.charts import TimeSeriesChart
-        
-        memory_chart = TimeSeriesChart().with_name('Memory Used %')
-        ```
-        
-        Like it's `flow` counterparts, `charts` adhere to the builder pattern for
-        constructing objects that interact with the SignalFx API.
-        
-        With our name in place, let's go ahead and add our program:
-        
-        ```python
-        memory_chart = TimeSeriesChart().with_name('Memory Used %').with_program(ts)
-        ```
-        
-        Each Chart understands how to serialize our SignalFlow programs appropriately,
-        so it is sufficient to simply pass in our reference here.
-        
-        Finally, let's change the plot type on our chart so that we see solid areas
-        instead of flimsy lines:
-        
-        ```python
-        from signal_analog.charts import PlotType
-        
-        memory_chart = TimeSeriesChart()\
-                         .with_name('Memory Used %')\
-                         .with_program(ts)
-                         .with_default_plot_type(PlotType.area_chart)
-        ```
-        
-        [Terrific]; there's only a few more details before we have a complete chart.
-        
-        In the following sections we'll see how we can create dashboards from
-        collections of charts.
-        
-        ### Building Dashboards
-        
-        `signal_analog` provides constructs for building charts in the
-        `signal_analog.dashboards` module.
-        
-        Consult the [upstream documentation][dashboards] for more information on the
-        Dashboard API.
-        
-        Building on the examples described in the previous section, we'd now like to
-        build a dashboard containing our memory chart.
-        
-        We start with the humble `Dashboard` object:
-        
-        ```python
-        from signal_analog.dashboards import Dashboard
-        
-        dash = Dashboard()
-        ```
-        
-        Many of the same methods for charts are available on dashboards as well, so
-        let's give our dashboard a memorable name and configure it's API token:
-        
-        ```python
-        dash.with_name('My Little Dashboard: Metrics are Magic')\
-            .with_api_token('my-api-token')
-        ```
-        
-        Our final task will be to add charts to our dashboard and create it in the API!
-        
-        ```python
-        response = dash\
-          .with_charts(memory_chart)\
-          .with_api_token('my-api-token')\
-          .create()
-        ```
-        
-        At this point one of two things will happen:
-        
-          - We receive some sort of error from the SignalFx API and an exception
-          is thrown
-          - We successfully created the dashboard, in which case the JSON response is
-          returned as a dictionary.
-        
-        Also, if you have an existing Dashboard Group and you want this new dashboard to be part of that dashboard group, you
-         can pass that group id of the dashboard group when creating the dashboard. Something like this:
-        
-        ```python
-        response = dash\
-          .with_charts(memory_chart)\
-          .with_api_token('my-api-token')\
-          .create(group_id="asdf;lkj")
-        ``` 
-         
-        Now, storing API keys in source isn't ideal, so if you'd like to see how you
-        can pass in your API keys at runtime check the documentation below to see how
-        you can [dynamically build a CLI for your resources](#cli-builder).
-        
-        ### Updating Dashboards
-        Once you have created a dashboard you can update properties like name and
-        description:
-        
-        ```python
-        dash.update(
-            name='updated_dashboard_name',
-            description='updated_dashboard_description'
-        )
-        ```
-        
-        `Dashboard` updates will also update any `Chart` configurations it owns.
-        
-            Note: If the given dashboard does not already exist, `update` will create a new dashboard for you
-        
-        ### Providing Dashboard Filters
-        
-        Dashboards can be configured to provide various filters that affect the behavior of all configured charts (overriding any conflicting filters at the chart level). You may wish to do this in order to quickly change the environment that you're observing for a given set of charts.
-        
-        
-        ```python
-        from signal_analog.filters import DashboardFilters, FilterVariable, FilterSource, FilterTime
-        app_var = FilterVariable().with_alias('app')\
-        .with_property('app')\
-        .with_is_required(True)\
-        .with_value('foo')
-        
-        env_var = FilterVariable().with_alias('env')\
-        .with_property('env')\
-        .with_is_required(True)\
-        .with_value('prod')
-        
-        aws_src = FilterSource().with_property("aws_region").with_value('us-west-2')
-        
-        time = FilterTime().with_start("-1h").with_end("Now")
-        
-        app_filter = DashboardFilters() \
-        .with_variables(app_var, env_var) \ 
-        .with_sources(aws_src) \
-        .with_time(time)
-        ```
-        So, here we are creating a few filters "app=foo" and "env=prod", 
-        a source filter "aws_region=us-west-2" and
-        a time filter "-1h till Now"
-        Now we can pass this config to a dashboard object:
-        
-        ```python
-        response = dash\
-        .with_charts(memory_chart)\
-        .with_api_token('my-api-token')\
-        .with_filters(app_filter)\
-        .create()
-        ```
-        
-        If you are updating an existing dashboard:
-        
-        ```python
-        response = dash\
-        .with_filters(app_filter)\
-        .update()
-        ```
-        
-        ### Dashboard Event Overlays and Selected Event Overlays
-        
-        To view events overlayed on your charts within a dashboard requires an event to be viewed, a chart with showEventLines
-        enabled, and a dashboard with the correct eventOverlays settings (and selectedEventOverlays to show events by default).
-        
-        Assuming that the events you would like to see exist; you would make a chart with showEventLines like so:
-        
-        ```python
-        from signal_analog.flow import Data
-        from signal_analog.charts import TimeSeriesChart
-        program = Data('cpu.utilization').publish()
-        chart = TimeSeriesChart().with_name('Chart With Event Overlays')\
-            .with_program(program).show_event_lines(True)
-        ```
-        With our chart defined, we are ready to prepare our event overlays and selected event overlays for the dashboard.
-        First we define the event signals we would like to match. In this case, we will look for an event named "test" (include
-         leading and/or trailing asterisks as wildcards if you need partial matching).
-        Next we use those event signals to create our eventOverlays, making sure to include a color index for our event's symbol,
-        and setting event line to True.
-        We also pass our event signals along to the selectedEventOverlays, which will tell the dashboard to display matching
-        events by default.
-        
-        ```python
-        from signal_analog.eventoverlays import EventSignals, EventOverlays, SelectedEventOverlays
-        events = EventSignals().with_event_search_text("*test*")\
-            .with_event_type("eventTimeSeries")
-        
-        eventoverlay = EventOverlays().with_event_signals(events)\
-            .with_event_color_index(1)\
-            .with_event_line(True)
-        
-        selectedeventoverlay = SelectedEventOverlays()\
-            .with_event_signals(events)
-        ```
-        
-        Next we combine our chart, our event overlay, and our selected event overlay into a dashboard object:
-        
-        ```python
-        from signal_analog.dashboards import Dashboard
-        dashboard_with_event_overlays = Dashboard().with_name('Dashboard With Overlays')\
-            .with_charts(chart)\
-            .with_event_overlay(eventoverlay)\
-            .with_selected_event_overlay(selectedeventoverlay)
-        ```
-        
-        Finally we build our resources in SignalFX with the cli builder:
-        
-        ```python
-        if __name__ == '__main__':
-            from signal_analog.cli import CliBuilder
-            cli = CliBuilder().with_resources(dashboard_with_event_overlays)\
-                .build()
-            cli()
-        ```
-        
-        ### Creating Detectors
-        
-        `signal_analog` provides a means of managing the lifecycle of `Detectors` in
-        the `signal_analog.detectors` module. As of `v0.21.0` only a subset of
-        the full Detector API is supported.
-        
-        Consult the [upstream documentation][detectors] for more information about
-        Detectors.
-        
-        Detectors are comprised of a few key elements:
-        
-          - A name
-          - A SignalFlow Program
-          - A set of rules for alerting
-        
-        We start by building a `Detector` object and giving it a name:
-        
-        ```python
-        from signal_analog.detectors import Detector
-        
-        detector = Detector().with_name('My Super Serious Detector')
-        ```
-        
-        We'll now need to give it a program to alert on:
-        
-        ```python
-        from signal_analog.flow import Program, Detect, Filter, Data
-        from signal_analog.combinators import GT
-        
-        # This program fires an alert if memory utilization is above 90% for the
-        # 'bar' application.
-        data = Data('memory.utilization', filter=Filter('app', 'bar')).publish(label='A')
-        alert_label = 'Memory Utilization Above 90'
-        detect = Detect(GT(data, 90)).publish(label=alert_label)
-        
-        detector.with_program(Program(detect))
-        ```
-        
-        With our name and program in hand, it's time to build up an alert rule that we
-        can use to notify our teammates:
-        
-        ```python
-        # We provide a number of notification strategies in the detectors module.
-        from signal_analog.detectors import EmailNotification, Rule, Severity
-        
-        info_rule = Rule()\
-          # From our detector defined above.
-          .for_label(alert_label)\
-          .with_severity(Severity.Info)\
-          .with_notifications(EmailNotification('me@example.com'))
-        
-        detector.with_rules(info_rule)
-        
-        # We can now create this resource in SignalFx:
-        detector.with_api_token('foo').create()
-        # For a more robust solution consult the "Creating a CLI for your Resources"
-        # section below.
-        ```
-        
-        To add multiple alerting rules we would need to use different `detect`
-        statements with distinct `label`s to differentiate them from one another.
-        
-        #### Detectors that Combine Data Streams
-        
-        More complex detectors, like those created as a function of two other data
-        streams, require a more complex setup including data stream assignments.
-        If we wanted to create a detector that watched for an average above a certain
-        threshold, we may want to use the quotient of the sum() of the data and the
-        count() of the datapoints over a given period of time.
-        
-        ```python
-        from signal_analog.flow import \
-            Assign, \
-            Data, \
-            Detect, \
-            Ref, \
-            When
-        
-        from signal_analog.combinators import \
-            Div, \
-            GT
-        
-        program = Program( \
-            Assign('my_var', Data('cpu.utilization')) \
-            Assign('my_other_var', Data('cpu.utilization').count()) \
-            Assign('mean', Div(Ref('my_var'), Ref('my_other_var'))) \
-            Detect(When(GT(Ref('mean'), 2000))) \
-        )
-        
-        print(program)
-        ```
-        
-        The above code generates the following program:
-        
-        ```
-        my_var = data('cpu.utilization')
-        my_other_var = data('cpu.utilization').count()
-        mean = (my_var / my_other_var)
-        
-        when(detect(mean > 2000))
-        ```
-        
-        #### Building Detectors from Existing Charts
-        
-        We can also build up Detectors from an existing chart, which allows us to reuse
-        our SignalFlow program and ensure consistency between what we're monitoring
-        and what we're alerting on.
-        
-        Let's assume that we already have a chart defined for our use:
-        
-        ```python
-        from signal_analog.flow import Program, Data
-        from signal_analog.charts import TimeSeriesChart
-        
-        program = Program(Data('cpu.utilization').publish(label='A'))
-        cpu_chart = TimeSeriesChart().with_name('Disk Utilization').with_program(program)
-        ```
-        
-        In order to alert on this chart we'll use the `from_chart`  builder for
-        detectors:
-        
-        ```python
-        from signal_analog.combinators import GT
-        from signal_analog.detectors import Detector
-        from signal_analog.flow import Detect
-        
-        # Alert when CPU utilization rises above 95%
-        detector = Detector()\
-            .with_name('CPU Detector')\
-            .from_chart(
-                cpu_chart,
-                # `p` is the Program object from the cpu_chart we passed in.
-                lambda p: Detect(GT(p.find_label('A'), 95).publish(label='Info Alert'))
-            )
-        ```
-        
-        The above example won't actually alert on anything until we add a `Rule`, which
-        you can find examples for in the previous section.
-        
-        ### Using Flow and Combinator Functions In Formulas
-        
-        `signal_analog` also provides functions for combining SignalFlow statements
-        into more complex SignalFlow Formulas. These sorts of Formulas can be useful
-        when creating more complex detectors and charts. For instance, if you would like
-        to multiply one data stream by another and receive the sum of that Formula,
-        it can be accomplished using Op and Mul like so:
-        
-        ```python
-        from signal_analog.flow import Op, Program, Data
-        from signal_analog.combinators import Mul
-        
-        # Multiply stream A by stream B and sum the result
-            A = Data('request.mean')
-        
-            B = Data('request.count')
-        
-            C = Op(Mul(A,B)).sum()
-        ```
-        
-        Print(C) in the above example would produce the following output:
-        
-        ```
-        (data("request.mean") * data("request.count")).sum()
-        ```
-        
-        ### Building Dashboard Groups
-        
-        `signal_analog` provides abstractions for building dashboard groups in the
-        `signal_analog.dashboards` module.
-        
-        Consult the [upstream documentation][dashboard-groups] for more information on
-        the Dashboard Groups API.
-        
-        Building on the examples described in the previous section, we'd now like to
-        build a dashboard group containing our dashboards.
-        
-        First, lets build a couple of Dashboard objects similar to how we did it in
-        the `Building Dashboards` example:
-        
-        ```python
-        from signal_analog.dashboards import Dashboard, DashboardGroup
-        
-        dg = DashboardGroup()
-        dash1 = Dashboard().with_name('My Little Dashboard1: Metrics are Magic')\
-            .with_charts(memory_chart)
-        dash2 = Dashboard().with_name('My Little Dashboard2: Metrics are Magic')\
-            .with_charts(memory_chart)
-        ```
-        **Note: we do not create Dashboard objects ourselves, the DashboardGroup object
-        is responsible for creating all child resources.**
-        
-        Many of the same methods for dashboards are available on dashboard groups as
-        well, so let's give our dashboard group a memorable name and configure it's
-        API token:
-        
-        ```python
-        
-        dg.with_name('My Dashboard Group')\
-            .with_api_token('my-api-token')
-        ```
-        
-        Our final task will be to add dashboard to our dashboard group and create it
-        in the API!
-        
-        ```python
-        response = dg\
-            .with_dashboards(dash1)\
-            .with_api_token('my-api-token')\
-            .create()
-        ```
-        
-        Now, storing API keys in source isn't ideal, so if you'd like to see how you
-        can pass in your API keys at runtime check the documentation below to see how
-        you can [dynamically build a CLI for your resources](#cli-builder).
-        
-        ### Updating Dashboard Groups
-        
-        Once you have created a dashboard group, you can update properties like name
-        and description of a dashboard group or add/remove dashboards in a group.
-        
-        *Example 1:*
-        
-        ```python
-        dg.with_api_token('my-api-token')\
-            .update(name='updated_dashboard_group_name',
-                    description='updated_dashboard_group_description')
-        ```
-        
-        *Example 2:*
-        
-        ```python
-        dg.with_api_token('my-api-token').with_dashboards(dash1, dash2).update()
-        ```
-        
-        ### Talking to the SignalFlow API Directly
-        
-        If you need to process SignalFx data outside the confince of the API it may be
-        useful to call the SignalFlow API directly. Note that you may incur time
-        penalties when pulling data out depending on the source of the data
-        (e.g. AWS/CloudWatch).
-        
-        SignalFlow constructs are contained in the `flow` module. The following is an
-        example SignalFlow program that monitors an API services (like [Riposte])
-        RPS metrics for the `foo` application in the `test` environment.
-        
-        ```python
-        from signal_analog.flow import Data, Filter
-        from signal_analog.combinators import And
-        
-        all_filters = And(Filter('env', 'prod'), Filter('app', 'foo'))
-        
-        program = Data('requests.count', filter=all_filters)).publish()
-        ```
-        
-        You now have an object representation of the SignalFlow program. To take it for
-        a test ride you can use the official SignalFx client like so:
-        
-        ```python
-        # Original example found here:
-        # https://github.com/signalfx/signalfx-python#executing-signalflow-computations
-        
-        import signalfx
-        from signal_analog.flow import Data, Filter
-        from signal_analog.combinators import And
-        
-        app_filter = Filter('app', 'foo')
-        env_filter = Filter('env', 'prod')
-        program = Data('requests.count', filter=And(app_filter, env_filter)).publish()
-        
-        with signalfx.SignalFx().signalflow('MY_TOKEN') as flow:
-            print('Executing {0} ...'.format(program))
-            computation = flow.execute(str(program))
-        
-            for msg in computation.stream():
-                if isinstance(msg, signalfx.signalflow.messages.DataMessage):
-                    print('{0}: {1}'.format(msg.logical_timestamp_ms, msg.data))
-                if isinstance(msg, signalfx.signalflow.messages.EventMessage):
-                    print('{0}: {1}'.format(msg.timestamp_ms, msg.properties))
-        ```
-        
-        ### General `Resource` Guidelines
-        
-        #### Charts Always Belong to Dashboards
-        
-        It is always assumed that a Chart belongs to an existing Dashboard. This makes
-        it easier for the library to manage the state of the world.
-        
-        #### Resource Names are Unique per Account
-        
-        In a `signal_analog` world it is assumed that all resource names are unique.
-        That is, if we have two dashboards 'Foo Dashboard', when we attempt to update
-        _either_ dashboard via `signal_analog` we expect to see errors.
-        
-        Resource names are assumed to be unique in order to simplify state management
-        by the library itself. In practice we have not found this to be a major
-        inconvenience.
-        
-        #### Configuration is the Source of Truth
-        
-        When conflicts arise between the state of a resource in your configuration and
-        what SignalFx thinks that state should be, this library **always** prefers the
-        local configuration.
-        
-        #### Only "CCRUD" Methods Interact with the SignalFx API
-        
-        `Resource` objects contain a number of builder methods to enable a "fluent" API
-        when describing your project's dashboards in SignalFx. It is assumed that these
-        methods do not perform state-affecting actions in the SignalFx API.
-        
-        Only "CCRUD" (Create, Clone, Read, Update, and Delete) methods will affect the
-        state of your resources in SignalFx.
-        
-        ### Creating a CLI for your Resources
-        
-        `signal_analog` provides builders for fully featured command line clients that
-        can manage the lifecycle of sets of resources.
-        
-        #### Simple CLI integration
-        
-        Integrating with the CLI is as simple as importing the builder and passing
-        it your resources. Let's consider an example where we want to update two
-        existing dashboards:
-        
-        ```python
-        #!/usr/bin/env python
-        
-        # ^ It's always good to include a "hashbang" so that your terminal knows
-        # how to run your script.
-        
-        from signal_analog.dashboards import Dashboard
-        from signal_analog.cli import CliBuilder
-        
-        ingest_dashboard = Dashboard().with_name('my-ingest-service')
-        service_dashboard = Dashboard().with_name('my-service')
-        
-        if __name__ == '__main__':
-          cli = CliBuilder()\
-              .with_resources(ingest_dashboard, service_dashboard)\
-              .build()
-          cli()
-        ```
-        
-        Assuming we called this `dashboards.py` we could run it in one of two ways:
-        
-          - Give the script execution rights and run it directly
-          (typically `chmod +x dashboards.py`)
-              - `./dashboards.py --api-key mykey update`
-          - Pass the script in to the Python executor
-              - `python dashboards.py --api-key mykey update`
-        
-        If you want to know about the available actions you can take with your new
-        CLI you can always the `--help` command.
-        
-        ```shell
-        ./dashboards.py --help
-        ```
-        
-        This gives you the following features:
-          - Consistent resource management
-              - All resources passed to the CLI builder can be updated with one
-              `update` invocation, rather than calling the `update()` method on each
-              resource indvidually
-          - API key handling for all resources
-              - Rather than duplicating your API key for each resource, you can instead
-              invoke the CLI with an API key
-              - This also provides a way to supply keys for users who don't want to
-              store them in source control (that's you! don't store your keys in
-              source control)
-        
-        ## Documentation
-        
-        - [Signal Analog Documentation](https://signal-analog.readthedocs.io/)
-        - [Introductory Article on Medium](https://medium.com/nikeengineering/introducing-signal-analog-the-troposphere-like-library-for-automating-monitoring-resources-c99eb8c2dca7)
-        
-        ## Example Code
-        
-        - See [examples](https://github.com/Nike-Inc/signal_analog/tree/master/examples) included in this project.
-        
-        ## Contributing
-        
-        Please read our [docs here for more info about contributing](CONTRIBUTING.md).
-        
-        [sfxdocs]: https://developers.signalfx.com/
-        [signalflow]: https://developers.signalfx.com/signalflow_analytics/signalflow_overview.html
-        [charts]: https://developers.signalfx.com/charts_reference.html
-        [terrific]: https://media.giphy.com/media/jir4LEGA68A9y/200.gif
-        [dashboards]: https://developers.signalfx.com/dashboards_reference.html
-        [dashboard-groups]: https://developers.signalfx.com/dashboard_groups_reference.html
-        [detectors]: https://developers.signalfx.com/detectors_reference.html
-        [Riposte]: https://github.com/Nike-inc/riposte
-        
-        
-        ## 2.9.2 (2019-11-11)
-        
-        * `StrArg` will only reject `None` instead of all falsey values, allowing `0` to be given as a value.
-        
-        ## 2.9.1 (2019-10-30)
-        
-        * Resources have learned that deleting nothing results in nothing, and will
-        stop complaining about this scenario (it will still register it's displeasure
-        in a debug log message)
-        
-        ## 2.9.0 (2019-09-26)
-        
-        * Added `BigPandaNotification` for BigPanda integration within detectors.
-        
-        ## 2.8.0 (2019-09-06)
-        
-        * Added `groupBy` support to the chart options. Allows grouping for example of HeatMap charts into groups on multiple levels.
-        * Added support for `colorScale2` option on HeatMap charts. This allows to set custom chart colors for a defined range of values.
-        
-        ## 2.7.2 (2019-05-14)
-        
-        ### Fixed
-        
-          - `signal_analog` has learned to use the `groupId` field when updating
-          Dashboard resources after the recent Sfx API changes
-        
-        ### Updated
-        
-          - As many documentation links as possible since the last doc update from Sfx.
-          Notable missing updates are those for 3rd party integration Notifications in
-          the `signal_analog.detectors` module.
-        
-        ## 2.7.0 (2019-04-03)
-        
-        ### Updated
-          * Removed dashboard numbering for two reasons:
-            1. There was a bug in the logic that caused dashboards to be deleted and recreated on update.
-            1. The functionality is no longer needed as SignalFx automatically maintains the order that dashboards were provided and allows easy reordering in the UI.
-          * AxisOptions are now optional where used
-        
-        ### Fixed
-        
-        * Fixing applyIfExists option for Dashboard variables.
-        
-        ## 2.6.0 (2019-03-21)
-        
-          * AxisOption parameters should be optional.
-          * Additional documentation.
-        
-        ## 2.5.0 (2019-03-20)
-        
-          * Added `Plot` class, a helper class that gives an interface more like that found in the SignalFx UI.
-          * Added `RollupType` enum for specifying the roll-up used in Charts.
-          * Added additional documentation links to README.
-          * Fix: TextCharts weren't working
-          * Fix: YAML load deprecation warning in logging config
-        
-        ## 2.4.0
-        
-          * Add numbering to dashboards in a dashboard group for better organization 
-          of dashboards
-        
-        ## 2.3.2 (2018-11-12)
-        
-          * The `percentile` function on `signal_analog.flow.Data` objects has been
-          fixed to use the correct constructor
-        
-        ## 2.3.1 (2018-11-06)
-        
-          * signal-analog now prefers `simplejson` if it is available on the path,
-          falling back to the `json` module otherwise.
-        
-        ## 2.3.0 (2018-10-30)
-        
-          * DashboardGroup has learned how to accept SignalFX Team ids so that they can
-          be associated with pre-existing teams via the `with_teams` builder method.
-        
-        ## 2.2.2 (2018-10-03)
-        
-        ### Fixed
-          * Add `deprecation` to setup.py.
-        
-        ## 2.2.1 (2018-10-02)
-        
-        ### Changed
-          * Added `with_secondary_visualization` function to enable display of various meters (Sparkline, Linear, Radial) in 
-          Single Value charts. This replaces the now defunct `with_sparkline_hidden` function. This will not be a 
-          'breaking change' until version 3.0.0 when `with_sparkline_hidden` will be removed from `signal_analog`.
-        
-          * Added the `deprecation` Python library to this project to note when `with_sparkline_hidden` should be removed. Upon 
-          version matching 3.0.0 or higher the tests for that function will begin to fail notifying whoever is releasing that 
-          version to remove the defunct `with_sparkline_hidden` function and tests.
-        
-        ## 2.2.0 (2018-09-27)
-        
-        ### Changed
-          * Dashboard Create method to accept group id of an existing dashboard group in which case the new dashboard will be
-           part of the dashboard group provided
-        
-           Example:
-        ```python
-        response = dashboard\
-          .with_charts(memory_chart)\
-          .with_api_token('my-api-token')\
-          .create(group_id="asdf;lkj")
-        ```
-          * Dashboard Group create method to pass group id of the newly created dashboard group to the dashboard create 
-          method so that we can avoid  a few redundant calls like cloning and deleting the dashboards
-        
-        ## 2.1.0 (2018-08-21)
-        
-        ### Added
-        
-          * ListCharts learned how to filter legend options via the
-          `with_legend_options` builder
-          * Future chart types that can filter legend options may now take advantage
-          of the `signal_analog.charts.LegendOptionsMixin` class
-          * The `FieldOption` class has learned to accept `SignalFxFieldOption`s which
-          provide mappings between field options seen in the UI and those used in the
-          API
-              * e.g. `Plot Name` in the UI and `sf_originatingMetric` in the API
-          * A new `TextChart` object has been added to `signal_analog.charts` that
-          enables text descriptions to be added to dashboards.
-          * `PublishLabelOptions` has learned to accept prefix, suffix, and unit
-          arguments when labelling data on charts.
-        
-        ### Changed
-        
-          * `PublishLabelOptions` has learned to accept all arguments as optional
-          with the exception of the `label` argument.
-        
-        ### Fixed
-        
-          * A fix has been added for Python 2 users that prevented successful
-          dashboard updates.
-        
-        ## 2.0.0 (2018-07-24)
-        
-        For assistance migrating from 1.x to 2.x please consult the
-        [migration guide][migration-1x].
-        
-        ### Added
-        
-          * Add support for the `dimensions`, `fill`, `integrate`, `kpss`,
-          `rateofchange` methods
-        
-        
-        ### Removed
-        
-          * `map` method support has been removed
-              * It didn't work properly to begin with, and will require some finagling
-              to get right given our approach to building SignalFlow statements
-        
-        ### Fixes
-        
-          * `top` and `bottom` method signatures have been fixed to use `count`, `by`,
-          and `percentage` arguments
-          * The following functions have been updated to raise an error if both
-          `by` and `over` are defined in the same method call:
-              * `count`, `max`, `mean`, `mean_plus_stddev`, `median`, `min`,
-              `percentile`, `random`, `size`, `stddev`, `sum`, `variance`
-          * `delta` has been updated to no longer accept any method arguments
-          * `ewma` has been updated to support the `over` key
-        
-        ## 1.6.0 (2018-07-18)
-        
-          * Add combinators for less-than-or-equal-to (`LTE`) and greater-than-or-equal-to (`GTE`)
-        
-        ## 1.5.1 (2018-06-21)
-        
-          * Fix detector update logic to include all fields instead of just name/description
-        
-        ## 1.5.0(2018-05-16)
-        
-          * Added `include_zero` method to `TimeSeriesChart` to allow setting the `includeZero` option.
-        
-        ## 1.4.0(2018-05-08)
-        
-          * Implements functionality to add event overlays and selected (default) event overlays to dashboards 
-          at dashboard creation or update. Includes wildcard matching using the asterisk (*) symbol. 
-        
-        ## 1.3.0(2018-04-17)
-        
-          * Implementing the rest of the Dashboard Filters: `source` and `time`
-        
-        ## 1.2.0 (2018-04-11)
-          * Added an Assign function that will enable more complex detectors which are constructed by combining multiple data streams
-          * Added a Ref flow operator that will enable referencing assignments in a way that can be validated at later steps by checking for an Assign object with a match between the reference string and the assignee
-        
-        ## 1.1.0 (2018-04-04)
-          * Introducing Dashboard Filters(only variables as of now) which can be configured to provide various filters that affect the behavior of all configured charts (overriding any conflicting filters at the chart level). You may wish to do this in order to quickly change the environment that you're observing for a given set of charts.
-        
-        ## 1.0.0 (2018-04-02)
-        
-          * Symbolic release for `signal_analog`. Future version bumps should conform
-          to the `semver` policy outlined [here][deployment].
-        
-        ## 0.25.1 (2018-03-22)
-        
-          * The timeshift method's arguments changed. Now accepts a single argument for offset.
-        
-        ## 0.24.0 (2018-03-09)
-        
-          * Fix string parsing to not exclude boolean False, which is required for certain functions like .publish()
-        
-        ## 0.23.0 (2018-03-06)
-        
-          * Added Op class in flow.py to allow multiplying and dividing datastreams
-          to create SignalFlow Functions
-        
-        ## 0.22.0 (2018-03-01)
-        
-          * Added Mul and Div combinators for multiplying and dividing streams
-          * Added "enable" option for publishing a stream. Setting enable=False
-            will hide that particular stream in a chart/detector.
-        
-        ## 0.21.0 (2018-02-28)
-        
-          * Dashboard Group support has been added giving you the ability group sets of
-          dashboards together in a convenient construct
-          * Detector support has been added giving you the ability to create detectors
-          from scratch or re-use the SignalFlow program of an existing Chart
-          * Dashboards and Charts now update via their `id` instead of by name to
-          mitigate name conflicts when creating multiple resources with the same name
-          * Dry-run results are now more consistent between all resources and expose
-          the API call (sans-headers) that would have been made to use for the given
-          resource
-        
-        ## 0.20.0 (2018-01-31)
-        
-          * Dashboards have learned how to update their child resources (e.g. if you
-            add a chart in your config, the change will be reflected when you next run
-            your configuration against SignalFx)
-          * The CLI builder has learned how to pass dry-run options to its configured resources
-          * Minor bugfixes for the `signal_analog.flow` module
-        
-        ## 0.19.1 (2018-01-26)
-        
-          * Added click to setup.py
-        
-        ## 0.19.0 (2018-01-19)
-        
-          * Added CLI builder to create and update dashboard resources
-        
-        ## 0.18.0 (2018-01-11)
-        
-          * Dashboard resources have learned to interactively prompt the user if the user wants to
-           create a new dashboard if there is a pre-existing match (this behavior is disabled
-              by default).
-          * Added "Update Dashboard" functionality where a user can update the properties of a dashboard(only name and description for now)
-        
-        ## 0.17.0 (2018-01-11)
-          * Added Heatmap Chart style
-             * Added by Jeremy Hicks
-        
-        ## 0.16.0 (2018-01-10)
-          * Added the ability to sort a list chart by value ascending/descending
-              * Added by Jeremy Hicks
-        
-        ## 0.15.0 (2018-01-08)
-        
-          * Added "Scale" to ColorBy class for coloring thresholds in SingleValueChart
-              * Added by Jeremy Hicks
-        
-        ## 0.14.0 (2018-01-04)
-        
-          * Added List Chart style
-              * Added by Jeremy Hicks
-        
-        ## 0.13.0 (2018-01-04)
-        
-          * Dashboard resources have learned how to force create themselves in the
-          SignalFx API regardless of a pre-existing match (this behavior is disabled
-          by default).
-        
-        ## 0.12.0 (2017-12-21)
-        
-          * Dashboard resources have learned how to check for themselves in the
-          SignalFx API, and will no longer create themselves if an exact match is found
-        
-        ## 0.3.0 (2017-09-25)
-        
-          * Adds support for base Resource object. Will be used for Chart/Dashboard
-          abstractions in future versions.
-          * Adds support for base Chart and TimeSeriesChart objects. Note that some
-          TimeSeriesChart builder options have not yet been implemented (and marked
-          clearly with NotImplementedErrors)
-        
-        ## 0.2.0 (2017-09-18)
-        
-          * Adds support for function combinators like `and`, `or`, and `not`
-        
-        ## 0.1.1 (2017-09-14)
-        
-          * Add README documentation
-        
-        ## 0.1.0 (2017-09-14)
-        
-          * Initial release
-        
-        [deployment]: https://github.com/Nike-Inc/signal_analog/wiki/Developers-::-Deployment
-        [migration-1x]: ./docs/migrating_from_1.x.md
-        
 Keywords: signal_analog signalfx dashboards charts detectors monitoring signalflow
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 2
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Developers
 Classifier: License :: OSI Approved :: BSD License
 Classifier: Natural Language :: English
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python :: 3
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Classifier: Topic :: Software Development :: Libraries
 Classifier: Topic :: Utilities
 Description-Content-Type: text/markdown
+Requires-Dist: enum34
+Requires-Dist: six
+Requires-Dist: requests
+Requires-Dist: click
+Requires-Dist: email-validator
+Requires-Dist: pyyaml
+Requires-Dist: markdown
+Requires-Dist: deprecation
+
+[![CircleCI](https://circleci.com/gh/Nike-Inc/signal_analog.svg?style=svg)](https://circleci.com/gh/Nike-Inc/signal_analog)
+# signal_analog
+
+A [`troposphere`](https://github.com/cloudtools/troposphere)-inspired library
+for programmatic, declarative definition and management of SignalFx Charts,
+Dashboards, and Detectors.
+
+This library assumes a basic familiarity with resources in SignalFx. For a
+good overview of the SignalFx API consult the [upstream documentation][sfxdocs].
+
+## TOC
+
+  - [Features](#features)
+  - [Installation](#installation)
+  - [Usage](#usage)
+      - [Building Charts](#building-charts)
+      - [Building Dashboards](#building-dashboards)
+      - [Updating Dashboards](#updating-dashboards)
+      - [Dashboard Filters](#providing-dashboard-filters)
+      - [Dashboard Event Overlays](#dashboard-event-overlays-and-selected-event-overlays)
+      - [Creating Detectors](#creating-detectors)
+          - [Detectors That Combine Data Streams](#detectors-that-combine-data-streams)
+          - [Building Detectors from Existing Charts](#building-detectors-from-existing-charts)
+      - [Using Flow and Combinator Functions In Formulas](#using-flow-and-combinator-functions-in-formulas)
+      - [Building Dashboard Groups](#building-dashboard-groups)
+      - [Updating Dashboard Group](#updating-dashboard-groups)
+      - [Talking to the SignalFlow API Directly](#talking-to-the-signalflow-api-directly)
+      - [General `Resource` Guidelines](#general-resource-guidelines)
+      - [Creating a CLI for your resources](#creating-a-cli-for-your-resources)
+  - [Documentation](#documentation)
+  - [Example Code](#example-code)
+  - [Contributing](#contributing)
+
+## Features
+
+  - Provides bindings for the SignalFlow DSL
+  - Provides abstractions for:
+      - Charts
+      - Dashboards, DashboardGroups
+      - Detectors
+  - A CLI builder to wrap resource definitions (useful for automation)
+
+## Installation
+
+Add `signal_analog` to the requirements file in your project:
+
+```
+# requirements.txt
+# ... your other dependencies
+signal_analog
+```
+
+Then run the following command to update your environment:
+
+```
+pip install -r requirements.txt
+```
+
+## Usage
+
+`signal_analog` provides two kinds of abstractions, one for building resources
+in the SignalFx API and the other for describing metric timeseries through the
+[Signal Flow DSL][signalflow].
+
+The following sections describe how to use `Resource` abstractions in
+conjunction with the [Signal Flow DSL][signalflow].
+
+### Building Charts
+
+`signal_analog` provides constructs for building charts in the
+`signal_analog.charts` module.
+
+Consult the [upstream documentation][charts] for more information Charts.
+
+Let's consider an example where we would like to build a chart to monitor
+memory utilization for a single applicaton in a single environment.
+
+This assumes a service reports metrics for application name as `app` and
+environment as `env` with memory utilization reporting via the
+`memory.utilization` metric name.
+
+In a timeseries chart, all data displayed on the screen comes from at least one
+`data` definition in the SignalFlow language. Let's begin by defining our
+timeseries:
+
+```python
+from signal_analog.flow import Data
+
+ts = Data('memory.utilization')
+```
+
+In SignalFlow parlance a timeseries is only displayed on a chart if it has been
+"published". All stream functions in SignalFlow have a `publish` method that
+may be called at the _end_ of all timeseries transformations.
+
+```python
+ts = Data('memory.utilization').publish()
+```
+
+As a convenience, all transformations on stream functions return the callee,
+so in the above example `ts` remains bound to an instance of `Data`.
+
+Now, this timeseries isn't very useful by itself; if we attached this program
+to a chart we would see _all_ timeseries for _all_ [Riposte] applications
+reporting to SignalFx!
+
+We can restrict our view of the data by adding a filter on application name:
+
+```python
+from signal_analog.flow import Data, Filter
+
+app_filter = Filter('app', 'foo')
+
+ts = Data('memory.utilization', filter=app_filter).publish()
+```
+
+Now if we created a chart with this program we would only be looking at metrics
+that relate to the `foo` application. Much better, but we're still
+looking at instance of `foo` _regardless_ of the environment it
+lives in.
+
+What we'll want to do is combine our `app_filter` with another filter for the
+environment. The `signal_analog.combinators` module provides some helpful
+constructs for achieving this goal:
+
+```python
+from signal_analog.combinators import And
+
+env_filter = Filter('env', 'prod')
+
+all_filters = And(app_filter, env_filter)
+
+ts = Data('memory.utilization', filter=all_filters).publish()
+```
+
+Excellent! We're now ready to create our chart.
+
+First, let's give our chart a name:
+
+```python
+from signal_analog.charts import TimeSeriesChart
+
+memory_chart = TimeSeriesChart().with_name('Memory Used %')
+```
+
+Like it's `flow` counterparts, `charts` adhere to the builder pattern for
+constructing objects that interact with the SignalFx API.
+
+With our name in place, let's go ahead and add our program:
+
+```python
+memory_chart = TimeSeriesChart().with_name('Memory Used %').with_program(ts)
+```
+
+Each Chart understands how to serialize our SignalFlow programs appropriately,
+so it is sufficient to simply pass in our reference here.
+
+Finally, let's change the plot type on our chart so that we see solid areas
+instead of flimsy lines:
+
+```python
+from signal_analog.charts import PlotType
+
+memory_chart = TimeSeriesChart()\
+                 .with_name('Memory Used %')\
+                 .with_program(ts)
+                 .with_default_plot_type(PlotType.area_chart)
+```
+
+[Terrific]; there's only a few more details before we have a complete chart.
+
+In the following sections we'll see how we can create dashboards from
+collections of charts.
+
+### Building Dashboards
+
+`signal_analog` provides constructs for building charts in the
+`signal_analog.dashboards` module.
+
+Consult the [upstream documentation][dashboards] for more information on the
+Dashboard API.
+
+Building on the examples described in the previous section, we'd now like to
+build a dashboard containing our memory chart.
+
+We start with the humble `Dashboard` object:
+
+```python
+from signal_analog.dashboards import Dashboard
+
+dash = Dashboard()
+```
+
+Many of the same methods for charts are available on dashboards as well, so
+let's give our dashboard a memorable name and configure it's API token:
+
+```python
+dash.with_name('My Little Dashboard: Metrics are Magic')\
+    .with_api_token('my-api-token')
+```
+
+Our final task will be to add charts to our dashboard and create it in the API!
+
+```python
+response = dash\
+  .with_charts(memory_chart)\
+  .with_api_token('my-api-token')\
+  .create()
+```
+
+At this point one of two things will happen:
+
+  - We receive some sort of error from the SignalFx API and an exception
+  is thrown
+  - We successfully created the dashboard, in which case the JSON response is
+  returned as a dictionary.
+
+Also, if you have an existing Dashboard Group and you want this new dashboard to be part of that dashboard group, you
+ can pass that group id of the dashboard group when creating the dashboard. Something like this:
+
+```python
+response = dash\
+  .with_charts(memory_chart)\
+  .with_api_token('my-api-token')\
+  .create(group_id="asdf;lkj")
+``` 
+
+Now, storing API keys in source isn't ideal, so if you'd like to see how you
+can pass in your API keys at runtime check the documentation below to see how
+you can [dynamically build a CLI for your resources](#cli-builder).
+
+### Updating Dashboards
+Once you have created a dashboard you can update properties like name and
+description:
+
+```python
+dash.update(
+    name='updated_dashboard_name',
+    description='updated_dashboard_description'
+)
+```
+
+`Dashboard` updates will also update any `Chart` configurations it owns.
+
+    Note: If the given dashboard does not already exist, `update` will create a new dashboard for you
+
+### Providing Dashboard Filters
+
+Dashboards can be configured to provide various filters that affect the behavior of all configured charts (overriding any conflicting filters at the chart level). You may wish to do this in order to quickly change the environment that you're observing for a given set of charts.
+
+
+```python
+from signal_analog.filters import DashboardFilters, FilterVariable, FilterSource, FilterTime
+app_var = FilterVariable().with_alias('app')\
+.with_property('app')\
+.with_is_required(True)\
+.with_value('foo')
+
+env_var = FilterVariable().with_alias('env')\
+.with_property('env')\
+.with_is_required(True)\
+.with_value('prod')
+
+aws_src = FilterSource().with_property("aws_region").with_value('us-west-2')
+
+time = FilterTime().with_start("-1h").with_end("Now")
+
+app_filter = DashboardFilters() \
+.with_variables(app_var, env_var) \ 
+.with_sources(aws_src) \
+.with_time(time)
+```
+So, here we are creating a few filters "app=foo" and "env=prod", 
+a source filter "aws_region=us-west-2" and
+a time filter "-1h till Now"
+Now we can pass this config to a dashboard object:
+
+```python
+response = dash\
+.with_charts(memory_chart)\
+.with_api_token('my-api-token')\
+.with_filters(app_filter)\
+.create()
+```
+
+If you are updating an existing dashboard:
+
+```python
+response = dash\
+.with_filters(app_filter)\
+.update()
+```
+
+### Dashboard Event Overlays and Selected Event Overlays
+
+To view events overlayed on your charts within a dashboard requires an event to be viewed, a chart with showEventLines
+enabled, and a dashboard with the correct eventOverlays settings (and selectedEventOverlays to show events by default).
+
+Assuming that the events you would like to see exist; you would make a chart with showEventLines like so:
+
+```python
+from signal_analog.flow import Data
+from signal_analog.charts import TimeSeriesChart
+program = Data('cpu.utilization').publish()
+chart = TimeSeriesChart().with_name('Chart With Event Overlays')\
+    .with_program(program).show_event_lines(True)
+```
+With our chart defined, we are ready to prepare our event overlays and selected event overlays for the dashboard.
+First we define the event signals we would like to match. In this case, we will look for an event named "test" (include
+ leading and/or trailing asterisks as wildcards if you need partial matching).
+Next we use those event signals to create our eventOverlays, making sure to include a color index for our event's symbol,
+and setting event line to True.
+We also pass our event signals along to the selectedEventOverlays, which will tell the dashboard to display matching
+events by default.
+
+```python
+from signal_analog.eventoverlays import EventSignals, EventOverlays, SelectedEventOverlays
+events = EventSignals().with_event_search_text("*test*")\
+    .with_event_type("eventTimeSeries")
+
+eventoverlay = EventOverlays().with_event_signals(events)\
+    .with_event_color_index(1)\
+    .with_event_line(True)
+
+selectedeventoverlay = SelectedEventOverlays()\
+    .with_event_signals(events)
+```
+
+Next we combine our chart, our event overlay, and our selected event overlay into a dashboard object:
+
+```python
+from signal_analog.dashboards import Dashboard
+dashboard_with_event_overlays = Dashboard().with_name('Dashboard With Overlays')\
+    .with_charts(chart)\
+    .with_event_overlay(eventoverlay)\
+    .with_selected_event_overlay(selectedeventoverlay)
+```
+
+Finally we build our resources in SignalFX with the cli builder:
+
+```python
+if __name__ == '__main__':
+    from signal_analog.cli import CliBuilder
+    cli = CliBuilder().with_resources(dashboard_with_event_overlays)\
+        .build()
+    cli()
+```
+
+### Creating Detectors
+
+`signal_analog` provides a means of managing the lifecycle of `Detectors` in
+the `signal_analog.detectors` module. As of `v0.21.0` only a subset of
+the full Detector API is supported.
+
+Consult the [upstream documentation][detectors] for more information about
+Detectors.
+
+Detectors are comprised of a few key elements:
+
+  - A name
+  - A SignalFlow Program
+  - A set of rules for alerting
+
+We start by building a `Detector` object and giving it a name:
+
+```python
+from signal_analog.detectors import Detector
+
+detector = Detector().with_name('My Super Serious Detector')
+```
+
+We'll now need to give it a program to alert on:
+
+```python
+from signal_analog.flow import Program, Detect, Filter, Data
+from signal_analog.combinators import GT
+
+# This program fires an alert if memory utilization is above 90% for the
+# 'bar' application.
+data = Data('memory.utilization', filter=Filter('app', 'bar')).publish(label='A')
+alert_label = 'Memory Utilization Above 90'
+detect = Detect(GT(data, 90)).publish(label=alert_label)
+
+detector.with_program(Program(detect))
+```
+
+With our name and program in hand, it's time to build up an alert rule that we
+can use to notify our teammates:
+
+```python
+# We provide a number of notification strategies in the detectors module.
+from signal_analog.detectors import EmailNotification, Rule, Severity
+
+info_rule = Rule()\
+  # From our detector defined above.
+  .for_label(alert_label)\
+  .with_severity(Severity.Info)\
+  .with_notifications(EmailNotification('me@example.com'))
+
+detector.with_rules(info_rule)
+
+# We can now create this resource in SignalFx:
+detector.with_api_token('foo').create()
+# For a more robust solution consult the "Creating a CLI for your Resources"
+# section below.
+```
+
+To add multiple alerting rules we would need to use different `detect`
+statements with distinct `label`s to differentiate them from one another.
+
+#### Detectors that Combine Data Streams
+
+More complex detectors, like those created as a function of two other data
+streams, require a more complex setup including data stream assignments.
+If we wanted to create a detector that watched for an average above a certain
+threshold, we may want to use the quotient of the sum() of the data and the
+count() of the datapoints over a given period of time.
+
+```python
+from signal_analog.flow import \
+    Assign, \
+    Data, \
+    Detect, \
+    Ref, \
+    When
+
+from signal_analog.combinators import \
+    Div, \
+    GT
+
+program = Program( \
+    Assign('my_var', Data('cpu.utilization')) \
+    Assign('my_other_var', Data('cpu.utilization').count()) \
+    Assign('mean', Div(Ref('my_var'), Ref('my_other_var'))) \
+    Detect(When(GT(Ref('mean'), 2000))) \
+)
+
+print(program)
+```
+
+The above code generates the following program:
+
+```
+my_var = data('cpu.utilization')
+my_other_var = data('cpu.utilization').count()
+mean = (my_var / my_other_var)
+
+when(detect(mean > 2000))
+```
+
+#### Building Detectors from Existing Charts
+
+We can also build up Detectors from an existing chart, which allows us to reuse
+our SignalFlow program and ensure consistency between what we're monitoring
+and what we're alerting on.
+
+Let's assume that we already have a chart defined for our use:
+
+```python
+from signal_analog.flow import Program, Data
+from signal_analog.charts import TimeSeriesChart
+
+program = Program(Data('cpu.utilization').publish(label='A'))
+cpu_chart = TimeSeriesChart().with_name('Disk Utilization').with_program(program)
+```
+
+In order to alert on this chart we'll use the `from_chart`  builder for
+detectors:
+
+```python
+from signal_analog.combinators import GT
+from signal_analog.detectors import Detector
+from signal_analog.flow import Detect
+
+# Alert when CPU utilization rises above 95%
+detector = Detector()\
+    .with_name('CPU Detector')\
+    .from_chart(
+        cpu_chart,
+        # `p` is the Program object from the cpu_chart we passed in.
+        lambda p: Detect(GT(p.find_label('A'), 95).publish(label='Info Alert'))
+    )
+```
+
+The above example won't actually alert on anything until we add a `Rule`, which
+you can find examples for in the previous section.
+
+### Linking Charts to Existing Detectors
+
+To see a visualization of a Detector's status from within a chart, the `signal_analog.flow` module provides an Alert data stream that can create a signal flow statement. That statement can be appended to the charts Program object. In this example we assume a Detector was previously created. To create the link we will need the detector id. One place to obtain the detector id is to navigate to the detector in the web user interface. The url will have the id in it. The url has the form: https://app.signalfx.com/#/detector/v2/{detector_id}
+
+To refresh our memory, our data in the previous chart example was:
+
+```python
+ts = Data('memory.utilization', filter=all_filters).publish()
+```
+
+We can append an additional alert data stream. Import Program and Alerts form the `signal_analog.flow` module. First we need to wrap the Data object in a Program object:
+
+```python
+ts_program = Program(ts)
+```
+
+Then we can create a new statement using an Alert object with the detector id, publish the stream, and append the new statement to our program:
+
+```python
+notifications = Alerts(detector_id).publish()
+ts_program.statements.append(notifications)
+```
+
+ The program can be included in a chart as usual:
+
+ ```python
+ memory_chart = TimeSeriesChart()\
+                 .with_program(ts_program)
+                 .with_default_plot_type(PlotType.area_chart)
+```
+
+ By default the alert will show as a green box around the chart when the Detector is not in Alarm. The Detector can also be accessed from the bell icon in the upper right corner of the chart. 
+
+### Using Flow and Combinator Functions In Formulas
+
+`signal_analog` also provides functions for combining SignalFlow statements
+into more complex SignalFlow Formulas. These sorts of Formulas can be useful
+when creating more complex detectors and charts. For instance, if you would like
+to multiply one data stream by another and receive the sum of that Formula,
+it can be accomplished using Op and Mul like so:
+
+```python
+from signal_analog.flow import Op, Program, Data
+from signal_analog.combinators import Mul
+
+# Multiply stream A by stream B and sum the result
+    A = Data('request.mean')
+
+    B = Data('request.count')
+
+    C = Op(Mul(A,B)).sum()
+```
+
+Print(C) in the above example would produce the following output:
+
+```
+(data("request.mean") * data("request.count")).sum()
+```
+
+### Building Dashboard Groups
+
+`signal_analog` provides abstractions for building dashboard groups in the
+`signal_analog.dashboards` module.
+
+Consult the [upstream documentation][dashboard-groups] for more information on
+the Dashboard Groups API.
+
+Building on the examples described in the previous section, we'd now like to
+build a dashboard group containing our dashboards.
+
+First, lets build a couple of Dashboard objects similar to how we did it in
+the `Building Dashboards` example:
+
+```python
+from signal_analog.dashboards import Dashboard, DashboardGroup
+
+dg = DashboardGroup()
+dash1 = Dashboard().with_name('My Little Dashboard1: Metrics are Magic')\
+    .with_charts(memory_chart)
+dash2 = Dashboard().with_name('My Little Dashboard2: Metrics are Magic')\
+    .with_charts(memory_chart)
+```
+**Note: we do not create Dashboard objects ourselves, the DashboardGroup object
+is responsible for creating all child resources.**
+
+Many of the same methods for dashboards are available on dashboard groups as
+well, so let's give our dashboard group a memorable name and configure it's
+API token:
+
+```python
+
+dg.with_name('My Dashboard Group')\
+    .with_api_token('my-api-token')
+```
+
+Our final task will be to add dashboard to our dashboard group and create it
+in the API!
+
+```python
+response = dg\
+    .with_dashboards(dash1)\
+    .with_api_token('my-api-token')\
+    .create()
+```
+
+Now, storing API keys in source isn't ideal, so if you'd like to see how you
+can pass in your API keys at runtime check the documentation below to see how
+you can [dynamically build a CLI for your resources](#cli-builder).
+
+### Updating Dashboard Groups
+
+Once you have created a dashboard group, you can update properties like name
+and description of a dashboard group or add/remove dashboards in a group.
+
+*Example 1:*
+
+```python
+dg.with_api_token('my-api-token')\
+    .update(name='updated_dashboard_group_name',
+            description='updated_dashboard_group_description')
+```
+
+*Example 2:*
+
+```python
+dg.with_api_token('my-api-token').with_dashboards(dash1, dash2).update()
+```
+
+### Talking to the SignalFlow API Directly
+
+If you need to process SignalFx data outside the confince of the API it may be
+useful to call the SignalFlow API directly. Note that you may incur time
+penalties when pulling data out depending on the source of the data
+(e.g. AWS/CloudWatch).
+
+SignalFlow constructs are contained in the `flow` module. The following is an
+example SignalFlow program that monitors an API services (like [Riposte])
+RPS metrics for the `foo` application in the `test` environment.
+
+```python
+from signal_analog.flow import Data, Filter
+from signal_analog.combinators import And
+
+all_filters = And(Filter('env', 'prod'), Filter('app', 'foo'))
+
+program = Data('requests.count', filter=all_filters)).publish()
+```
+
+You now have an object representation of the SignalFlow program. To take it for
+a test ride you can use the official SignalFx client like so:
+
+```python
+# Original example found here:
+# https://github.com/signalfx/signalfx-python#executing-signalflow-computations
+
+import signalfx
+from signal_analog.flow import Data, Filter
+from signal_analog.combinators import And
+
+app_filter = Filter('app', 'foo')
+env_filter = Filter('env', 'prod')
+program = Data('requests.count', filter=And(app_filter, env_filter)).publish()
+
+with signalfx.SignalFx().signalflow('MY_TOKEN') as flow:
+    print('Executing {0} ...'.format(program))
+    computation = flow.execute(str(program))
+
+    for msg in computation.stream():
+        if isinstance(msg, signalfx.signalflow.messages.DataMessage):
+            print('{0}: {1}'.format(msg.logical_timestamp_ms, msg.data))
+        if isinstance(msg, signalfx.signalflow.messages.EventMessage):
+            print('{0}: {1}'.format(msg.timestamp_ms, msg.properties))
+```
+
+### General `Resource` Guidelines
+
+#### Charts Always Belong to Dashboards
+
+It is always assumed that a Chart belongs to an existing Dashboard. This makes
+it easier for the library to manage the state of the world.
+
+#### Resource Names are Unique per Account
+
+In a `signal_analog` world it is assumed that all resource names are unique.
+That is, if we have two dashboards 'Foo Dashboard', when we attempt to update
+_either_ dashboard via `signal_analog` we expect to see errors.
+
+Resource names are assumed to be unique in order to simplify state management
+by the library itself. In practice we have not found this to be a major
+inconvenience.
+
+#### Configuration is the Source of Truth
+
+When conflicts arise between the state of a resource in your configuration and
+what SignalFx thinks that state should be, this library **always** prefers the
+local configuration.
+
+#### Only "CCRUD" Methods Interact with the SignalFx API
+
+`Resource` objects contain a number of builder methods to enable a "fluent" API
+when describing your project's dashboards in SignalFx. It is assumed that these
+methods do not perform state-affecting actions in the SignalFx API.
+
+Only "CCRUD" (Create, Clone, Read, Update, and Delete) methods will affect the
+state of your resources in SignalFx.
+
+### Creating a CLI for your Resources
+
+`signal_analog` provides builders for fully featured command line clients that
+can manage the lifecycle of sets of resources.
+
+#### Simple CLI integration
+
+Integrating with the CLI is as simple as importing the builder and passing
+it your resources. Let's consider an example where we want to update two
+existing dashboards:
+
+```python
+#!/usr/bin/env python
+
+# ^ It's always good to include a "hashbang" so that your terminal knows
+# how to run your script.
+
+from signal_analog.dashboards import Dashboard
+from signal_analog.cli import CliBuilder
+
+ingest_dashboard = Dashboard().with_name('my-ingest-service')
+service_dashboard = Dashboard().with_name('my-service')
+
+if __name__ == '__main__':
+  cli = CliBuilder()\
+      .with_resources(ingest_dashboard, service_dashboard)\
+      .build()
+  cli()
+```
+
+Assuming we called this `dashboards.py` we could run it in one of two ways:
+
+  - Give the script execution rights and run it directly
+  (typically `chmod +x dashboards.py`)
+      - `./dashboards.py --api-key mykey update`
+  - Pass the script in to the Python executor
+      - `python dashboards.py --api-key mykey update`
+
+If you want to know about the available actions you can take with your new
+CLI you can always the `--help` command.
+
+```shell
+./dashboards.py --help
+```
+
+This gives you the following features:
+  - Consistent resource management
+      - All resources passed to the CLI builder can be updated with one
+      `update` invocation, rather than calling the `update()` method on each
+      resource indvidually
+  - API key handling for all resources
+      - Rather than duplicating your API key for each resource, you can instead
+      invoke the CLI with an API key
+      - This also provides a way to supply keys for users who don't want to
+      store them in source control (that's you! don't store your keys in
+      source control)
+
+## Documentation
+
+- [Signal Analog Documentation](https://signal-analog.readthedocs.io/)
+- [Introductory Article on Medium](https://medium.com/nikeengineering/introducing-signal-analog-the-troposphere-like-library-for-automating-monitoring-resources-c99eb8c2dca7)
+
+## Example Code
+
+- See [examples](https://github.com/Nike-Inc/signal_analog/tree/master/examples) included in this project.
+
+## Contributing
+
+Please read our [docs here for more info about contributing](CONTRIBUTING.md).
+
+[sfxdocs]: https://developers.signalfx.com/
+[signalflow]: https://developers.signalfx.com/signalflow_analytics/signalflow_overview.html
+[charts]: https://developers.signalfx.com/charts_reference.html
+[terrific]: https://media.giphy.com/media/jir4LEGA68A9y/200.gif
+[dashboards]: https://developers.signalfx.com/dashboards_reference.html
+[dashboard-groups]: https://developers.signalfx.com/dashboard_groups_reference.html
+[detectors]: https://developers.signalfx.com/detectors_reference.html
+[Riposte]: https://github.com/Nike-inc/riposte
+
+
+## 2.9.3 (2020-3-18)
+
+* Added `Alerts` in `signal_analog.flow` module to allow linking Detectors to Charts. 
+
+## 2.9.2 (2019-11-11)
+
+* `StrArg` will only reject `None` instead of all falsey values, allowing `0` to be given as a value.
+
+## 2.9.1 (2019-10-30)
+
+* Resources have learned that deleting nothing results in nothing, and will
+stop complaining about this scenario (it will still register it's displeasure
+in a debug log message)
+
+## 2.9.0 (2019-09-26)
+
+* Added `BigPandaNotification` for BigPanda integration within detectors.
+
+## 2.8.0 (2019-09-06)
+
+* Added `groupBy` support to the chart options. Allows grouping for example of HeatMap charts into groups on multiple levels.
+* Added support for `colorScale2` option on HeatMap charts. This allows to set custom chart colors for a defined range of values.
+
+## 2.7.2 (2019-05-14)
+
+### Fixed
+
+  - `signal_analog` has learned to use the `groupId` field when updating
+  Dashboard resources after the recent Sfx API changes
+
+### Updated
+
+  - As many documentation links as possible since the last doc update from Sfx.
+  Notable missing updates are those for 3rd party integration Notifications in
+  the `signal_analog.detectors` module.
+
+## 2.7.0 (2019-04-03)
+
+### Updated
+  * Removed dashboard numbering for two reasons:
+    1. There was a bug in the logic that caused dashboards to be deleted and recreated on update.
+    1. The functionality is no longer needed as SignalFx automatically maintains the order that dashboards were provided and allows easy reordering in the UI.
+  * AxisOptions are now optional where used
+
+### Fixed
+
+* Fixing applyIfExists option for Dashboard variables.
+
+## 2.6.0 (2019-03-21)
+
+  * AxisOption parameters should be optional.
+  * Additional documentation.
+
+## 2.5.0 (2019-03-20)
+
+  * Added `Plot` class, a helper class that gives an interface more like that found in the SignalFx UI.
+  * Added `RollupType` enum for specifying the roll-up used in Charts.
+  * Added additional documentation links to README.
+  * Fix: TextCharts weren't working
+  * Fix: YAML load deprecation warning in logging config
+
+## 2.4.0
+
+  * Add numbering to dashboards in a dashboard group for better organization 
+  of dashboards
+
+## 2.3.2 (2018-11-12)
+
+  * The `percentile` function on `signal_analog.flow.Data` objects has been
+  fixed to use the correct constructor
+
+## 2.3.1 (2018-11-06)
+
+  * signal-analog now prefers `simplejson` if it is available on the path,
+  falling back to the `json` module otherwise.
+
+## 2.3.0 (2018-10-30)
+
+  * DashboardGroup has learned how to accept SignalFX Team ids so that they can
+  be associated with pre-existing teams via the `with_teams` builder method.
+
+## 2.2.2 (2018-10-03)
+
+### Fixed
+  * Add `deprecation` to setup.py.
+
+## 2.2.1 (2018-10-02)
+
+### Changed
+  * Added `with_secondary_visualization` function to enable display of various meters (Sparkline, Linear, Radial) in 
+  Single Value charts. This replaces the now defunct `with_sparkline_hidden` function. This will not be a 
+  'breaking change' until version 3.0.0 when `with_sparkline_hidden` will be removed from `signal_analog`.
+
+  * Added the `deprecation` Python library to this project to note when `with_sparkline_hidden` should be removed. Upon 
+  version matching 3.0.0 or higher the tests for that function will begin to fail notifying whoever is releasing that 
+  version to remove the defunct `with_sparkline_hidden` function and tests.
+
+## 2.2.0 (2018-09-27)
+
+### Changed
+  * Dashboard Create method to accept group id of an existing dashboard group in which case the new dashboard will be
+   part of the dashboard group provided
+
+   Example:
+```python
+response = dashboard\
+  .with_charts(memory_chart)\
+  .with_api_token('my-api-token')\
+  .create(group_id="asdf;lkj")
+```
+  * Dashboard Group create method to pass group id of the newly created dashboard group to the dashboard create 
+  method so that we can avoid  a few redundant calls like cloning and deleting the dashboards
+
+## 2.1.0 (2018-08-21)
+
+### Added
+
+  * ListCharts learned how to filter legend options via the
+  `with_legend_options` builder
+  * Future chart types that can filter legend options may now take advantage
+  of the `signal_analog.charts.LegendOptionsMixin` class
+  * The `FieldOption` class has learned to accept `SignalFxFieldOption`s which
+  provide mappings between field options seen in the UI and those used in the
+  API
+      * e.g. `Plot Name` in the UI and `sf_originatingMetric` in the API
+  * A new `TextChart` object has been added to `signal_analog.charts` that
+  enables text descriptions to be added to dashboards.
+  * `PublishLabelOptions` has learned to accept prefix, suffix, and unit
+  arguments when labelling data on charts.
+
+### Changed
+
+  * `PublishLabelOptions` has learned to accept all arguments as optional
+  with the exception of the `label` argument.
+
+### Fixed
+
+  * A fix has been added for Python 2 users that prevented successful
+  dashboard updates.
+
+## 2.0.0 (2018-07-24)
+
+For assistance migrating from 1.x to 2.x please consult the
+[migration guide][migration-1x].
+
+### Added
+
+  * Add support for the `dimensions`, `fill`, `integrate`, `kpss`,
+  `rateofchange` methods
+
+
+### Removed
+
+  * `map` method support has been removed
+      * It didn't work properly to begin with, and will require some finagling
+      to get right given our approach to building SignalFlow statements
+
+### Fixes
+
+  * `top` and `bottom` method signatures have been fixed to use `count`, `by`,
+  and `percentage` arguments
+  * The following functions have been updated to raise an error if both
+  `by` and `over` are defined in the same method call:
+      * `count`, `max`, `mean`, `mean_plus_stddev`, `median`, `min`,
+      `percentile`, `random`, `size`, `stddev`, `sum`, `variance`
+  * `delta` has been updated to no longer accept any method arguments
+  * `ewma` has been updated to support the `over` key
+
+## 1.6.0 (2018-07-18)
+
+  * Add combinators for less-than-or-equal-to (`LTE`) and greater-than-or-equal-to (`GTE`)
+
+## 1.5.1 (2018-06-21)
+
+  * Fix detector update logic to include all fields instead of just name/description
+
+## 1.5.0(2018-05-16)
+
+  * Added `include_zero` method to `TimeSeriesChart` to allow setting the `includeZero` option.
+
+## 1.4.0(2018-05-08)
+
+  * Implements functionality to add event overlays and selected (default) event overlays to dashboards 
+  at dashboard creation or update. Includes wildcard matching using the asterisk (*) symbol. 
+
+## 1.3.0(2018-04-17)
+
+  * Implementing the rest of the Dashboard Filters: `source` and `time`
+
+## 1.2.0 (2018-04-11)
+  * Added an Assign function that will enable more complex detectors which are constructed by combining multiple data streams
+  * Added a Ref flow operator that will enable referencing assignments in a way that can be validated at later steps by checking for an Assign object with a match between the reference string and the assignee
+
+## 1.1.0 (2018-04-04)
+  * Introducing Dashboard Filters(only variables as of now) which can be configured to provide various filters that affect the behavior of all configured charts (overriding any conflicting filters at the chart level). You may wish to do this in order to quickly change the environment that you're observing for a given set of charts.
+
+## 1.0.0 (2018-04-02)
+
+  * Symbolic release for `signal_analog`. Future version bumps should conform
+  to the `semver` policy outlined [here][deployment].
+
+## 0.25.1 (2018-03-22)
+
+  * The timeshift method's arguments changed. Now accepts a single argument for offset.
+
+## 0.24.0 (2018-03-09)
+
+  * Fix string parsing to not exclude boolean False, which is required for certain functions like .publish()
+
+## 0.23.0 (2018-03-06)
+
+  * Added Op class in flow.py to allow multiplying and dividing datastreams
+  to create SignalFlow Functions
+
+## 0.22.0 (2018-03-01)
+
+  * Added Mul and Div combinators for multiplying and dividing streams
+  * Added "enable" option for publishing a stream. Setting enable=False
+    will hide that particular stream in a chart/detector.
+
+## 0.21.0 (2018-02-28)
+
+  * Dashboard Group support has been added giving you the ability group sets of
+  dashboards together in a convenient construct
+  * Detector support has been added giving you the ability to create detectors
+  from scratch or re-use the SignalFlow program of an existing Chart
+  * Dashboards and Charts now update via their `id` instead of by name to
+  mitigate name conflicts when creating multiple resources with the same name
+  * Dry-run results are now more consistent between all resources and expose
+  the API call (sans-headers) that would have been made to use for the given
+  resource
+
+## 0.20.0 (2018-01-31)
+
+  * Dashboards have learned how to update their child resources (e.g. if you
+    add a chart in your config, the change will be reflected when you next run
+    your configuration against SignalFx)
+  * The CLI builder has learned how to pass dry-run options to its configured resources
+  * Minor bugfixes for the `signal_analog.flow` module
+
+## 0.19.1 (2018-01-26)
+
+  * Added click to setup.py
+
+## 0.19.0 (2018-01-19)
+
+  * Added CLI builder to create and update dashboard resources
+
+## 0.18.0 (2018-01-11)
+
+  * Dashboard resources have learned to interactively prompt the user if the user wants to
+   create a new dashboard if there is a pre-existing match (this behavior is disabled
+      by default).
+  * Added "Update Dashboard" functionality where a user can update the properties of a dashboard(only name and description for now)
+
+## 0.17.0 (2018-01-11)
+  * Added Heatmap Chart style
+     * Added by Jeremy Hicks
+
+## 0.16.0 (2018-01-10)
+  * Added the ability to sort a list chart by value ascending/descending
+      * Added by Jeremy Hicks
+
+## 0.15.0 (2018-01-08)
+
+  * Added "Scale" to ColorBy class for coloring thresholds in SingleValueChart
+      * Added by Jeremy Hicks
+
+## 0.14.0 (2018-01-04)
+
+  * Added List Chart style
+      * Added by Jeremy Hicks
+
+## 0.13.0 (2018-01-04)
+
+  * Dashboard resources have learned how to force create themselves in the
+  SignalFx API regardless of a pre-existing match (this behavior is disabled
+  by default).
+
+## 0.12.0 (2017-12-21)
+
+  * Dashboard resources have learned how to check for themselves in the
+  SignalFx API, and will no longer create themselves if an exact match is found
+
+## 0.3.0 (2017-09-25)
+
+  * Adds support for base Resource object. Will be used for Chart/Dashboard
+  abstractions in future versions.
+  * Adds support for base Chart and TimeSeriesChart objects. Note that some
+  TimeSeriesChart builder options have not yet been implemented (and marked
+  clearly with NotImplementedErrors)
+
+## 0.2.0 (2017-09-18)
+
+  * Adds support for function combinators like `and`, `or`, and `not`
+
+## 0.1.1 (2017-09-14)
+
+  * Add README documentation
+
+## 0.1.0 (2017-09-14)
+
+  * Initial release
+
+[deployment]: https://github.com/Nike-Inc/signal_analog/wiki/Developers-::-Deployment
+[migration-1x]: ./docs/migrating_from_1.x.md
+
+
```

