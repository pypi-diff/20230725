# Comparing `tmp/fastestimator-1.5.2.tar.gz` & `tmp/fastestimator-1.6.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/fastestimator-1.5.2.tar", last modified: Tue Apr 25 20:41:41 2023, max compression
+gzip compressed data, was "dist/fastestimator-1.6.0.tar", last modified: Tue Jul 25 19:02:24 2023, max compression
```

## Comparing `fastestimator-1.5.2.tar` & `fastestimator-1.6.0.tar`

### file list

```diff
@@ -1,766 +1,803 @@
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      591 2023-04-25 20:41:41.000000 fastestimator-1.5.2/PKG-INFO
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5698 2023-04-25 20:02:11.000000 fastestimator-1.5.2/README.md
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3092 2023-04-25 20:40:45.000000 fastestimator-1.5.2/fastestimator/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/architecture/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1018 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/architecture/pytorch/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1609 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/pytorch/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7452 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/pytorch/attention_unet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2898 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/pytorch/lenet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4148 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/pytorch/resnet9.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5889 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/pytorch/unet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6188 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/pytorch/wideresnet.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/architecture/tensorflow/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1624 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/tensorflow/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4800 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/tensorflow/attention_unet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2216 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/tensorflow/lenet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3355 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/tensorflow/resnet9.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3718 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/tensorflow/unet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5580 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/architecture/tensorflow/wideresnet.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/backend/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10290 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1836 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_abs.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2252 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_argmax.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4939 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_binary_crossentropy.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3876 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_cast.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5024 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_categorical_crossentropy.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1859 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_check_nan.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3294 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_clip_by_value.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2539 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_concat.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1410 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_convert_tensor_precision.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7734 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_dice_score.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1850 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_exp.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2335 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_expand_dims.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2502 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_feed_forward.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2699 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_flip.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6244 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_focal_loss.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3148 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_gather.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3421 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_gather_from_batch.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4694 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_get_gradient.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2512 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_get_image_dims.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1895 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_get_lr.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1979 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_get_shape.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2225 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_hinge.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3484 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_huber.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4511 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_iwd.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3161 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_l1_loss.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1797 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_l2_regularization.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4558 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_lambertw.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4420 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_load_model.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2226 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_matmul.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2161 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_maximum.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2788 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_mean_squared_error.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2483 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_ones_like.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5065 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_percentile.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2727 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_permute.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1952 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_pow.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2923 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_random_normal_like.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3005 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_random_uniform_like.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3123 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_reduce_max.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3259 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_reduce_mean.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3159 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_reduce_min.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3199 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_reduce_std.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2997 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_reduce_sum.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3067 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_reshape.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4256 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_resize3d.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3182 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_roll.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4633 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_save_model.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3069 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_set_lr.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1839 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_sign.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3639 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_smooth_l1_loss.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4889 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_sparse_categorical_crossentropy.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2785 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_squeeze.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5661 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_tensor_normalize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2431 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_tensor_pow.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1994 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_tensor_round.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2070 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_tensor_sqrt.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3832 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_to_shape.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3835 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_to_tensor.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2807 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_to_type.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1948 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_transpose.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5245 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_update_model.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2207 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_watch.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2482 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_zeros_like.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2416 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/backend/_zscore.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/cli/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1618 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/cli/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8845 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/cli/history.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5358 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/cli/logs.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1843 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/cli/main.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5468 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/cli/plot.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3485 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/cli/run.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6574 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/cli/train.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/dataset/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2529 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    16449 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/batch_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1804 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/csv_dataset.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/dataset/data/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1757 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1566 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/breast_cancer.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3396 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/cifair10.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2831 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/cifair100.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1568 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/cifar10.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1915 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/cifar100.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5708 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/cub200.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3698 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/food101.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3712 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/horse2zebra.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2174 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/imdb_review.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3750 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/mendeley.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4011 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/mitmovie_ner.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1338 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/mnist.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3321 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/montgomery.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10000 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/mscoco.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3856 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/nih_chestxray.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2643 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/omniglot.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3269 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/penn_treebank.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2695 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/shakespeare.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1195 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/skl_digits.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6097 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/svhn.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2827 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/svhn_cropped.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3914 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/tednmt.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4183 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/tiny_imagenet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5509 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/data/usps.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    20437 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/dataloader.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    25375 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1974 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/dir_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2263 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/extend_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4086 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/generator_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3599 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/labeled_dir_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1988 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/numpy_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8402 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/op_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1476 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/pickle_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9018 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/dataset/siamese_dir_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    31566 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/estimator.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/layers/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1012 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/layers/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/layers/pytorch/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1200 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/layers/pytorch/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3887 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/layers/pytorch/cropping_2d.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6553 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/layers/pytorch/hadamard.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/layers/tensorflow/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1370 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/layers/tensorflow/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7334 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/layers/tensorflow/hadamard.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2591 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/layers/tensorflow/instance_norm.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2490 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/layers/tensorflow/reflection_padding_2d.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    50615 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/network.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/op/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1152 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/op/numpyop/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1318 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/op/numpyop/meta/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1390 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/meta/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4118 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/meta/fuse.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4386 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/meta/one_of.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5873 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/meta/repeat.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4997 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/meta/sometimes.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5956 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7544 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/affine.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4466 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/center_crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4639 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5041 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/crop_non_empty_mask_if_exists.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4920 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/elastic_transform.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4292 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/flip.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4545 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/grid_distortion.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4284 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/horizontal_flip.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4568 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/iaa_crop_and_pad.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4797 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/longest_max_size.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4014 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/mask_dropout.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6019 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/multivariate.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4665 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/optical_distortion.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5191 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/pad_if_needed.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4439 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4680 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_crop_near_bbox.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3406 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_grid_shuffle.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5091 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_resized_crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4294 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_rotate_90.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4887 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_scale.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4454 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_sized_bbox_safe_crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5023 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_sized_crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3034 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/read_mat.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4755 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/resize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5430 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/rotate.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6176 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/shift_scale_rotate.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4818 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/smallest_max_size.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4306 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/transpose.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4308 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/vertical_flip.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    16413 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/numpyop.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10320 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2760 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/autocontrast.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2280 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/binarize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2245 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/blur.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3497 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/brightness.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3718 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/calibate.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2494 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/channel_dropout.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2089 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/channel_shuffle.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2287 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/channel_transpose.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2580 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/clahe.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3349 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/coarse_dropout.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3488 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/color.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3208 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/color_jitter.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3488 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/contrast.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2563 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/downscale.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2864 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/equalize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2256 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/expand_dims.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2551 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/from_float.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2761 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/gaussian_blur.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2672 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/gaussian_noise.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3575 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/hadamard.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3064 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/hue_saturation_value.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2520 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/iaa_additive_gaussian_noise.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2812 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/image_compression.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2078 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/invert_img.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2562 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/iso_noise.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2473 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/median_blur.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2497 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/minmax.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2381 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/motion_blur.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3004 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/multiplicative_noise.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2615 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/normalize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3310 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/onehot.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3155 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/pad_sequence.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2708 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/posterize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3022 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_brightness_contrast.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2687 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_fog.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2508 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_gamma.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3433 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_rain.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3368 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_shadow.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5438 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_shapes.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2744 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_snow.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3585 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_sun_flare.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3696 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/read_image.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2424 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/reshape.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3017 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/rgb_shift.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    23957 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/rua.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3546 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/sharpness.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3808 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/shear_x.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3809 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/shear_y.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2407 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/solarize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2367 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/to_array.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2396 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/to_float.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2138 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/to_gray.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2060 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/to_sepia.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3114 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/tokenize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3709 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/translate_x.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3711 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/translate_y.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3279 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/univariate.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3057 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/numpyop/univariate/word_to_id.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6800 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/op.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/op/tensorop/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2454 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2342 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/argmax.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/op/tensorop/augmentation/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1226 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/augmentation/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7301 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/augmentation/cutmix_batch.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4185 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/augmentation/mixup_batch.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2277 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/average.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3393 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/dice.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3568 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/gather.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/op/tensorop/gradient/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1323 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/gradient/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3673 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/gradient/fgsm.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4835 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/gradient/gradient.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2455 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/gradient/watch.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/op/tensorop/loss/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2296 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/loss/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5519 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/loss/cross_entropy.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3404 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/loss/focal_loss.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2522 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/loss/hinge.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4060 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/loss/l1_loss.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2257 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/loss/l2_regularization.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2495 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/loss/loss.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2585 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/loss/mean_squared_error.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2866 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/loss/mix_loss.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9186 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/loss/super_loss.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/op/tensorop/meta/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1454 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/meta/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3687 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/meta/fuse.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4517 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/meta/one_of.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7965 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/meta/repeat.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4195 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/meta/sometimes.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/op/tensorop/model/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1176 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/model/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10649 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/model/model.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    11964 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/model/update.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2968 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/normalize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2362 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/permute.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2385 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/reshape.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2720 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/resize3d.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5991 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/tensorop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4326 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/op/tensorop/un_hadamard.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    35452 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/pipeline.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/schedule/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1448 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/schedule/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8480 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/schedule/lr_shedule.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9875 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/schedule/schedule.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/search/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1386 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/search/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5793 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/search/golden_section.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3425 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/search/grid_search.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9034 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/search/search.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/search/visualize/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1829 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/search/visualize/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7925 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/search/visualize/cartesian.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7666 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/search/visualize/heatmap.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4789 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/search/visualize/parallel_coordinate_plot.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4977 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/search/visualize/vis_util.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3193 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/search/visualize/visualize.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/summary/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1621 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/summary/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    41578 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/summary/history.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/summary/logs/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1321 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/summary/logs/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8515 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/summary/logs/log_parse.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    34368 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/summary/logs/log_plot.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7620 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/summary/summary.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    17954 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/summary/system.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/test/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/test/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2840 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/test/nightly_util.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10332 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/test/unittest_util.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/trace/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1410 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/trace/adapt/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1678 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/adapt/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3857 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/adapt/early_stopping.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5529 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/adapt/lr_scheduler.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5503 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/adapt/pbm_calibrator.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3590 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/adapt/reduce_lr_on_plateau.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3453 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/adapt/terminate_on_nan.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/trace/io/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2227 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/io/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4977 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/io/best_model_saver.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7098 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/io/csv_logger.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3490 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/io/image_saver.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3056 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/io/image_viewer.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3908 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/io/model_saver.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4974 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/io/restore_wizard.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    25346 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/io/tensorboard.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    22579 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/io/test_report.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    41506 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/io/traceability.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/trace/meta/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      965 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/meta/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4238 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/meta/_per_ds.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/trace/metric/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2360 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/metric/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4100 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/metric/accuracy.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10591 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/metric/bleu_score.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5417 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/metric/calibration_error.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4839 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/metric/confusion_matrix.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3795 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/metric/dice.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4950 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/metric/f1_score.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5061 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/metric/mcc.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    18344 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/metric/mean_average_precision.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4895 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/metric/precision.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4866 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/metric/recall.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    19578 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/trace.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/trace/xai/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1588 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/xai/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10667 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/xai/eigen_cam.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7808 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/xai/grad_cam.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7266 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/xai/instance_tracker.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6905 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/xai/label_tracker.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9267 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/trace/xai/saliency.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/util/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3768 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/util/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    23214 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/util/base_util.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4225 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/util/cli_util.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5328 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/util/data.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    24492 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/util/img_data.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8260 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/util/latex_util.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    57327 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/util/traceability_util.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    11038 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/util/util.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5366 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/util/wget_util.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator/xai/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1030 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/xai/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    12171 2023-04-25 20:02:11.000000 fastestimator-1.5.2/fastestimator/xai/saliency.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator.egg-info/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      591 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator.egg-info/PKG-INFO
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    34489 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator.egg-info/SOURCES.txt
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)        1 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator.egg-info/dependency_links.txt
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)       63 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator.egg-info/entry_points.txt
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      655 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator.egg-info/requires.txt
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)       19 2023-04-25 20:41:41.000000 fastestimator-1.5.2/fastestimator.egg-info/top_level.txt
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)       38 2023-04-25 20:41:41.000000 fastestimator-1.5.2/setup.cfg
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3090 2023-04-25 20:40:45.000000 fastestimator-1.5.2/setup.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/backend/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/backend/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1665 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/backend/test_get_lr.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3584 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/backend/test_save_model_load_model.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1694 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/backend/test_set_lr.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4617 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/backend/test_update_model.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/cli/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/cli/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3718 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/cli/test_main.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1883 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/cli/test_train.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/dataset/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/dataset/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2376 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/dataset/test_batch_dataset.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/meta/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/meta/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3002 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/meta/test_fuse.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2190 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/meta/test_one_of.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1975 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/meta/test_repeat.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1950 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/meta/test_sometimes.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/multivariate/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/multivariate/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1615 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/multivariate/test_read_mat.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/univariate/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/univariate/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2342 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/univariate/test_hadamard.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2054 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/univariate/test_read_image.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/augmentation/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/augmentation/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5170 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/augmentation/test_cutmix_batch.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/gradient/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/gradient/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2144 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/gradient/test_fgsm.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3632 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/gradient/test_gradientop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2076 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/gradient/test_watch.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4052 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/test_cross_entropy.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1836 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/test_hinge.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3804 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/test_l1_loss.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10344 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/test_l2_regularization.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1810 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/test_mean_squared_error.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8515 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/test_super_loss.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/meta/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/meta/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2673 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/meta/test_fuse.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2632 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/meta/test_one_of.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2511 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/meta/test_repeat.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2408 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/meta/test_sometimes.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/model/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/model/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7189 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/model/test_modelop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    22429 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/model/test_updateop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1592 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/test_argmax.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1613 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/test_average.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1650 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/test_reshape.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4149 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/test_un_hadamard.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1190 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/op/test_op.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/schedule/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/schedule/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3971 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/schedule/test_arc.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    13590 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/schedule/test_epoch_scheduler.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    14280 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/schedule/test_repeat_scheduler.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1742 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/schedule/test_schedule.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/search/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/search/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/search/visualize/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/search/visualize/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5667 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/search/visualize/test_visualize.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/summary/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/summary/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    11980 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/summary/test_history.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    17978 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/summary/test_system.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    23833 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/test_estimator.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    28044 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/test_network.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    98463 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/test_pipeline.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2952 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/test_early_stopping.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4333 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/test_lr_scheduler.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3709 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/test_pbm_calibrator.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3934 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/test_reduce_lr_on_plateau.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5057 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/test_terminate_on_nan.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4498 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_best_model_saver.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2934 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_csv_logger.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2822 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_image_saver.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2021 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_image_viewer.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8180 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_model_saver.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4049 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_restore_wizard.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3114 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_saliency.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8691 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_tensorboard.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    13603 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_test_report.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6037 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_traceability.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4671 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_accuracy.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3818 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_calibration_error.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8046 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_confusion_matrix.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2167 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_dice.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8699 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_f1_score.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7268 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_mcc.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3575 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_mean_average_precision.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8730 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_precision.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8644 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_recall.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2273 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/test_eval_essential.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3766 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/test_logger.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2273 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/test_test_essential.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4778 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/test_trace.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2989 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/test_train_essential.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/xai/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      702 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/xai/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9440 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/xai/test_instance_tracker.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8956 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/trace/xai/test_label_tracker.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/integration_test/util/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/util/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1938 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/util/test_img_data.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    11088 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/util/test_traceability_util.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6280 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/integration_test/util/test_util.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2991 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/test_attention_unet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2086 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/test_lenet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1950 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/test_resnet9.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2514 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/test_unet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1225 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/test_wideresnet.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2280 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/test_attention_unet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2180 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/test_lenet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2143 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/test_resnet9.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2174 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/test_unet.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1280 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/test_wideresnet.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1451 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_abs.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2269 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_argmax.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6396 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_binary_crossentropy.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2682 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_cast.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6604 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_categorical_crossentropy.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2531 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_check_nan.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2812 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_clip_by_value.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2477 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_concat.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3920 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_dice_score.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1471 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_exp.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2267 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_expand_dims.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1475 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_feed_forward.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2499 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_gather.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3014 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_gather_from_batch.py
--rwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)     3742 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_get_gradient.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1499 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_get_image_dims.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1657 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_hinge.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5710 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_iwd.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1939 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_lambertw.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1518 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_matmul.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1479 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_maximum.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1824 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_mean_squared_error.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1596 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_ones_like.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9198 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_percentile.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2662 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_permute.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1466 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_pow.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2211 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_random_normal_like.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2225 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_random_uniform_like.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1964 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reduce_max.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1979 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reduce_mean.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1960 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reduce_min.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1909 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reduce_std.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1958 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reduce_sum.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1926 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reshape.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2645 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_resize3d.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3089 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_roll.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2029 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_sign.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3546 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_sparse_categorical_crossentropy.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2305 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_squeeze.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2520 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_tensor_normalize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2536 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_tensor_pow.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2182 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_tensor_round.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2202 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_tensor_sqrt.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1679 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_to_shape.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3038 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_to_tensor.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2509 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_to_type.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1499 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_transpose.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1600 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_watch.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1604 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_zeros_like.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1463 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/backend/test_zscore.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/cli/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/cli/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1494 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/cli/test_cli_util.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1534 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_batch_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1215 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_csv_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2420 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_data.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1383 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_dir_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1559 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_extend_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1076 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_generator_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1393 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_labeled_dir_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    13000 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_numpy_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      983 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_pickle_dataset.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1517 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_siamese_dir_dataset.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/layers/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/layers/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/layers/pytorch/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/layers/pytorch/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1675 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/layers/pytorch/test_cropping_2d.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3029 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/layers/pytorch/test_hadamard.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/layers/tensorflow/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/layers/tensorflow/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2903 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/layers/tensorflow/test_hadamard.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1157 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/layers/tensorflow/test_instance_norm.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1628 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/layers/tensorflow/test_reflection_padding_2d.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/loss/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/loss/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3752 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/loss/test_focal_loss.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1749 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/loss/test_mix_loss.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/meta/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/meta/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1864 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/meta/test_fuse.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3212 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/meta/test_one_of.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5323 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/meta/test_repeat.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2117 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/meta/test_sometimes.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2012 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_affine.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2092 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_center_crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2122 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1590 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_crop_non_empy_mask_if_exists.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2057 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_elastic_transform.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1989 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_flip.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2053 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_grid_distortion.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2073 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_horizontal_flip.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2049 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_iaa_crop_and_pad.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2109 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_longest_max_size.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2157 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_mask_dropout.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2097 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_optical_distortion.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2021 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_pad_if_needed.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2160 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1820 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_crop_near_bbox.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2073 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_grid_shuffle.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2196 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_resized_crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2065 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_rotate_90.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1653 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_scale.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2851 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_sized_bbox_safe_crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2390 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_sized_crop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2128 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_resize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2005 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_rotate.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2057 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_shift_scale_rotate.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2123 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_smallest_max_size.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2029 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_transpose.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2057 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_vertical_flip.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1494 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/test_numpyop.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2165 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_autocontrast.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1591 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_binarize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1970 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_blur.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2149 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_brightness.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2644 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_calibrate.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2054 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_channel_dropout.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2054 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_channel_shuffle.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2061 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_channel_transpose.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2093 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_clahe.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2037 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_coarse_dropout.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2109 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_color.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2078 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_color_jitter.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2133 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_contrast.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2001 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_downscale.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2117 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_equalize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1602 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_expand_dims.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2001 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_fromfloat.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2029 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_gaussian_blur.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2037 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_gaussian_noise.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2181 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_hue_saturation_value.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2124 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_iaa_additive_gaussian_noise.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2161 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_image_compression.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2005 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_invert_img.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2117 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_iso_noise.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2070 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_median_blur.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1559 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_minmax.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2070 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_motion_blur.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2045 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_multiplicative_noise.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2001 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_normalize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1380 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_onehot.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2113 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_pad_sequence.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2125 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_posterize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2186 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_brightness_contrast.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2062 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_fog.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2021 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_gamma.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2070 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_rain.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2086 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_shadow.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3662 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_shapes.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2070 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_snow.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2106 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_sun_flare.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1586 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_reshape.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1997 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_rgb_shift.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2107 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_rua.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2141 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_sharpness.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2121 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_shear_x.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2121 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_shear_y.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2050 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_solarize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1199 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_to_array.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2046 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_to_float.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2038 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_to_gray.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1989 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_to_sepia.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2417 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_tokenize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2153 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_translate_x.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2153 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_translate_y.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2222 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_word_to_id.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/augmentation/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/augmentation/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4002 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/augmentation/test_mixup_batch.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/meta/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/meta/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2783 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/meta/test_fuse.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7141 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/meta/test_one_of.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    15616 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/meta/test_repeat.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4632 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/meta/test_sometimes.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5034 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/test_normalize.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1296 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/test_tensorop.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2279 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/op/test_op.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/schedule/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/schedule/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1315 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/schedule/test_epoch_scheduler.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1606 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/schedule/test_lr_schedule.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1188 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/schedule/test_repeat_scheduler.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/search/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/search/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1803 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/search/test_golden_section_search.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1753 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/search/test_grid_search.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4279 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/search/test_search.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/summary/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/summary/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/summary/logs/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/summary/logs/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3794 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/summary/logs/test_metrics.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10448 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/summary/test_history.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4160 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/summary/test_summary.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/test/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/test/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4942 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/test/test_unittest_util.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/trace/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/trace/__init__.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/trace/metric/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/trace/metric/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3591 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/trace/metric/test_bleu_score.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/util/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/util/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1278 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/util/test_data.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5530 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/util/test_traceability_util.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    18690 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/util/test_util.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1018 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/util/test_wget_util.py
-drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-25 20:41:41.000000 fastestimator-1.5.2/test/PR_test/unit_test/xai/
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/xai/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2825 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/PR_test/unit_test/xai/test_saliency.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/__init__.py
--rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1255 2023-04-25 20:02:11.000000 fastestimator-1.5.2/test/run_pr_test.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      594 2023-07-25 19:02:24.000000 fastestimator-1.6.0/PKG-INFO
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6396 2023-07-25 19:01:12.000000 fastestimator-1.6.0/README.md
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3093 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/architecture/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1018 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/architecture/pytorch/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1609 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/pytorch/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7452 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/pytorch/attention_unet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2898 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/pytorch/lenet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4148 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/pytorch/resnet9.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5945 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/pytorch/unet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6188 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/pytorch/wideresnet.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/architecture/tensorflow/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1624 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/tensorflow/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4800 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/tensorflow/attention_unet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2319 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/architecture/tensorflow/lenet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3355 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/tensorflow/resnet9.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3811 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/tensorflow/unet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5580 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/architecture/tensorflow/wideresnet.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/backend/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10420 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1783 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/backend/_abs.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2252 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_argmax.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4853 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_binary_crossentropy.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3989 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_cast.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5087 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_categorical_crossentropy.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1859 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_check_nan.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3294 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_clip_by_value.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2539 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_concat.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1410 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_convert_tensor_precision.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7866 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_dice_score.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1850 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_exp.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2335 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_expand_dims.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2502 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_feed_forward.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2699 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_flip.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6816 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_focal_loss.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3148 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_gather.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3421 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_gather_from_batch.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4636 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_get_gradient.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2512 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_get_image_dims.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1895 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_get_lr.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1959 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/backend/_get_shape.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2228 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_hinge.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3344 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_huber.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4476 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_iwd.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2991 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_l1_loss.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1797 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_l2_regularization.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4558 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_lambertw.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4420 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_load_model.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2226 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_matmul.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2161 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_maximum.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2740 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_mean_squared_error.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2483 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_ones_like.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5065 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_percentile.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2727 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_permute.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1952 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_pow.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2923 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_random_normal_like.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3005 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_random_uniform_like.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3123 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_reduce_max.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3259 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_reduce_mean.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3159 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_reduce_min.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3199 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_reduce_std.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2997 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_reduce_sum.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3067 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_reshape.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4323 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_resize3d.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3182 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_roll.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4835 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_save_model.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3069 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_set_lr.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1839 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_sign.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3572 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_smooth_l1_loss.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4987 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_sparse_categorical_crossentropy.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2785 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_squeeze.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5742 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_tensor_normalize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2431 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_tensor_pow.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1994 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_tensor_round.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2070 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_tensor_sqrt.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3832 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_to_shape.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4770 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/backend/_to_tensor.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2807 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_to_type.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1948 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_transpose.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5214 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_update_model.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2207 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_watch.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2477 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_where.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2482 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_zeros_like.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2464 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/backend/_zscore.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/cli/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1618 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/cli/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8845 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/cli/history.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5392 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/cli/logs.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1843 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/cli/main.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5468 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/cli/plot.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4180 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/cli/run.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6574 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/cli/train.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/dataset/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2315 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    16882 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/batch_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1935 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/combined_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4517 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/csv_dataset.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/dataset/data/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1820 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/data/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1566 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/breast_cancer.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3956 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/data/cifair10.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3118 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/data/cifair100.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3447 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/data/cifar10.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3488 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/data/cifar100.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4029 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/data/cub200.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6809 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/data/em_3d.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3698 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/food101.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3712 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/horse2zebra.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2174 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/imdb_review.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4488 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/data/medmnist.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3750 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/mendeley.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4039 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/data/mitmovie_ner.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1338 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/mnist.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3321 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/montgomery.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    12377 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/mscoco.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3856 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/nih_chestxray.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2643 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/omniglot.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9767 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/data/pascal_voc.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3269 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/penn_treebank.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2695 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/shakespeare.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1195 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/skl_digits.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6097 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/svhn.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2827 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/svhn_cropped.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3914 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/tednmt.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4183 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/data/tiny_imagenet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5324 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/data/usps.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    22543 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/dataloader.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    26711 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1974 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/dir_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2452 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/extend_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4081 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/generator_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    16321 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/interleave_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3599 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/labeled_dir_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2004 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/numpy_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10140 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/dataset/op_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1476 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/pickle_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9011 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/dataset/siamese_dir_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    33059 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/estimator.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/layers/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1012 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/layers/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/layers/pytorch/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1200 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/layers/pytorch/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3887 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/layers/pytorch/cropping_2d.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6553 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/layers/pytorch/hadamard.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/layers/tensorflow/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1370 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/layers/tensorflow/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7334 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/layers/tensorflow/hadamard.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2591 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/layers/tensorflow/instance_norm.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2490 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/layers/tensorflow/reflection_padding_2d.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    55423 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/network.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/op/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1152 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/op/numpyop/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1318 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/op/numpyop/meta/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1390 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/meta/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4118 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/meta/fuse.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4413 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/meta/one_of.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5847 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/op/numpyop/meta/repeat.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4971 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/op/numpyop/meta/sometimes.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5956 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7544 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/affine.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4466 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/center_crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4639 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5041 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/crop_non_empty_mask_if_exists.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4920 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/elastic_transform.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4302 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/flip.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4555 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/grid_distortion.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4294 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/horizontal_flip.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4568 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/iaa_crop_and_pad.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4807 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/longest_max_size.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4011 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/mask_dropout.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6019 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/multivariate.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4654 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/optical_distortion.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5222 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/pad_if_needed.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4439 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4680 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_crop_near_bbox.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3563 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_grid_shuffle.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5091 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_resized_crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4294 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_rotate_90.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4887 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_scale.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4454 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_sized_bbox_safe_crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5023 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_sized_crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3034 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/read_mat.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4755 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/resize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5430 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/rotate.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6186 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/shift_scale_rotate.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4818 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/smallest_max_size.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4295 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/transpose.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4318 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/vertical_flip.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    16598 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/op/numpyop/numpyop.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10320 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2760 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/autocontrast.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2280 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/binarize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2350 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/blur.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3497 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/brightness.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3718 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/calibate.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2501 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/channel_dropout.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2089 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/channel_shuffle.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2291 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/channel_transpose.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2580 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/clahe.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3346 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/coarse_dropout.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3488 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/color.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3208 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/color_jitter.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3488 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/contrast.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2563 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/downscale.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2864 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/equalize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2256 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/expand_dims.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2551 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/from_float.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2750 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/gaussian_blur.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2672 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/gaussian_noise.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3575 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/hadamard.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3064 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/hue_saturation_value.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2520 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/iaa_additive_gaussian_noise.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2812 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/image_compression.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2078 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/invert_img.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2562 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/iso_noise.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2467 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/median_blur.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2497 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/minmax.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2375 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/motion_blur.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3004 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/multiplicative_noise.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2978 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/normalize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3490 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/onehot.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3155 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/pad_sequence.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2708 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/posterize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3022 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_brightness_contrast.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2687 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_fog.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2508 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_gamma.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3433 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_rain.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3372 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_shadow.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5438 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_shapes.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2744 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_snow.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3585 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_sun_flare.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3696 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/read_image.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2424 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/reshape.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3017 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/rgb_shift.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    23957 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/rua.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3546 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/sharpness.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3808 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/shear_x.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3809 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/shear_y.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2407 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/solarize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2367 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/to_array.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2396 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/to_float.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2138 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/to_gray.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2060 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/to_sepia.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3114 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/tokenize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3709 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/translate_x.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3711 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/translate_y.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3297 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/univariate.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3057 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/numpyop/univariate/word_to_id.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6800 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/op.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/op/tensorop/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2326 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2362 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/argmax.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/op/tensorop/augmentation/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1226 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/augmentation/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7214 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/augmentation/cutmix_batch.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4108 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/augmentation/mixup_batch.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2277 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/average.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3568 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/gather.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/op/tensorop/gradient/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1323 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/gradient/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3673 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/gradient/fgsm.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4835 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/gradient/gradient.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2455 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/gradient/watch.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/op/tensorop/loss/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2300 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/loss/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5748 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/loss/cross_entropy.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5174 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/loss/dice_loss.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3876 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/loss/focal_loss.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2522 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/loss/hinge.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4048 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/loss/l1_loss.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2257 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/loss/l2_regularization.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2495 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/loss/loss.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2585 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/loss/mean_squared_error.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9186 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/loss/super_loss.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/op/tensorop/meta/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1454 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/meta/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3687 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/meta/fuse.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4519 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/meta/one_of.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    12283 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/meta/repeat.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4195 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/meta/sometimes.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/op/tensorop/model/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1176 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/model/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10480 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/op/tensorop/model/model.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    12067 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/model/update.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3060 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/normalize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2375 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/permute.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2385 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/reshape.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3250 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/resize3d.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5991 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/tensorop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4326 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/op/tensorop/un_hadamard.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    41667 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/pipeline.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/schedule/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1450 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/schedule/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8667 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/schedule/lr_schedule.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10918 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/schedule/schedule.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/search/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1386 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/search/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5793 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/search/golden_section.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3425 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/search/grid_search.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9239 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/search/search.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/search/visualize/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1829 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/search/visualize/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7925 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/search/visualize/cartesian.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7666 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/search/visualize/heatmap.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4789 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/search/visualize/parallel_coordinate_plot.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5115 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/search/visualize/vis_util.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3193 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/search/visualize/visualize.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/slicer/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1412 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/slicer/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3554 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/slicer/axis_slicer.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2179 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/slicer/mean_unslicer.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10974 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/slicer/slicer.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    13977 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/slicer/sliding_slicer.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/summary/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1621 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/summary/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    41454 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/summary/history.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/summary/logs/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1321 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/summary/logs/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8691 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/summary/logs/log_parse.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    33817 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/summary/logs/log_plot.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9909 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/summary/summary.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    18385 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/summary/system.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/test/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/test/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2840 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/test/nightly_util.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10332 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/test/unittest_util.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/trace/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1410 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/trace/adapt/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1678 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/adapt/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3867 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/adapt/early_stopping.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5530 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/adapt/lr_scheduler.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5503 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/adapt/pbm_calibrator.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3605 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/adapt/reduce_lr_on_plateau.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3453 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/adapt/terminate_on_nan.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/trace/io/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2539 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/io/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7889 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/io/batch_display.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4992 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/io/best_model_saver.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9018 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/trace/io/csv_logger.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5271 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/io/grid_display.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3490 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/io/image_saver.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3056 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/io/image_viewer.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3908 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/io/model_saver.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4974 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/io/restore_wizard.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    23746 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/trace/io/tensorboard.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    22579 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/io/test_report.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    43469 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/trace/io/traceability.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/trace/meta/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      965 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/meta/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3967 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/meta/_per_ds.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/trace/metric/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2419 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/metric/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4100 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/metric/accuracy.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8151 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/metric/auc.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10591 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/metric/bleu_score.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5417 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/metric/calibration_error.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4839 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/metric/confusion_matrix.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8372 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/metric/dice.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4950 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/metric/f1_score.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5061 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/trace/metric/mcc.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    18372 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/trace/metric/mean_average_precision.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4895 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/metric/precision.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4866 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/metric/recall.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    21156 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/trace.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/trace/xai/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1588 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/xai/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10667 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/xai/eigen_cam.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7808 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/xai/grad_cam.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7266 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/xai/instance_tracker.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6905 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/xai/label_tracker.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9267 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/trace/xai/saliency.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/types/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5119 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/types/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/util/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4218 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/util/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    27829 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/util/base_util.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4225 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/util/cli_util.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4347 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/util/data.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3861 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/util/google_download_util.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    31984 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/util/img_data.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8260 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/util/latex_util.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    58481 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/util/traceability_util.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    19845 2023-07-25 18:41:50.000000 fastestimator-1.6.0/fastestimator/util/util.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5366 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/util/wget_util.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator/xai/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1030 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/xai/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    12171 2023-04-28 17:54:33.000000 fastestimator-1.6.0/fastestimator/xai/saliency.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator.egg-info/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      594 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator.egg-info/PKG-INFO
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    36004 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator.egg-info/SOURCES.txt
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)        1 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator.egg-info/dependency_links.txt
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)       63 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator.egg-info/entry_points.txt
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      718 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator.egg-info/requires.txt
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)       19 2023-07-25 19:02:24.000000 fastestimator-1.6.0/fastestimator.egg-info/top_level.txt
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)       38 2023-07-25 19:02:24.000000 fastestimator-1.6.0/setup.cfg
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4700 2023-07-25 18:41:50.000000 fastestimator-1.6.0/setup.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/backend/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/backend/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1665 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/backend/test_get_lr.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3584 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/backend/test_save_model_load_model.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1694 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/backend/test_set_lr.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4617 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/backend/test_update_model.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/cli/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/cli/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4980 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/cli/test_main.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1883 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/cli/test_train.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/dataset/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/dataset/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2376 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/dataset/test_batch_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    11055 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/integration_test/dataset/test_interleave_dataset.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/meta/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/meta/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3002 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/meta/test_fuse.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2190 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/meta/test_one_of.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1975 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/meta/test_repeat.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1950 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/meta/test_sometimes.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/multivariate/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/multivariate/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1615 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/multivariate/test_read_mat.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/univariate/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/univariate/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2342 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/univariate/test_hadamard.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2054 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/univariate/test_read_image.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/augmentation/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/augmentation/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5170 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/augmentation/test_cutmix_batch.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/gradient/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/gradient/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2144 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/gradient/test_fgsm.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3632 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/gradient/test_gradientop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2076 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/gradient/test_watch.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4052 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/test_cross_entropy.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1836 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/test_hinge.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3065 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/test_l1_loss.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10341 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/test_l2_regularization.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1810 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/test_mean_squared_error.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8292 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/test_super_loss.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/meta/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/meta/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2673 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/meta/test_fuse.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2632 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/meta/test_one_of.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2511 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/meta/test_repeat.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2408 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/meta/test_sometimes.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/model/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/model/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7189 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/model/test_modelop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    22429 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/model/test_updateop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1592 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/test_argmax.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1613 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/test_average.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1650 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/test_reshape.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4149 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/test_un_hadamard.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1190 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/op/test_op.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/schedule/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/schedule/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3971 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/schedule/test_arc.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    13590 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/schedule/test_epoch_scheduler.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    14280 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/schedule/test_repeat_scheduler.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1742 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/schedule/test_schedule.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/search/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/search/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/search/visualize/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/search/visualize/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5667 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/search/visualize/test_visualize.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/slicer/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/integration_test/slicer/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7128 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/integration_test/slicer/test_axis_slicer.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3281 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/integration_test/slicer/test_slicer.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4719 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/integration_test/slicer/test_sliding_slicer.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/summary/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/summary/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    11980 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/summary/test_history.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    17978 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/summary/test_system.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    23833 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/test_estimator.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    28311 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/test_network.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)   100833 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/integration_test/test_pipeline.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2952 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/test_early_stopping.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4333 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/test_lr_scheduler.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3709 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/test_pbm_calibrator.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3934 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/test_reduce_lr_on_plateau.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5057 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/test_terminate_on_nan.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4296 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_batch_display.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4498 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_best_model_saver.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7106 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_csv_logger.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2822 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_image_saver.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2021 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_image_viewer.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8180 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_model_saver.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4049 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_restore_wizard.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3146 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_saliency.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8730 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_tensorboard.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    13603 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_test_report.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6037 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_traceability.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4671 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_accuracy.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3818 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_calibration_error.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8046 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_confusion_matrix.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2045 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_dice.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8699 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_f1_score.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7268 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_mcc.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3575 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_mean_average_precision.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8730 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_precision.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8644 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_recall.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2273 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/test_eval_essential.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3771 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/test_logger.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2273 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/test_test_essential.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4778 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/test_trace.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3023 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/test_train_essential.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/xai/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      702 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/xai/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9440 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/xai/test_instance_tracker.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8956 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/trace/xai/test_label_tracker.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/integration_test/util/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/util/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1938 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/util/test_img_data.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    11100 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/util/test_traceability_util.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6428 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/integration_test/util/test_util.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2991 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/test_attention_unet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2086 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/test_lenet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1950 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/test_resnet9.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2514 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/test_unet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1225 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/test_wideresnet.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2280 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/test_attention_unet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2180 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/test_lenet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2143 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/test_resnet9.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2174 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/test_unet.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1280 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/test_wideresnet.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1451 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_abs.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2269 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_argmax.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6396 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_binary_crossentropy.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2682 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_cast.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     6604 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_categorical_crossentropy.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2531 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_check_nan.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2812 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_clip_by_value.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2477 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_concat.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     8362 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_dice_score.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1471 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_exp.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2267 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_expand_dims.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1475 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_feed_forward.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2499 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_gather.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3014 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_gather_from_batch.py
+-rwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)     3742 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_get_gradient.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1499 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_get_image_dims.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1657 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_hinge.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5710 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_iwd.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1939 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_lambertw.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1518 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_matmul.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1479 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_maximum.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1824 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_mean_squared_error.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1596 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_ones_like.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     9198 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_percentile.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2662 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_permute.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1466 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_pow.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2211 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_random_normal_like.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2225 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_random_uniform_like.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1964 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reduce_max.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1979 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reduce_mean.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1960 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reduce_min.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1909 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reduce_std.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1958 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reduce_sum.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1926 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reshape.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2645 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_resize3d.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3089 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_roll.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2029 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_sign.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3534 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_sparse_categorical_crossentropy.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2305 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_squeeze.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2783 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_tensor_normalize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2536 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_tensor_pow.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2182 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_tensor_round.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2202 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_tensor_sqrt.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1679 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_to_shape.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3038 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_to_tensor.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2509 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_to_type.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1499 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_transpose.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1600 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_watch.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1557 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_where.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1604 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_zeros_like.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1463 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/backend/test_zscore.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/cli/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/cli/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1494 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/cli/test_cli_util.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1874 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_batch_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2888 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_combine_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4975 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_csv_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2420 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_data.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1383 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_dir_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1559 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_extend_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1076 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_generator_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7131 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_interleave_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1393 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_labeled_dir_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    13000 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_numpy_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      983 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_pickle_dataset.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1517 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_siamese_dir_dataset.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/layers/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/layers/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/layers/pytorch/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/layers/pytorch/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1675 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/layers/pytorch/test_cropping_2d.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3029 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/layers/pytorch/test_hadamard.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/layers/tensorflow/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/layers/tensorflow/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2903 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/layers/tensorflow/test_hadamard.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1157 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/layers/tensorflow/test_instance_norm.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1628 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/layers/tensorflow/test_reflection_padding_2d.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/loss/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/loss/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3752 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/loss/test_focal_loss.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/meta/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/meta/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1864 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/meta/test_fuse.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3212 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/meta/test_one_of.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5323 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/meta/test_repeat.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2117 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/meta/test_sometimes.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2012 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_affine.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2092 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_center_crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2122 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1590 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_crop_non_empy_mask_if_exists.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2057 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_elastic_transform.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1989 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_flip.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2053 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_grid_distortion.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2073 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_horizontal_flip.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2049 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_iaa_crop_and_pad.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2109 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_longest_max_size.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2157 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_mask_dropout.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2097 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_optical_distortion.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2021 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_pad_if_needed.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2160 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1820 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_crop_near_bbox.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2073 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_grid_shuffle.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2196 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_resized_crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2065 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_rotate_90.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1653 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_scale.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2851 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_sized_bbox_safe_crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2390 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_sized_crop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2128 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_resize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2005 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_rotate.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2057 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_shift_scale_rotate.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2123 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_smallest_max_size.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2029 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_transpose.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2057 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_vertical_flip.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1494 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/test_numpyop.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2165 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_autocontrast.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1591 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_binarize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1970 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_blur.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2149 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_brightness.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2644 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_calibrate.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2054 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_channel_dropout.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2054 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_channel_shuffle.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2061 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_channel_transpose.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2093 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_clahe.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2037 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_coarse_dropout.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2109 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_color.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2078 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_color_jitter.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2133 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_contrast.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2001 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_downscale.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2117 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_equalize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1602 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_expand_dims.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2001 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_fromfloat.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2029 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_gaussian_blur.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2037 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_gaussian_noise.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2181 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_hue_saturation_value.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2124 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_iaa_additive_gaussian_noise.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2161 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_image_compression.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2059 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_invert_img.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2117 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_iso_noise.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2070 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_median_blur.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1559 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_minmax.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2070 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_motion_blur.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2045 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_multiplicative_noise.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2001 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_normalize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2258 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_onehot.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2113 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_pad_sequence.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2125 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_posterize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2186 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_brightness_contrast.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2062 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_fog.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2021 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_gamma.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2070 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_rain.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2086 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_shadow.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3662 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_shapes.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2070 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_snow.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2106 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_sun_flare.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1586 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_reshape.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1997 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_rgb_shift.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2107 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_rua.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2141 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_sharpness.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2121 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_shear_x.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2121 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_shear_y.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2050 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_solarize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1199 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_to_array.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2046 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_to_float.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2038 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_to_gray.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1989 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_to_sepia.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2417 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_tokenize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2153 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_translate_x.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2153 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_translate_y.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2222 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_word_to_id.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/augmentation/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/augmentation/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4002 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/augmentation/test_mixup_batch.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/meta/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/meta/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2783 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/meta/test_fuse.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7142 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/meta/test_one_of.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    15616 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/meta/test_repeat.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4632 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/meta/test_sometimes.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5434 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/test_normalize.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3686 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/test_resize3d.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1296 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/test_tensorop.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2279 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/op/test_op.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/schedule/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/schedule/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1315 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/schedule/test_epoch_scheduler.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1607 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/schedule/test_lr_schedule.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1188 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/schedule/test_repeat_scheduler.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/search/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/search/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1803 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/search/test_golden_section_search.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1753 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/search/test_grid_search.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4279 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/search/test_search.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/slicer/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/unit_test/slicer/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     7315 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/unit_test/slicer/test_axis_slicer.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1621 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/unit_test/slicer/test_mean_slicer.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4196 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/unit_test/slicer/test_slicer.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    22534 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/unit_test/slicer/test_sliding_slicer.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/summary/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/summary/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/summary/logs/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/summary/logs/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3794 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/summary/logs/test_metrics.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    10448 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/summary/test_history.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4160 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/summary/test_summary.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/test/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/test/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4942 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/test/test_unittest_util.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/trace/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/trace/__init__.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/trace/metric/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/trace/metric/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     4787 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/trace/metric/test_auc_score.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3591 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/trace/metric/test_bleu_score.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/types/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/unit_test/types/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     3377 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/unit_test/types/test_types.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/util/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/util/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1278 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/util/test_data.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     5530 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/util/test_traceability_util.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)    19505 2023-07-25 18:41:50.000000 fastestimator-1.6.0/test/PR_test/unit_test/util/test_util.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1018 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/util/test_wget_util.py
+drwxrwxr-x   0 xiaomeng  (1001) xiaomeng  (1001)        0 2023-07-25 19:02:24.000000 fastestimator-1.6.0/test/PR_test/unit_test/xai/
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/xai/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     2825 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/PR_test/unit_test/xai/test_saliency.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)      692 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/__init__.py
+-rw-rw-r--   0 xiaomeng  (1001) xiaomeng  (1001)     1255 2023-04-28 17:54:33.000000 fastestimator-1.6.0/test/run_pr_test.py
```

### Comparing `fastestimator-1.5.2/README.md` & `fastestimator-1.6.0/README.md`

 * *Files 10% similar despite different names*

```diff
@@ -1,132 +1,145 @@
 # FastEstimator
+
 <p align="center">
-  <img src="./tutorial/resources/icon.png" title="we are cool">
+  <img src="https://github.com/fastestimator-util/fastestimator-misc/blob/master/resource/pictures/icon.png?raw=true" title="we are cool">
 </p>
 
 [![License](https://img.shields.io/badge/License-Apache_2.0-informational.svg)](LICENSE)
 [![Build Status](http://jenkins.fastestimator.org:8080/buildStatus/icon?subject=PR-build&job=fastestimator%2Ffastestimator%2Fmaster)](http://jenkins.fastestimator.org:8080/job/fastestimator/job/fastestimator/job/master/)
 [![Build Status](http://jenkins.fastestimator.org:8080/buildStatus/icon?subject=nightly-build&job=nightly)](http://jenkins.fastestimator.org:8080/job/nightly/)
 [![Codacy Badge](https://app.codacy.com/project/badge/Grade/3a46ea86b8f04caab271f2a7bd6f4bd9)](https://www.codacy.com/gh/fastestimator/fastestimator/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=fastestimator/fastestimator&amp;utm_campaign=Badge_Grade)
 [![Codacy Badge](https://app.codacy.com/project/badge/Coverage/3a46ea86b8f04caab271f2a7bd6f4bd9)](https://www.codacy.com/gh/fastestimator/fastestimator/dashboard?utm_source=github.com&utm_medium=referral&utm_content=fastestimator/fastestimator&utm_campaign=Badge_Coverage)
 [![PyPI version](https://badge.fury.io/py/fastestimator.svg)](https://pypi.org/project/fastestimator/)
 [![PyPI stable Download](https://img.shields.io/pypi/dm/fastestimator?label=stable%20downloads&color=16D1B4)](https://pypistats.org/packages/fastestimator)
 [![PyPI stable Download](https://img.shields.io/pypi/dm/fastestimator-nightly?label=nightly%20downloads&color=16D1B4)](https://pypistats.org/packages/fastestimator-nightly)
 
-
 FastEstimator is a high-level deep learning library built on TensorFlow2 and PyTorch. With the help of FastEstimator, you can easily build a high-performance deep learning model and run it anywhere. :wink:
 
 For more information, please visit our [website](https://www.fastestimator.org/).
 
-## Installation:
-### Prerequisites
-* Python 3.7 - 3.9
-* Nvidia Driver >= 450 (GPU only)
-* CUDA >= 11.0 (GPU only)
+## Support Matrix
+
+| FastEstimator  | Python | TensorFlow | PyTorch | CUDA |  Installation Instruction |
+| -------------  | ------  | --------- | ------- | ---- | ----------- |
+| Nightly  | 3.8-3.10  | 2.11.1 | 2.0.1 | 11.8 | master branch |
+| 1.6 (recent stable) | 3.8-3.10  | 2.11.1 | 2.0.1 | 11.8 | [r1.6 branch](https://github.com/fastestimator/fastestimator/tree/r1.6) |
+| 1.5  | 3.7-3.9  | 2.9.1 | 1.10.2 | 11.0 | [r1.5 branch](https://github.com/fastestimator/fastestimator/tree/r1.5) |
+| 1.4  | 3.6-3.8  | 2.4.1 | 1.7.1 | 11.0 | [r1.4 branch](https://github.com/fastestimator/fastestimator/tree/r1.4) |
+| 1.3  | 3.6-3.8  | 2.4.1 | 1.7.1 | 11.0 | [r1.3 branch](https://github.com/fastestimator/fastestimator/tree/r1.3) |
+| 1.2  | 3.6-3.8  | 2.4.1 | 1.7.1 | 11.0 | [r1.2 branch](https://github.com/fastestimator/fastestimator/tree/r1.2) |
+| 1.1  | 3.6-3.8  | 2.3.0 | 1.6.0 | 10.1 | [r1.1 branch](https://github.com/fastestimator/fastestimator/tree/r1.1) |
 
-### 1. Install Dependencies:
+## Installation
+
+### 1. Install Dependencies
 
 * Install TensorFlow
-    * Linux/MAC:
-        ```bash
-        pip install tensorflow==2.9.1
-        ```
-    * Windows:
-        Please follow [this](https://github.com/fastestimator/fastestimator/blob/master/installation_docs/tensorflow_windows_installation.md) installation guide.
+  * Linux:
+
+      ```bash
+      pip install tensorflow==2.11.1
+      ```
+
+  * Mac (M1/M2):
+        Please follow this [installation guide](https://github.com/fastestimator/fastestimator/blob/master/installation_docs/mac_installation.md)
+
+  * Windows:
+        Please follow this [installation guide](https://github.com/fastestimator/fastestimator/blob/master/installation_docs/tensorflow_windows_installation.md)
 
 * Install PyTorch
-    * CPU:
-        ```bash
-        pip install torch==1.10.2+cpu torchvision==0.11.3+cpu torchaudio==0.10.2+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html
-        ```
-    * GPU:
-        ```bash
-        pip install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchaudio==0.10.2+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html
-        ```
+  * CPU:
+
+      ```bash
+      pip install torch==2.0.1+cpu torchvision==0.15.2+cpu torchaudio==2.0.2+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html
+      ```
+
+  * GPU:
+
+      ```bash
+      pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 -f https://download.pytorch.org/whl/cu118/torch_stable.html
+      ```
+
 * Extra Dependencies:
-    * Windows:
+  * Windows:
+    * Install Build Tools for Visual Studio 2019 [here](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2019).
 
-        * Install Build Tools for Visual Studio 2019 [here](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2019).
+    * Install latest Visual C++ redistributable [here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) and choose x86 for 32 bit OS, x64 for 64 bit OS.
 
-        * Install latest Visual C++ redistributable [here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) and choose x86 for 32 bit OS, x64 for 64 bit OS.
+  * Linux:
 
-    * Linux:
-        ``` bash
-        $ apt-get install libglib2.0-0 libsm6 libxrender1 libxext6
-        ```
+      ``` bash
+      apt-get install libglib2.0-0 libsm6 libxrender1 libxext6
+      ```
 
-    * Mac:
-        ``` bash
-        $ echo No extra dependency needed ":)"
-        ```
+  * Mac:
+    * Please follow this [installation guide](https://github.com/fastestimator/fastestimator/blob/master/installation_docs/mac_installation.md)
 
-### 2. Install FastEstimator:
-* Stable (Linux/Mac):
-    ``` bash
-    $ pip install fastestimator
-    ```
+### 2. Install FastEstimator
 
-* Stable (Windows):
+* Stable:
 
-    First download zip file from [available releases](https://github.com/fastestimator/fastestimator/releases)
     ``` bash
-    $ pip install fastestimator-x.x.x.zip
+    pip install fastestimator
     ```
 
 * Nightly (Linux/Mac):
-    ``` bash
-    $ pip install fastestimator-nightly
-    ```
-
-* Nightly (Windows):
 
-    First download zip file [here](https://github.com/fastestimator/fastestimator/archive/master.zip)
     ``` bash
-    $ pip install fastestimator-master.zip
+    pip install fastestimator-nightly
     ```
 
-
-
 ## Docker Hub
+
 Docker containers create isolated virtual environments that share resources with a host machine. Docker provides an easy way to set up a FastEstimator environment. You can simply pull our image from [Docker Hub](https://hub.docker.com/r/fastestimator/fastestimator/tags) and get started:
+
 * Stable:
-    * GPU:
-        ``` bash
-        docker pull fastestimator/fastestimator:latest-gpu
-        ```
-    * CPU:
-        ``` bash
-        docker pull fastestimator/fastestimator:latest-cpu
-        ```
+  * GPU:
+
+      ``` bash
+      docker pull fastestimator/fastestimator:latest-gpu
+      ```
+
+  * CPU:
+
+      ``` bash
+      docker pull fastestimator/fastestimator:latest-cpu
+      ```
+
 * Nighly:
-    * GPU:
-        ``` bash
-        docker pull fastestimator/fastestimator:nightly-gpu
-        ```
-    * CPU:
-        ``` bash
-        docker pull fastestimator/fastestimator:nightly-cpu
-        ```
+  * GPU:
+
+      ``` bash
+      docker pull fastestimator/fastestimator:nightly-gpu
+      ```
+
+  * CPU:
+
+      ``` bash
+      docker pull fastestimator/fastestimator:nightly-cpu
+      ```
+
+## Useful Links
 
-## Useful Links:
 * [Website](https://www.fastestimator.org): More info about FastEstimator API and news.
 * [Tutorial Series](https://github.com/fastestimator/fastestimator/tree/master/tutorial): Everything you need to know about FastEstimator.
 * [Application Hub](https://github.com/fastestimator/fastestimator/tree/master/apphub): End-to-end deep learning examples in FastEstimator.
 
-
-
 ## Citation
+
 Please cite FastEstimator in your publications if it helps your research:
+
 ```
 @misc{fastestimator,
   title  = {FastEstimator: A Deep Learning Library for Fast Prototyping and Productization},
   author = {Xiaomeng Dong and Junpyo Hong and Hsi-Ming Chang and Michael Potter and Aritra Chowdhury and
             Purujit Bahl and Vivek Soni and Yun-Chan Tsai and Rajesh Tamada and Gaurav Kumar and Caroline Favart and
             V. Ratna Saripalli and Gopal Avinash},
   note   = {NeurIPS Systems for ML Workshop},
   year   = {2019},
   url    = {http://learningsys.org/neurips19/assets/papers/10_CameraReadySubmission_FastEstimator_final_camera.pdf}
 }
 ```
 
 ## License
+
 [Apache License 2.0](https://github.com/fastestimator/fastestimator/blob/master/LICENSE)
```

### Comparing `fastestimator-1.5.2/fastestimator/__init__.py` & `fastestimator-1.6.0/fastestimator/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,14 +21,15 @@
     # Block the tkinter module from being imported on Mac. This is necessary in order for Mac multiprocessing to work,
     # since other modules such as nltk import tkinter, and it seems more likely that AI developers will need
     # multiprocessing than tkinter.
     sys.modules['tkinter'] = None
 
 # Fix known bugs with libraries which use multiprocessing in a way which conflicts with pytorch data loader
 import cv2
+
 cv2.setNumThreads(0)
 try:
     import SimpleITK as sitk
     sitk.ProcessObject.SetGlobalDefaultNumberOfThreads(1)
 except ModuleNotFoundError:
     pass
 
@@ -45,15 +46,15 @@
 if TYPE_CHECKING:
     # Allow IDEs to play nice with lazy loading
     from fastestimator import architecture, backend, dataset, layers, op, schedule, search, summary, trace, util, xai
     from fastestimator.estimator import Estimator, enable_deterministic, record_history
     from fastestimator.network import Network, build
     from fastestimator.pipeline import Pipeline
 
-__version__ = '1.5.2'
+__version__ = '1.6.0'
 fe_deterministic_seed = None
 fe_history_path = None  # Where to save training histories. None for ~/fastestimator_data/history.db, False to disable
 fe_build_count = 0
 
 # Disable history logging for tests by default (they can still turn it on/off manually in setUpClass/tearDownClass)
 if __name__ != '__main__':
     for frame in inspect.stack()[1:]:
```

### Comparing `fastestimator-1.5.2/fastestimator/architecture/__init__.py` & `fastestimator-1.6.0/fastestimator/architecture/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/architecture/pytorch/__init__.py` & `fastestimator-1.6.0/fastestimator/architecture/pytorch/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/architecture/pytorch/attention_unet.py` & `fastestimator-1.6.0/fastestimator/architecture/pytorch/attention_unet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/architecture/pytorch/lenet.py` & `fastestimator-1.6.0/fastestimator/architecture/pytorch/lenet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/architecture/pytorch/resnet9.py` & `fastestimator-1.6.0/fastestimator/architecture/pytorch/resnet9.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/architecture/pytorch/unet.py` & `fastestimator-1.6.0/fastestimator/architecture/pytorch/unet.py`

 * *Files 3% similar despite different names*

```diff
@@ -58,15 +58,15 @@
     """
     def __init__(self, in_channels: int, mid_channels: int, out_channels: int) -> None:
         super().__init__()
         self.layers = nn.Sequential(nn.Conv2d(in_channels, mid_channels, 3, padding=1),
                                     nn.ReLU(inplace=True),
                                     nn.Conv2d(mid_channels, mid_channels, 3, padding=1),
                                     nn.ReLU(inplace=True),
-                                    nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
+                                    nn.Upsample(scale_factor=2),
                                     nn.Conv2d(mid_channels, out_channels, 3, padding=1),
                                     nn.ReLU(inplace=True))
 
         for layer in self.layers:
             if isinstance(layer, nn.Conv2d):
                 he_normal(layer.weight.data)
                 layer.bias.data.zero_()
@@ -78,20 +78,21 @@
 class UNet(nn.Module):
     """A standard UNet implementation in PyTorch.
 
     This class is intentionally not @traceable (models and layers are handled by a different process).
 
     Args:
         input_size: The size of the input tensor (channels, height, width).
+        output_channel: The number of output channels.
 
     Raises:
         ValueError: Length of `input_size` is not 3.
         ValueError: `input_size`[1] or `input_size`[2] is not a multiple of 16.
     """
-    def __init__(self, input_size: Tuple[int, int, int] = (1, 128, 128)) -> None:
+    def __init__(self, input_size: Tuple[int, int, int] = (1, 128, 128), output_channel: int = 1) -> None:
         UNet._check_input_size(input_size)
         super().__init__()
         self.input_size = input_size
         self.enc1 = UNetEncoderBlock(in_channels=input_size[0], out_channels=64)
         self.enc2 = UNetEncoderBlock(in_channels=64, out_channels=128)
         self.enc3 = UNetEncoderBlock(in_channels=128, out_channels=256)
         self.enc4 = UNetEncoderBlock(in_channels=256, out_channels=512)
@@ -99,15 +100,15 @@
         self.dec4 = UNetDecoderBlock(in_channels=1024, mid_channels=512, out_channels=256)
         self.dec3 = UNetDecoderBlock(in_channels=512, mid_channels=256, out_channels=128)
         self.dec2 = UNetDecoderBlock(in_channels=256, mid_channels=128, out_channels=64)
         self.dec1 = nn.Sequential(nn.Conv2d(128, 64, 3, padding=1),
                                   nn.ReLU(inplace=True),
                                   nn.Conv2d(64, 64, 3, padding=1),
                                   nn.ReLU(inplace=True),
-                                  nn.Conv2d(64, 1, 1),
+                                  nn.Conv2d(64, output_channel, 1),
                                   nn.Sigmoid())
 
         for layer in self.dec1:
             if isinstance(layer, nn.Conv2d):
                 he_normal(layer.weight.data)
                 layer.bias.data.zero_()
```

### Comparing `fastestimator-1.5.2/fastestimator/architecture/pytorch/wideresnet.py` & `fastestimator-1.6.0/fastestimator/architecture/pytorch/wideresnet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/architecture/tensorflow/__init__.py` & `fastestimator-1.6.0/fastestimator/architecture/tensorflow/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/architecture/tensorflow/attention_unet.py` & `fastestimator-1.6.0/fastestimator/architecture/tensorflow/attention_unet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/architecture/tensorflow/lenet.py` & `fastestimator-1.6.0/fastestimator/architecture/tensorflow/lenet.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,18 +8,22 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Tuple
+from typing import TYPE_CHECKING, Tuple
 
 import tensorflow as tf
-from tensorflow.keras import Sequential, layers
+
+if TYPE_CHECKING:
+    from tensorflow.python.keras import Sequential, layers
+else:
+    from tensorflow.keras import Sequential, layers
 
 
 # noinspection PyPep8Naming
 def LeNet(input_shape: Tuple[int, int, int] = (28, 28, 1), classes: int = 10) -> tf.keras.Model:
     """A standard LeNet implementation in TensorFlow.
 
     The LeNet model has 3 convolution layers and 2 dense layers.
```

### Comparing `fastestimator-1.5.2/fastestimator/architecture/tensorflow/resnet9.py` & `fastestimator-1.6.0/fastestimator/architecture/tensorflow/resnet9.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/architecture/tensorflow/unet.py` & `fastestimator-1.6.0/fastestimator/architecture/tensorflow/unet.py`

 * *Files 6% similar despite different names*

```diff
@@ -16,19 +16,20 @@
 
 import tensorflow as tf
 from tensorflow.keras.layers import Conv2D, Dropout, Input, MaxPooling2D, UpSampling2D, concatenate
 from tensorflow.keras.models import Model
 
 
 # noinspection PyPep8Naming
-def UNet(input_size: Tuple[int, int, int] = (128, 128, 1)) -> tf.keras.Model:
+def UNet(input_size: Tuple[int, int, int] = (128, 128, 1), output_channel: int = 1) -> tf.keras.Model:
     """A standard UNet implementation in TensorFlow
 
     Args:
         input_size: The size of the input tensor (height, width, channels).
+        output_channel: The number of output channels.
 
     Raises:
         ValueError: Length of `input_size` is not 3.
         ValueError: `input_size`[0] or `input_size`[1] is not a multiple of 16.
 
     Returns:
         A TensorFlow UNet model.
@@ -73,15 +74,15 @@
     conv8 = Conv2D(128, 3, **conv_config)(merge8)
     conv8 = Conv2D(128, 3, **conv_config)(conv8)
 
     up9 = Conv2D(64, 3, **conv_config)(UpSampling2D(**up_config)(conv8))
     merge9 = concatenate([conv1, up9], axis=-1)
     conv9 = Conv2D(64, 3, **conv_config)(merge9)
     conv9 = Conv2D(64, 3, **conv_config)(conv9)
-    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)
+    conv10 = Conv2D(output_channel, 1, activation='sigmoid')(conv9)
     model = Model(inputs=inputs, outputs=conv10)
     return model
 
 
 def _check_input_size(input_size):
     if len(input_size) != 3:
         raise ValueError("Length of `input_size` is not 3 (channel, height, width)")
```

### Comparing `fastestimator-1.5.2/fastestimator/architecture/tensorflow/wideresnet.py` & `fastestimator-1.6.0/fastestimator/architecture/tensorflow/wideresnet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/__init__.py` & `fastestimator-1.6.0/fastestimator/backend/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -74,14 +74,15 @@
                                                           '_tensor_sqrt': ['tensor_sqrt'],
                                                           '_to_shape': ['to_shape'],
                                                           '_to_tensor': ['to_tensor'],
                                                           '_to_type': ['to_type'],
                                                           '_transpose': ['transpose'],
                                                           '_update_model': ['update_model'],
                                                           '_watch': ['watch'],
+                                                          '_where': ['where'],
                                                           '_zeros_like': ['zeros_like'],
                                                           '_zscore': ['zscore'],
                                                           })
 
 if TYPE_CHECKING:
     from fastestimator.backend._abs import abs
     from fastestimator.backend._argmax import argmax
@@ -140,9 +141,10 @@
     from fastestimator.backend._tensor_sqrt import tensor_sqrt
     from fastestimator.backend._to_shape import to_shape
     from fastestimator.backend._to_tensor import to_tensor
     from fastestimator.backend._to_type import to_type
     from fastestimator.backend._transpose import transpose
     from fastestimator.backend._update_model import update_model
     from fastestimator.backend._watch import watch
+    from fastestimator.backend._where import where
     from fastestimator.backend._zeros_like import zeros_like
     from fastestimator.backend._zscore import zscore
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_abs.py` & `fastestimator-1.6.0/fastestimator/backend/_sign.py`

 * *Files 10% similar despite different names*

```diff
@@ -17,45 +17,45 @@
 import numpy as np
 import tensorflow as tf
 import torch
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor, np.ndarray)
 
 
-def abs(tensor: Tensor) -> Tensor:
-    """Compute the absolute value of a tensor.
+def sign(tensor: Tensor) -> Tensor:
+    """Compute the sign of a tensor.
 
     This method can be used with Numpy data:
     ```python
     n = np.array([-2, 7, -19])
-    b = fe.backend.abs(n)  # [2, 7, 19]
+    b = fe.backend.sign(n)  # [-1, 1, -1]
     ```
 
     This method can be used with TensorFlow tensors:
     ```python
     t = tf.constant([-2, 7, -19])
-    b = fe.backend.abs(t)  # [2, 7, 19]
+    b = fe.backend.sign(t)  # [-1, 1, -1]
     ```
 
     This method can be used with PyTorch tensors:
     ```python
     p = torch.tensor([-2, 7, -19])
-    b = fe.backend.abs(p)  # [2, 7, 19]
+    b = fe.backend.sign(p)  # [-1, 1, -1]
     ```
 
     Args:
         tensor: The input value.
 
     Returns:
-        The absolute value of `tensor`.
+        The sign of each value of the `tensor`.
 
     Raises:
         ValueError: If `tensor` is an unacceptable data type.
     """
     if tf.is_tensor(tensor):
-        return tf.abs(tensor)
+        return tf.sign(tensor)
     elif isinstance(tensor, torch.Tensor):
-        return torch.abs(tensor)
+        return tensor.sign()
     elif isinstance(tensor, np.ndarray):
-        return np.abs(tensor)
+        return np.sign(tensor)
     else:
         raise ValueError("Unrecognized tensor type {}".format(type(tensor)))
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_argmax.py` & `fastestimator-1.6.0/fastestimator/backend/_argmax.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_binary_crossentropy.py` & `fastestimator-1.6.0/fastestimator/backend/_binary_crossentropy.py`

 * *Files 6% similar despite different names*

```diff
@@ -26,16 +26,15 @@
 def binary_crossentropy(y_pred: Tensor,
                         y_true: Tensor,
                         from_logits: bool = False,
                         average_loss: bool = True,
                         class_weights: Optional[Weight_Dict] = None) -> Tensor:
     """Compute binary crossentropy.
 
-    This method is applicable when there are only two label classes (zero and one). There should be a single floating
-    point prediction per example.
+    This method is applicable when there are only two label classes (zero and one).
 
     This method can be used with TensorFlow tensors:
     ```python
     true = tf.constant([[1], [0], [1], [0]])
     pred = tf.constant([[0.9], [0.3], [0.8], [0.1]])
     weights = tf.lookup.StaticHashTable(
         tf.lookup.KeyValueTensorInitializer(tf.constant([1]), tf.constant([2.0])), default_value=1.0)
@@ -81,22 +80,22 @@
             sample_weights = class_weights.lookup(
                 tf.cast(tf.reshape(y_true, tf.shape(ce)), dtype=class_weights.key_dtype))
             ce = ce * sample_weights
 
         ce = tf.reshape(ce, [tf.shape(ce)[0], -1])
         ce = tf.reduce_mean(ce, 1)
     else:
-        y_true = y_true.to(torch.float)
+        y_true = y_true.to(y_pred.dtype)
         if from_logits:
             ce = torch.nn.BCEWithLogitsLoss(reduction="none")(input=y_pred, target=y_true.view(y_pred.size()))
         else:
             ce = torch.nn.BCELoss(reduction="none")(input=y_pred, target=y_true.view(y_pred.size()))
 
         if class_weights is not None:
-            sample_weights = torch.ones_like(y_true, dtype=torch.float)
+            sample_weights = torch.ones_like(y_true)
             for key in class_weights.keys():
                 sample_weights[y_true == key] = class_weights[key]
             ce = ce * sample_weights.reshape(ce.shape)
 
         ce = ce.view(ce.shape[0], -1)
         ce = torch.mean(ce, dim=1)
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_cast.py` & `fastestimator-1.6.0/fastestimator/backend/_cast.py`

 * *Files 2% similar despite different names*

```diff
@@ -74,12 +74,14 @@
             return data.type(STRING_TO_TORCH_DTYPE[dtype])
         else:
             return np.array(data, dtype=dtype)
     elif tf.is_tensor(dtype) or isinstance(dtype, torch.Tensor) or isinstance(dtype, np.ndarray):
         if tf.is_tensor(dtype):
             return tf.cast(data, dtype.dtype)
         elif isinstance(dtype, torch.Tensor):
-            return torch.tensor(data).type(dtype.dtype)
+            if isinstance(data, torch.Tensor):
+                return data.to(dtype.dtype)
+            return torch.tensor(data, dtype=dtype.dtype, device=dtype.device)
         else:
             return np.array(data, dtype=dtype.dtype)
     else:
         ValueError("Unexpected reference data type.")
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_categorical_crossentropy.py` & `fastestimator-1.6.0/fastestimator/backend/_categorical_crossentropy.py`

 * *Files 1% similar despite different names*

```diff
@@ -54,15 +54,16 @@
     b = fe.backend.categorical_crossentropy(y_pred=pred, y_true=true)  # 0.228
     b = fe.backend.categorical_crossentropy(y_pred=pred, y_true=true, average_loss=False)  # [0.223, 0.105, 0.356]
     b = fe.backend.categorical_crossentropy(y_pred=pred, y_true=true, average_loss=False, class_weights=weights)
     # [0.446, 0.105, 1.068]
     ```
 
     Args:
-        y_pred: Prediction with a shape like (Batch, C). dtype: float32 or float16.
+        y_pred: Prediction with a shape like (Batch, ..., C) for tensorflow and (Batch, C, ...) for PyTorch. dtype:
+            float32 or float16.
         y_true: Ground truth class labels with a shape like `y_pred`. dtype: int or float32 or float16.
         from_logits: Whether y_pred is from logits. If True, a softmax will be applied to the prediction.
         average_loss: Whether to average the element-wise loss.
         class_weights: Mapping of class indices to a weight for weighting the loss function. Useful when you need to pay
             more attention to samples from an under-represented class.
 
     Returns:
@@ -79,15 +80,15 @@
         if class_weights is not None:
             sample_weights = class_weights.lookup(tf.math.argmax(y_true, axis=-1, output_type=class_weights.key_dtype))
             ce = ce * sample_weights
     else:
         y_true = y_true.to(torch.float)
         ce = _categorical_crossentropy_torch(y_pred=y_pred, y_true=y_true, from_logits=from_logits)
         if class_weights is not None:
-            y_class = torch.argmax(y_true, dim=-1)
+            y_class = torch.argmax(y_true, dim=1)
             sample_weights = torch.ones_like(y_class, dtype=torch.float)
             for key in class_weights.keys():
                 sample_weights[y_class == key] = class_weights[key]
             ce = ce * sample_weights.reshape(ce.shape)
 
     if average_loss:
         ce = reduce_mean(ce)
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_check_nan.py` & `fastestimator-1.6.0/fastestimator/backend/_check_nan.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_clip_by_value.py` & `fastestimator-1.6.0/fastestimator/backend/_clip_by_value.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_concat.py` & `fastestimator-1.6.0/fastestimator/backend/_concat.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_convert_tensor_precision.py` & `fastestimator-1.6.0/fastestimator/backend/_convert_tensor_precision.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_dice_score.py` & `fastestimator-1.6.0/fastestimator/backend/_dice_score.py`

 * *Files 20% similar despite different names*

```diff
@@ -8,184 +8,157 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import TypeVar
+import math
+from typing import List, Optional, TypeVar
 
 import numpy as np
 import tensorflow as tf
+import tensorflow.keras.mixed_precision as mixed_precision
 import torch
 
+from fastestimator.backend._cast import cast
+from fastestimator.backend._reduce_max import reduce_max
 from fastestimator.backend._reduce_mean import reduce_mean
 from fastestimator.backend._reduce_sum import reduce_sum
+from fastestimator.backend._where import where
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor, np.ndarray)
 
-allowed_data_types = [
-    torch.float,
-    torch.float16,
-    torch.float32,
-    torch.float64,
-    np.float,
-    np.float16,
-    np.float32,
-    np.float64,
-    tf.float16,
-    tf.float32,
-    tf.float64
-]
 
-
-def get_denominator(y_true: Tensor, y_pred: Tensor, soft_dice: bool) -> Tensor:
-    """
-        Calculate sum/squared sum of y_true and y_pred
-
-        Args:
-            y_pred: Prediction with a shape like (Batch, C, H, W) for torch and (Batch, H, W, C) for tensorflow or numpy. dtype: float32 or float16.
-            y_true: Ground truth class labels with a shape like `y_pred`. dtype: int or float32 or float16.
-            soft_dice: Whether to add direct sum or square sum of inputs
-
-        Return:
-            The sum or squared sum of y_pred and y_true
-    """
-    if soft_dice:
-        return y_true**2 + y_pred**2
+def _get_channel_axis(tensor: Tensor) -> int:
+    if tf.is_tensor(tensor) or isinstance(tensor, np.ndarray):
+        return -1
+    elif isinstance(tensor, torch.Tensor):
+        return 1
     else:
-        return y_true + y_pred
+        raise ValueError(f"Unsupported tensor type: {type(tensor)}.")
 
 
-def get_axis(y_true: Tensor, channel_average: bool) -> Tensor:
-    """
-        Get the axis to apply reduced_sum on.
-
-        Args:
-            y_true: Ground truth class labels with a shape like (Batch, C, H, W) for torch and (Batch, H, W, C) for tensorflow or numpy. dtype: int or float32 or float16.
-            channel_average: Whether to average the channel wise dice score.
-
-        Returns:
-            The axis on which reduce_sum needs to be applied.
-    """
-    dims = len(y_true.shape)
-    if dims <= 2:
-        return None
-    else:
-        input_axis = list(range(dims))
-        axis = input_axis[1:]
-        if channel_average:
-            if tf.is_tensor(y_true) or isinstance(y_true, np.ndarray):
-                axis = input_axis[1:-1]
-            elif isinstance(y_true, torch.Tensor):
-                axis = input_axis[2:]
-            else:
-                raise ValueError("Unsupported tensor type.")
-
-        return axis
-
-
-def cast(y_true, epsilon, dtype):
-    """
-        Cast y_true, epsilon to desired data type.
-
-        Args:
-            y_true: Ground truth class labels with a shape like (Batch, C, H, W) for torch and (Batch, H, W, C) for tensorflow or numpy. dtype: int or float32 or float16.
-            epsilon: Floating point value to avoid divide by zero error.
-            dtype: Datatype to which the y_true and epsilon should be converted to.
-
-        Returns:
-            Converted y_true and epsilon values.
-
-        Raises:
-            AssertionError: If `y_true` are unacceptable data types. if data type is other than np.array, tensor.Tensor, tf.Tensor.
-    """
-    if dtype not in allowed_data_types:
-        raise ValueError("Provided datatype {} is not supported, only {} data types are supported".format(
-            dtype, allowed_data_types))
-
-    if tf.is_tensor(y_true):
-        return tf.cast(y_true, dtype), tf.cast(epsilon, dtype)
-    elif isinstance(y_true, torch.Tensor):
-        return y_true.type(dtype), torch.tensor(epsilon).type(dtype)
-    elif isinstance(y_true, np.ndarray):
-        return np.array(y_true, dtype=dtype), np.array(epsilon, dtype=dtype)
-    else:
-        raise ValueError("Unsupported tensor type.")
+def _get_spacial_axes(tensor: Tensor, channel_axis: int) -> List[int]:
+    dims = len(tensor.shape)
+    if channel_axis == -1:
+        return list(range(dims)[1:-1])
+    return list(range(dims)[2:])
 
 
 def dice_score(y_pred: Tensor,
                y_true: Tensor,
                soft_dice: bool = False,
                sample_average: bool = False,
                channel_average: bool = False,
+               channel_weights: Optional[Tensor] = None,
+               mask_overlap: bool = True,
+               threshold: Optional[float] = None,
+               empty_nan: bool = False,
                epsilon: float = 1e-6) -> Tensor:
-    """
-    Compute Dice score.
+    """Compute Dice score.
 
     This method can be used with Numpy data:
     ```python
-    true = np.array([[[[0, 1, 1], [1, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 0, 1], [1, 0, 1]]]])
-    pred = np.array([[[[0, 1, 0], [1, 0, 0], [1, 0, 1]], [[0, 1, 1], [1, 0, 1], [0, 0, 0]], [[0, 0, 1], [1, 0, 1], [1, 0, 1]]]])
-    b = fe.backend.dice_score(y_pred=pred, y_true=true)  # 0.161
-    b = fe.backend.dice_score(y_pred=pred, y_true=true, soft_dice=True)  # 0.161
-    b = fe.backend.dice_score(y_pred=pred, y_true=true, channel_average=True)  # 0.1636
-    b = fe.backend.dice_score(y_pred=pred, y_true=true, sample_average=True)  # 0.161
+    true = np.array([[[[0, 1, 1], [1, 0, 1], [1, 0, 1]],
+                      [[0, 1, 1], [1, 0, 1], [1, 0, 1]],
+                      [[0, 1, 1], [1, 0, 1], [1, 0, 1]]]])
+    pred = np.array([[[[0, 1, 0], [1, 0, 0], [1, 0, 1]],
+                      [[0, 1, 1], [1, 0, 1], [0, 0, 0]],
+                      [[0, 0, 1], [1, 0, 1], [1, 0, 1]]]])
+    b = fe.backend.dice_score(y_pred=pred, y_true=true)  # [[0.90909083, 0.79999984, 0.79999995]]
+    b = fe.backend.dice_score(y_pred=pred, y_true=true, soft_dice=True)  # [[0.90909083, 0.79999984, 0.79999995]]
+    b = fe.backend.dice_score(y_pred=pred, y_true=true, channel_average=True)  # [0.83636354]
+    b = fe.backend.dice_score(y_pred=pred, y_true=true, sample_average=True)  # [0.90909083, 0.79999984, 0.79999995]
 
     This method can be used with TensorFlow tensors:
     ```python
-    true = tf.constant([[[[0, 1, 1], [1, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 0, 1], [1, 0, 1]]]])
-    pred = tf.constant([[[[0, 1, 0], [1, 0, 0], [1, 0, 1]], [[0, 1, 1], [1, 0, 1], [0, 0, 0]], [[0, 0, 1], [1, 0, 1], [1, 0, 1]]]])
-    b = fe.backend.dice_score(y_pred=pred, y_true=true)  # 0.161
-    b = fe.backend.dice_score(y_pred=pred, y_true=true, soft_dice=True)  # 0.161
-    b = fe.backend.dice_score(y_pred=pred, y_true=true, channel_average=True)  # 0.1636
-    b = fe.backend.dice_score(y_pred=pred, y_true=true, sample_average=True)  # 0.161
+    true = tf.constant([[[[0, 1, 1], [1, 0, 1], [1, 0, 1]],
+                         [[0, 1, 1], [1, 0, 1], [1, 0, 1]],
+                         [[0, 1, 1], [1, 0, 1], [1, 0, 1]]]])
+    pred = tf.constant([[[[0, 1, 0], [1, 0, 0], [1, 0, 1]],
+                         [[0, 1, 1], [1, 0, 1], [0, 0, 0]],
+                         [[0, 0, 1], [1, 0, 1], [1, 0, 1]]]])
+    b = fe.backend.dice_score(y_pred=pred, y_true=true)  # [[0.9090908 , 0.79999983, 0.79999995]]
+    b = fe.backend.dice_score(y_pred=pred, y_true=true, soft_dice=True)  # [[0.9090908 , 0.79999983, 0.79999995]]
+    b = fe.backend.dice_score(y_pred=pred, y_true=true, channel_average=True)  # [0.83636355]
+    b = fe.backend.dice_score(y_pred=pred, y_true=true, sample_average=True)  # [0.9090908 , 0.79999983, 0.79999995]
     ```
 
     This method can be used with PyTorch tensors:
     ```python
-    true = torch.tensor([[[[0, 1, 1], [1, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 0, 1], [1, 0, 1]]]])
-    pred = torch.tensor([[[[0, 1, 0], [1, 0, 0], [1, 0, 1]], [[0, 1, 1], [1, 0, 1], [0, 0, 0]], [[0, 0, 1], [1, 0, 1], [1, 0, 1]]]])
-    b = fe.backend.dice_score(y_pred=pred, y_true=true)  # 0.161
-    b = fe.backend.dice_score(y_pred=pred, y_true=true, soft_dice=True)  # 0.161
-    b = fe.backend.dice_score(y_pred=pred, y_true=true, channel_average=True)  # 0.1636
-    b = fe.backend.dice_score(y_pred=pred, y_true=true, sample_average=True)  # 0.161
+    true = torch.tensor([[[[0, 1, 1], [1, 0, 1], [1, 0, 1]],
+                          [[0, 1, 1], [1, 0, 1], [1, 0, 1]],
+                          [[0, 1, 1], [1, 0, 1], [1, 0, 1]]]])
+    pred = torch.tensor([[[[0, 1, 0], [1, 0, 0], [1, 0, 1]],
+                          [[0, 1, 1], [1, 0, 1], [0, 0, 0]],
+                          [[0, 0, 1], [1, 0, 1], [1, 0, 1]]]])
+    b = fe.backend.dice_score(y_pred=pred, y_true=true)  # [[0.8000, 0.8000, 0.9091]]
+    b = fe.backend.dice_score(y_pred=pred, y_true=true, soft_dice=True)  # [[0.8000, 0.8000, 0.9091]]
+    b = fe.backend.dice_score(y_pred=pred, y_true=true, channel_average=True)  # [0.8364]
+    b = fe.backend.dice_score(y_pred=pred, y_true=true, sample_average=True)  # [0.8000, 0.8000, 0.9091]
     ```
 
-    ```
     Args:
-        y_pred: Prediction with a shape like (Batch, C, H, W) for torch and (Batch, H, W, C) for tensorflow or numpy. dtype: float32 or float16.
-        y_true: Ground truth class labels with a shape like `y_pred`. dtype: int or float32 or float16.
-        soft_dice: Whether to square elements. If True, square of elements is added.
-        sample_average: Whether to average the element-wise dice score.
-        channel_average: Whether to average the channel wise dice score.
+        y_pred: Prediction with a shape like (Batch, C, ...) for torch and (Batch, ..., C) for tensorflow or numpy.
+        y_true: Ground truth class labels with a shape like `y_pred`.
+        soft_dice: Whether to square elements in the denominator.
+        sample_average: Whether to average the dice score along the batch dimension.
+        channel_average: Whether to average the dice score along the channel dimension.
+        channel_weights: A tensor of weights (size 1xN_Channels) to apply to each channel before reduction.
+        mask_overlap: Whether an individual pixel can belong to only 1 class (False) or more than 1 class
+            (True). If False, a threshold of 0.0 can be used to binarize by whatever the maximum predicted class is.
+        threshold: The threshold for binarizing the prediction. Set this to 0.0 if you are using a background class. Set
+            to None if continuous values are desired (ex. for a loss).
+        empty_nan: If a target mask is totally empty (object is missing) and the prediction is also empty, should this
+            function return 0.0 (False) or NaN (True) for that particular mask channel.
         epsilon: floating point value to avoid divide by zero error.
 
     Returns:
-        The dice score between `y_pred` and `y_true`. A scalar if `average_sample` is True, else a tensor with the shape (Batch).
+        The dice score between `y_pred` and `y_true`.
 
     Raises:
-        AssertionError: If `y_true` or `y_pred` are unacceptable data types. if data type is other than np.array, tensor.Tensor, tf.Tensor.
+        AssertionError: If `y_true` or `y_pred` something other than np.array, tensor.Tensor, or tf.Tensor.
     """
-    y_true, epsilon = cast(y_true, epsilon, y_pred.dtype)
-
-    axis = get_axis(y_true, channel_average)
-
-    keep_dims = False
-    if axis == None:
-        keep_dims = True
-
-    numerator = reduce_sum(y_true * y_pred, axis=axis, keepdims=keep_dims)
+    y_true = cast(y_true, dtype=y_pred)
+    channel_axis = _get_channel_axis(y_pred)
+    spacial_axes = _get_spacial_axes(y_pred, channel_axis=channel_axis)
+
+    if not mask_overlap:
+        # Find the max prediction per channel
+        pick = reduce_max(y_pred, axis=channel_axis, keepdims=True)
+        # Assign each pixel only to the max prediction across the channels
+        y_pred = where(y_pred >= pick, y_pred, 0.0)
+    if threshold is not None:
+        # Only accept predictions which are over the given confidence threshold
+        y_pred = where(y_pred > threshold, 1.0, 0.0)
+        y_pred = cast(y_pred, dtype=y_true)
+
+    if mixed_precision.global_policy().compute_dtype == 'float16':
+        # In mixed precision large masks can be too big to reduce without overflowing. Use reduce_mean instead in such
+        # cases in both numerator and denominator: (x/N)/(y/N) = x/y
+        reduce = reduce_mean
+    else:
+        reduce = reduce_sum
 
-    denominator = get_denominator(y_true, y_pred, soft_dice)
+    numerator = reduce(y_pred * y_true, axis=spacial_axes)
 
-    denominator = reduce_sum(denominator, axis=axis, keepdims=keep_dims)
+    if soft_dice:
+        denominator = reduce(y_pred ** 2, axis=spacial_axes) + reduce(y_true ** 2, axis=spacial_axes)
+    else:
+        denominator = reduce(y_pred, axis=spacial_axes) + reduce(y_true, axis=spacial_axes)
 
-    dice_score = (2 * numerator) / (denominator + epsilon)
+    dice = 2.0 * numerator / (denominator + epsilon)  # N x C
 
+    if channel_weights is not None:
+        channel_weights = cast(channel_weights, dtype=y_pred)
+        dice = dice * channel_weights
+    if empty_nan:
+        dice = where(reduce_max(y_true, axis=spacial_axes) + reduce_max(y_pred, axis=spacial_axes) < 1e-4,
+                     math.nan,
+                     dice)
     if channel_average:
-        dice_score = reduce_mean(dice_score, axis=-1)
-
+        dice = reduce_mean(dice, axis=channel_axis)  # N
     if sample_average:
-        dice_score = reduce_mean(dice_score)
+        dice = reduce_mean(dice, axis=0)  # 1 or C
 
-    return dice_score
+    return dice
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_exp.py` & `fastestimator-1.6.0/fastestimator/backend/_exp.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_expand_dims.py` & `fastestimator-1.6.0/fastestimator/backend/_expand_dims.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_feed_forward.py` & `fastestimator-1.6.0/fastestimator/backend/_feed_forward.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_flip.py` & `fastestimator-1.6.0/fastestimator/backend/_flip.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_focal_loss.py` & `fastestimator-1.6.0/fastestimator/backend/_focal_loss.py`

 * *Files 8% similar despite different names*

```diff
@@ -64,15 +64,16 @@
 
 def focal_loss(y_true: Tensor,
                y_pred: Tensor,
                gamma: float = 2.0,
                alpha: float = 0.25,
                from_logits: bool = False,
                normalize: bool = True,
-               reduction: str = "mean") -> Tensor:
+               shape_reduction: str = "sum",
+               sample_reduction: str = "mean") -> Tensor:
     """Calculate the focal loss between two tensors.
 
     Original implementation from https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/focal_loss.py .
     Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.
 
     This method can be used with TensorFlow tensors:
     ```python
@@ -94,51 +95,64 @@
         y_true: Ground truth class labels with shape([batch_size, d0, .. dN]), which should take values of 1 or 0.
         y_pred: Prediction score for each class, with a shape like y_true. dtype: float32 or float16.
         alpha: Weighting factor in range (0,1) to balance
                 positive vs negative examples or (-1/None) to ignore. Default = 0.25
         gamma: Exponent of the modulating factor (1 - p_t) to
                balance easy vs hard examples.
         normalize: Whether to normalize focal loss along samples based on number of positive classes per samples.
+        shape_reduction:
+                 'none' | 'mean' | 'sum'
+                 'none': No reduction will be applied to the output.
+                 'mean': The output will be averaged across classes.
+                 'sum': The output will be summed across classes.
         from_logits: Whether y_pred is logits (without sigmoid).
-        reduction: 'none' | 'mean' | 'sum'
+        sample_reduction: 'none' | 'mean' | 'sum'
                  'none': No reduction will be applied to the output.
-                 'mean': The output will be averaged.
-                 'sum': The output will be summed.
+                 'mean': The output will be averaged across batch size.
+                 'sum': The output will be summed across batch size.
     Returns:
         The Focal loss between `y_true` and `y_pred`
 
     Raises:
         ValueError: If `y_pred` or 'y_true' is an unacceptable data type.
     """
     if gamma is None or gamma < 0:
         raise ValueError("Value of gamma should be greater than or equal to zero.")
 
     if alpha is None or (alpha < 0 or alpha > 1):
         raise ValueError("Value of alpha can either be -1 or None or within range (0, 1)")
 
     if tf.is_tensor(y_true):
         y_true = tf.cast(y_true, dtype=y_pred.dtype)
-        focal_loss = SigmoidFocalCrossEntropy(from_logits=from_logits,
-                                              alpha=alpha,
-                                              gamma=gamma,
-                                              reduction=tf.keras.losses.Reduction.NONE)(y_pred=y_pred, y_true=y_true)
+        fl = SigmoidFocalCrossEntropy(from_logits=from_logits,
+                                      alpha=alpha,
+                                      gamma=gamma,
+                                      reduction=tf.keras.losses.Reduction.NONE)(y_pred=y_pred, y_true=y_true)
+        gt_shape = tf.shape(y_true)
+        fl_shape = tf.shape(fl)
     elif isinstance(y_true, torch.Tensor):
         y_true = y_true.to(y_pred.dtype)
-        focal_loss = pytorch_focal_loss(y_pred=y_pred, y_true=y_true, alpha=alpha, gamma=gamma, from_logits=from_logits)
+        fl = pytorch_focal_loss(y_pred=y_pred, y_true=y_true, alpha=alpha, gamma=gamma, from_logits=from_logits)
+        gt_shape = y_true.shape
+        fl_shape = fl.shape
     else:
         raise ValueError("Unsupported tensor type.")
 
+    focal_reduce_axis = [*range(1, len(fl_shape))]
     # normalize along the batch size based on number of positive classes
     if normalize:
-        focal_reduce_axis = [*range(len(focal_loss.shape))][1:]
-        focal_loss = reduce_sum(focal_loss, axis=focal_reduce_axis)
-
-        gt_reduce_axis = [*range(len(y_true.shape))][1:]
+        gt_reduce_axis = [*range(1, len(gt_shape))]
         gt_count = clip_by_value(reduce_sum(y_true, axis=gt_reduce_axis), min_value=1)
-        focal_loss = focal_loss / gt_count
+        gt_count = gt_count[(..., ) + (None, ) * len(focal_reduce_axis)]
+        fl = fl / gt_count
 
-    if reduction == "mean":
-        focal_loss = reduce_mean(focal_loss)
-    elif reduction == "sum":
-        focal_loss = reduce_sum(focal_loss)
+    if shape_reduction == "sum":
+        fl = reduce_sum(fl, axis=focal_reduce_axis)
+    elif shape_reduction == "mean":
+        fl = reduce_mean(fl, axis=focal_reduce_axis)
+
+    if sample_reduction == "mean":
+        fl = reduce_mean(fl)
+    elif sample_reduction == "sum":
+        fl = reduce_sum(fl)
 
-    return focal_loss
+    return fl
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_gather.py` & `fastestimator-1.6.0/fastestimator/backend/_gather.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_gather_from_batch.py` & `fastestimator-1.6.0/fastestimator/backend/_gather_from_batch.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_get_gradient.py` & `fastestimator-1.6.0/fastestimator/backend/_get_gradient.py`

 * *Files 2% similar despite different names*

```diff
@@ -72,16 +72,15 @@
             gradients = tape.gradient(target, sources)
     elif isinstance(target, torch.Tensor):
         gradients = torch.autograd.grad(target,
                                         sources,
                                         grad_outputs=torch.ones_like(target),
                                         retain_graph=retain_graph,
                                         create_graph=higher_order,
-                                        allow_unused=True,
-                                        only_inputs=True)
+                                        allow_unused=True)
 
         if isinstance(sources, torch.Tensor):
             #  The behavior table of tf and torch backend
             #  ---------------------------------------------------------------
             #        | case 1                     | case 2                    |
             #  ---------------------------------------------------------------|
             #  tf    | target: tf.Tensor          | target: tf.Tensor         |
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_get_image_dims.py` & `fastestimator-1.6.0/fastestimator/backend/_get_image_dims.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_get_lr.py` & `fastestimator-1.6.0/fastestimator/backend/_get_lr.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_get_shape.py` & `fastestimator-1.6.0/fastestimator/backend/_get_shape.py`

 * *Files 10% similar despite different names*

```diff
@@ -8,24 +8,24 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import TypeVar
+from typing import Tuple
 
 import numpy as np
 import tensorflow as tf
 import torch
 
-Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor, np.ndarray)
+from fastestimator.types import Array
 
 
-def get_shape(tensor: Tensor) -> Tensor:
+def get_shape(tensor: Array) -> Tuple[int, ...]:
     """Find shape of a given `tensor`.
 
     This method can be used with Numpy data:
     ```python
     n = np.array([[[0, 1], [2, 3]], [[4, 5], [6, 7]], [[8, 9], [10, 11]]])
     b = fe.backend.get_shape(n)  # [3,2,2]
     ```
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_hinge.py` & `fastestimator-1.6.0/fastestimator/backend/_hinge.py`

 * *Files 14% similar despite different names*

```diff
@@ -47,9 +47,9 @@
 
     Returns:
         The hinge loss between `y_true` and `y_pred`
 
     Raises:
         ValueError: If `y_pred` is an unacceptable data type.
     """
-    y_true = cast(y_true, 'float32')
+    y_true = cast(y_true, dtype=y_pred)
     return reduce_mean(clip_by_value(1.0 - y_true * y_pred, min_value=0), axis=-1)
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_huber.py` & `fastestimator-1.6.0/fastestimator/backend/_huber.py`

 * *Files 4% similar despite different names*

```diff
@@ -61,18 +61,16 @@
         ValueError: If `y_pred` is an unacceptable data type.
         ValueError: If beta is less than 1 for Smooth L1 loss and Huber Loss
     """
     if beta <= 0:
         raise ValueError("Beta cannot be less than or equal to 0")
 
     if tf.is_tensor(y_pred):
-        if y_pred.ndim == 1:
+        if tf.rank(y_pred) == 1:
             y_true = tf.expand_dims(y_true, axis=-1)
             y_pred = tf.expand_dims(y_pred, axis=-1)
-        regression_loss = tf.keras.losses.huber(y_true, y_pred, delta=beta)
-        huber_loss = reduce_mean(regression_loss, axis=[*range(len(regression_loss.shape))][1:])
+        huber_loss = tf.keras.losses.huber(y_true, y_pred, delta=beta)
     elif isinstance(y_pred, torch.Tensor):
-        huber_loss = reduce_mean(
-            torch.nn.HuberLoss(reduction="none", delta=beta)(y_pred, y_true), axis=[*range(len(y_pred.shape))][1:])
+        huber_loss = reduce_mean(torch.nn.HuberLoss(reduction="none", delta=beta)(y_pred, y_true), axis=-1)
     else:
         raise ValueError("Unrecognized tensor type {}".format(type(y_pred)))
     return huber_loss
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_iwd.py` & `fastestimator-1.6.0/fastestimator/backend/_iwd.py`

 * *Files 2% similar despite different names*

```diff
@@ -79,12 +79,12 @@
     """
     if eps is None:
         eps = np.array(pairwise_distance * math.pow((1.0 - max_prob) / (max_prob * (tensor.shape[-1] - 1)), 1 / power),
                        dtype=TENSOR_TO_NP_DTYPE[tensor.dtype])
         eps = to_tensor(
             eps, target_type='torch' if isinstance(tensor, torch.Tensor) else 'tf' if tf.is_tensor(tensor) else 'np')
         if isinstance(eps, torch.Tensor):
-            eps = eps.to("cuda:0" if torch.cuda.is_available() else "cpu")
+            eps = eps.to(tensor.device)
     tensor = maximum(tensor, eps)
     tensor = tensor_pow(1.0 / tensor, power)
     tensor = tensor / reshape(reduce_sum(tensor, axis=-1), shape=[-1, 1])
     return tensor
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_l1_loss.py` & `fastestimator-1.6.0/fastestimator/backend/_l1_loss.py`

 * *Files 6% similar despite different names*

```diff
@@ -56,18 +56,16 @@
     Returns:
         The L1 loss between `y_true` and `y_pred`.
 
     Raises:
         ValueError: If `y_pred` is an unacceptable data type.
     """
     if tf.is_tensor(y_pred):
-        if y_pred.ndim == 1:
+        if tf.rank(y_pred) == 1:
             y_true = tf.expand_dims(y_true, axis=-1)
             y_pred = tf.expand_dims(y_pred, axis=-1)
-        regression_loss = tf.keras.losses.MAE(y_true, y_pred)
-        mae = reduce_mean(regression_loss, axis=[ax for ax in range(len(regression_loss.shape))][1:])
+        mae = tf.losses.MAE(y_true, y_pred)
     elif isinstance(y_pred, torch.Tensor):
-        mae = reduce_mean(
-            torch.nn.L1Loss(reduction="none")(y_pred, y_true), axis=[ax for ax in range(len(y_pred.shape))][1:])
+        mae = reduce_mean(torch.nn.L1Loss(reduction="none")(y_pred, y_true), axis=-1)
     else:
         raise ValueError("Unrecognized tensor type {}".format(type(y_pred)))
     return mae
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_l2_regularization.py` & `fastestimator-1.6.0/fastestimator/backend/_l2_regularization.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_lambertw.py` & `fastestimator-1.6.0/fastestimator/backend/_lambertw.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_load_model.py` & `fastestimator-1.6.0/fastestimator/backend/_load_model.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_matmul.py` & `fastestimator-1.6.0/fastestimator/backend/_matmul.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_maximum.py` & `fastestimator-1.6.0/fastestimator/backend/_maximum.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_mean_squared_error.py` & `fastestimator-1.6.0/fastestimator/backend/_mean_squared_error.py`

 * *Files 1% similar despite different names*

```diff
@@ -54,12 +54,11 @@
 
     Raises:
         ValueError: If `y_pred` is an unacceptable data type.
     """
     if tf.is_tensor(y_pred):
         mse = tf.losses.MSE(y_true, y_pred)
     elif isinstance(y_pred, torch.Tensor):
-        mse = reduce_mean(
-            torch.nn.MSELoss(reduction="none")(y_pred, y_true), axis=[ax for ax in range(y_pred.ndim)][1:])
+        mse = reduce_mean(torch.nn.MSELoss(reduction="none")(y_pred, y_true), axis=-1)
     else:
         raise ValueError("Unrecognized tensor type {}".format(type(y_pred)))
     return mse
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_ones_like.py` & `fastestimator-1.6.0/fastestimator/backend/_ones_like.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_percentile.py` & `fastestimator-1.6.0/fastestimator/backend/_percentile.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_permute.py` & `fastestimator-1.6.0/fastestimator/backend/_permute.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_pow.py` & `fastestimator-1.6.0/fastestimator/backend/_pow.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_random_normal_like.py` & `fastestimator-1.6.0/fastestimator/backend/_random_normal_like.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_random_uniform_like.py` & `fastestimator-1.6.0/fastestimator/backend/_random_uniform_like.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_reduce_max.py` & `fastestimator-1.6.0/fastestimator/backend/_reduce_max.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_reduce_mean.py` & `fastestimator-1.6.0/fastestimator/backend/_reduce_mean.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_reduce_min.py` & `fastestimator-1.6.0/fastestimator/backend/_reduce_min.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_reduce_std.py` & `fastestimator-1.6.0/fastestimator/backend/_reduce_std.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_reduce_sum.py` & `fastestimator-1.6.0/fastestimator/backend/_reduce_sum.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_reshape.py` & `fastestimator-1.6.0/fastestimator/backend/_reshape.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_resize3d.py` & `fastestimator-1.6.0/fastestimator/backend/_resize3d.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,35 +8,36 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import List, TypeVar
+from typing import Sequence, TypeVar
 
 import tensorflow as tf
 import torch
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
 
 
-def resize_3d(tensor: Tensor, output_shape: List[int], resize_mode: str = 'nearest') -> Tensor:
-    """Reshape a `tensor` to conform to a given shape.
+def resize_3d(tensor: Tensor, output_shape: Sequence[int], resize_mode: str = 'nearest') -> Tensor:
+    """Reshape a `tensor` to conform to a given shape.Currently torch doesn't support 16 bit tensors on cpu.
 
     This method can be used with TensorFlow tensors:
     ```python
     t = tf.constant([[[[[0.], [1.]], [[2.], [3.]]], [[[4.], [5.]], [[6.], [7.]]]]])
     b = fe.backend.resize_3d(t, output_shape=[3, 3, 3])  # [[[[[0.], [0.], [1.], [1.]], [[0.], [0.], [1.], [1.]], [[2.], [2.], [3.], [3.]], [[2.], [2.], [3.], [3.]]],
                                                             [[[0.], [0.], [1.], [1.]], [[0.], [0.], [1.], [1.]], [[2.], [2.], [3.], [3.]], [[2.], [2.], [3.], [3.]]],
                                                             [[[4.], [4.], [5.], [5.]], [[4.], [4.], [5.], [5.]], [[6.], [6.], [7.], [7.]], [[6.], [6.], [7.], [7.]]],
                                                             [[[4.], [4.], [5.], [5.]], [[4.], [4.], [5.], [5.]], [[6.], [6.], [7.], [7.]], [[6.], [6.], [7.], [7.]]]]]
     ```
 
     This method can be used with PyTorch tensors:
+
     ```python
     p = torch.tensor([[[[[0., 1.], [2., 3.]], [[4., 5.], [6., 7.]]]]])
     b = fe.backend.resize_3d(p, output_shape=[3, 3, 3])  # [[[[[0., 0., 1., 1.], [0., 0., 1., 1.], [2., 2., 3., 3.], [2., 2., 3., 3.]],
                                                               [[0., 0., 1., 1.], [0., 0., 1., 1.], [2., 2., 3., 3.], [2., 2., 3., 3.]],
                                                               [[4., 4., 5., 5.], [4., 4., 5., 5.], [6., 6., 7., 7.], [6., 6., 7., 7.]],
                                                               [[4., 4., 5., 5.], [4., 4., 5., 5.], [6., 6., 7., 7.], [6., 6., 7., 7.]]]]]
     ```
@@ -58,15 +59,15 @@
         return resize_tensorflow_tensor(tensor, output_shape, resize_mode)
     elif isinstance(tensor, torch.Tensor):
         return torch.nn.functional.interpolate(tensor, output_shape, mode=resize_mode)
     else:
         raise ValueError("Unrecognized tensor type {}".format(type(tensor)))
 
 
-def resize_tensorflow_tensor(data: tf.Tensor, output_shape: List[int], resize_mode: str) -> tf.Tensor:
+def resize_tensorflow_tensor(data: tf.Tensor, output_shape: Sequence[int], resize_mode: str) -> tf.Tensor:
     """
         Resize tensorflow tensor
 
         Input:
             data: Input tensorflow tensor
             output_shape: (X, Y, Z) Expected output shape of tensor
     """
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_roll.py` & `fastestimator-1.6.0/fastestimator/backend/_roll.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_save_model.py` & `fastestimator-1.6.0/fastestimator/backend/_save_model.py`

 * *Files 6% similar despite different names*

```diff
@@ -66,15 +66,19 @@
         model.save_weights(model_path)
         if save_architecture:
             model.save(filepath=os.path.join(save_dir, model_name), include_optimizer=save_optimizer)
         if save_optimizer:
             assert model.current_optimizer, "optimizer does not exist"
             optimizer_path = os.path.join(save_dir, "{}_opt.pkl".format(model_name))
             with open(optimizer_path, 'wb') as f:
-                saved_data = {'weights': model.current_optimizer.get_weights(), 'lr': get_lr(model)}
+                saved_data = {'lr': get_lr(model)}
+                if hasattr(model.current_optimizer, 'get_weights'):
+                    saved_data['weights'] = model.current_optimizer.get_weights()
+                else:
+                    saved_data['weights'] = model.current_optimizer.variables()
                 if isinstance(model.current_optimizer, tfa.optimizers.DecoupledWeightDecayExtension) or hasattr(
                         model.current_optimizer, "inner_optimizer") and isinstance(
                             model.current_optimizer.inner_optimizer, tfa.optimizers.DecoupledWeightDecayExtension):
                     saved_data['weight_decay'] = tf.keras.backend.get_value(model.current_optimizer.weight_decay)
                 pickle.dump(saved_data, f)
         return model_path
     elif isinstance(model, torch.nn.Module):
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_set_lr.py` & `fastestimator-1.6.0/fastestimator/backend/_set_lr.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_sign.py` & `fastestimator-1.6.0/fastestimator/backend/_transpose.py`

 * *Files 18% similar despite different names*

```diff
@@ -17,45 +17,45 @@
 import numpy as np
 import tensorflow as tf
 import torch
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor, np.ndarray)
 
 
-def sign(tensor: Tensor) -> Tensor:
-    """Compute the sign of a tensor.
+def transpose(tensor: Tensor) -> Tensor:
+    """Transpose the `tensor`.
 
     This method can be used with Numpy data:
     ```python
-    n = np.array([-2, 7, -19])
-    b = fe.backend.sign(n)  # [-1, 1, -1]
+    n = np.array([[0,1,2],[3,4,5],[6,7,8]])
+    b = fe.backend.transpose(n)  # [[0, 3, 6], [1, 4, 7], [2, 5, 8]]
     ```
 
     This method can be used with TensorFlow tensors:
     ```python
-    t = tf.constant([-2, 7, -19])
-    b = fe.backend.sign(t)  # [-1, 1, -1]
+    t = tf.constant([[0,1,2],[3,4,5],[6,7,8]])
+    b = fe.backend.transpose(t)  # [[0, 3, 6], [1, 4, 7], [2, 5, 8]]
     ```
 
     This method can be used with PyTorch tensors:
     ```python
-    p = torch.tensor([-2, 7, -19])
-    b = fe.backend.sign(p)  # [-1, 1, -1]
+    p = torch.tensor([[0,1,2],[3,4,5],[6,7,8]])
+    b = fe.backend.transpose(p)  # [[0, 3, 6], [1, 4, 7], [2, 5, 8]]
     ```
 
     Args:
         tensor: The input value.
 
     Returns:
-        The sign of each value of the `tensor`.
+        The transposed `tensor`.
 
     Raises:
         ValueError: If `tensor` is an unacceptable data type.
     """
     if tf.is_tensor(tensor):
-        return tf.sign(tensor)
+        return tf.transpose(tensor)
     elif isinstance(tensor, torch.Tensor):
-        return tensor.sign()
+        return tensor.T
     elif isinstance(tensor, np.ndarray):
-        return np.sign(tensor)
+        return np.transpose(tensor)
     else:
         raise ValueError("Unrecognized tensor type {}".format(type(tensor)))
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_smooth_l1_loss.py` & `fastestimator-1.6.0/fastestimator/backend/_smooth_l1_loss.py`

 * *Files 3% similar despite different names*

```diff
@@ -66,14 +66,14 @@
 
     if tf.is_tensor(y_pred):
         y_true = tf.cast(y_true, y_pred.dtype)
         regression_diff = tf.math.abs(y_true - y_pred)  # |y - f(x)|
         regression_loss = tf.where(tf.math.less(regression_diff, beta),
                                    0.5 * tf.math.pow(regression_diff, 2) / beta,
                                    regression_diff - 0.5 * beta)
-        smooth_mae = reduce_mean(regression_loss, axis=[*range(len(regression_loss.shape))][1:])
+        smooth_mae = reduce_mean(regression_loss, axis=-1)
     elif isinstance(y_pred, torch.Tensor):
         smooth_mae = reduce_mean(
-            torch.nn.SmoothL1Loss(reduction="none", beta=beta)(y_pred, y_true), axis=[*range(len(y_pred.shape))][1:])
+            torch.nn.SmoothL1Loss(reduction="none", beta=beta)(y_pred, y_true), axis=-1)
     else:
         raise ValueError("Unrecognized tensor type {}".format(type(y_pred)))
     return smooth_mae
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_sparse_categorical_crossentropy.py` & `fastestimator-1.6.0/fastestimator/backend/_sparse_categorical_crossentropy.py`

 * *Files 6% similar despite different names*

```diff
@@ -54,16 +54,18 @@
     b = fe.backend.sparse_categorical_crossentropy(y_pred=pred, y_true=true)  # 0.228
     b = fe.backend.sparse_categorical_crossentropy(y_pred=pred, y_true=true, average_loss=False)  # [0.22, 0.11, 0.36]
     b = fe.backend.sparse_categorical_crossentropy(y_pred=pred, y_true=true, average_loss=False, class_weights=weights)
     # [0.44, 0.11, 1.08]
     ```
 
     Args:
-        y_pred: Prediction with a shape like (Batch, C). dtype: float32 or float16.
-        y_true: Ground truth class labels with a shape like (Batch) or (Batch, 1). dtype: int.
+        y_pred: Prediction with a shape like (Batch, ..., C) for tensorflow and (Batch, C, ...) for PyTorch. dtype:
+            float32 or float16.
+        y_true: Ground truth class labels with a shape like (Batch, ...), with each element representing the label index
+            starting from 0. dtype: int.
         from_logits: Whether y_pred is from logits. If True, a softmax will be applied to the prediction.
         average_loss: Whether to average the element-wise loss.
         class_weights: Mapping of class indices to a weight for weighting the loss function. Useful when you need to pay
             more attention to samples from an under-represented class.
 
     Returns:
         The sparse categorical crossentropy between `y_pred` and `y_true`. A scalar if `average_loss` is True, else a
@@ -77,15 +79,14 @@
     if tf.is_tensor(y_pred):
         ce = tf.losses.sparse_categorical_crossentropy(y_pred=y_pred, y_true=y_true, from_logits=from_logits)
         if class_weights is not None:
             sample_weights = class_weights.lookup(
                 tf.cast(tf.reshape(y_true, tf.shape(ce)), dtype=class_weights.key_dtype))
             ce = ce * sample_weights
     else:
-        y_true = y_true.view(-1)
         if from_logits:
             ce = torch.nn.CrossEntropyLoss(reduction="none")(input=y_pred, target=y_true.long())
         else:
             ce = torch.nn.NLLLoss(reduction="none")(input=torch.log(y_pred), target=y_true.long())
 
         if class_weights is not None:
             sample_weights = torch.ones_like(y_true, dtype=torch.float)
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_squeeze.py` & `fastestimator-1.6.0/fastestimator/backend/_squeeze.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_tensor_normalize.py` & `fastestimator-1.6.0/fastestimator/backend/_tensor_normalize.py`

 * *Files 5% similar despite different names*

```diff
@@ -13,14 +13,15 @@
 # limitations under the License.
 # ==============================================================================
 from typing import Optional, Sequence, Tuple, TypeVar, Union
 
 import numpy as np
 import tensorflow as tf
 import torch
+import torchvision.transforms as T
 
 from fastestimator.backend._convert_tensor_precision import convert_tensor_precision
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor, np.ndarray)
 
 
 def normalize(tensor: Tensor,
@@ -63,19 +64,22 @@
             The normalized values of `tensor`.
 
         Raises:
             ValueError: If `tensor` is an unacceptable data type.
     """
     framework, device = get_framework(tensor)
 
-    mean = get_scaled_data(mean, max_pixel_value, framework, device)
-    std = get_scaled_data(std, max_pixel_value, framework, device)
-
-    tensor = (convert_tensor_precision(tensor) - convert_tensor_precision(mean)) / (convert_tensor_precision(std) +
-                                                                                    epsilon)
+    mean = convert_tensor_precision(get_scaled_data(mean, max_pixel_value, framework, device))
+    std = convert_tensor_precision(get_scaled_data(std, max_pixel_value, framework, device))
+    tensor = convert_tensor_precision(tensor)
+
+    if framework == 'torch':
+        tensor = T.Normalize(mean=mean, std=std + epsilon)(tensor)
+    else:
+        tensor = (tensor - mean) / (std + epsilon)
 
     return tensor
 
 
 def get_framework(tensor: Tensor) -> Tuple[str, Optional[str]]:
     """
         Get the framework of the input data.
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_tensor_pow.py` & `fastestimator-1.6.0/fastestimator/backend/_tensor_pow.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_tensor_round.py` & `fastestimator-1.6.0/fastestimator/backend/_tensor_round.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_tensor_sqrt.py` & `fastestimator-1.6.0/fastestimator/backend/_tensor_sqrt.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_to_shape.py` & `fastestimator-1.6.0/fastestimator/backend/_to_shape.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_to_tensor.py` & `fastestimator-1.6.0/fastestimator/backend/_to_tensor.py`

 * *Files 17% similar despite different names*

```diff
@@ -8,26 +8,56 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Collection, TypeVar, Union
+from typing import Collection, Literal, Union, overload
 
 import numpy as np
 import tensorflow as tf
 import torch
 
-Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor, np.ndarray)
+from fastestimator.types import Array, ArrayT, CollectionT
 
 
-def to_tensor(data: Union[Collection, Tensor, float, int, None],
-              target_type: str,
-              shared_memory: bool = False) -> Union[Collection, Tensor, None]:
+@overload
+def to_tensor(data: CollectionT, target_type: str, shared_memory: bool = False) -> CollectionT:
+    ...
+
+
+@overload
+def to_tensor(data: Union[Array, float, int], target_type: Literal['tf'], shared_memory: bool = False) -> tf.Tensor:
+    ...
+
+
+@overload
+def to_tensor(data: Union[Array, float, int], target_type: Literal['torch'],
+              shared_memory: bool = False) -> torch.Tensor:
+    ...
+
+
+@overload
+def to_tensor(data: Union[Array, float, int], target_type: Literal['np'], shared_memory: bool = False) -> np.ndarray:
+    ...
+
+
+@overload
+def to_tensor(data: Union[Array, float, int], target_type: str, shared_memory: bool = False) -> Array:
+    ...
+
+
+@overload
+def to_tensor(data: None, target_type: str, shared_memory: bool = False) -> None:
+    ...
+
+
+def to_tensor(data: Union[Collection, Array, float, int, None], target_type: str,
+              shared_memory: bool = False) -> Union[Collection, ArrayT, Array, None]:
     """Convert tensors within a collection of `data` to a given `target_type` recursively.
 
     This method can be used with Numpy data:
     ```python
     data = {"x": np.ones((10,15)), "y":[np.ones((4)), np.ones((5, 3))], "z":{"key":np.ones((2,2))}}
     t = fe.backend.to_tensor(data, target_type='tf')
     # {"x": <tf.Tensor>, "y":[<tf.Tensor>, <tf.Tensor>], "z": {"key": <tf.Tensor>}}
@@ -63,14 +93,17 @@
     conversion_function = {"tf": tf.convert_to_tensor, "torch": torch.from_numpy, "np": np.array}
     if isinstance(data, target_instance[target_type]):
         if shared_memory and target_type == "torch":
             data.share_memory_()
         return data
     elif data is None:
         return None
+    elif isinstance(data, str):
+        # We don't convert strings to tensors because torch collate behavior is just to wrap strings into a list
+        return data
     elif isinstance(data, dict):
         return {key: to_tensor(value, target_type) for (key, value) in data.items()}
     elif isinstance(data, list):
         return [to_tensor(val, target_type) for val in data]
     elif isinstance(data, tuple) and hasattr(data, '_fields'):  # Named tuple
         return type(data)([to_tensor(val, target_type) for val in data])
     elif isinstance(data, tuple):
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_to_type.py` & `fastestimator-1.6.0/fastestimator/backend/_to_type.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_update_model.py` & `fastestimator-1.6.0/fastestimator/backend/_update_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -13,14 +13,15 @@
 # limitations under the License.
 # ==============================================================================
 from typing import Callable, Dict, List, Optional, Union
 
 import tensorflow as tf
 import torch
 
+from fastestimator.util.base_util import warn
 
 _ALREADY_GAVE_FE_GRAD_WARNING = False
 
 
 def update_model(model: Union[tf.keras.Model, torch.nn.Module],
                  gradients: List[Union[tf.Tensor, torch.Tensor]],
                  defer: bool = False,
@@ -77,16 +78,16 @@
 
     elif isinstance(model, torch.nn.Module):
         trainable_params = [p for p in model.parameters() if p.requires_grad]
         for gradient, parameter in zip(gradients, trainable_params):
             if gradient is None:
                 global _ALREADY_GAVE_FE_GRAD_WARNING
                 if not _ALREADY_GAVE_FE_GRAD_WARNING:
-                    print("\033[93m{}\033[00m".format("FastEstimator-Warn: 'None' detected in gradients. Some or all "
-                                                      "of your computation graph may not be connected to your loss."))
+                    warn("'None' detected in gradients. Some or all of your computation graph may not be connected " +
+                         "to your loss.")
                     _ALREADY_GAVE_FE_GRAD_WARNING = True
                 continue
             if parameter.grad is not None:
                 parameter.grad += gradient
             else:
                 parameter.grad = gradient.clone()
         if defer:
```

### Comparing `fastestimator-1.5.2/fastestimator/backend/_watch.py` & `fastestimator-1.6.0/fastestimator/backend/_watch.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_zeros_like.py` & `fastestimator-1.6.0/fastestimator/backend/_zeros_like.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/backend/_zscore.py` & `fastestimator-1.6.0/fastestimator/backend/_zscore.py`

 * *Files 7% similar despite different names*

```diff
@@ -40,17 +40,18 @@
     ```python
     p = torch.tensor([[0,1],[2,3]])
     b = fe.backend.zscore(p)  # [[-1.34164079, -0.4472136 ],[0.4472136 , 1.34164079]]
     ```
 
     Args:
         data: The input tensor or array.
+        epsilon: A numerical stability constant.
 
     Returns:
-        Data after substracting mean and divided by standard deviation.
+        Data after subtracting mean and divided by standard deviation.
 
     Raises:
         ValueError: If `tensor` is an unacceptable data type.
     """
     if tf.is_tensor(data):
         data = tf.cast(data, tf.float32)
         mean = tf.reduce_mean(data)
```

### Comparing `fastestimator-1.5.2/fastestimator/cli/__init__.py` & `fastestimator-1.6.0/fastestimator/cli/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/cli/history.py` & `fastestimator-1.6.0/fastestimator/cli/history.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/cli/logs.py` & `fastestimator-1.6.0/fastestimator/cli/logs.py`

 * *Files 2% similar despite different names*

```diff
@@ -59,15 +59,15 @@
     parser = subparsers.add_parser('logs',
                                    description='Generates comparison graphs amongst one or more log files',
                                    formatter_class=argparse.ArgumentDefaultsHelpFormatter,
                                    allow_abbrev=False)
     parser.add_argument('log_dir',
                         metavar='<Log Dir>',
                         type=str,
-                        help="The path to a folder containing one or more log files")
+                        help="The path to a folder containing one or more log files, or the path to a single log file")
     parser.add_argument('--extension',
                         metavar='E',
                         type=str,
                         help="The file type / extension of your logs",
                         default=".txt")
     parser.add_argument('--recursive', action='store_true', help="Recursively search sub-directories for log files")
     group = parser.add_mutually_exclusive_group()
```

### Comparing `fastestimator-1.5.2/fastestimator/cli/main.py` & `fastestimator-1.6.0/fastestimator/cli/main.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/cli/plot.py` & `fastestimator-1.6.0/fastestimator/cli/plot.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/cli/run.py` & `fastestimator-1.6.0/fastestimator/cli/run.py`

 * *Files 10% similar despite different names*

```diff
@@ -12,14 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import argparse
 import json
 import os
 import sys
+from ast import literal_eval
 from typing import Any, Dict, List, Optional
 
 from fastestimator.util.cli_util import parse_cli_to_dictionary
 
 
 def run(args: Dict[str, Any], unknown: Optional[List[str]]) -> None:
     """Invoke the fastestimator_run function from a file.
@@ -41,19 +42,19 @@
     sys.path.insert(0, dir_name)
     spec_module = __import__(module_name, globals(), locals())
     if hasattr(spec_module, "fastestimator_run"):
         spec_module.fastestimator_run(**hyperparameters)
     elif hasattr(spec_module, "get_estimator"):
         est = spec_module.get_estimator(**hyperparameters)
         if "train" in est.pipeline.data:
-            est.fit()
+            est.fit(summary=args['summary'], warmup=args['warmup'], eager=args['eager'])
         if "test" in est.pipeline.data:
-            est.test()
+            est.test(summary=args['summary'], eager=args['eager'])
     else:
-        raise ValueError("The file {} does not contain 'fastestimator_run' or 'get_estimator'".format(module_name))
+        raise ValueError("The file {} does not have 'fastestimator_run' or 'get_estimator' defined".format(module_name))
 
 
 def configure_run_parser(subparsers: argparse._SubParsersAction) -> None:
     """Add a run parser to an existing argparser.
 
     Args:
         subparsers: The parser object to be appended to.
@@ -64,12 +65,23 @@
                                    allow_abbrev=False)
     # use an argument group for required flag arguments since otherwise they will show up as optional in the help
     parser.add_argument('entry_point', type=str, help='The path to the python file')
     parser.add_argument('--hyperparameters',
                         dest='hyperparameters_json',
                         type=str,
                         help="The path to the hyperparameters JSON file")
+    parser.add_argument('--warmup',
+                        type=literal_eval,
+                        help="Warmup setting, can be True or False",
+                        choices=[True, False],
+                        default=True)
+    parser.add_argument('--eager',
+                        type=literal_eval,
+                        help="Eager setting, can be True or False",
+                        choices=[True, False],
+                        default=False)
+    parser.add_argument('--summary', type=str, help="Experiment name", default=None)
     parser.add_argument_group(
         'hyperparameter arguments',
         'Arguments to be passed through to the fastestimator_run() call. \
         Examples might look like --epochs <int>, --batch_size <int>, --optimizer <str>, etc...')
     parser.set_defaults(func=run)
```

### Comparing `fastestimator-1.5.2/fastestimator/cli/train.py` & `fastestimator-1.6.0/fastestimator/cli/train.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/__init__.py` & `fastestimator-1.6.0/fastestimator/dataset/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -13,30 +13,38 @@
 # limitations under the License.
 # ==============================================================================
 # FEDataset, OpDataset, and FEDataLoader intentionally not imported here to reduce user confusion with auto-complete
 from typing import TYPE_CHECKING
 
 import lazy_loader as lazy
 
-__getattr__, __dir__, __all__ = lazy.attach(__name__,
-                                            submodules={'data'},
-                                            submod_attrs={'batch_dataset': ['BatchDataset'],
-                                                          'csv_dataset': ['CSVDataset'],
-                                                          'dir_dataset': ['DirDataset'],
-                                                          'generator_dataset': ['GeneratorDataset'],
-                                                          'labeled_dir_dataset': ['LabeledDirDataset'],
-                                                          'numpy_dataset': ['NumpyDataset'],
-                                                          'pickle_dataset': ['PickleDataset'],
-                                                          'siamese_dir_dataset': ['SiameseDirDataset'],
-                                                          'extend_dataset': ['ExtendDataset'], })
+__getattr__, __dir__, __all__ = lazy.attach(
+    __name__,
+    submodules={"data"},
+    submod_attrs={
+        "batch_dataset": ["BatchDataset"],
+        "csv_dataset": ["CSVDataset"],
+        "dir_dataset": ["DirDataset"],
+        "generator_dataset": ["GeneratorDataset"],
+        "labeled_dir_dataset": ["LabeledDirDataset"],
+        "numpy_dataset": ["NumpyDataset"],
+        "pickle_dataset": ["PickleDataset"],
+        "siamese_dir_dataset": ["SiameseDirDataset"],
+        "extend_dataset": ["ExtendDataset"],
+        "combined_dataset": ["CombinedDataset"],
+        "interleave_dataset": ["InterleaveDataset"]
+    },
+)
 
 if TYPE_CHECKING:
     from fastestimator.dataset import data
     from fastestimator.dataset.batch_dataset import BatchDataset
+    from fastestimator.dataset.combined_dataset import CombinedDataset
     from fastestimator.dataset.csv_dataset import CSVDataset
     from fastestimator.dataset.dir_dataset import DirDataset
+    from fastestimator.dataset.extend_dataset import ExtendDataset
     from fastestimator.dataset.generator_dataset import GeneratorDataset
     from fastestimator.dataset.labeled_dir_dataset import LabeledDirDataset
     from fastestimator.dataset.numpy_dataset import NumpyDataset
     from fastestimator.dataset.pickle_dataset import PickleDataset
     from fastestimator.dataset.siamese_dir_dataset import SiameseDirDataset
-    from fastestimator.dataset.extend_dataset import ExtendDataset
+    from fastestimator.dataset.interleave_dataset import InterleaveDataset
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/batch_dataset.py` & `fastestimator-1.6.0/fastestimator/dataset/batch_dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,16 +16,17 @@
 import random
 from typing import Any, Dict, Iterable, List, Optional, Sequence, Union
 
 import numpy as np
 
 from fastestimator.dataset.dataset import DatasetSummary, FEDataset
 from fastestimator.dataset.extend_dataset import ExtendDataset
+from fastestimator.dataset.interleave_dataset import InterleaveDataset
+from fastestimator.util.base_util import to_list, warn
 from fastestimator.util.traceability_util import traceable
-from fastestimator.util.base_util import to_list
 
 
 @traceable()
 class BatchDataset(FEDataset):
     """BatchDataset extracts a list (batch) of data from a single dataset or multiple datasets.
 
     This dataset helps to enable several use-cases:
@@ -102,15 +103,15 @@
             assert is_same_key != is_disjoint_key, "dataset keys must be all same or all disjoint"
         self.same_feature = is_same_key
         if self.probability:
             assert self.same_feature, "keys must be exactly same among datasets when using probability distribution"
             assert len(self.datasets) == len(self.probability), "the length of dataset must match probability"
             assert len(self.num_samples) == 1, "num_sample must be scalar for probability mode"
             assert len(self.datasets) > 1, "number of datasets must be more than one to use probability mode"
-            assert sum(self.probability) == 1, "sum of probability must be 1"
+            assert abs(sum(self.probability) - 1) < 1e-8, "Probabilities must sum to 1"
             for p in self.probability:
                 assert isinstance(p, float) and p > 0, "must provide positive float for probability distribution"
         else:
             assert len(self.datasets) == len(self.num_samples), "the number of dataset must match num_samples"
         # set up batch size
         if self.same_feature:
             if self.probability:
@@ -120,14 +121,15 @@
         else:
             assert len(set(num_examples)) == 1, "the number of output samples must be the same for disjoint features"
             self.fe_batch = num_examples[0]
         self.all_fe_datasets = all([isinstance(dataset, FEDataset) for dataset in self.datasets])
         # Check ExtendDataset
         for idx, dataset in enumerate(self.datasets):
             assert not isinstance(dataset, ExtendDataset), "Input Dataset cannot be an ExtendDataset object"
+            assert not isinstance(dataset, InterleaveDataset), "Input Dataset cannot be an InterleaveDataset object"
 
     def _do_split(self, splits: Sequence[Iterable[int]]) -> List['BatchDataset']:
         """This class overwrites the .split() method instead of _do_split().
 
         Args:
             splits: Which indices to remove from the current dataset in order to create new dataset(s). One dataset will
                 be generated for every element of the `splits` sequence.
@@ -206,15 +208,15 @@
 
     def summary(self) -> DatasetSummary:
         """Generate a summary representation of this dataset.
         Returns:
             A summary representation of this dataset.
         """
         if not self.all_fe_datasets:
-            print("FastEstimator-Warn: BatchDataset summary will be incomplete since non-FEDatasets were used.")
+            warn("BatchDataset summary will be incomplete since non-FEDatasets were used.")
             return DatasetSummary(num_instances=len(self), keys={})
         summaries = [ds.summary() for ds in self.datasets]
         keys = {k: v for summary in summaries for k, v in summary.keys.items()}
         return DatasetSummary(num_instances=len(self), keys=keys)
 
     def __len__(self) -> int:
         """Compute the length of this dataset.
@@ -272,20 +274,20 @@
         Args:
             batch_idx: Which batch is it.
 
         Returns:
             A list of data instance dictionaries corresponding to the current `batch_idx`.
         """
         if self.probability:
-            index = list(np.random.choice(range(self.n_datasets), size=self.num_samples, p=self.probability))
-            num_samples = [index.count(i) for i in range(self.n_datasets)]
+            index = list(np.random.choice(range(len(self.datasets)), size=self.num_samples, p=self.probability))
+            num_samples = [index.count(i) for i in range(len(self.datasets))]
         else:
             num_samples = self.num_samples
-        indices = [[index_map[batch_idx * num_sample + idx] for idx in range(num_sample)] for num_sample, index_map
-                   in zip(num_samples, self.index_maps)]
+        indices = [[index_map[batch_idx * num_sample + idx] for idx in range(num_sample)] for num_sample,
+                   index_map in zip(num_samples, self.index_maps)]
         return indices
 
     def fe_reset_ds(self, shuffle: bool = True, *, seed: Optional[int] = None) -> None:
         """Rearrange the index maps of this BatchDataset.
 
         Args:
             shuffle: Whether to shuffle the dataset. If False the method will do nothing so long as index maps already
@@ -303,18 +305,20 @@
         # Don't bother re-initializing if shuffle is False
         if shuffle is False and self.index_maps:
             return
         num_samples = self.num_samples
         if self.probability:
             num_samples = num_samples * len(self.datasets)
         self.index_maps = []
-        for dataset, num_sample in zip(self.datasets, num_samples):
+        for idx, (dataset, num_sample) in enumerate(zip(self.datasets, num_samples)):
             index_map = [list(range(len(dataset))) for _ in range(math.ceil(len(self) * num_sample / len(dataset)))]
             for mapping in index_map:
                 if seed is not None:
-                    random.Random(seed).shuffle(mapping)
+                    # adding idx to the seed because we need to make sure different datasets have different index
+                    # orders, in the meantime, their random behavior should still be conditioned on seed.
+                    random.Random(seed + idx).shuffle(mapping)
                 else:
                     random.shuffle(mapping)
             if hasattr(dataset, "fe_batch_indices"):
                 self.index_maps.append([dataset.fe_batch_indices(item) for sublist in index_map for item in sublist])
             else:
                 self.index_maps.append([item for sublist in index_map for item in sublist])
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/__init__.py` & `fastestimator-1.6.0/fastestimator/dataset/data/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -14,17 +14,17 @@
 # ==============================================================================
 from typing import TYPE_CHECKING
 
 import lazy_loader as lazy
 
 __getattr__, __dir__, __all__ = lazy.attach(__name__,
                                             submodules={'breast_cancer', 'cifair10', 'cifair100', 'cifar10',
-                                                        'cifar100', 'cub200', 'food101', 'horse2zebra', 'imdb_review',
+                                                        'cifar100', 'cub200','em_3d', 'food101', 'horse2zebra', 'imdb_review',
                                                         'mendeley', 'mitmovie_ner', 'mnist', 'montgomery', 'mscoco',
                                                         'nih_chestxray', 'omniglot', 'penn_treebank', 'shakespeare',
-                                                        'skl_digits', 'svhn', 'svhn_cropped', 'tednmt', 'usps'}
+                                                        'skl_digits', 'svhn', 'svhn_cropped', 'tednmt', 'usps', 'pascal_voc', 'medmnist'}
                                             )
 
 if TYPE_CHECKING:
-    from fastestimator.dataset.data import breast_cancer, cifair10, cifair100, cifar10, cifar100, cub200, food101, \
-        horse2zebra, imdb_review, mendeley, mitmovie_ner, mnist, montgomery, mscoco, nih_chestxray, omniglot, \
-        penn_treebank, shakespeare, skl_digits, svhn, svhn_cropped, tednmt, usps
+    from fastestimator.dataset.data import breast_cancer, cifair10, cifair100, cifar10, cifar100, cub200, em_3d, \
+        food101, horse2zebra, imdb_review, mendeley, mitmovie_ner, mnist, montgomery, mscoco, nih_chestxray, omniglot, \
+        penn_treebank, shakespeare, skl_digits, svhn, svhn_cropped, tednmt, usps, pascal_voc, medmnist
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/breast_cancer.py` & `fastestimator-1.6.0/fastestimator/dataset/data/breast_cancer.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/cifair10.py` & `fastestimator-1.6.0/fastestimator/dataset/data/cifair10.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2019 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2022 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,66 +10,77 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import os
 import pickle
-from typing import Tuple, List
+import shutil
+from pathlib import Path
+from typing import List, Tuple
 
 import numpy as np
-from tensorflow.keras.utils import get_file
 
 from fastestimator.dataset.numpy_dataset import NumpyDataset
+from fastestimator.util.google_download_util import download_file_from_google_drive
 
 
-def load_data(image_key: str = "x", label_key: str = "y") -> Tuple[NumpyDataset, NumpyDataset]:
+def load_data(root_dir: str = None, image_key: str = "x", label_key: str = "y") -> Tuple[NumpyDataset, NumpyDataset]:
     """Load and return the ciFAIR10 dataset.
 
     This is the cifar10 dataset but with test set duplicates removed and replaced. See
     https://arxiv.org/pdf/1902.00423.pdf or https://cvjena.github.io/cifair/ for details. Cite the paper if you use the
     dataset.
 
     Args:
+        root_dir: The path to store the downloaded data. When `path` is not provided, the data will be saved into
+            `fastestimator_data` under the user's home directory.
         image_key: The key for image.
         label_key: The key for label.
 
     Returns:
         (train_data, test_data)
     """
-    dirname = 'ciFAIR-10'
-    archive_name = 'ciFAIR-10.zip'
-    origin = 'https://github.com/cvjena/cifair/releases/download/v1.0/ciFAIR-10.zip'
-    md5_hash = 'ca08fd390f0839693d3fc45c4e49585f'
-
-    path = get_file(archive_name, origin=origin, file_hash=md5_hash, hash_algorithm='md5', extract=True,
-                    archive_format='zip')
-    path = os.path.join(os.path.dirname(path), dirname)
+    home = str(Path.home())
+
+    if root_dir is None:
+        root_dir = os.path.join(home, 'fastestimator_data', 'ciFAIR10')
+    else:
+        root_dir = os.path.join(os.path.abspath(root_dir), 'ciFAIR10')
+    os.makedirs(root_dir, exist_ok=True)
+
+    image_compressed_path = os.path.join(root_dir, 'ciFAIR10.zip')
+    image_extracted_path = os.path.join(root_dir, 'ciFAIR-10')
+
+    if not os.path.exists(image_extracted_path):
+        print("Downloading data to {}".format(root_dir))
+        download_file_from_google_drive('1dqTgqMVvgx_FZNAC7TqzoA0hYX1ttOUq', image_compressed_path)
+
+        print("Extracting data to {}".format(root_dir))
+        shutil.unpack_archive(image_compressed_path, root_dir)
 
     num_train_samples = 50000
 
     x_train = np.empty((num_train_samples, 3, 32, 32), dtype='uint8')
-    y_train = np.empty((num_train_samples,), dtype='uint8')
+    y_train = np.empty((num_train_samples, ), dtype='uint8')
 
     for i in range(1, 6):
-        fpath = os.path.join(path, f'data_batch_{i}')
-        (x_train[(i - 1) * 10000:i * 10000, :, :, :],
-         y_train[(i - 1) * 10000:i * 10000]) = _load_batch(fpath)
+        fpath = os.path.join(image_extracted_path, f'data_batch_{i}')
+        (x_train[(i - 1) * 10000:i * 10000, :, :, :], y_train[(i - 1) * 10000:i * 10000]) = _load_batch(fpath)
 
-    fpath = os.path.join(path, 'test_batch')
+    fpath = os.path.join(image_extracted_path, 'test_batch')
     x_test, y_test = _load_batch(fpath)
 
-    y_train = np.reshape(y_train, (len(y_train), 1))
-    y_test = np.reshape(y_test, (len(y_test), 1))
+    y_train = np.array(y_train, dtype=np.uint8)
+    y_test = np.array(y_test, dtype=np.uint8)
 
     x_train = x_train.transpose((0, 2, 3, 1))
     x_test = x_test.transpose((0, 2, 3, 1))
 
     x_test = x_test.astype(x_train.dtype)
-    y_test = y_test.astype(y_train.dtype)
 
     train_data = NumpyDataset({image_key: x_train, label_key: y_train})
     test_data = NumpyDataset({image_key: x_test, label_key: y_test})
     return train_data, test_data
 
 
 def _load_batch(file_path: str, label_key: str = 'labels') -> Tuple[np.ndarray, List[int]]:
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/cifair100.py` & `fastestimator-1.6.0/fastestimator/dataset/data/cifair100.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,74 +1,78 @@
-# Copyright 2019 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2022 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import os
+import shutil
+from pathlib import Path
 from typing import Tuple
 
 import numpy as np
-from tensorflow.keras.utils import get_file
 
 from fastestimator.dataset.data.cifair10 import _load_batch
 from fastestimator.dataset.numpy_dataset import NumpyDataset
+from fastestimator.util.google_download_util import download_file_from_google_drive
 
 
-def load_data(image_key: str = "x",
-              label_key: str = "y",
+def load_data(root_dir: str = None, image_key: str = "x", label_key: str = "y",
               label_mode: str = "fine") -> Tuple[NumpyDataset, NumpyDataset]:
     """Load and return the ciFAIR100 dataset.
 
     This is the cifar100 dataset but with test set duplicates removed and replaced. See
     https://arxiv.org/pdf/1902.00423.pdf or https://cvjena.github.io/cifair/ for details. Cite the paper if you use the
     dataset.
 
     Args:
+        root_dir: The path to store the downloaded data. When `path` is not provided, the data will be saved into
+            `fastestimator_data` under the user's home directory.
         image_key: The key for image.
         label_key: The key for label.
-        label_mode: Either "fine" for 100 classes or "coarse" for 20 classes.
 
     Returns:
         (train_data, test_data)
-
-    Raises:
-        ValueError: If the label_mode is invalid.
     """
-    if label_mode not in ['fine', 'coarse']:
-        raise ValueError("label_mode must be one of either 'fine' or 'coarse'.")
+    home = str(Path.home())
+
+    if root_dir is None:
+        root_dir = os.path.join(home, 'fastestimator_data', 'ciFAIR100')
+    else:
+        root_dir = os.path.join(os.path.abspath(root_dir), 'ciFAIR100')
+    os.makedirs(root_dir, exist_ok=True)
+
+    image_compressed_path = os.path.join(root_dir, 'ciFAIR100.zip')
+    image_extracted_path = os.path.join(root_dir, 'ciFAIR-100')
+
+    if not os.path.exists(image_extracted_path):
+        print("Downloading data to {}".format(root_dir))
+        download_file_from_google_drive('1ZE_wf5UTd9fJqBgikb7MJtfFEeAfXybS', image_compressed_path)
 
-    dirname = 'ciFAIR-100'
-    archive_name = 'ciFAIR-100.zip'
-    origin = 'https://github.com/cvjena/cifair/releases/download/v1.0/ciFAIR-100.zip'
-    md5_hash = 'ddc236ab4b12eeb8b20b952614861a33'
-
-    path = get_file(archive_name, origin=origin, file_hash=md5_hash, hash_algorithm='md5', extract=True,
-                    archive_format='zip')
-    path = os.path.join(os.path.dirname(path), dirname)
+        print("Extracting data to {}".format(root_dir))
+        shutil.unpack_archive(image_compressed_path, root_dir)
 
-    fpath = os.path.join(path, 'train')
+    fpath = os.path.join(image_extracted_path, 'train')
     x_train, y_train = _load_batch(fpath, label_key=label_mode + '_labels')
 
-    fpath = os.path.join(path, 'test')
+    fpath = os.path.join(image_extracted_path, 'test')
     x_test, y_test = _load_batch(fpath, label_key=label_mode + '_labels')
 
-    y_train = np.reshape(y_train, (len(y_train), 1))
-    y_test = np.reshape(y_test, (len(y_test), 1))
+    y_train = np.array(y_train, dtype=np.uint8)
+    y_test = np.array(y_test, dtype=np.uint8)
 
     x_train = x_train.transpose((0, 2, 3, 1))
     x_test = x_test.transpose((0, 2, 3, 1))
 
     x_test = x_test.astype(x_train.dtype)
-    y_test = y_test.astype(y_train.dtype)
 
     train_data = NumpyDataset({image_key: x_train, label_key: y_train})
     test_data = NumpyDataset({image_key: x_test, label_key: y_test})
     return train_data, test_data
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/cifar10.py` & `fastestimator-1.6.0/fastestimator/dataset/data/mnist.py`

 * *Files 10% similar despite different names*

```diff
@@ -16,23 +16,20 @@
 
 import tensorflow as tf
 
 from fastestimator.dataset.numpy_dataset import NumpyDataset
 
 
 def load_data(image_key: str = "x", label_key: str = "y") -> Tuple[NumpyDataset, NumpyDataset]:
-    """Load and return the CIFAR10 dataset.
-
-    Please consider using the ciFAIR10 dataset instead. CIFAR10 contains duplicates between its train and test sets.
+    """Load and return the MNIST dataset.
 
     Args:
         image_key: The key for image.
         label_key: The key for label.
 
     Returns:
         (train_data, eval_data)
     """
-    print("\033[93m {}\033[00m".format("FastEstimator-Warn: Consider using the ciFAIR10 dataset instead."))
-    (x_train, y_train), (x_eval, y_eval) = tf.keras.datasets.cifar10.load_data()
+    (x_train, y_train), (x_eval, y_eval) = tf.keras.datasets.mnist.load_data()
     train_data = NumpyDataset({image_key: x_train, label_key: y_train})
     eval_data = NumpyDataset({image_key: x_eval, label_key: y_eval})
     return train_data, eval_data
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/cub200.py` & `fastestimator-1.6.0/fastestimator/dataset/data/usps.py`

 * *Files 22% similar despite different names*

```diff
@@ -8,137 +8,120 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
+import gzip
 import os
-import random
-import tarfile
+from multiprocessing import Pool
 from pathlib import Path
-from typing import Optional, TypeVar
+from typing import Optional, Tuple
 
-import pandas as pd
-import requests
-from tqdm import tqdm
+import numpy as np
+import wget
+from PIL import Image
 
-from fastestimator.dataset.csv_dataset import CSVDataset
+from fastestimator.dataset.labeled_dir_dataset import LabeledDirDataset
+from fastestimator.util.google_download_util import download_file_from_google_drive
+from fastestimator.util.util import cpu_count
+from fastestimator.util.wget_util import bar_custom, callback_progress
 
-Response = TypeVar('Response', bound=requests.models.Response)
+wget.callback_progress = callback_progress
 
 
-def _download_file_from_google_drive(id: str, destination: str) -> None:
-    """Download the data from the Google drive public URL.
-
-    This method will create a session instance to persist the requests and reuse TCP connection for the large files.
+def _write_image(image: np.ndarray, path: str, idx: int, mode: str) -> None:
+    """Perform basic image pre-processing and save the image to disk.
 
     Args:
-        id: File ID of Google drive URL.
-        destination: Destination path where the data needs to be stored.
+        image: The image to be saved.
+        path: Where to save the image.
+        idx: The index of the given image (used for naming).
+        mode: The mode corresponding to this image ('train' vs 'test').
     """
-    URL = "https://drive.google.com/uc?export=download&confirm=t"
-    CHUNK_SIZE = 128
-    session = requests.Session()
-
-    response = session.get(URL, params={'id': id}, stream=True)
-    token = _get_confirm_token(response)
-
-    if token:
-        params = {'id': id, 'confirm': token}
-        response = session.get(URL, params=params, stream=True)
-
-    total_size = int(response.headers.get('Content-Length', 0))
-    progress = tqdm(total=total_size, unit='B', unit_scale=True)
-    with open(destination, "wb") as f:
-        for chunk in response.iter_content(CHUNK_SIZE):
-            if chunk:  # filter out keep-alive new chunks
-                progress.update(len(chunk))
-                f.write(chunk)
-    progress.close()
+    image = (image - image.min()) / max(image.max() - image.min(), 1e-8) * 255
+    img = Image.fromarray(image.astype(np.uint8))
+    img.save(os.path.join(path, '{}_{}.png'.format(mode, idx)))
 
 
-def _get_confirm_token(response: Response) -> str:
-    """Retrieve the token from the cookie jar of HTTP request to keep the session alive.
+def _write_data(images: np.ndarray, labels: np.ndarray, base_path: str, mode: str) -> None:
+    """Write a set of images to disk based on their class labels.
 
     Args:
-        response: Response object of the HTTP request.
+        images: The images to be saved.
+        labels: The corresponding image labels (used to determine which folder to write the image into)
+        base_path: The bath into which to write the images
+        mode: The mode corresponding to these images ('train' vs 'test').
+    """
+    if not os.path.exists(base_path):
+        print("Writing image data to {}".format(base_path))
+        os.makedirs(base_path)
+        for i in range(min(labels), max(labels) + 1):
+            os.makedirs(os.path.join(base_path, "{}".format(i)))
+        with Pool(cpu_count()) as p:
+            p.starmap(
+                _write_image,
+                zip(images,
+                    map(lambda l: os.path.join(base_path, "{}".format(l)), labels),
+                    range(len(labels)), (mode for _ in range(len(labels)))))
 
-    Returns"
-        The value of cookie in the response object.
 
-    """
-    for key, value in response.cookies.items():
-        if key.startswith('download_warning'):
-            return value
+def _extract_images_labels(filename: str) -> Tuple[np.ndarray, np.ndarray]:
+    """Read images and labels out of their compressed file format.
 
-    return None
+    Args:
+        filename: The name of the compressed file to extract from.
 
+    Returns:
+        (images, labels)
+    """
+    # https://github.com/haeusser/learning_by_association/blob/master/semisup/tools/usps.py
+    print('Extracting', filename)
+    with gzip.open(filename, 'rb') as f:
+        raw_data = f.read().split()
+    data = np.asarray([raw_data[start:start + 257] for start in range(0, len(raw_data), 257)], dtype=np.float32)
+    images_vec = data[:, 1:]
+    images = np.reshape(images_vec, (images_vec.shape[0], 16, 16))
+    labels = data[:, 0].astype(int)
+    return images, labels
 
-def load_data(root_dir: Optional[str] = None) -> CSVDataset:
-    """Load and return the Caltech-UCSD Birds 200 (CUB200) dataset.
 
-    Sourced from http://www.vision.caltech.edu/visipedia/CUB-200.html. This method will download the data to local
-        storage if the data has not been previously downloaded.
+def load_data(root_dir: Optional[str] = None) -> Tuple[LabeledDirDataset, LabeledDirDataset]:
+    """Load and return the USPS dataset.
 
     Args:
         root_dir: The path to store the downloaded data. When `path` is not provided, the data will be saved into
             `fastestimator_data` under the user's home directory.
 
     Returns:
-        train_data
+        (train_data, test_data)
     """
     home = str(Path.home())
 
     if root_dir is None:
-        root_dir = os.path.join(home, 'fastestimator_data', 'CUB200')
+        root_dir = os.path.join(home, 'fastestimator_data', 'USPS')
     else:
-        root_dir = os.path.join(os.path.abspath(root_dir), 'CUB200')
+        root_dir = os.path.join(os.path.abspath(root_dir), 'USPS')
     os.makedirs(root_dir, exist_ok=True)
 
-    csv_path = os.path.join(root_dir, 'cub200.csv')
-    image_compressed_path = os.path.join(root_dir, 'images.tgz')
-    annotation_compressed_path = os.path.join(root_dir, 'annotations.tgz')
-    image_extracted_path = os.path.join(root_dir, 'images')
-    annotation_extracted_path = os.path.join(root_dir, 'annotations-mat')
-
-    if not (os.path.exists(image_extracted_path) and os.path.exists(annotation_extracted_path)):
-        # download
-        if not (os.path.exists(image_compressed_path) and os.path.exists(annotation_compressed_path)):
-            print("Downloading data to {}".format(root_dir))
-            _download_file_from_google_drive('1GDr1OkoXdhaXWGA8S3MAq3a522Tak-nx', image_compressed_path)
-            _download_file_from_google_drive('16NsbTpMs5L6hT4hUJAmpW2u7wH326WTR', annotation_compressed_path)
-
-        # extract
-        print("\nExtracting files ...")
-        with tarfile.open(image_compressed_path) as img_tar:
-            img_tar.extractall(root_dir)
-        with tarfile.open(annotation_compressed_path) as anno_tar:
-            anno_tar.extractall(root_dir)
-
-    # glob and generate csv
-    if not os.path.exists(csv_path):
-        image_folder = os.path.join(root_dir, "images")
-        class_names = os.listdir(image_folder)
-        label_map = {}
-        images = []
-        labels = []
-        idx = 0
-        for class_name in class_names:
-            if not class_name.startswith("._"):
-                image_folder_class = os.path.join(image_folder, class_name)
-                label_map[class_name] = idx
-                idx += 1
-                image_names = os.listdir(image_folder_class)
-                for image_name in image_names:
-                    if not image_name.startswith("._"):
-                        images.append(os.path.join(image_folder_class, image_name))
-                        labels.append(label_map[class_name])
-        zipped_list = list(zip(images, labels))
-        random.shuffle(zipped_list)
-        df = pd.DataFrame(zipped_list, columns=["image", "label"])
-        df['image'] = df['image'].apply(lambda x: os.path.relpath(x, root_dir))
-        df['image'] = df['image'].apply(os.path.normpath)
-        df['annotation'] = df['image'].str.replace('images', 'annotations-mat').str.replace('jpg', 'mat')
-        df.to_csv(csv_path, index=False)
-        print("Data summary is saved at {}".format(csv_path))
-    return CSVDataset(csv_path)
+    # download data to memory
+    train_compressed_path = os.path.join(root_dir, "zip.train.gz")
+    test_compressed_path = os.path.join(root_dir, "zip.test.gz")
+    train_base_path = os.path.join(root_dir, "train")
+    test_base_path = os.path.join(root_dir, "test")
+
+    if not os.path.exists(train_base_path):
+        print("Downloading train data to {}".format(root_dir))
+        download_file_from_google_drive("1NlaCnlhV-PA_Rek8w8eQqJUeYCZJ0olG", train_compressed_path)
+        train_images, train_labels = _extract_images_labels(train_compressed_path)
+        _write_data(train_images, train_labels, train_base_path, "train")
+
+    if not os.path.exists(test_base_path):
+        print("Downloading test data to {}".format(root_dir))
+        download_file_from_google_drive("1lagM-V1nmAdS3Uz9Uk4bB9cKqE_agt59", test_compressed_path)
+        test_images, test_labels = _extract_images_labels(test_compressed_path)
+        _write_data(test_images, test_labels, test_base_path, "test")
+
+    # make datasets
+    return LabeledDirDataset(train_base_path, file_extension=".png"), LabeledDirDataset(test_base_path,
+                                                                                        file_extension=".png")
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/food101.py` & `fastestimator-1.6.0/fastestimator/dataset/data/food101.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/horse2zebra.py` & `fastestimator-1.6.0/fastestimator/dataset/data/horse2zebra.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/imdb_review.py` & `fastestimator-1.6.0/fastestimator/dataset/data/imdb_review.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/mendeley.py` & `fastestimator-1.6.0/fastestimator/dataset/data/mendeley.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/mitmovie_ner.py` & `fastestimator-1.6.0/fastestimator/dataset/data/mitmovie_ner.py`

 * *Files 6% similar despite different names*

```diff
@@ -92,12 +92,12 @@
 
     x_train, y_train, x_vocab, y_vocab = get_sentences_and_labels(train_data_path)
     x_eval, y_eval, x_eval_vocab, y_eval_vocab = get_sentences_and_labels(test_data_path)
     x_vocab |= x_eval_vocab
     y_vocab |= y_eval_vocab
     x_train = np.array(x_train)
     x_eval = np.array(x_eval)
-    y_train = np.array(y_train)
-    y_eval = np.array(y_eval)
+    y_train = np.array(y_train, dtype=object)
+    y_eval = np.array(y_eval, dtype=object)
     train_data = NumpyDataset({"x": x_train, "y": y_train})
     eval_data = NumpyDataset({"x": x_eval, "y": y_eval})
     return train_data, eval_data, x_vocab, y_vocab
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/mnist.py` & `fastestimator-1.6.0/fastestimator/dataset/data/skl_digits.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,35 +1,32 @@
-# Copyright 2019 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2022 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Tuple
-
-import tensorflow as tf
-
 from fastestimator.dataset.numpy_dataset import NumpyDataset
+from sklearn import datasets
 
 
-def load_data(image_key: str = "x", label_key: str = "y") -> Tuple[NumpyDataset, NumpyDataset]:
-    """Load and return the MNIST dataset.
+def load_data(image_key: str = "x", label_key: str = "y") -> NumpyDataset:
+    """Load and return the Sklearn digits dataset.
 
     Args:
         image_key: The key for image.
         label_key: The key for label.
 
     Returns:
         (train_data, eval_data)
     """
-    (x_train, y_train), (x_eval, y_eval) = tf.keras.datasets.mnist.load_data()
-    train_data = NumpyDataset({image_key: x_train, label_key: y_train})
-    eval_data = NumpyDataset({image_key: x_eval, label_key: y_eval})
-    return train_data, eval_data
+    ds = datasets.load_digits()
+    images = ds.images
+    targets = ds.target
+    return NumpyDataset({image_key: images, label_key: targets})
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/montgomery.py` & `fastestimator-1.6.0/fastestimator/dataset/data/montgomery.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/mscoco.py` & `fastestimator-1.6.0/fastestimator/dataset/data/mscoco.py`

 * *Files 23% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 
 import numpy as np
 import wget
 from pycocotools.coco import COCO
 
 from fastestimator.dataset.dir_dataset import DirDataset
 from fastestimator.util.traceability_util import traceable
-from fastestimator.util.base_util import Suppressor
+from fastestimator.util.util import Suppressor
 from fastestimator.util.wget_util import bar_custom, callback_progress
 
 wget.callback_progress = callback_progress
 
 
 @traceable()
 class MSCOCODataset(DirDataset):
@@ -36,43 +36,49 @@
 
     This dataset combines images from the MSCOCO data directory with their corresponding bboxes, masks, and captions.
 
     Args:
         image_dir: The path the directory containing MSOCO images.
         annotation_file: The path to the file containing annotation data.
         caption_file: The path the file containing caption data.
-        include_bboxes: Whether images should be paired with their associated bounding boxes. If true, images without
-            bounding boxes will be ignored and other images may be oversampled in order to take their place.
-        include_masks: Whether images should be paired with their associated masks. If true, images without masks will
-            be ignored and other images may be oversampled in order to take their place.
-        include_captions: Whether images should be paired with their associated captions. If true, images without
-            captions will be ignored and other images may be oversampled in order to take their place.
+        keypoint_file: The path the file containing keypoint data.
+        include_bboxes: Whether images should be paired with their associated bounding boxes.
+        include_masks: Whether images should be paired with their associated masks.
+        include_captions: Whether images should be paired with their associated captions.
+        include_keypoints: Whether images should be paired with keypoints.
         min_bbox_area: Bounding boxes with a total area less than `min_bbox_area` will be discarded.
+        replacement: If true, images without requested attributes will be ignored and other images may be oversampled in
+            order to take their place.
     """
 
     instances: Optional[COCO]
     captions: Optional[COCO]
 
     def __init__(self,
                  image_dir: str,
                  annotation_file: str,
                  caption_file: str,
+                 keypoint_file: str,
                  include_bboxes: bool = True,
                  include_masks: bool = False,
                  include_captions: bool = False,
-                 min_bbox_area=1.0) -> None:
+                 include_keypoints: bool = False,
+                 min_bbox_area=1.0,
+                 replacement: bool = True) -> None:
         super().__init__(root_dir=image_dir, data_key="image", recursive_search=False)
         if include_masks:
             assert include_bboxes, "must include bboxes with mask data"
         self.include_bboxes = include_bboxes
         self.include_masks = include_masks
         self.min_bbox_area = min_bbox_area
+        self.replacement = replacement
         with Suppressor():
-            self.instances = COCO(annotation_file)
+            self.instances = COCO(annotation_file) if include_bboxes or include_masks else None
             self.captions = COCO(caption_file) if include_captions else None
+            self.keypoints = COCO(keypoint_file) if include_keypoints else None
 
     def __getitem__(self, index: Union[int, str]) -> Union[Dict[str, Any], np.ndarray, List[Any]]:
         """Look up data from the dataset.
 
         Args:
             index: Either an int corresponding to a particular element of data, or a string in which case the
                 corresponding column of data will be returned. If bboxes, masks, or captions are required and the data
@@ -81,25 +87,27 @@
 
         Returns:
             A data dictionary if the index was an int, otherwise a column of data in list format.
         """
         has_data = False
         response = {}
         while not has_data:
-            has_box, has_mask, has_caption = True, True, True
+            has_box, has_mask, has_caption, has_keypoint = True, True, True, True
             response = self._get_single_item(index)
             if isinstance(index, str):
                 return response
             if self.include_bboxes and not response["bbox"]:
                 has_box = False
             if self.include_masks and not response["mask"]:
                 has_mask = False
             if self.captions and not response["caption"]:
                 has_caption = False
-            has_data = has_box and has_mask and has_caption
+            if self.keypoints and not response["keypoint"]:
+                has_keypoint = False
+            has_data = has_box and has_mask and has_caption and has_keypoint if self.replacement else True
             index = np.random.randint(len(self))
         return response
 
     def _get_single_item(self, index: Union[int, str]) -> Union[Dict[str, Any], np.ndarray, List[Any]]:
         """Look up data from the dataset.
 
         Args:
@@ -113,36 +121,40 @@
         if isinstance(index, str):
             return response
         else:
             response = deepcopy(response)
         image = response["image"]
         image_id = int(os.path.splitext(os.path.basename(image))[0])
         response["image_id"] = image_id
-        if self.include_bboxes:
+        if self.include_bboxes or self.include_masks:
             self._populate_instance_data(response, image_id)
         if self.captions:
             self._populate_caption_data(response, image_id)
+        if self.keypoints:
+            self._populate_keypoint_data(response, image_id)
         return response
 
     def _populate_instance_data(self, data: Dict[str, Any], image_id: int) -> None:
         """Add instance data to a data dictionary.
 
         Args:
             data: The dictionary to be augmented.
             image_id: The id of the image for which to find data.
         """
-        data["bbox"] = []
+        if self.include_bboxes:
+            data["bbox"] = []
         if self.include_masks:
             data["mask"] = []
-        annotation_ids = self.instances.getAnnIds(imgIds=image_id, iscrowd=False)
+        annotation_ids = self.instances.getAnnIds(imgIds=image_id, iscrowd=None)
         if annotation_ids:
             annotations = self.instances.loadAnns(annotation_ids)
             for annotation in annotations:
                 if annotation["bbox"][2] * annotation["bbox"][3] > self.min_bbox_area:
-                    data["bbox"].append(tuple(annotation['bbox'] + [annotation['category_id']]))
+                    if self.include_bboxes:
+                        data["bbox"].append(tuple(annotation['bbox'] + [annotation['category_id']]))
                     if self.include_masks:
                         data["mask"].append(self.instances.annToMask(annotation))
 
     def _populate_caption_data(self, data: Dict[str, Any], image_id: int) -> None:
         """Add captions to a data dictionary.
 
         Args:
@@ -152,27 +164,52 @@
         data["caption"] = []
         annotation_ids = self.captions.getAnnIds(imgIds=image_id)
         if annotation_ids:
             annotations = self.captions.loadAnns(annotation_ids)
             for annotation in annotations:
                 data["caption"].append(annotation['caption'])
 
+    def _populate_keypoint_data(self, data: Dict[str, Any], image_id: int) -> None:
+        """Add keypoints to a data dictionary.
+
+        Args:
+            data: The dictionary to be augmented.
+            image_id: The id of the image for which to find captions.
+        """
+        data["keypoint"] = []
+        data["keypoint_bbox"] = []
+        annotation_ids = self.keypoints.getAnnIds(imgIds=image_id)
+        if annotation_ids:
+            annotations = self.keypoints.loadAnns(annotation_ids)
+            for annotation in annotations:
+                if annotation['num_keypoints'] > 0:
+                    data["keypoint"].append(np.array(annotation['keypoints']).reshape(17, 3).astype('int32'))
+                    data["keypoint_bbox"].append(tuple(annotation['bbox']))
+
 
 def load_data(root_dir: Optional[str] = None,
               load_bboxes: bool = True,
               load_masks: bool = False,
-              load_captions: bool = False) -> Tuple[MSCOCODataset, MSCOCODataset]:
+              load_captions: bool = False,
+              load_keypoints: bool = False,
+              replacement: bool = True) -> Tuple[MSCOCODataset, MSCOCODataset]:
     """Load and return the COCO dataset.
 
     Args:
         root_dir: The path to store the downloaded data. When `path` is not provided, the data will be saved into
             `fastestimator_data` under the user's home directory.
-        load_bboxes: Whether to load bbox-related data.
+        load_bboxes: Whether to load bbox-related data, in [x1, y1, w, h] format.
         load_masks: Whether to load mask data (in the form of an array of 1-hot images).
         load_captions: Whether to load caption-related data.
+        load_keypoints: Whether to load keypoint data, in format of [array(17, 3)]. 17 is the number of keypoints, 3
+            is the keypoint format in (x,y,v) with x,y being coordinate and v being visibility. v=0 means not labeled,
+            v=1 means labeled but not visible, and v=2 means labeled and visible. In addition, the bbox of keypoint
+            object will also be available under 'keypoint_bbox' key.
+        replacement: If the specific attribute is missing (like bbox), whether to replace the sample with another random
+            sample.
 
     Returns:
         (train_data, eval_data)
     """
     if root_dir is None:
         root_dir = os.path.join(str(Path.home()), 'fastestimator_data', 'MSCOCO2017')
     else:
@@ -196,25 +233,26 @@
             if not os.path.exists(zip_path):
                 print("Downloading {} to {}".format(zip_name, root_dir))
                 wget.download(download_url, zip_path, bar=bar_custom)
             # Extract
             print("Extracting {}".format(zip_name))
             with zipfile.ZipFile(zip_path, 'r') as zip_file:
                 zip_file.extractall(os.path.dirname(zip_path))
-
-    train_annotation = os.path.join(annotation_data, "instances_train2017.json")
-    eval_annotation = os.path.join(annotation_data, "instances_val2017.json")
-    train_captions = os.path.join(annotation_data, "captions_train2017.json")
-    eval_captions = os.path.join(annotation_data, "captions_val2017.json")
     train_ds = MSCOCODataset(train_data,
-                             train_annotation,
-                             train_captions,
+                             annotation_file=os.path.join(annotation_data, "instances_train2017.json"),
+                             caption_file=os.path.join(annotation_data, "captions_train2017.json"),
+                             keypoint_file=os.path.join(annotation_data, "person_keypoints_train2017.json"),
                              include_bboxes=load_bboxes,
                              include_masks=load_masks,
-                             include_captions=load_captions)
+                             include_captions=load_captions,
+                             include_keypoints=load_keypoints,
+                             replacement=replacement)
     eval_ds = MSCOCODataset(eval_data,
-                            eval_annotation,
-                            eval_captions,
+                            annotation_file=os.path.join(annotation_data, "instances_val2017.json"),
+                            caption_file=os.path.join(annotation_data, "captions_val2017.json"),
+                            keypoint_file=os.path.join(annotation_data, "person_keypoints_val2017.json"),
                             include_bboxes=load_bboxes,
                             include_masks=load_masks,
-                            include_captions=load_captions)
+                            include_captions=load_captions,
+                            include_keypoints=load_keypoints,
+                            replacement=replacement)
     return train_ds, eval_ds
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/nih_chestxray.py` & `fastestimator-1.6.0/fastestimator/dataset/data/nih_chestxray.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/omniglot.py` & `fastestimator-1.6.0/fastestimator/dataset/data/omniglot.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/penn_treebank.py` & `fastestimator-1.6.0/fastestimator/dataset/data/penn_treebank.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/shakespeare.py` & `fastestimator-1.6.0/fastestimator/dataset/data/shakespeare.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/skl_digits.py` & `fastestimator-1.6.0/fastestimator/trace/meta/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,32 +1,23 @@
-# Copyright 2022 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2021 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from fastestimator.dataset.numpy_dataset import NumpyDataset
-from sklearn import datasets
+from typing import TYPE_CHECKING
 
+import lazy_loader as lazy
 
-def load_data(image_key: str = "x", label_key: str = "y") -> NumpyDataset:
-    """Load and return the Sklearn digits dataset.
+__getattr__, __dir__, __all__ = lazy.attach(__name__,
+                                            submod_attrs={'_per_ds': ['per_ds']})
 
-    Args:
-        image_key: The key for image.
-        label_key: The key for label.
-
-    Returns:
-        (train_data, eval_data)
-    """
-    ds = datasets.load_digits()
-    images = ds.images
-    targets = ds.target
-    return NumpyDataset({image_key: images, label_key: targets})
+if TYPE_CHECKING:
+    from fastestimator.trace.meta._per_ds import per_ds
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/svhn.py` & `fastestimator-1.6.0/fastestimator/dataset/data/svhn.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/svhn_cropped.py` & `fastestimator-1.6.0/fastestimator/dataset/data/svhn_cropped.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/tednmt.py` & `fastestimator-1.6.0/fastestimator/dataset/data/tednmt.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/data/tiny_imagenet.py` & `fastestimator-1.6.0/fastestimator/dataset/data/tiny_imagenet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/dataloader.py` & `fastestimator-1.6.0/fastestimator/dataset/dataloader.py`

 * *Files 4% similar despite different names*

```diff
@@ -11,28 +11,34 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import functools
 import random
 from abc import ABC
-from typing import Any, Callable, Dict, List, Optional, Sized, Tuple, Union
+from typing import Any, Callable, Dict, List, Optional, Protocol, Sized, Tuple, Union
 
 import numpy as np
 from torch import Tensor
-from torch.utils.data import DataLoader, Dataset, Sampler, _DatasetKind
+from torch.utils.data import DataLoader, Sampler, _DatasetKind
 from torch.utils.data._utils.collate import default_collate, default_convert
 from torch.utils.data._utils.fetch import _MapDatasetFetcher
 from torch.utils.data.dataloader import _BaseDataLoaderIter, _MultiProcessingDataLoaderIter, \
     _SingleProcessDataLoaderIter
 
 from fastestimator.dataset.extend_dataset import ExtendDataset
+from fastestimator.dataset.interleave_dataset import InterleaveDataset
 from fastestimator.dataset.op_dataset import OpDataset
-from fastestimator.util.base_util import Suppressor
-from fastestimator.util.data import FilteredData
+from fastestimator.types import FilteredData, MapDataset
+from fastestimator.util.util import Suppressor
+
+
+class PostProcessFunction(Protocol):
+    def __call__(self, data: Dict[str, Any], shared: bool = True) -> Union[Dict[str, Any], FilteredData]:
+        ...
 
 
 class FEDataLoader(DataLoader):
     """A Data Loader that can handle filtering data.
 
     This class is intentionally not @traceable.
 
@@ -60,21 +66,21 @@
     _current_threads = []
     FE_LOADER_KIND = 7
 
     # The typing for 'dataset' should be an 'and' rather than 'or' but that feature is still under development:
     # https://github.com/python/typing/issues/213
 
     def __init__(self,
-                 dataset: Union[Dataset, Sized],
-                 postprocess_fn: Optional[Callable[[Dict[str, Any]], Union[Dict[str, Any], FilteredData]]] = None,
+                 dataset: MapDataset,
+                 postprocess_fn: Optional[PostProcessFunction] = None,
                  batch_size: Optional[int] = 1,
                  steps_per_epoch: Optional[int] = None,
                  shuffle: bool = False,
                  num_workers: int = 0,
-                 collate_fn: Callable = None,
+                 collate_fn: Optional[Callable] = None,
                  drop_last: bool = False):
         reset_fn = dataset.fe_reset_ds if hasattr(dataset, 'fe_reset_ds') else None
         convert_fn = dataset.fe_batch_indices if hasattr(dataset, 'fe_batch_indices') else None
         sampler = InfiniteSampler(data_source=dataset, shuffle=shuffle, reset_fn=reset_fn, convert_fn=convert_fn)
         if batch_size is not None and batch_size < 1:
             raise ValueError(f"batch_size must be None or a positive integer, but got {batch_size}")
         # Figure out the real batch size. This is already done in OpDataset, but if user manually instantiates this
@@ -100,15 +106,15 @@
                 to_yield = len(dataset)
             if drop_last:
                 to_yield -= to_yield % (batch_size or 1)
         self.fe_samples_to_yield = to_yield
         self.fe_drop_last = drop_last
         self.fe_collate_fn = collate_fn or default_collate
         if self.fe_batch_size in (0, None) and batch_size is None and self.fe_collate_fn == default_collate:
-            # The user did not provide a batch dataset nor a batch size, so default collate won't work. Have to try
+            # The user did not provide a batched dataset nor a batch size, so default collate won't work. Have to try
             # convert instead.
             self.fe_collate_fn = default_convert
         self.fe_postprocess_fn = postprocess_fn
 
         # We could disable pre-collating when num_workers=0, but this would lead to inconsistent batch ordering between
         # single- and multi-processing.
 
@@ -196,15 +202,14 @@
 
 class _BaseFELoaderIter(_BaseDataLoaderIter, ABC):
     """A base class for the FE Data iterators.
 
     Args:
         loader: The parent loader object that will own this iterator.
     """
-
     def __init__(self, loader: FEDataLoader):
         super().__init__(loader)
         self.fe_batch_size = loader.fe_batch_size
         self.fe_drop_last = loader.fe_drop_last
         self.fe_collate_fn = loader.fe_collate_fn
         self.fe_postprocess_fn = loader.fe_postprocess_fn
         self.fe_samples_to_yield = loader.fe_samples_to_yield
@@ -271,15 +276,16 @@
     if not real_batch or (self.fe_drop_last and len(real_batch) < self.fe_batch_size):
         self.fe_extra_data.clear()  # Throw out any extra data
         raise StopIteration
     # Collate the batch
     collated = self.fe_collate_fn(real_batch)
     # Apply any batch-level operations
     if self.fe_postprocess_fn is not None:
-        collated = self.fe_postprocess_fn(collated)
+        # Don't place tensor into shared memory if it's already on the host device as this can lead to infinite lockup
+        collated = self.fe_postprocess_fn(collated, shared=False)
         if isinstance(collated, FilteredData):
             if collated.replacement:
                 self.fe_samples_yielded -= len(real_batch)
             return _next_pre_batch(self)
     return collated
 
 
@@ -297,31 +303,53 @@
     while self.fe_samples_yielded < self.fe_samples_to_yield:
         collated, candidate_batch = self._next_data()
         if collated is True:  # Not regular if check since collated might be FilteredData
             self.fe_samples_yielded += 1
             return candidate_batch
         if isinstance(collated, FilteredData):
             # The batch was filtered during the forward_batch pass
-            if not collated.replacement:
-                self.fe_samples_yielded += 1
+            if isinstance(self._dataset, InterleaveDataset):
+                # We have to burn an entire cycle of data in order to ensure that the next sample comes from the desired
+                # dataset again without messing up any interactions between a fancy pattern and merge_grad
+                for _ in range(len(self._dataset.pattern) - 1):
+                    self._next_data()
+                if not collated.replacement:
+                    self.fe_samples_yielded += len(self._dataset.pattern)  # You burned this one + the rest of the cycle
+            else:
+                if not collated.replacement:
+                    self.fe_samples_yielded += 1
         else:
             # The filtered data appeared before batching, need to find it
             for instance in candidate_batch:
                 if isinstance(instance, FilteredData):
-                    if not instance.replacement:
-                        self.fe_samples_yielded += 1
+                    if isinstance(self._dataset, InterleaveDataset):
+                        # Burn data
+                        for _ in range(len(self._dataset.pattern) - 1):
+                            self._next_data()
+                        if not instance.replacement:
+                            self.fe_samples_yielded += len(self._dataset.pattern)
+                    else:
+                        if not instance.replacement:
+                            self.fe_samples_yielded += 1
                     break
             else:
                 # The else block is reached iff the for loop never breaks (probably should never get here)
                 collated = self.fe_collate_fn(candidate_batch)
                 if self.fe_postprocess_fn is not None:
-                    collated = self.fe_postprocess_fn(collated)
+                    collated = self.fe_postprocess_fn(collated, shared=False)
                     if isinstance(collated, FilteredData):
-                        if not collated.replacement:
-                            self.fe_samples_yielded += 1
+                        if isinstance(self._dataset, InterleaveDataset):
+                            # Burn data
+                            for _ in range(len(self._dataset.pattern) - 1):
+                                self._next_data()
+                            if not collated.replacement:
+                                self.fe_samples_yielded += len(self._dataset.pattern)
+                        else:
+                            if not collated.replacement:
+                                self.fe_samples_yielded += 1
                         return _next_post_batch(self)
                 self.fe_samples_yielded += 1
                 return collated
     raise StopIteration
 
 
 class _SPPreBatchIter(_BaseFELoaderIter, _SingleProcessDataLoaderIter):
@@ -347,21 +375,21 @@
         data_source: The dataset to be sampled.
         shuffle: Whether to shuffle when sampling.
         reset_fn: A function to be invoked (using the provided `shuffle` arg) every time the dataset has been fully
             traversed.
         convert_fn: A function to be invoked (using the current index) every sample in order to convert an integer index
             into some arbitrary alternative index representation.
     """
-
     def __init__(self,
                  data_source: Sized,
                  shuffle: bool = True,
                  reset_fn: Optional[Callable[[bool], None]] = None,
                  convert_fn: Optional[Callable[[int], Any]] = None):
-        super().__init__(data_source=data_source)
+        super().__init__(data_source=None)  # Arg is unused and triggers a warning in torch 2.1
+        self.interleave_ds = isinstance(data_source, InterleaveDataset)
         self.ds_len = len(data_source)
         if self.ds_len < 1:
             raise ValueError("dataset length must be at least 1")
         self.indices = [i for i in range(self.ds_len)]
         self.shuffle = shuffle
         self.reset_fn = reset_fn
         self.convert_fn = convert_fn
@@ -370,24 +398,26 @@
     def __len__(self):
         return self.ds_len
 
     def __iter__(self):
         self.idx = 0
         if self.reset_fn:
             self.reset_fn(self.shuffle)
-        if self.shuffle:
+        if self.shuffle and not self.interleave_ds:
+            # interleave_ds requires unshuffled indices to work correctly with its repeating pattern
             random.shuffle(self.indices)
         return self
 
     def __next__(self):
         if self.idx == self.ds_len:
             self.idx = 0
             if self.reset_fn:
                 self.reset_fn(self.shuffle)
-            if self.shuffle:
+            if self.shuffle and not self.interleave_ds:
+                # interleave_ds requires unshuffled indices to work correctly with its repeating pattern
                 random.shuffle(self.indices)
         elem = self.indices[self.idx]
         self.idx += 1
         if self.convert_fn:
             elem = self.convert_fn(elem)
         return elem
 
@@ -396,15 +426,14 @@
 # Here we use a hack to patch a special fetcher into the pytorch ecosystem. This allows us to return the dataset indices
 # alongside the collated data points in case the batch needs to be re-constructed later. It won't interfere with regular
 # pytorch usage since our reserved 'kind' value is 7 whereas pytorch only uses 0 and 1.
 ###
 
 
 class _IdxMapDatasetFetcher(_MapDatasetFetcher):
-
     def fetch(self, possibly_batched_index):
         if self.auto_collation:
             data = [self.dataset[idx] for idx in possibly_batched_index]
         else:
             data = self.dataset[possibly_batched_index]
         return possibly_batched_index, self.collate_fn(data)
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/dataset.py` & `fastestimator-1.6.0/fastestimator/dataset/dataset.py`

 * *Files 4% similar despite different names*

```diff
@@ -12,22 +12,24 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import math
 import random
 from collections import defaultdict
 from copy import deepcopy
-from typing import Any, Dict, Hashable, Iterable, List, Optional, Sequence, Tuple, Union
+from typing import Any, Dict, Hashable, Iterable, List, Optional, Sequence, Tuple, Union, cast, overload
 
 import jsonpickle
 import numpy as np
 from torch.utils.data import Dataset
+from typing_extensions import Self
 
+from fastestimator.types import DataSequence
+from fastestimator.util.base_util import FEID, get_shape, get_type
 from fastestimator.util.traceability_util import FeSplitSummary, traceable
-from fastestimator.util.base_util import get_type, FEID, get_shape
 
 
 class KeySummary:
     """A summary of the dataset attributes corresponding to a particular key.
 
     This class is intentionally not @traceable.
 
@@ -37,17 +39,18 @@
             ragged.
         dtype: The data type of instances corresponding to the given key.
     """
     num_unique_values: Optional[int]
     shape: List[Optional[int]]
     dtype: str
 
-    def __init__(self, dtype: str, num_unique_values: Optional[int] = None, shape: List[Optional[int]] = ()) -> None:
+    def __init__(self, dtype: str, num_unique_values: Optional[int] = None,
+                 shape: Sequence[Optional[int]] = ()) -> None:
         self.num_unique_values = num_unique_values
-        self.shape = shape
+        self.shape = list(shape)
         self.dtype = dtype
 
     def __repr__(self):
         return "<KeySummary {}>".format(self.__getstate__())
 
     def __getstate__(self):
         return {k: v for k, v in self.__dict__.items() if v is not None}
@@ -166,18 +169,37 @@
                                     seed=seed,
                                     stratify=stratify)
             table.fields['split'] = split_summary
             # Put the new parent summary into the child table to ensure it will always exist in the final set of tables
             for child in children:
                 child._fe_traceability_summary[parent_id] = deepcopy(table)
 
+    @overload
     def split(self,
+              __fraction1: Union[float, int, Iterable[int]],
+              /,
+              *,
+              seed: Optional[int] = None,
+              stratify: Optional[str] = None) -> Self:
+        ...
+
+    @overload
+    def split(self,
+              __fraction1: Union[float, int, Iterable[int]],
+              __fraction2: Union[float, int, Iterable[int]],
+              /,
               *fractions: Union[float, int, Iterable[int]],
               seed: Optional[int] = None,
-              stratify: Optional[str] = None) -> Union['FEDataset', List['FEDataset']]:
+              stratify: Optional[str] = None) -> List[Self]:
+        ...
+
+    def split(self,
+              *fractions: Union[float, int, Iterable[int]],
+              seed: Optional[int] = None,
+              stratify: Optional[str] = None) -> Union[Self, List[Self]]:
         """Split this dataset into multiple smaller datasets.
 
         This function enables several types of splitting:
         1. Splitting by fractions.
             ```python
             ds = fe.dataset.FEDataset(...)  # len(ds) == 1000
             ds2 = ds.split(0.1)  # len(ds) == 900, len(ds2) == 100
@@ -248,15 +270,15 @@
         if method == 'number':
             if stratify is not None:
                 splits = self._get_stratified_splits(n_samples, seed, stratify)
             else:
                 splits = self._get_fractional_splits(n_samples, seed)
         else:  # method == 'indices':
             assert stratify is None, "Stratify may only be specified when splitting by count or fraction, not by index"
-            splits = fractions
+            splits = cast(Sequence[Iterable[int]], fractions)
         splits = self._do_split(splits)
         FEDataset.fix_split_traceabilty(self, splits, fractions, seed, stratify)
         if len(fractions) == 1:
             return splits[0]
         return splits
 
     def _get_stratified_splits(self, split_counts: List[int], seed: Optional[int],
@@ -282,16 +304,18 @@
             sample = self[idx]
             key = sample[stratify]
             if hasattr(key, "tobytes"):
                 key = key.tobytes()  # Makes numpy arrays hashable
             distribution[key].append(idx)
 
         supply = {key: len(values) for key, values in distribution.items()}
-        split_requests = [{key: (n_split * n_tot) / original_size
-                           for key, n_tot in supply.items()} for n_split in split_counts]
+        split_requests = [{
+            key: (n_split * n_tot) / original_size
+            for key, n_tot in supply.items()
+        } for n_split in split_counts]
 
         def transfer(source: Dict[Any, int], sink: Dict[Any, int], key: Any, request: int) -> int:
             allowance = min(request, source[key])
             source[key] -= allowance
             sink[key] += allowance
             return allowance
 
@@ -375,15 +399,15 @@
         Useful if sub-classes want to split by something other than indices (see SiameseDirDataset for example).
 
         Returns:
             The apparent length of the dataset for the purpose of the .split() function
         """
         return len(self)
 
-    def _do_split(self, splits: Sequence[Iterable[int]]) -> List['FEDataset']:
+    def _do_split(self, splits: Sequence[Iterable[int]]) -> List[Self]:
         """Split the current dataset apart into several smaller datasets.
 
         Args:
             splits: Which indices to remove from the current dataset in order to create new dataset(s). One dataset will
                 be generated for every iterable within the `splits` sequence.
 
         Returns:
@@ -414,14 +438,22 @@
     def __init__(self, data: Dict[int, Dict[str, Any]]) -> None:
         self.data = data
         self._summary = None
 
     def __len__(self) -> int:
         return len(self.data)
 
+    @overload
+    def __getitem__(self, index: int) -> Dict[str, Any]:
+        ...
+
+    @overload
+    def __getitem__(self, index: str) -> Union[np.ndarray, List[Any]]:
+        ...
+
     def __getitem__(self, index: Union[int, str]) -> Union[Dict[str, Any], np.ndarray, List[Any]]:
         """Look up data from the dataset.
 
         ```python
         data = fe.dataset.InMemoryDataset(...)  # {"x": <100>}, len(data) == 1000
         element = data[0]  # {"x": <100>}
         column = data["x"]  # <1000x100>
@@ -431,22 +463,32 @@
             index: Either an int corresponding to a particular element of data, or a string in which case the
                 corresponding column of data will be returned.
 
         Returns:
             A data dictionary if the index was an int, otherwise a column of data in list format.
         """
         if isinstance(index, int):
+            if index >= len(self):
+                raise StopIteration
             return self.data[index]
         else:
             result = [elem[index] for elem in self.data.values()]
             if isinstance(result[0], np.ndarray):
                 return np.array(result)
             return result
 
-    def __setitem__(self, key: Union[int, str], value: Union[Dict[str, Any], Sequence[Any]]) -> None:
+    @overload
+    def __setitem__(self, key: int, value: Dict[str, Any]) -> None:
+        ...
+
+    @overload
+    def __setitem__(self, key: str, value: DataSequence) -> None:
+        ...
+
+    def __setitem__(self, key: Union[int, str], value: Union[Dict[str, Any], DataSequence]) -> None:
         """Modify data in the dataset.
 
         ```python
         data = fe.dataset.InMemoryDataset(...)  # {"x": <100>}, len(data) == 1000
         column = data["x"]  # <1000x100>
         column = column - np.mean(column)
         data["x"] = column
@@ -458,24 +500,27 @@
             value: The value to be inserted for the given `key`. Must be a dictionary if `key` is an integer. Otherwise
                 must be a sequence with the same length as the current length of the dataset.
 
         Raises:
             AssertionError: If the `value` is inappropriate given the type of the `key`.
         """
         if isinstance(key, int):
-            assert isinstance(value, Dict), "if setting a value using an integer index, must provide a dictionary"
+            assert isinstance(value, Dict), \
+                f"if setting a value using an integer index, must provide a dictionary (got {type(value)})"
             self.data[key] = value
         else:
+            assert isinstance(value, DataSequence), \
+                f"if setting a value using a key index, must provide a sequence (got {type(value)})"
             assert len(value) == len(self.data), \
                 "input value must be of length {}, but had length {}".format(len(self.data), len(value))
             for i in range(len(self.data)):
                 self.data[i][key] = value[i]
         self._summary = None
 
-    def _skip_init(self, data: Dict[int, Dict[str, Any]], **kwargs) -> 'InMemoryDataset':
+    def _skip_init(self, data: Dict[int, Dict[str, Any]], **kwargs) -> Self:
         """A helper method to create new dataset instances without invoking their __init__ methods.
 
         Args:
             data: The data dictionary to be used in the new dataset.
             **kwargs: Any other member variables to be assigned in the new dataset.
 
         Returns:
@@ -484,15 +529,15 @@
         obj = self.__class__.__new__(self.__class__)
         obj.data = data
         for k, v in kwargs.items():
             obj.__setattr__(k, v)
         obj._summary = None
         return obj
 
-    def _do_split(self, splits: Sequence[Iterable[int]]) -> List['InMemoryDataset']:
+    def _do_split(self, splits: Sequence[Iterable[int]]) -> List[Self]:
         """Split the current dataset apart into several smaller datasets.
 
         Args:
             splits: Which indices to remove from the current dataset in order to create new dataset(s). One dataset will
                 be generated for every iterable within the `splits` sequence.
 
         Returns:
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/dir_dataset.py` & `fastestimator-1.6.0/fastestimator/dataset/dir_dataset.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/extend_dataset.py` & `fastestimator-1.6.0/fastestimator/dataset/extend_dataset.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from torch.utils.data import Dataset
 
+from fastestimator.dataset.interleave_dataset import InterleaveDataset
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class ExtendDataset(Dataset):
     """ExtendDataset either extends or contracts the length of provided Dataset.
 
@@ -43,10 +44,11 @@
         """Verify that the given input values are valid.
         Raises:
             AssertionError: If any of the parameters are found to by unacceptable for a variety of reasons.
         """
         assert isinstance(self.spoof_length, int), "Only accept positive integer type as spoof_length"
         assert self.spoof_length > 0, "Invalid spoof_length. Expand Length cannot be less than or equal to 0"
         assert not isinstance(self.dataset, ExtendDataset), "Input Dataset cannot be an ExtendDataset object"
+        assert not isinstance(self.dataset, InterleaveDataset), "Input Dataset cannot be an InterleaveDataset object"
 
     def __getitem__(self, index):
         return self.dataset[index]
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/generator_dataset.py` & `fastestimator-1.6.0/fastestimator/dataset/generator_dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Any, Dict, Generator, Iterable, List, Optional, Sequence, Sized
 
 from fastestimator.dataset.dataset import DatasetSummary, FEDataset, KeySummary
+from fastestimator.util.base_util import get_shape, get_type, warn
 from fastestimator.util.traceability_util import traceable
-from fastestimator.util.base_util import get_type, get_shape
 
 
 @traceable(blacklist='_summary')
 class GeneratorDataset(FEDataset):
     """A dataset from a generator function.
 
     Args:
@@ -35,43 +35,44 @@
         next(self.generator)  # Can't send non-none values to a new generator, so need to run a 'warm-up' first
         self._summary = None
 
     def __len__(self):
         return self.samples_per_epoch
 
     def __getitem__(self, index: int):
+        if index >= len(self):
+            raise StopIteration
         return self.generator.send(index)
 
     def _do_split(self, splits: Sequence[Iterable[int]]) -> List['GeneratorDataset']:
         """Split the current dataset apart into several smaller datasets.
 
         Args:
             splits: Which indices to remove from the current dataset in order to create new dataset(s). One dataset will
                 be generated for every iterable within the `splits` sequence.
 
         Returns:
             New datasets generated by removing data at the indices specified by `splits` from the current dataset.
         """
-        print("FastEstimator-Warn: You probably don't actually want to split a generator dataset")
+        warn("You probably don't actually want to split a generator dataset")
         self._summary = None
         results = []
         for split in splits:
             if isinstance(split, Sized):
                 size = len(split)
             else:
                 # TODO - make this efficient somehow
                 size = sum(1 for _ in split)
             results.append(GeneratorDataset(self.generator, size))
             self.samples_per_epoch -= size
         return results
 
     def _get_stratified_splits(self, split_counts: List[int], seed: Optional[int],
                                stratify: str) -> Sequence[Iterable[int]]:
-        print("\033[93m {}\033[00m".format(
-            "Warning! GeneratorDataset does not support stratified splits. Falling back to classical split method."))
+        warn("GeneratorDataset does not support stratified splits. Falling back to classical split method.")
         return self._get_fractional_splits(split_counts=split_counts, seed=seed)
 
     def summary(self) -> DatasetSummary:
         """Generate a summary representation of this dataset.
         Returns:
             A summary representation of this dataset.
         """
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/labeled_dir_dataset.py` & `fastestimator-1.6.0/fastestimator/dataset/labeled_dir_dataset.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/numpy_dataset.py` & `fastestimator-1.6.0/fastestimator/dataset/numpy_dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -39,8 +39,8 @@
                 current_size = len(val)
             else:
                 raise ValueError("Please ensure you are passing numpy array or list in the data dictionary.")
             if size is not None:
                 assert size == current_size, "All data arrays must have the same number of elements"
             else:
                 size = current_size
-        super().__init__({i: {k: v[i] for k, v in data.items()} for i in range(size)})
+        super().__init__({i: {k: v[i] for k, v in data.items()} for i in range(size)} if size else {})
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/op_dataset.py` & `fastestimator-1.6.0/fastestimator/dataset/op_dataset.py`

 * *Files 13% similar despite different names*

```diff
@@ -8,23 +8,26 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
+import ctypes
 from copy import deepcopy
-from multiprocessing import Lock
-from typing import Any, Dict, List, Mapping, Optional, Set, Union
+from multiprocessing import Array, Lock
+from typing import Any, Dict, List, Optional, Set, Union
 
 import numpy as np
+from natsort import humansorted
 from torch.utils.data import Dataset
 
 from fastestimator.op.numpyop.numpyop import NumpyOp, forward_numpyop
-from fastestimator.util.data import FilteredData
+from fastestimator.types import FilteredData
+from fastestimator.util.base_util import warn
 from fastestimator.util.traceability_util import traceable
 
 
 class _DelayedDeepDict(dict):
     """A class to perform delayed deep copying from another dictionary.
 
     This class is intentionally not @traceable (need quick instantiation).
@@ -92,14 +95,17 @@
         self.base = {}
         # We need to mark all of the arrays as writeable again to avoid warnings from pytorch. Once torch wraps the
         # arrays, in-place edits on the torch tensors do not impact the numpy arrays anyways.
         for val in self.values():
             if isinstance(val, np.ndarray):
                 val.flags.writeable = True
 
+    def as_dict(self) -> Dict[str, Any]:
+        return dict(self)
+
 
 @traceable(blacklist='lock')
 class OpDataset(Dataset):
     """A wrapper for datasets which allows operators to be applied to them in a pipeline.
 
     This class should not be directly instantiated by the end user. The fe.Pipeline will automatically wrap datasets
     within an Op dataset as needed.
@@ -108,17 +114,14 @@
         dataset: The base dataset to wrap.
         ops: A list of ops to be applied after the base `dataset` `__getitem__` is invoked.
         mode: What mode the system is currently running in ('train', 'eval', 'test', or 'infer').
         output_keys: What keys can be produced from pipeline. If None or empty, all keys will be considered.
         deep_remainder: Whether data which is not modified by Ops should be deep copied or not. This argument is used to
             help with RAM management, but end users can almost certainly ignore it.
     """
-    to_warn: Set[str] = set()
-    warned: Set[str] = set()
-
     def __init__(self,
                  dataset: Dataset,
                  ops: List[NumpyOp],
                  mode: str,
                  output_keys: Optional[Set[str]] = None,
                  deep_remainder: bool = True) -> None:
         # Track whether this dataset returns batches or not (useful for pipeline and traceability)
@@ -132,16 +135,20 @@
         if hasattr(dataset, "fe_batch_indices"):
             self.fe_batch_indices = dataset.fe_batch_indices
         self.ops = ops
         self.mode = mode
         self.output_keys = output_keys
         self.deep_remainder = deep_remainder
         self.lock = Lock()
+        self.to_warn: Set[str] = set()
+        if not hasattr(OpDataset, 'warned'):
+            # Declaring this outside the init would trigger mac multi-processing to pick a non-fork start method
+            OpDataset.warned = Array(ctypes.c_char, 200, lock=False)
 
-    def __getitem__(self, index: int) -> Union[Mapping[str, Any], List[Mapping[str, Any]], FilteredData]:
+    def __getitem__(self, index: int) -> Union[Dict[str, Any], List[Dict[str, Any]], FilteredData]:
         """Fetch a data instance at a specified index, and apply transformations to it.
 
         Args:
             index: Which datapoint to retrieve.
 
         Returns:
             The data dictionary from the specified index, with transformations applied OR an indication that this index
@@ -157,32 +164,58 @@
                 if data_id not in unique_samples:
                     data = _DelayedDeepDict(data)
                     filter_data = forward_numpyop(self.ops, data, {'mode': self.mode})
                     if filter_data:
                         results.append(filter_data)
                     else:
                         data.finalize(retain=self.output_keys, deep_remainder=self.deep_remainder)
-                        results.append(data)
                         if data.warn:
-                            self.to_warn |= (data.to_warn - self.warned)
+                            self.to_warn |= data.to_warn
+                        results.append(data.as_dict())
                     unique_samples[data_id] = idx
                 else:
                     results.append(results[unique_samples[data_id]])
         else:
             results = _DelayedDeepDict(item)
             filter_data = forward_numpyop(self.ops, results, {'mode': self.mode})
             if filter_data:
                 return filter_data
             results.finalize(retain=self.output_keys, deep_remainder=self.deep_remainder)
             if results.warn:
-                self.to_warn |= (results.to_warn - self.warned)
+                self.to_warn |= results.to_warn
+            results = results.as_dict()
         if self.to_warn and self.lock.acquire(block=False):
-            self.warned.update(self.to_warn)
-            print("FastEstimator-Warn: The following key(s) are being pruned since they are unused outside of the "
-                  "Pipeline. To prevent this, you can declare the key(s) as inputs to Traces or TensorOps: "
-                  f"{', '.join(self.to_warn)}")
+            self.handle_warning(self.to_warn)
             self.to_warn.clear()
             # We intentionally never release the lock so that during multi-threading only 1 message can be printed
         return results
 
+    @classmethod
+    def handle_warning(cls, candidates: Set[str]) -> None:
+        """A function which prints warning messages about unused keys if such messages haven't already been printed.
+
+        Args:
+            candidates: Unused keys which you might need to print a warning message about.
+        """
+        if not candidates:
+            return
+        # Keys can't contain the ":" or ";" character due to check_io_names base_util function
+        warned = set((str(cls.warned.value, 'utf8') or "").split(":"))
+        if ";" not in warned:
+            # We use ; as a special character to indicate that the warned buffer was overflowed by too many keys
+            to_warn = candidates - warned
+            if to_warn:
+                warn("The following key(s) are being pruned since they are unused outside of the "
+                     "Pipeline. To prevent this, you can declare the key(s) as inputs to Traces or TensorOps: "
+                     f"{', '.join(humansorted(to_warn))}")
+                warned |= to_warn
+                warned = bytes(":".join(warned), 'utf8')
+                if len(warned) > 198:
+                    # This would overflow the warning buffer, so disable the warning mechanism in the future
+                    # Note that the warning will still happen the first time the overly-long keys appear.
+                    # 198 rather than 199 to allow for a null terminator at the end of the array.
+                    warn("Any further key pruning warnings in subsequent epochs will not be printed.")
+                    warned = bytes(";", 'utf8')
+                cls.warned.value = warned
+
     def __len__(self):
         return len(self.dataset)
```

### Comparing `fastestimator-1.5.2/fastestimator/dataset/pickle_dataset.py` & `fastestimator-1.6.0/fastestimator/dataset/pickle_dataset.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/dataset/siamese_dir_dataset.py` & `fastestimator-1.6.0/fastestimator/dataset/siamese_dir_dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,14 +15,15 @@
 from copy import deepcopy
 from typing import Any, Dict, Iterable, List, Optional, Sequence, Set, Tuple
 
 import numpy as np
 
 from fastestimator.dataset.dataset import DatasetSummary
 from fastestimator.dataset.labeled_dir_dataset import LabeledDirDataset
+from fastestimator.util.base_util import warn
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable(blacklist=('data', 'class_data', '_summary'))
 class SiameseDirDataset(LabeledDirDataset):
     """A dataset which returns pairs of data.
 
@@ -113,16 +114,15 @@
         self.class_data = self._data_to_class(self.data, self.label_key)
         # The summary function is being cached by a base class, so reset our cache here
         self._summary = None
         return results
 
     def _get_stratified_splits(self, split_counts: List[int], seed: Optional[int],
                                stratify: str) -> Sequence[Iterable[int]]:
-        print("\033[93m {}\033[00m".format(
-            "Warning! SiameseDirDataset does not support stratified splits. Falling back to classical split method."))
+        warn("SiameseDirDataset does not support stratified splits. Falling back to classical split method.")
         return self._get_fractional_splits(split_counts=split_counts, seed=seed)
 
     def __getitem__(self, index: int):
         """Extract items from the dataset based on the given `batch_idx`.
 
         Args:
             index: Which data instance to use as the 'left' element.
```

### Comparing `fastestimator-1.5.2/fastestimator/estimator.py` & `fastestimator-1.6.0/fastestimator/estimator.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,18 +9,19 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import inspect
+import math
 import os
 import random
 from collections import ChainMap
-from typing import Any, Dict, Iterable, List, Optional, Sequence, Set, Union
+from typing import Any, Dict, Iterable, List, Optional, Sequence, Set, Union, overload
 
 import numpy as np
 import tensorflow as tf
 import torch
 from tensorflow.python.distribute.input_lib import DistributedDataset
 from torch.utils.data import DataLoader
 
@@ -35,29 +36,28 @@
 from fastestimator.summary.system import Summary, System
 from fastestimator.trace.io.best_model_saver import BestModelSaver
 from fastestimator.trace.io.model_saver import ModelSaver
 from fastestimator.trace.io.restore_wizard import RestoreWizard
 from fastestimator.trace.io.traceability import Traceability
 from fastestimator.trace.trace import EvalEssential, Logger, PerDSTrace, TestEssential, Trace, TrainEssential, \
     sort_traces
-from fastestimator.util.base_util import NonContext, Suppressor, to_list, to_set
-from fastestimator.util.data import Data, FilteredData
+from fastestimator.types import FilteredData
+from fastestimator.util.base_util import NonContext, filter_nones, to_list, to_set, warn
+from fastestimator.util.data import Data
 from fastestimator.util.traceability_util import traceable
-from fastestimator.util.util import draw
+from fastestimator.util.util import Suppressor, draw
 
 
 def _verify_dependency_versions() -> None:
     """Print warning messages if the user is using unexpected versions of TF or torch.
     """
-    if tf.__version__ != '2.9.1':
-        print("\033[93m{}\033[00m".format("FastEstimator-Warn: Expected TensorFlow version 2.9.1 but found "
-                                          f"{tf.__version__}. The framework may not work as expected."))
-    if torch.__version__ not in ('1.10.2', '1.10.2+cpu', '1.10.2+cu113'):
-        print("\033[93m{}\033[00m".format("FastEstimator-Warn: Expected PyTorch version 1.10.2 but found "
-                                          f"{torch.__version__}. The framework may not work as expected."))
+    if tf.__version__ not in {'2.11.1', '2.11.0'}:
+        warn(f"Expected TensorFlow version 2.11.1 but found {tf.__version__}. The framework may not work as expected.")
+    if torch.__version__ not in ('2.0.1', '2.0.1+cpu', '2.0.1+cu118'):
+        warn(f"Expected PyTorch version 2.0.1 but found {torch.__version__}. The framework may not work as expected.")
 
 
 @traceable()
 class Estimator:
     """One class to rule them all.
 
     Estimator is the highest level class within FastEstimator. It is the class which is invoked to actually train
@@ -90,26 +90,26 @@
 
     def __init__(self,
                  pipeline: Pipeline,
                  network: BaseNetwork,
                  epochs: int,
                  train_steps_per_epoch: Optional[int] = None,
                  eval_steps_per_epoch: Optional[int] = None,
-                 traces: Union[None, Trace, Scheduler[Trace], Iterable[Union[Trace, Scheduler[Trace]]]] = None,
+                 traces: Union[None, Trace, Scheduler[Trace], Sequence[Union[None, Trace, Scheduler[Trace]]]] = None,
                  log_steps: Optional[int] = 100,
                  eval_log_steps: Sequence[int] = (),
-                 monitor_names: Union[None, str, Iterable[str]] = None):
+                 monitor_names: Union[None, str, Iterable[Optional[str]]] = None):
         self.traces_in_use = []
         self.filepath = os.path.realpath(inspect.stack()[2].filename)  # Record this for history tracking
         assert log_steps is None or log_steps >= 0, \
             "log_steps must be None or positive (or 0 to disable only train logging)"
-        self.monitor_names = to_set(monitor_names) | network.get_loss_keys()
+        self.monitor_names = filter_nones(to_set(monitor_names)) | network.get_loss_keys()
         self.system = System(network=network,
                              pipeline=pipeline,
-                             traces=to_list(traces),
+                             traces=filter_nones(to_list(traces)),
                              log_steps=log_steps,
                              total_epochs=epochs,
                              train_steps_per_epoch=train_steps_per_epoch,
                              eval_steps_per_epoch=eval_steps_per_epoch,
                              eval_log_steps=eval_log_steps,
                              system_config=self.fe_summary())
 
@@ -121,14 +121,22 @@
     def network(self) -> BaseNetwork:
         return self.system.network
 
     @property
     def traces(self) -> List[Union[Trace, Scheduler[Trace]]]:
         return self.system.traces
 
+    @overload
+    def fit(self, summary: None = None, warmup: bool = True, eager: bool = False) -> None:
+        ...
+
+    @overload
+    def fit(self, summary: str, warmup: bool = True, eager: bool = False) -> Summary:
+        ...
+
     def fit(self, summary: Optional[str] = None, warmup: bool = True, eager: bool = False) -> Optional[Summary]:
         """Train the network for the number of epochs specified by the estimator's constructor.
 
         Args:
             summary: A name for the experiment. If provided, the log history will be recorded in-memory and returned as
                 a summary object at the end of training.
             warmup: Whether to perform warmup before training begins. The warmup procedure will test one step at every
@@ -172,23 +180,31 @@
         if "train" in run_modes:
             self.traces_in_use.insert(0, TrainEssential(monitor_names=self.monitor_names.union(extra_monitor_keys)))
             no_save_warning = True
             for trace in get_current_items(self.traces_in_use, run_modes=run_modes):
                 if isinstance(trace, (ModelSaver, BestModelSaver)):
                     no_save_warning = False
             if no_save_warning:
-                print("FastEstimator-Warn: No ModelSaver Trace detected. Models will not be saved.")
+                warn("No ModelSaver Trace detected. Models will not be saved.")
         if "eval" in run_modes and "eval" in self.pipeline.get_modes():
             self.traces_in_use.insert(1, EvalEssential(monitor_names=self.monitor_names.union(extra_monitor_keys)))
         if "test" in run_modes and "test" in self.pipeline.get_modes():
             self.traces_in_use.insert(0, TestEssential(monitor_names=self.monitor_names.union(extra_monitor_keys)))
         # insert system instance to trace
         for trace in get_current_items(self.traces_in_use, run_modes=run_modes):
             trace.system = self.system
 
+    @overload
+    def test(self, summary: None = None, eager: bool = False) -> None:
+        ...
+
+    @overload
+    def test(self, summary: str, eager: bool = False) -> Summary:
+        ...
+
     def test(self, summary: Optional[str] = None, eager: bool = False) -> Optional[Summary]:
         """Run the pipeline / network in test mode for one epoch.
 
         Args:
             summary: A name for the experiment. If provided, the log history will be recorded in-memory and returned as
                 a summary object at the end of training. If None, the default value will be whatever `summary` name was
                 most recently provided to this Estimator's .fit() or .test() methods.
@@ -215,62 +231,79 @@
         Args:
             eager: Whether to run the training in eager mode. This is only related to TensorFlow training because
                 PyTorch by nature is always in eager mode.
         """
         all_traces = get_current_items(self.traces_in_use, run_modes={"train", "eval"})
         sort_traces(all_traces, ds_ids=[])  # This ensures that the traces can sort properly for on_begin and on_end
         monitor_names = self.monitor_names
+        unmet_monitor_names = set(monitor_names)
         for mode in self.pipeline.get_modes() - {"test"}:
             scheduled_items = self.pipeline.get_scheduled_items(mode) + self.network.get_scheduled_items(
                 mode) + self.get_scheduled_items(mode)
             signature_epochs = get_signature_epochs(scheduled_items, self.system.total_epochs, mode=mode)
             epochs_with_data = self.pipeline.get_epochs_with_data(total_epochs=self.system.total_epochs, mode=mode)
             for epoch in signature_epochs:
                 if epoch not in epochs_with_data:
                     continue
                 ds_ids = self.pipeline.get_ds_ids(epoch, mode)
                 for ds_id in ds_ids:
-                    network_output_keys = self.network.get_all_output_keys(mode, epoch, ds_id=ds_id)
-                    network_input_keys = self.network.get_effective_input_keys(mode, epoch, ds_id=ds_id)
                     trace_input_keys = set()
                     trace_output_keys = {"*"}
                     traces = get_current_items(self.traces_in_use, run_modes=mode, epoch=epoch, ds_id=ds_id)
                     for idx, trace in enumerate(traces):
-                        if idx > 0:  # ignore TrainEssential and EvalEssential's inputs for unmet requirement checking
+                        if idx == 0:
+                            # Trace 0 is either TrainEssential or EvalEssential. Their inputs are the keys which should
+                            # be monitored, which is a union of self.monitor_names and potentially other keys which were
+                            # found when looping through traces to look for fe_monitor_names.
+                            monitor_names.update(trace.inputs)
+                        else:
+                            # We want to ignore monitor_names for for unmet requirement checking
                             trace_input_keys.update(trace.inputs)
                         trace_output_keys.update(trace.get_outputs(ds_ids=ds_ids))
-                    # key checking
-                    with self.pipeline(mode=mode,
-                                       epoch=epoch,
-                                       ds_id=ds_id,
-                                       steps_per_epoch=None,
-                                       output_keys=trace_input_keys - network_output_keys
-                                       | network_input_keys) as loader:
-                        loader = self._configure_loader(loader)
-                        with Suppressor():
+
+                    with self.network(mode=mode,
+                                      epoch=epoch,
+                                      ds_id=ds_id,
+                                      desired_output_keys=trace_input_keys | monitor_names,
+                                      warmup=True,
+                                      eager=eager):
+
+                        network_input_keys = self.network.ctx_inputs
+                        network_output_keys = self.network.ctx_outputs
+
+                        # key checking
+                        with self.pipeline(
+                                mode=mode,
+                                epoch=epoch,
+                                ds_id=ds_id,
+                                steps_per_epoch=None,
+                                output_keys=(trace_input_keys - network_output_keys)
+                                | network_input_keys | monitor_names) as loader:
+                            loader = self._configure_loader(loader)
                             if isinstance(loader, tf.data.Dataset):
                                 batch = list(loader.take(1))[0]
                             else:
-                                batch = next(iter(loader))
-                        batch = self._configure_tensor(loader, batch)
-                    assert isinstance(batch, dict), "please make sure data output format is dictionary"
-                    pipeline_output_keys = to_set(batch.keys())
-
-                    monitor_names = monitor_names - (pipeline_output_keys | network_output_keys)
-                    unmet_requirements = trace_input_keys - (pipeline_output_keys | network_output_keys
-                                                             | trace_output_keys)
-                    assert not unmet_requirements, \
-                        "found missing key(s) during epoch {} mode {} ds_id {}: {}".format(epoch, mode, ds_id,
-                                                                                           unmet_requirements)
-                    sort_traces(traces, ds_ids=ds_ids, available_outputs=pipeline_output_keys | network_output_keys)
-                    trace_input_keys.update(traces[0].inputs)
-                    self.network.load_epoch(mode, epoch, ds_id, output_keys=trace_input_keys, warmup=True, eager=eager)
-                    self.network.run_step(batch)
-                    self.network.unload_epoch()
-        assert not monitor_names, "found missing key(s): {}".format(monitor_names)
+                                with Suppressor(allow_pyprint=True, show_if_exception=True):
+                                    # TF multi-gpu print-spams here in version 2.11
+                                    batch = next(iter(loader))
+                            batch = self._configure_tensor(loader, batch)
+                        assert isinstance(batch, dict), \
+                            f"please make sure data output format is dictionary (got {type(batch)})"
+                        pipeline_output_keys = to_set(batch.keys())
+
+                        unmet_monitor_names = unmet_monitor_names - (pipeline_output_keys | network_output_keys)
+                        unmet_requirements = trace_input_keys - (pipeline_output_keys | network_output_keys
+                                                                 | trace_output_keys)
+                        assert not unmet_requirements, \
+                            "found missing key(s) during epoch {} mode {} ds_id {}: {}".format(epoch, mode, ds_id,
+                                                                                            unmet_requirements)
+                        sort_traces(traces, ds_ids=ds_ids, available_outputs=pipeline_output_keys | network_output_keys)
+                        trace_input_keys.update(traces[0].inputs)
+                        self.network.run_step(batch)
+        assert not unmet_monitor_names, "found missing key(s): {}".format(unmet_monitor_names)
 
     def get_scheduled_items(self, mode: str) -> List[Any]:
         """Get a list of items considered for scheduling.
 
         Args:
             mode: Current execution mode.
 
@@ -286,14 +319,18 @@
         the trace on_end method.
 
         Args:
             run_modes: The current execution modes.
             eager: Whether to run the training in eager mode. This is only related to TensorFlow training because
                 PyTorch by nature is always in eager mode.
         """
+        with Suppressor():
+            # TODO - remove this after updating to TF > 2.11
+            from tensorflow.python.autograph.pyct.static_analysis.liveness import Analyzer
+            Analyzer.lamba_check(None, None)  # type: ignore
         all_traces = sort_traces(get_current_items(self.traces_in_use, run_modes=run_modes), ds_ids=[])
         with NonContext() if fe.fe_history_path is False else HistoryRecorder(
                 self.system, self.filepath, db_path=fe.fe_history_path):
             try:
                 self._run_traces_on_begin(traces=all_traces)
                 if "train" in run_modes or "eval" in run_modes:
                     # If the training is re-starting from a restore wizard, it should re-run the last eval epoch
@@ -334,69 +371,71 @@
             ds_traces = get_current_items(self.traces_in_use,
                                           run_modes=self.system.mode,
                                           epoch=self.system.epoch_idx,
                                           ds_id=self.system.ds_id)
             trace_input_keys = set()
             for ds_trace in ds_traces:
                 trace_input_keys.update(ds_trace.inputs)
-            network_input_keys = self.network.get_effective_input_keys(mode=self.system.mode,
-                                                                       epoch=self.system.epoch_idx,
-                                                                       ds_id=self.system.ds_id)
-            network_output_keys = self.network.get_all_output_keys(mode=self.system.mode,
-                                                                   epoch=self.system.epoch_idx,
-                                                                   ds_id=self.system.ds_id)
-            self.network.load_epoch(mode=self.system.mode,
-                                    epoch=self.system.epoch_idx,
-                                    ds_id=self.system.ds_id,
-                                    output_keys=trace_input_keys,
-                                    eager=eager)
-
-            with self.pipeline(mode=self.system.mode,
-                               epoch=self.system.epoch_idx,
-                               ds_id=self.system.ds_id,
-                               steps_per_epoch=self.system.steps_per_epoch,
-                               output_keys=trace_input_keys - network_output_keys | network_input_keys) as loader:
-
-                if self.system.mode == 'eval':
-                    log_steps_per_epoch = len(loader) // loader.get_batch_size(
-                    ) if not self.system.steps_per_epoch else self.system.steps_per_epoch
-                    self.system.eval_log_steps = [
-                        1, log_steps_per_epoch // 3, (2 * log_steps_per_epoch) // 3, log_steps_per_epoch
-                    ] if not self.system.eval_log_steps else self.system.eval_log_steps
-
-                loader = self._configure_loader(loader)
-                iterator = iter(loader)
-                with Suppressor():
-                    batch = next(iterator)
-                ds_traces = sort_traces(ds_traces,
-                                        available_outputs=to_set(batch.keys()) | network_output_keys,
-                                        ds_ids=ds_ids)
-                per_ds_traces = [trace for trace in ds_traces if isinstance(trace, PerDSTrace)]
-                self._run_traces_on_ds_begin(traces=per_ds_traces)
-                while True:
-                    try:
-                        if self.system.mode == "train":
-                            self.system.update_global_step()
-                        self.system.update_batch_idx()
-                        batch = self._configure_tensor(loader, batch)
-                        self._run_traces_on_batch_begin(batch, traces=ds_traces)
-
-                        batch, prediction = self.network.run_step(batch)
-                        self._run_traces_on_batch_end(batch, prediction, traces=ds_traces)
-                        if isinstance(loader, DataLoader) and (
-                            (self.system.batch_idx == self.system.train_steps_per_epoch and self.system.mode == "train")
-                                or
-                            (self.system.batch_idx == self.system.eval_steps_per_epoch and self.system.mode == "eval")):
-                            raise StopIteration
-                        with Suppressor():
+            # Note that monitor_names are included in the trace_inputs here, rather than being excluded and then
+            # manually union-ed again later as was done in in _warmup.
+
+            with self.network(mode=self.system.mode,
+                              epoch=self.system.epoch_idx,
+                              ds_id=self.system.ds_id,
+                              desired_output_keys=trace_input_keys,
+                              eager=eager):
+
+                network_input_keys = self.network.ctx_inputs
+                network_output_keys = self.network.ctx_outputs
+
+                with self.pipeline(mode=self.system.mode,
+                                   epoch=self.system.epoch_idx,
+                                   ds_id=self.system.ds_id,
+                                   steps_per_epoch=self.system.steps_per_epoch,
+                                   output_keys=(trace_input_keys - network_output_keys)
+                                   | network_input_keys) as loader:
+
+                    if self.system.mode == 'eval':
+                        log_steps_per_epoch = math.ceil(
+                            len(loader) /
+                            loader.get_batch_size()) if not self.system.steps_per_epoch else self.system.steps_per_epoch
+                        self.system.eval_log_steps = ([
+                            1, log_steps_per_epoch // 3, (2 * log_steps_per_epoch) // 3, log_steps_per_epoch
+                        ], log_steps_per_epoch) if not self.system.eval_log_steps_request else \
+                            (self.system.eval_log_steps_request, log_steps_per_epoch)
+
+                    loader = self._configure_loader(loader)
+                    iterator = iter(loader)
+                    with Suppressor(allow_pyprint=True, show_if_exception=True):
+                        # multi-gpu tensorflow prints a ton of complaint messages here
+                        batch = next(iterator)
+                    ds_traces = sort_traces(ds_traces,
+                                            available_outputs=to_set(batch.keys()) | network_output_keys,
+                                            ds_ids=ds_ids)
+                    per_ds_traces = [trace for trace in ds_traces if isinstance(trace, PerDSTrace)]
+                    self._run_traces_on_ds_begin(traces=per_ds_traces)
+                    while True:
+                        try:
+                            if self.system.mode == "train":
+                                self.system.update_global_step()
+                            self.system.update_batch_idx()
+                            batch = self._configure_tensor(loader, batch)
+                            self._run_traces_on_batch_begin(batch, traces=ds_traces)
+                            batch = self.network.run_step(batch)
+                            self._run_traces_on_batch_end(batch, traces=ds_traces)
+                            if isinstance(loader,
+                                          DataLoader) and ((self.system.batch_idx == self.system.train_steps_per_epoch
+                                                            and self.system.mode == "train") or
+                                                           (self.system.batch_idx == self.system.eval_steps_per_epoch
+                                                            and self.system.mode == "eval")):
+                                raise StopIteration
                             batch = next(iterator)
-                    except StopIteration:
-                        break
-                self._run_traces_on_ds_end(traces=per_ds_traces, data=end_epoch_data)
-            self.network.unload_epoch()
+                        except StopIteration:
+                            break
+                    self._run_traces_on_ds_end(traces=per_ds_traces, data=end_epoch_data)
         self._run_traces_on_epoch_end(traces=epoch_traces, data=end_epoch_data)
 
     def _configure_loader(self, loader: Union[DataLoader, tf.data.Dataset]) -> Union[DataLoader, tf.data.Dataset]:
         """A method to configure a given dataloader for use with this Estimator's Network.
 
         This method will ensure that the `loader` returns the correct data type (tf.Tensor or torch.Tensor) depending on
          the requirements of the Network. It also handles issues with multi-gpu data sharding.
@@ -510,24 +549,22 @@
             traces: List of traces.
         """
         data = Data(batch)
         for trace in traces:
             trace.on_batch_begin(data)
         self._check_early_exit()
 
-    def _run_traces_on_batch_end(self, batch: Dict[str, Any], prediction: Dict[str, Any],
-                                 traces: Iterable[Trace]) -> None:
+    def _run_traces_on_batch_end(self, batch: Dict[str, Any], traces: Iterable[Trace]) -> None:
         """Invoke the on_batch_end methods of given traces.
 
         Args:
             batch: The batch data which was provided by the pipeline.
-            prediction: The prediction data which was generated by the network.
             traces: List of traces.
         """
-        data = Data(ChainMap(prediction, batch))
+        data = Data(batch)
         for trace in traces:
             trace.on_batch_end(data)
         self._check_early_exit()
 
     def _run_traces_on_ds_end(self, traces: Iterable[PerDSTrace], data: Data) -> None:
         """Invoke the on_ds_begin methods of given traces.
```

### Comparing `fastestimator-1.5.2/fastestimator/layers/__init__.py` & `fastestimator-1.6.0/fastestimator/layers/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/layers/pytorch/__init__.py` & `fastestimator-1.6.0/fastestimator/layers/pytorch/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/layers/pytorch/cropping_2d.py` & `fastestimator-1.6.0/fastestimator/layers/pytorch/cropping_2d.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/layers/pytorch/hadamard.py` & `fastestimator-1.6.0/fastestimator/layers/pytorch/hadamard.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/layers/tensorflow/__init__.py` & `fastestimator-1.6.0/fastestimator/layers/tensorflow/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/layers/tensorflow/hadamard.py` & `fastestimator-1.6.0/fastestimator/layers/tensorflow/hadamard.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/layers/tensorflow/instance_norm.py` & `fastestimator-1.6.0/fastestimator/layers/tensorflow/instance_norm.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/layers/tensorflow/reflection_padding_2d.py` & `fastestimator-1.6.0/fastestimator/layers/tensorflow/reflection_padding_2d.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/network.py` & `fastestimator-1.6.0/fastestimator/network.py`

 * *Files 9% similar despite different names*

```diff
@@ -13,230 +13,261 @@
 # limitations under the License.
 # ==============================================================================
 import gc
 import os
 import sys
 import tempfile
 from collections import ChainMap
-from typing import Any, Callable, Dict, Iterable, List, MutableMapping, Optional, Set, Tuple, TypeVar, Union
+from threading import Lock
+from typing import Any, Callable, Dict, Iterable, List, MutableMapping, Optional, Sequence, Set, Tuple, Type, TypeVar, \
+    Union, overload
 
 import gdown
+import keras.mixed_precision as mixed_precision_tf
 import numpy as np
 import tensorflow as tf
-import tensorflow.keras.mixed_precision as mixed_precision_tf
 import torch
+from keras.engine.sequential import Sequential
+from keras.mixed_precision.loss_scale_optimizer import LossScaleOptimizer, LossScaleOptimizerV3
 from tensorflow.python.distribute.values import DistributedValues
-from tensorflow.python.keras.engine.sequential import Sequential
+from typing_extensions import Self
 
 import fastestimator as fe
 from fastestimator.backend._load_model import load_model
 from fastestimator.backend._to_tensor import to_tensor
 from fastestimator.op.numpyop import Batch, NumpyOp, RemoveIf, forward_numpyop
 from fastestimator.op.op import get_inputs_by_op, write_outputs_by_op
 from fastestimator.op.tensorop.model.update import UpdateOp
 from fastestimator.op.tensorop.tensorop import TensorOp
+from fastestimator.pipeline import Pipeline
 from fastestimator.schedule.schedule import EpochScheduler, RepeatScheduler, Scheduler, get_current_items
-from fastestimator.util.base_util import NonContext, to_list
+from fastestimator.slicer.slicer import Slicer, forward_slicers, reverse_slicers, sanity_assert_slicers
+from fastestimator.types import Array, Model
+from fastestimator.util.base_util import NonContext, filter_nones, to_list, warn
 from fastestimator.util.traceability_util import trace_model, traceable
-from fastestimator.util.util import get_batch_size
+from fastestimator.util.util import Suppressor, detach_tensors, get_batch_size, get_device, get_num_gpus, \
+    move_tensors_to_device
 
-Model = TypeVar('Model', tf.keras.Model, torch.nn.Module)
 T = TypeVar('T')
 
 GOOGLE_DRIVE_URL = "https://drive.google.com"
+_MAC_BUILD_WARNING = False
 
 
-@traceable()
+@traceable(blacklist=('ctx_lock', ))
 class BaseNetwork:
     """A base class for Network objects.
 
     Networks are used to define the computation graph surrounding one or more models during training.
 
     Args:
         target_type: What tensor type is expected by this network ('torch' or 'tf').
         ops: The operators to be executed throughout training / testing / inference. These are likely to contain one or
             more model ops, as well as loss ops and update ops.
         postprocessing: A collection of NumpyOps to be run on the CPU after all of the normal `ops` have been executed.
             Unlike the NumpyOps found in the pipeline, these ops will run on batches of data rather than single points.
+        slicers: Slicers to use if you want to cut apart a single batch of data into multiple slices in order to fit
+            them onto a smaller GPU. After cutting the data apart and running through the `ops`, the samples are fused
+            back together into a single batch on the CPU before being handed over to the `pops`.
 
     Raises:
         ValueError: Mixed precision settings for all models are not the same.
     """
     def __init__(
         self,
         target_type: str,
         device: Optional[torch.device],
-        ops: Iterable[Union[TensorOp, Scheduler[TensorOp]]],
-        postprocessing: Union[None, NumpyOp, Scheduler[NumpyOp], Iterable[Union[NumpyOp, Scheduler[NumpyOp]]]] = None
+        ops: Sequence[Union[None, TensorOp, Scheduler[TensorOp]]],
+        postprocessing: Union[None, NumpyOp, Scheduler[NumpyOp], Sequence[Union[None, NumpyOp,
+                                                                                Scheduler[NumpyOp]]]] = None,
+        slicers: Union[None, Slicer, Scheduler[Slicer], Sequence[Union[None, Slicer, Scheduler[Slicer]]]] = None,
     ) -> None:
-        self.ops = to_list(ops)
+        self.ops = filter_nones(to_list(ops))
         self.target_type = target_type
         self.device = device
         for op in get_current_items(self.ops):
             op.build(framework=self.target_type, device=self.device)
-        self.models = to_list(_collect_models(ops))
-        self.postprocessing = to_list(postprocessing)
+        self.models = to_list(_collect_models(self.ops))
+        self.mixed_precision = any([model.mixed_precision for model in self.models])
+        if self.mixed_precision and not all([model.mixed_precision for model in self.models]):
+            raise ValueError("Cannot mix full precision and mixed-precision models")
+        self.postprocessing = filter_nones(to_list(postprocessing))
         for pop in self.postprocessing:
             if isinstance(pop, RemoveIf):
                 raise ValueError("Filtering is currently not supported in network post-processing")
             if isinstance(pop, Batch):
                 raise ValueError("Post-processing data is already batched, so Batch Op is not supported here.")
+        self.slicers = filter_nones(to_list(slicers))
         self._verify_inputs()
-        self.effective_inputs = dict()
-        self.effective_outputs = dict()
-        self.epoch_ops = []
-        self.epoch_postprocessing = []
-        self.epoch_models = set()
-        self.epoch_state = dict()
-        self.mixed_precision = any([model.mixed_precision for model in self.models])
-
-        if self.mixed_precision and not all([model.mixed_precision for model in self.models]):
-            raise ValueError("Cannot mix full precision and mixed-precision models")
+        # Per-Epoch/Mode/DS-ID Variables
+        self.ctx_lock = Lock()
+        self.ctx_inputs: Set[str] = set()
+        self.ctx_gpu_inputs: Set[str] = set()  # The inputs needed by TensorOps specifically
+        self.ctx_outputs: Set[str] = set()
+        self.ctx_ops: List[TensorOp] = []
+        self.ctx_postprocessing: List[NumpyOp] = []
+        self.ctx_slicers: List[Slicer] = []
+        self.ctx_models: Set[Model] = set()
+        self.ctx_state: Dict[str, Any] = dict()
 
     def _verify_inputs(self) -> None:
         """Ensure that all ops are TensorOps.
 
         Raises:
             AssertionError: If any of the ops are not TensorOps.
         """
         for op in get_current_items(self.ops):
             assert isinstance(op, TensorOp), "unsupported op format, Network ops must be TensorOps"
         for op in get_current_items(self.postprocessing):
             assert isinstance(op, NumpyOp), "unsupported op format, Network postprocessing must be NumpyOps"
+        for slicer in get_current_items(self.slicers):
+            assert isinstance(slicer, Slicer), f"unsupported slicer object detected of type: {type(slicer)}"
 
     def get_scheduled_items(self, mode: str) -> List[Any]:
         """Get a list of items considered for scheduling.
 
         Args:
             mode: Current execution mode.
 
         Returns:
             List of schedulable items in Network.
         """
         if mode == "train":
-            all_items = self.ops + [model.optimizer for model in self.models] + self.postprocessing
+            all_items = self.ops + [model.optimizer for model in self.models] + self.postprocessing + self.slicers
         else:
-            all_items = self.ops + self.postprocessing
+            all_items = self.ops + self.postprocessing + self.slicers
         return all_items
 
-    def load_epoch(self,
-                   mode: str,
-                   epoch: int,
-                   ds_id: str,
-                   output_keys: Optional[Set[str]] = None,
-                   warmup: bool = False,
-                   eager: bool = False) -> None:
-        """Prepare the network to run a given epoch and mode.
-
-        This method is necessary since schedulers and op mode restrictions may result in different computation graphs
-        every epoch.
-
-        Args:
-            mode: The mode to prepare to execute. One of 'train', 'eval', 'test', or 'infer'.
-            epoch: The epoch to prepare to execute.
-            ds_id: The current dataset id.
-            output_keys: What keys can be moved from the GPU back to the CPU after executing a step.
-            warmup: Whether to prepare to execute it warmup mode or not (end users can likely ignore this argument).
-            eager: Whether to run the training in eager mode. This is only related to TensorFlow training because
-                PyTorch by nature is always in eager mode.
-        """
-        self.effective_inputs[mode] = self.get_effective_input_keys(mode, epoch, ds_id)
-        self.effective_outputs[mode] = self.get_all_output_keys(mode, epoch, ds_id)
-        if output_keys:
-            self.effective_outputs[mode] = self.effective_outputs[mode].intersection(
-                output_keys) | self._get_effective_postprocessing_input_keys(mode, epoch, ds_id)
-        self.epoch_ops = get_current_items(self.ops, mode, epoch, ds_id=ds_id)
-        self.epoch_postprocessing = get_current_items(self.postprocessing, mode, epoch, ds_id=ds_id)
-        self.epoch_models = set.union(*[op.get_fe_models() for op in self.epoch_ops])
-        gradient_ops = [op for op in self.epoch_ops if op.fe_retain_graph() is not None]
+    def __call__(self,
+                 mode: str,
+                 epoch: int,
+                 ds_id: str,
+                 desired_output_keys: Optional[Set[str]] = None,
+                 warmup: bool = False,
+                 eager: bool = False) -> Self:
+        # Make sure that a network isn't currently instantiated with other settings
+        acquired = self.ctx_lock.acquire(blocking=False)
+        if not acquired:
+            raise ValueError("You cannot invoke a Network's __call__ method while it is already active.")
+        self.ctx_inputs, self.ctx_gpu_inputs, self.ctx_outputs = self._get_ctx_inputs_and_outputs(
+            mode, epoch, ds_id, desired_keys=desired_output_keys)
+        self.ctx_ops = get_current_items(self.ops, mode, epoch, ds_id=ds_id)
+        self.ctx_postprocessing = get_current_items(self.postprocessing, mode, epoch, ds_id=ds_id)
+        self.ctx_slicers = get_current_items(self.slicers, mode, epoch, ds_id=ds_id)
+        sanity_assert_slicers(self.ctx_slicers)
+        self.ctx_models = set.union(*[op.get_fe_models() for op in self.ctx_ops])
+        gradient_ops = [op for op in self.ctx_ops if op.fe_retain_graph() is not None]
         for idx, gradient_op in enumerate(gradient_ops):
             gradient_op.fe_retain_graph(idx != len(gradient_ops) - 1)
-        self.epoch_state = {
+        self.ctx_state = {
             "warmup": warmup,
             "mode": mode,
             "req_grad": len(gradient_ops) > 0,
             "epoch": epoch,
             "deferred": {},
             "eager": eager
         }
         # warmup: bool, mode: str, req_grad: bool, epoch: int, deferred: Dict[str, List[Callable]]]
-        for model in self.epoch_models:
+        for model in self.ctx_models:
             if hasattr(model, "optimizer") and model.optimizer is not None:
                 if isinstance(model.optimizer, Scheduler):
                     model.current_optimizer = model.optimizer.get_current_value(epoch)
                 else:
                     model.current_optimizer = model.optimizer
+        self.ctx_lock.release()
+        return self
+
+    def __enter__(self) -> Self:
+        acquired = self.ctx_lock.acquire(blocking=False)
+        if not acquired:
+            raise ValueError("This network is already in use.")
+        return self
 
-    def unload_epoch(self) -> None:
+    def __exit__(self, *exc: Tuple[Optional[Type], Optional[Exception], Optional[Any]]) -> None:
         """Clean up the network after running an epoch.
         """
-        pass
+        self.ctx_inputs = set()
+        self.ctx_outputs = set()
+        self.ctx_gpu_inputs = set()
+        self.ctx_ops = []
+        self.ctx_postprocessing = []
+        self.ctx_slicers = []
+        self.ctx_models = set()
+        self.ctx_state = dict()
+
+        self.ctx_lock.release()
 
     def get_loss_keys(self) -> Set[str]:
         """Find all of the keys associated with model losses.
 
         Returns:
             All of the keys associated with model losses in this network.
         """
         loss_keys = set()
         for op in get_current_items(self.ops):
             loss_keys |= op.get_fe_loss_keys()
         return loss_keys
 
-    def get_effective_input_keys(self, mode: str, epoch: int, ds_id: str = '') -> Set[str]:
-        """Determine which keys need to be provided as input to the network during the given `epoch`.
+    def _get_ctx_inputs_and_outputs(self,
+                                    mode: str,
+                                    epoch: int,
+                                    ds_id: str = '',
+                                    desired_keys: Optional[Set[str]] = None) -> Tuple[Set[str], Set[str], Set[str]]:
+        """Figure out the Network's input and output keys for the current mode/epoch/ds_id.
 
         Args:
             mode: The execution mode to consider. One of 'train', 'eval', 'test', or 'infer'.
             epoch: The epoch number to consider for determining inputs.
             ds_id: The current dataset id.
+            desired_keys: Which outputs do you actually want returned from the network for further processing.
 
         Returns:
-            The necessary inputs for the network to execute the given `epoch` and `mode`.
+            A tuple consisting of:
+                1) The necessary inputs for the network to execute
+                2) The inputs which need to be given to the GPU ops
+                3) The outputs the network will return
         """
-        input_keys = set()
+        network_input_keys = set()
+        gpu_input_keys = set()
         produced_keys = set()
-        for op in get_current_items(self.ops + self.postprocessing, mode, epoch, ds_id=ds_id):
-            input_keys.update(set(key for key in op.inputs if key not in produced_keys))
+        slice_inputs = set()
+        unslice_inputs = set()
+        pops_inputs = set()
+        pops_produced_keys = set()
+        for slicer in get_current_items(self.slicers, mode, epoch, ds_id=ds_id):
+            network_input_keys.update(set(slicer.slice_inputs))
+            unslice_inputs.update(set(slicer.unslice_inputs))
+        slice_inputs.update(network_input_keys)
+        for op in get_current_items(self.ops, mode, epoch, ds_id=ds_id):
+            unsatisfied_inputs = set(key for key in op.inputs if key not in produced_keys)
+            network_input_keys.update(unsatisfied_inputs)
+            gpu_input_keys.update(unsatisfied_inputs)
             produced_keys.update(op.outputs)
-        return input_keys
-
-    def _get_effective_postprocessing_input_keys(self, mode: str, epoch: int, ds_id: str = '') -> Set[str]:
-        """Determine which keys need to be provided as input to the postprocessing during the given `epoch`.
-
-        Args:
-            mode: The execution mode to consider. One of 'train', 'eval', 'test', or 'infer'.
-            epoch: The epoch number to consider for determining inputs.
-            ds_id: The current dataset id.
-
-        Returns:
-            The necessary inputs for the postprocessing to execute the given `epoch` and `mode`.
-        """
-        input_keys = set()
-        produced_keys = set()
+        network_input_keys.update(unslice_inputs - produced_keys)
         for op in get_current_items(self.postprocessing, mode, epoch, ds_id=ds_id):
-            input_keys.update(set(key for key in op.inputs if key not in produced_keys))
+            network_input_keys.update(set(key for key in op.inputs if key not in produced_keys))
             produced_keys.update(op.outputs)
-        return input_keys
-
-    def get_all_output_keys(self, mode: str, epoch: int, ds_id: str = '') -> Set[str]:
-        """Get all of the keys that will be generated by the network during the given `epoch` and `mode`.
-
-        Args:
-            mode: The execution mode to consider. One of 'train', 'eval', 'test', or 'infer'.
-            epoch: The epoch number to consider when searching for outputs.
-            ds_id: The current dataset id.
+            pops_inputs.update(set(key for key in op.inputs if key not in pops_produced_keys))
+            pops_produced_keys.update(op.outputs)
+        # Figure out outputs
+        output_keys = produced_keys
+        if desired_keys:
+            # If pops require a key then we can't throw it away on the GPU, even if Traces won't use that key later
+            output_keys = (output_keys & desired_keys) | pops_inputs
+        if slice_inputs:
+            # You want the key (output_keys) AND you sliced the key (slice_inputs | produced_keys) but you didn't
+            # unslice it
+            sliced_but_not_unsliced = (output_keys & (slice_inputs | produced_keys)) - unslice_inputs
+            if sliced_but_not_unsliced:
+                state = {'epoch': epoch, 'mode': mode, 'ds_id': ds_id}
+                raise ValueError(
+                    "Since you are using Slicers, you must specify how you would like the following keys to be" +
+                    f" un-sliced during {state}: {sliced_but_not_unsliced}")
 
-        Returns:
-            The keys that will be generated by the network's Ops during the `epoch` for the given `mode`.
-        """
-        output_keys = set()
-        for op in get_current_items(self.ops + self.postprocessing, mode, epoch, ds_id=ds_id):
-            output_keys.update(op.outputs)
-        return output_keys
+        return network_input_keys, gpu_input_keys, output_keys
 
     @staticmethod
     def _forward_batch(batch: MutableMapping[str, Any], state: Dict[str, Any], ops: List[TensorOp]) -> None:
         """Run a forward pass through the network's Op chain given a `batch` of data.
 
         Args:
             batch: A batch of input data. Predictions from the network will be written back into this dictionary.
@@ -250,31 +281,49 @@
             if op.outputs:
                 write_outputs_by_op(op, batch, data)
         for fn_list in state['deferred'].values():
             for fn in fn_list:
                 fn()
         state['deferred'].clear()
 
-    def run_step(self, batch: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any]]:  # Batch, Prediction
+    def run_step(self, batch: Dict[str, Array]) -> Dict[str, Array]:  # Batch, Prediction
         """Run a forward step through the Network on a batch of data, including postprocessing.
 
-        This method expects that Network.load_epoch() has already been invoked. The return data will be on the CPU.
+        Usage:
+
+        ```python
+        with network(epoch=1, mode='train', ds_id=''):
+            network.run_step()
+        ```
+
+        The return data will be on the CPU.
 
         Args:
             batch: The batch of data serving as input to the Network.
 
         Returns:
-            (batch_data, prediction_data)
+            The input data along with prediction data (input keys may be overwritten/obscured).
         """
-        batch, prediction = self._run_step(batch)
-        forward_numpyop(ops=self.epoch_postprocessing,
-                        data=ChainMap(prediction, batch),
-                        state=self.epoch_state,
-                        batched=self.target_type)
-        return batch, prediction
+        if not self.ctx_lock.locked:
+            raise ValueError("To invoke the run_step method you must first enter the network (see the doc string)")
+        if not self.ctx_state:
+            raise ValueError("To invoke the run_step method you must first configure the network (see the doc string)")
+        if self.ctx_slicers:
+            minibatches = forward_slicers(self.ctx_slicers, data=batch)
+            results: List[Tuple[Dict[str, Array], Dict[str, Array]]] = []
+            for minibatch in minibatches:
+                results.append(self._run_step(minibatch))
+            batch = reverse_slicers(self.ctx_slicers,
+                                    data=[ChainMap(result[1], result[0]) for result in results],
+                                    original_data=batch)
+        else:
+            batch, prediction = self._run_step(batch)
+            batch = ChainMap(prediction, batch)
+        forward_numpyop(ops=self.ctx_postprocessing, data=batch, state=self.ctx_state, batched=self.target_type)
+        return batch
 
     def _run_step(self, batch: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any]]:  # Batch, Prediction
         """Run a forward step through the Network on a batch of data, excluding postprocessing.
 
         Implementations of this method within derived classes should handle bringing the prediction data back from the
         (multi-)GPU environment to the CPU. This method expects that Network.load_epoch() has already been invoked.
 
@@ -282,71 +331,115 @@
             batch: The batch of data serving as input to the Network.
 
         Returns:
             (batch_data, prediction_data)
         """
         raise NotImplementedError
 
-    def transform(self, data: Dict[str, Any], mode: str, epoch: int = 1, ds_id: str = '') -> Dict[str, Any]:
-        """Run a forward step through the Network on an element of data.
+    @overload
+    def transform(self, data: Dict[str, Array], mode: str, epoch: int = 1, ds_id: str = '') -> Dict[str, Array]:
+        ...
+
+    @overload
+    def transform(self, data: Iterable[Dict[str, Array]], mode: str, epoch: int = 1,
+                  ds_id: str = '') -> List[Dict[str, Array]]:
+        ...
+
+    @overload
+    def transform(self, data: Pipeline, mode: str, epoch: int = 1, ds_id: str = '') -> List[Dict[str, Array]]:
+        ...
+
+    def transform(self,
+                  data: Union[Dict[str, Array], Iterable[Dict[str, Array]], Pipeline],
+                  mode: str,
+                  epoch: int = 1,
+                  ds_id: str = '') -> Union[Dict[str, Array], List[Dict[str, Array]]]:
+        """Run a forward step through the Network on one or more elements of data.
 
         Args:
-            data: The element to data to use as input.
+            data: The data to use as input (or a pipeline to process an entire dataset at once).
             mode: The mode in which to run the transform. One of 'train', 'eval', 'test', or 'infer'.
             epoch: The epoch in which to run the transform.
             ds_id: The current dataset id.
 
         Returns:
             prediction_data overlaid on the input `data`.
         """
-        self.load_epoch(mode, epoch, ds_id, warmup=False, eager=True)
-        data = to_tensor(data, target_type=self.target_type)
-        data, prediction = self.run_step(data)
-        self.unload_epoch()
-        return {**data, **prediction}
+        results = []
+        with self(mode=mode, epoch=epoch, ds_id=ds_id, warmup=False, eager=isinstance(data, dict) and not self.slicers):
+            if isinstance(data, Pipeline):
+                with data(mode=mode, epoch=epoch, ds_id=ds_id, shuffle=False) as loader:
+                    for batch in loader:
+                        batch = to_tensor(batch, target_type=self.target_type)
+                        results.append(self._do_transform(batch))
+            else:
+                batches = to_list(data)
+                for batch in batches:
+                    batch = to_tensor(batch, target_type=self.target_type)
+                    results.append(self._do_transform(batch))
+        if isinstance(data, dict):
+            return results[0]
+        return results
+
+    def _do_transform(self, batch: Dict[str, Array]) -> Dict[str, Array]:
+        """A handle to allow subclasses to modify the behavior of the transform method before it calls run_step
+
+        Args:
+            batch: A single batch of data on which to run.
+
+        Returns:
+            The predictions overlaid on the input batch dictionary.
+        """
+        return self.run_step(batch)
 
 
-def _collect_models(ops: Iterable[Union[TensorOp, Scheduler[TensorOp]]]) -> Set[Model]:
+def _collect_models(
+    ops: Union[None, TensorOp, Scheduler[TensorOp], Iterable[Union[None, TensorOp,
+                                                                   Scheduler[TensorOp]]]]) -> Set[Model]:
     """Collect all model instances from amongst a list of ops.
 
     Args:
         ops: The ops to be searched through.
 
     Returns:
         All of the model instances contained within the `ops`.
     """
     models = set()
-    for op in get_current_items(ops):
+    ops_list = filter_nones(to_list(ops))
+    for op in get_current_items(ops_list):
         models |= op.get_fe_models()
     return models
 
 
 # noinspection PyPep8Naming
 def Network(
-        ops: Iterable[Union[TensorOp, Scheduler[TensorOp]]],
-        pops: Union[None, NumpyOp, Scheduler[NumpyOp], Iterable[Union[NumpyOp,
-                                                                      Scheduler[NumpyOp]]]] = None) -> BaseNetwork:
+    ops: Sequence[Union[None, TensorOp, Scheduler[TensorOp]]],
+    pops: Union[None, NumpyOp, Scheduler[NumpyOp], Sequence[Union[None, NumpyOp, Scheduler[NumpyOp]]]] = None,
+    slicers: Union[None, Slicer, Scheduler[Slicer], Sequence[Union[None, Slicer, Scheduler[Slicer]]]] = None
+) -> BaseNetwork:
     """A function to automatically instantiate the correct Network derived class based on the given `ops`.
 
     Args:
         ops: A collection of Ops defining the graph for this Network. It should contain at least one ModelOp, and all
             models should be either TensorFlow or Pytorch. We currently do not support mixing TensorFlow and Pytorch
             models within the same network.
         pops: Postprocessing Ops. A collection of NumpyOps to be run on the CPU after all of the normal `ops` have been
             executed. Unlike the NumpyOps found in the pipeline, these ops will run on batches of data rather than
             single points.
+        slicers: Slicers to use if you want to cut apart a single batch of data into multiple slices in order to fit
+            them onto a smaller GPU. After cutting the data apart and running through the `ops`, the samples are fused
+            back together into a single batch on the CPU before being handed over to the `pops`.
 
     Returns:
         A network instance containing the given `ops`.
 
     Raises:
         AssertionError: If TensorFlow and PyTorch models are mixed, or if no models are provided.
         ValueError: If a model is provided whose type cannot be identified as either TensorFlow or PyTorch.
     """
-    ops = to_list(ops)
     models = _collect_models(ops)
     framework = set()
     model_names = set()
     for model in models:
         # 'Model' and 'model' should not be considered unique in case you are saving on a non-case-sensitive filesystem
         model_names.add(model.model_name.lower())
         if isinstance(model, tf.keras.Model):
@@ -358,79 +451,79 @@
     if len(framework) == 0:
         framework.add('tf')  # We will use tf as default framework if no models are found
     assert len(framework) == 1, "please make sure either tensorflow or torch model is used in network"
     assert len(model_names) == len(models), "all models must have unique model names"
 
     framework = framework.pop()
     if framework == "tf":
-        network = TFNetwork(ops, pops)
+        network = TFNetwork(ops, pops, slicers)
     elif framework == "torch":
-        network = TorchNetwork(ops, pops)
+        network = TorchNetwork(ops, pops, slicers)
     else:
         raise ValueError("Unknown model type")
     return network
 
 
-@traceable()
+@traceable(blacklist=('ctx_lock', ))
 class TorchNetwork(BaseNetwork):
     """An extension of BaseNetwork for PyTorch models.
 
     Args:
         ops: The ops defining the execution graph for this Network.
         postprocessing: A collection of NumpyOps to be run on the CPU after all of the normal `ops` have been executed.
             Unlike the NumpyOps found in the pipeline, these ops will run on batches of data rather than single points.
+        slicers: Slicers to use if you want to cut apart a single batch of data into multiple slices in order to fit
+            them onto a smaller GPU. After cutting the data apart and running through the `ops`, the samples are fused
+            back together into a single batch on the CPU before being handed over to the `pops`.
 
     """
+    device: torch.device
+
     def __init__(
         self,
-        ops: Iterable[Union[TensorOp, Scheduler[TensorOp]]],
-        postprocessing: Union[None, NumpyOp, Scheduler[NumpyOp], Iterable[Union[NumpyOp, Scheduler[NumpyOp]]]] = None
+        ops: Sequence[Union[None, TensorOp, Scheduler[TensorOp]]],
+        postprocessing: Union[None, NumpyOp, Scheduler[NumpyOp], Sequence[Union[None, NumpyOp,
+                                                                                Scheduler[NumpyOp]]]] = None,
+        slicers: Union[None, Slicer, Scheduler[Slicer], Sequence[Union[None, Slicer, Scheduler[Slicer]]]] = None,
     ) -> None:
         super().__init__(target_type='torch',
-                         device=torch.device("cuda:0" if torch.cuda.is_available() else "cpu"),
+                         device=get_device(),
                          ops=ops,
-                         postprocessing=postprocessing)
-
-    def load_epoch(self,
-                   mode: str,
-                   epoch: int,
-                   ds_id: str,
-                   output_keys: Optional[Set[str]] = None,
-                   warmup: bool = False,
-                   eager: bool = False) -> None:
-        """Prepare the network to run a given epoch and mode.
+                         postprocessing=postprocessing,
+                         slicers=slicers)
 
-        This method is necessary since schedulers and op mode restrictions may result in different computation graphs
-        every epoch. This also moves all of the necessary models from the CPU onto the GPU(s).
-
-        Args:
-            mode: The mode to prepare to execute. One of 'train', 'eval', 'test', or 'infer'.
-            epoch: The epoch to prepare to execute.
-            ds_id: The current dataset id.
-            output_keys: What keys must be moved from the GPU back to the CPU after executing a step.
-            warmup: Whether to prepare to execute it warmup mode or not (end users can likely ignore this argument).
-            eager: Whether to run the training in eager mode. This is only related to TensorFlow training because
-                PyTorch by nature is always in eager mode.
-        """
-        super().load_epoch(mode=mode, epoch=epoch, ds_id=ds_id, output_keys=output_keys, warmup=warmup, eager=eager)
-        if self.device.type == "cuda":
-            for model in self.epoch_models:
+    def __call__(self,
+                 mode: str,
+                 epoch: int,
+                 ds_id: str,
+                 desired_output_keys: Optional[Set[str]] = None,
+                 warmup: bool = False,
+                 eager: bool = False) -> Self:
+        super().__call__(mode=mode,
+                         epoch=epoch,
+                         ds_id=ds_id,
+                         desired_output_keys=desired_output_keys,
+                         warmup=warmup,
+                         eager=eager)
+        if self.device.type != "cpu":
+            for model in self.ctx_models:
                 # move model variables to gpu
                 model.to(self.device)
                 if model.current_optimizer and mode == "train":
                     # move optimizer variables to gpu
                     self._move_optimizer_between_device(model.current_optimizer.state, self.device)
         # Set all of the contiguous final updates to defer their updates by default to enable things like CycleGan
         # This is not necessary for TF because overriding tf weights does not confuse the gradient tape computation
-        for op in reversed(self.epoch_ops):
+        for op in reversed(self.ctx_ops):
             if isinstance(op, UpdateOp):
                 op._old_defer = op.defer
                 op.defer = True
             else:
                 break
+        return self
 
     def _move_optimizer_between_device(self, data: Dict[str, Any], device: Union[str, torch.device]) -> None:
         """Move optimizer state between gpu and cpu recursively.
 
         Args:
             data: Optimizer state.
             device: The target device.
@@ -440,225 +533,178 @@
                 self._move_optimizer_between_device(data[key], device)
             else:
                 try:
                     data[key] = data[key].to(device)
                 except (RuntimeError, AssertionError, AttributeError):
                     pass
 
-    def unload_epoch(self) -> None:
+    def __exit__(self, *exc: Tuple[Optional[Type], Optional[Exception], Optional[Any]]) -> None:
         """Clean up the network after running an epoch.
 
         In this case we move all of the models from the GPU(s) back to the CPU.
         """
-        if self.device.type == "cuda":
-            for model in self.epoch_models:
+        if self.device.type != "cpu":
+            for model in self.ctx_models:
                 # move model variables to cpu
                 model.to("cpu")
-                if model.current_optimizer and self.epoch_state["mode"] == "train":
+                if model.current_optimizer and self.ctx_state["mode"] == "train":
                     # move optimizer variables to cpu
                     self._move_optimizer_between_device(model.current_optimizer.state, "cpu")
         # Set the final update ops back to their original defer status
-        for op in reversed(self.epoch_ops):
+        for op in reversed(self.ctx_ops):
             if isinstance(op, UpdateOp):
                 op.defer = op.__dict__.get('_old_defer', op.defer)
             else:
                 break
+        super().__exit__(*exc)
 
-    def _get_effective_batch_input(self, batch: MutableMapping[str, Any], mode: str) -> Dict[str, Any]:
+    def _get_effective_batch_input(self, batch: MutableMapping[str, Any]) -> Dict[str, Any]:
         """Copy input data from the the CPU onto the GPU(s).
 
         This method will filter inputs from the batch so that only data required by the network during execution will be
         copied to the GPU.
 
         Args:
             batch: The input data to be moved.
-            mode: The current execution mode. One of 'train', 'eval', 'test', or 'infer'.
 
         Returns:
             The input data ready for use on GPU(s).
         """
-        if self.device.type == "cuda":
+        if self.device.type != "cpu":
             new_batch = {
-                key: self._move_tensor_between_device(batch[key], self.device)
-                for key in self.effective_inputs[mode] if key in batch
+                key: move_tensors_to_device(batch[key], self.device)
+                for key in self.ctx_gpu_inputs if key in batch
             }
         else:
-            new_batch = {key: batch[key] for key in self.effective_inputs[mode] if key in batch}
+            new_batch = {key: batch[key] for key in self.ctx_gpu_inputs if key in batch}
         return new_batch
 
     def _run_step(self, batch: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any]]:
         """Run a forward step through the Network on a batch of data.
 
         Implementations of this method within derived classes should handle bringing the prediction data back from the
         (multi-)GPU environment to the CPU. This method expects that Network.load_epoch() has already been invoked.
 
         Args:
             batch: The batch of data serving as input to the Network.
 
         Returns:
             (batch_data, prediction_data)
         """
-        mode = self.epoch_state["mode"]
-        batch_in = self._get_effective_batch_input(batch, mode)
-        self.epoch_state["tape"] = NonContext()
+        batch_in = self._get_effective_batch_input(batch)
+        self.ctx_state["tape"] = NonContext()
         # gpu operation
-        with torch.no_grad() if not self.epoch_state["req_grad"] else NonContext():
-            with torch.cuda.amp.autocast() if self.mixed_precision else NonContext():
-                self._forward_batch(batch_in, self.epoch_state, self.epoch_ops)
+        with torch.no_grad() if not self.ctx_state["req_grad"] else NonContext():
+            with torch.autocast(device_type=self.device.type) if self.mixed_precision else NonContext():
+                self._forward_batch(batch_in, self.ctx_state, self.ctx_ops)
 
         # copy data to cpu
-        if self.device.type == "cuda":
+        if self.device.type != "cpu":
             prediction = {
-                key: self._move_tensor_between_device(self._detach_tensor(batch_in[key]), "cpu")
-                for key in self.effective_outputs[mode] if key in batch_in
+                key: move_tensors_to_device(detach_tensors(batch_in[key]), "cpu")
+                for key in self.ctx_outputs if key in batch_in
             }
         else:
-            prediction = {
-                key: self._detach_tensor(batch_in[key])
-                for key in self.effective_outputs[mode] if key in batch_in
-            }
+            prediction = {key: detach_tensors(batch_in[key]) for key in self.ctx_outputs if key in batch_in}
         return batch, prediction
 
-    def _move_tensor_between_device(self, data: T, device: Union[str, torch.device]) -> T:
-        """Move tensor between gpu and cpu recursively.
-
-        Args:
-            data: The input data to be moved.
-            device: The target device.
-
-        Returns:
-            Output data.
-        """
-        if isinstance(data, dict):
-            return {key: self._move_tensor_between_device(value, device) for (key, value) in data.items()}
-        elif isinstance(data, list):
-            return [self._move_tensor_between_device(val, device) for val in data]
-        elif isinstance(data, tuple):
-            return tuple([self._move_tensor_between_device(val, device) for val in data])
-        elif isinstance(data, set):
-            return set([self._move_tensor_between_device(val, device) for val in data])
-        elif isinstance(data, torch.Tensor):
-            return data.to(device)
-        else:
-            return data
-
-    def _detach_tensor(self, data: T) -> T:
-        """Detach tensor from current graph recursively.
-
-        Args:
-            data: The data to be detached.
 
-        Returns:
-            Output data.
-        """
-        if isinstance(data, dict):
-            return {key: self._detach_tensor(value) for (key, value) in data.items()}
-        elif isinstance(data, list):
-            return [self._detach_tensor(val) for val in data]
-        elif isinstance(data, tuple):
-            return tuple([self._detach_tensor(val) for val in data])
-        elif isinstance(data, set):
-            return set([self._detach_tensor(val) for val in data])
-        elif isinstance(data, torch.Tensor):
-            return data.detach()
-        return data
-
-
-@traceable()
+@traceable(blacklist=('ctx_lock', ))
 class TFNetwork(BaseNetwork):
     """An extension of BaseNetwork for TensorFlow models.
 
     Args:
         ops: The ops defining the execution graph for this Network.
         postprocessing: A collection of NumpyOps to be run on the CPU after all of the normal `ops` have been executed.
             Unlike the NumpyOps found in the pipeline, these ops will run on batches of data rather than single points.
+        slicers: Slicers to use if you want to cut apart a single batch of data into multiple slices in order to fit
+            them onto a smaller GPU. After cutting the data apart and running through the `ops`, the samples are fused
+            back together into a single batch on the CPU before being handed over to the `pops`.
     """
     def __init__(
         self,
-        ops: Iterable[Union[TensorOp, Scheduler[TensorOp]]],
-        postprocessing: Union[None, NumpyOp, Scheduler[NumpyOp], Iterable[Union[NumpyOp, Scheduler[NumpyOp]]]] = None
+        ops: Sequence[Union[None, TensorOp, Scheduler[TensorOp]]],
+        postprocessing: Union[None, NumpyOp, Scheduler[NumpyOp], Sequence[Union[None, NumpyOp,
+                                                                                Scheduler[NumpyOp]]]] = None,
+        slicers: Union[None, Slicer, Scheduler[Slicer], Sequence[Union[None, Slicer, Scheduler[Slicer]]]] = None,
     ) -> None:
-        super().__init__(target_type='tf', device=None, ops=ops, postprocessing=postprocessing)
-
-    def load_epoch(self,
-                   mode: str,
-                   epoch: int,
-                   ds_id: str,
-                   output_keys: Optional[Set[str]] = None,
-                   warmup: bool = False,
-                   eager: bool = False) -> None:
-        """Prepare the network to run a given epoch and mode.
+        super().__init__(target_type='tf', device=None, ops=ops, postprocessing=postprocessing, slicers=slicers)
 
-        This method is necessary since schedulers and op mode restrictions may result in different computation graphs
-        every epoch. This also converts the epoch index a tensor to avoid tensorflow graph rebuilding.
-
-        Args:
-            mode: The mode to prepare to execute. One of 'train', 'eval', 'test', or 'infer'.
-            epoch: The epoch to prepare to execute.
-            ds_id: The current dataset id.
-            output_keys: What keys must be moved from the GPU back to the CPU after executing a step.
-            warmup: Whether to prepare to execute it warmup mode or not (end users can likely ignore this argument).
-            eager: Whether to run the training in eager mode. This is only related to TensorFlow training because
-                PyTorch by nature is always in eager mode.
-        """
-        super().load_epoch(mode=mode, epoch=epoch, ds_id=ds_id, output_keys=output_keys, warmup=warmup, eager=eager)
+    def __call__(self,
+                 mode: str,
+                 epoch: int,
+                 ds_id: str,
+                 desired_output_keys: Optional[Set[str]] = None,
+                 warmup: bool = False,
+                 eager: bool = False) -> Self:
+        super().__call__(mode=mode,
+                         epoch=epoch,
+                         ds_id=ds_id,
+                         desired_output_keys=desired_output_keys,
+                         warmup=warmup,
+                         eager=eager)
         # Don't cause a re-trace just because epoch changed
-        self.epoch_state["epoch"] = tf.convert_to_tensor(self.epoch_state["epoch"])
+        self.ctx_state["epoch"] = tf.convert_to_tensor(self.ctx_state["epoch"])
         # Need to re-trace the TF graph if optimizer or layer trainable setting is changing:
-        trainable_str = "".join([str(layer.trainable) for model in self.epoch_models for layer in model.layers])
+        trainable_str = "".join([str(layer.trainable) for model in self.ctx_models for layer in model.layers])
         opt_str = "x".join(
-            [str(id(model.current_optimizer)) for model in self.epoch_models if hasattr(model, 'current_optimizer')])
-        self.epoch_state["_force_tf_retrace"] = hash(trainable_str + opt_str)  # Hash to keep at fixed memory overhead
+            [str(id(model.current_optimizer)) for model in self.ctx_models if hasattr(model, 'current_optimizer')])
+        self.ctx_state["_force_tf_retrace"] = hash(trainable_str + opt_str)  # Hash to keep at fixed memory overhead
+        self.ctx_manual_gpu_data_handling = False
+        return self
 
-    def unload_epoch(self) -> None:
+    def __exit__(self, *exc: Tuple[Optional[Type], Optional[Exception], Optional[Any]]) -> None:
         # This prevents a tf graph memory leak that would slow down long trainings. Since we
         # re-build graphs every epoch there is no reason to keep old ones around.
         strategy = tf.distribute.get_strategy()
         if isinstance(strategy, tf.distribute.MirroredStrategy):
-            return  # TODO - Find a way to clear graph for multi-gpu
+            pass  # TODO - Find a way to clear graph for multi-gpu
         else:
             tf.keras.backend.clear_session()
+        super().__exit__(*exc)
 
     def _run_step(self, batch: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any]]:
         """Run a forward step through the Network on a batch of data.
 
         Implementations of this method within derived classes should handle bringing the prediction data back from the
         (multi-)GPU environment to the CPU. This method expects that Network.load_epoch() has already been invoked.
 
         Args:
             batch: The batch of data serving as input to the Network.
 
         Returns:
             (batch_data, prediction_data)
         """
-        mode = self.epoch_state["mode"]
-        batch_in = self._get_effective_batch_input(batch, mode)
+        batch_in = self._get_effective_batch_input(batch)
         strategy = tf.distribute.get_strategy()
         if isinstance(strategy, tf.distribute.MirroredStrategy):
-            if self.epoch_state["eager"]:
-                prediction = strategy.run(
-                    self._forward_step_eager,
-                    args=(batch_in, self.epoch_state, self.epoch_ops, to_list(self.effective_outputs[mode])))
-            else:
-                prediction = strategy.run(
-                    self._forward_step_static,
-                    args=(batch_in, self.epoch_state, self.epoch_ops, to_list(self.effective_outputs[mode])))
+            with Suppressor(allow_pyprint=True, show_if_exception=True):
+                if self.ctx_manual_gpu_data_handling:
+                    batch_in = next(
+                        iter(strategy.experimental_distribute_dataset(tf.data.Dataset.from_tensors(batch_in))))
+                if self.ctx_state["eager"]:
+                    prediction = strategy.run(self._forward_step_eager,
+                                              args=(batch_in, self.ctx_state, self.ctx_ops, to_list(self.ctx_outputs)))
+                else:
+                    prediction = strategy.run(self._forward_step_static,
+                                              args=(batch_in, self.ctx_state, self.ctx_ops, to_list(self.ctx_outputs)))
             batch = self._per_replica_to_global(batch)
             prediction = self._per_replica_to_global(prediction)
         else:
-            if self.epoch_state["eager"]:
-                prediction = self._forward_step_eager(batch_in,
-                                                      self.epoch_state,
-                                                      self.epoch_ops,
-                                                      to_list(self.effective_outputs[mode]))
-            else:
-                prediction = self._forward_step_static(batch_in,
-                                                       self.epoch_state,
-                                                       self.epoch_ops,
-                                                       to_list(self.effective_outputs[mode]))
+            with Suppressor(allow_pyprint=True, show_if_exception=True):
+                if self.ctx_state["eager"]:
+                    prediction = self._forward_step_eager(batch_in,
+                                                          self.ctx_state,
+                                                          self.ctx_ops,
+                                                          to_list(self.ctx_outputs))
+                else:
+                    prediction = self._forward_step_static(batch_in,
+                                                           self.ctx_state,
+                                                           self.ctx_ops,
+                                                           to_list(self.ctx_outputs))
         return batch, prediction
 
     def _per_replica_to_global(self, data: T) -> T:
         """Combine data from "per-replica" values recursively.
 
         For multi-GPU training, data are distributed using `tf.distribute.Strategy.experimental_distribute_dataset`.
         This method collects data from all replicas and combines them into one.
@@ -684,26 +730,25 @@
         elif isinstance(data, tuple):
             return tuple([self._per_replica_to_global(val) for val in data])
         elif isinstance(data, set):
             return set([self._per_replica_to_global(val) for val in data])
         else:
             return data
 
-    def _get_effective_batch_input(self, batch: MutableMapping[str, Any], mode: str) -> Dict[str, Any]:
+    def _get_effective_batch_input(self, batch: MutableMapping[str, Any]) -> Dict[str, Any]:
         """Filter input data so that only the data required by the Network is moved onto the GPU.
 
         Args:
             batch: An unfiltered batch of input data.
-            mode: The current execution mode. One of 'train', 'eval', 'test', or 'infer'.
 
         Returns:
             The filtered input data ready for use on GPU(s).
         """
         new_batch = {}
-        for key in self.effective_inputs[mode]:
+        for key in self.ctx_gpu_inputs:
             if key in batch:
                 new_batch[key] = batch[key]
         return new_batch
 
     def _forward_step_eager(self,
                             batch: Dict[str, Any],
                             state: Dict[str, Any],
@@ -759,39 +804,29 @@
         del state['tape']
         del tape
         for key in effective_outputs:
             if key in batch:
                 prediction[key] = batch[key]
         return prediction
 
-    def transform(self, data: Dict[str, Any], mode: str, epoch: int = 1, ds_id: str = '') -> Dict[str, Any]:
-        """Run a forward step through the Network on an element of data.
-
-        Args:
-            data: The element to data to use as input.
-            mode: The mode in which to run the transform. One of 'train', 'eval', 'test', or 'infer'.
-            epoch: The epoch in which to run the transform.
-            ds_id: The current dataset id.
-
-        Returns:
-            (batch_data, prediction_data)
-        """
+    def _do_transform(self, batch: Dict[str, Array]) -> Dict[str, Array]:
         # Distribute multi-gpu data for processing
         sub_sample = False
         strategy = tf.distribute.get_strategy()
         if isinstance(strategy, tf.distribute.MirroredStrategy):
-            batch_size, num_devices = get_batch_size(data), strategy.num_replicas_in_sync
+            batch_size, num_devices = get_batch_size(batch), strategy.num_replicas_in_sync
             if batch_size < num_devices:
-                data = self._fill_batch(data, num_devices - batch_size)
+                batch = self._fill_batch(batch, num_devices - batch_size)
                 sub_sample = True
-            data = next(iter(strategy.experimental_distribute_dataset(tf.data.Dataset.from_tensors(data))))
-        results = super().transform(data, mode, epoch, ds_id=ds_id)
+            self.ctx_manual_gpu_data_handling = True
+        batch = super()._do_transform(batch)
         if sub_sample:
-            results = self._subsample_data(results, batch_size)
-        return results
+            batch = self._subsample_data(batch, batch_size)
+            self.ctx_manual_gpu_data_handling = False
+        return batch
 
     def _fill_batch(self, data: T, n: int) -> T:
         """Fill data on batch dimension repeating the first n indices at the end.
 
         Args:
             data: The data to be filled.
             n: The number of times to be repeated.
@@ -805,44 +840,62 @@
             return [self._fill_batch(val, n) for val in data]
         elif isinstance(data, tuple):
             return tuple([self._fill_batch(val, n) for val in data])
         elif isinstance(data, set):
             return set([self._fill_batch(val, n) for val in data])
         elif hasattr(data, "shape"):
             paddings = [[0, n]] + [[0, 0] for _ in range(len(data.shape) - 1)]
-            return np.pad(data, pad_width=paddings, mode="symmetric")
+            return tf.pad(data, paddings=paddings, mode="symmetric")
         else:
             return data
 
     def _subsample_data(self, data: T, n: int) -> T:
         """Subsample data by selecting the first n indices recursively.
 
         Args:
             data: The data to be subsampled.
             n: The number of indices to be subsampled.
 
         Returns:
             Subsampled data.
         """
-        if isinstance(data, dict):
+        if isinstance(data, (dict, ChainMap)):
             return {key: self._subsample_data(val, n) for (key, val) in data.items()}
         elif isinstance(data, list):
             return [self._subsample_data(val, n) for val in data]
         elif isinstance(data, tuple):
             return tuple([self._subsample_data(val, n) for val in data])
         elif isinstance(data, set):
             return set([self._subsample_data(val, n) for val in data])
         elif hasattr(data, "shape") and list(data.shape) and data.shape[0] > n:
             return data[0:n]
         else:
             return data
 
 
-def build(model_fn: Callable[[], Union[Model, List[Model]]],
-          optimizer_fn: Union[str, Scheduler, Callable, List[str], List[Callable], List[Scheduler], None],
+@overload
+def build(model_fn: Callable[[], Model],
+          optimizer_fn: Union[None, str, Scheduler, Callable],
+          weights_path: Union[str, None, List[Union[str, None]]] = None,
+          model_name: Union[str, List[str], None] = None,
+          mixed_precision: bool = False) -> Model:
+    ...
+
+
+@overload
+def build(model_fn: Callable[[], Sequence[Model]],
+          optimizer_fn: Union[None, str, Scheduler, Callable, Sequence[Union[None, str, Callable, Scheduler]]],
+          weights_path: Union[str, None, List[Union[str, None]]] = None,
+          model_name: Union[str, List[str], None] = None,
+          mixed_precision: bool = False) -> List[Model]:
+    ...
+
+
+def build(model_fn: Callable[[], Union[Model, Sequence[Model]]],
+          optimizer_fn: Union[None, str, Scheduler, Callable, Sequence[Union[None, str, Callable, Scheduler]]],
           weights_path: Union[str, None, List[Union[str, None]]] = None,
           model_name: Union[str, List[str], None] = None,
           mixed_precision: bool = False) -> Union[Model, List[Model]]:
     """Build model instances and associate them with optimizers.
 
     This method can be used with TensorFlow models / optimizers:
     ```python
@@ -870,39 +923,39 @@
             should match the number of models generated by the `model_fn`.
         mixed_precision: Whether to enable mixed-precision network operations.
 
     Returns:
         models: The model(s) built by FastEstimator.
     """
     def _generate_model_names(num_names):
-        names = ["model" if i + fe.fe_build_count == 0 else "model{}".format(i + fe.fe_build_count) for i in
-                 range(num_names)]
+        names = [
+            "model" if i + fe.fe_build_count == 0 else "model{}".format(i + fe.fe_build_count) for i in range(num_names)
+        ]
         fe.fe_build_count += num_names
         return names
 
     # The following garbage collection is needed for if a TF model was running, but then died due to an exception being
     # thrown, but the exception was then caught, whereupon the user wanted to switch to a pytorch model instead. Absent
     # this collection, you would see: "Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error". This
     # would be followed by the death of the pytorch multi-processor which would report something like the following:
     # RuntimeError: DataLoader worker (pid 4225) is killed by signal: Aborted.
     # RuntimeError: DataLoader worker (pid(s) 4225, 4226, 4227) exited unexpectedly
     gc.collect()
     # tensorflow models requires setting global policies prior to model creation. Since there is no way to know the
     # framework of model, setting the policy for both tf and pytorch here.
     if mixed_precision:
         if sys.platform == 'darwin':
-            print("\033[93m{}\033[00m".format("FastEstimator-Warn: Mixed Precision is not currently supported on Mac / "
-                                              "Metal. This flag will be ignored."))
+            warn("Mixed Precision is not currently supported on Mac / Metal. This flag will be ignored.")
             mixed_precision = False
         else:
             mixed_precision_tf.set_global_policy(mixed_precision_tf.Policy('mixed_float16'))
     else:
         mixed_precision_tf.set_global_policy(mixed_precision_tf.Policy('float32'))
     models = None
-    if torch.cuda.device_count() > 1:
+    if get_num_gpus() > 1:
         # We need to figure out whether model_fn returns tf models or torch models
         if not isinstance(tf.distribute.get_strategy(), tf.distribute.MirroredStrategy):
             # If we've already done this and gotten TF model, the above flag will be set and this will be skipped. If we
             # are dealing with pytorch models, the model_fn() invocation will be kept so as to not waste clock cycles.
             models = to_list(model_fn())
             if isinstance(models[0], tf.keras.Model):
                 models = None  # We will re-instantiate the models again now that we know we need MirroredStrategy
@@ -960,15 +1013,15 @@
         framework = "torch"
     elif isinstance(model, Sequential):
         raise DeprecationWarning("Importing from tensorflow.python.keras.models/layers is deprecated. Import from "
                                  "tensorflow.keras.models/layers instead")
     else:
         raise ValueError("unrecognized model format: {}".format(type(model)))
     # torch multi-gpu handling
-    if framework == "torch" and torch.cuda.device_count() > 1:
+    if framework == "torch" and get_num_gpus() > 1:
         model = torch.nn.DataParallel(model)
     # mark models with its mixed_precision flag
     model.mixed_precision = mixed_precision
     if isinstance(optimizer_fn, EpochScheduler):
         for epoch, optimizer_def in optimizer_fn.epoch_dict.items():
             optimizer_fn.epoch_dict[epoch] = _build_optimizer(optimizer_def, model, framework, mixed_precision)
         model.current_optimizer = optimizer_fn.get_current_value(1)
@@ -990,16 +1043,17 @@
             os.rename(os.path.join('./', file_name), os.path.join(tmp_dir, file_name))
             weight = gdown.download(weight, os.path.join(tmp_dir, file_name), quiet=False)
         load_model(model, weight)
     model.model_name = name
     return model
 
 
-def _build_optimizer(optimizer_fn: Union[str, Callable, None], model: Model, framework: str,
-                     mixed_precision: bool) -> Union[None, tf.optimizers.Optimizer, torch.optim.Optimizer]:
+def _build_optimizer(
+    optimizer_fn: Union[str, Callable, None], model: Model, framework: str, mixed_precision: bool
+) -> Union[None, tf.optimizers.Optimizer, tf.optimizers.legacy.Optimizer, torch.optim.Optimizer]:
     """A helper method to instantiate an optimizer.
 
     Args:
         optimizer_fn: The function responsible for constructing an optimizer, or else a string indicating one of the
             default optimizers to be used.
         model: The model to associate the optimizer with.
         framework: Which backend framework should be used ('tf' or 'torch').
@@ -1020,21 +1074,23 @@
     Args:
         name: The name of the default optimizer to instantiate.
         framework: Which backend framework should be used ('tf' or 'torch').
 
     Returns:
         An optimizer instance corresponding to the given `name` and `framework`.
     """
+    # The legacy optimizers appear to be faster than the new ones on both mac and linux. Revisit this speed test again
+    # after tf version > 2.12
     tf_optimizer_fn = {
-        'adadelta': tf.optimizers.Adadelta,
-        'adagrad': tf.optimizers.Adagrad,
-        'adam': tf.optimizers.Adam,
-        'adamax': tf.optimizers.Adamax,
-        'rmsprop': tf.optimizers.RMSprop,
-        'sgd': tf.optimizers.SGD
+        'adadelta': tf.optimizers.legacy.Adadelta,
+        'adagrad': tf.optimizers.legacy.Adagrad,
+        'adam': tf.optimizers.legacy.Adam,
+        'adamax': tf.optimizers.legacy.Adamax,
+        'rmsprop': tf.optimizers.legacy.RMSprop,
+        'sgd': tf.optimizers.legacy.SGD
     }
     pytorch_optimizer_fn = {
         'adadelta': lambda x: torch.optim.Adadelta(params=x),
         'adagrad': lambda x: torch.optim.Adagrad(params=x),
         'adam': lambda x: torch.optim.Adam(params=x),
         'adamax': lambda x: torch.optim.Adamax(params=x),
         'rmsprop': lambda x: torch.optim.RMSprop(params=x),
@@ -1043,16 +1099,17 @@
     if framework == "tf":
         optimizer_fn = tf_optimizer_fn[name]
     else:
         optimizer_fn = pytorch_optimizer_fn[name]
     return optimizer_fn
 
 
-def _optimizer_fn_to_optimizer(optimizer_fn: Union[Callable, None], model: Model, framework: str,
-                               mixed_precision: bool) -> Union[None, tf.optimizers.Optimizer, torch.optim.Optimizer]:
+def _optimizer_fn_to_optimizer(
+        optimizer_fn: Union[Callable, None], model: Model, framework: str,
+        mixed_precision: bool) -> Union[None, tf.optimizers.legacy.Optimizer, torch.optim.Optimizer]:
     """A helper function to invoke an optimizer function.
 
     Args:
         optimizer_fn: The function to be invoked in order to instantiate an optimizer.
         model: The model with which the optimizer should be associated.
         framework: Which backend framework should be used ('tf' or 'torch').
         mixed_precision: Whether to enable mixed-precision training.
@@ -1064,22 +1121,41 @@
     if optimizer_fn:
         if framework == "tf":
             try:
                 optimizer = optimizer_fn()
             except:
                 raise AssertionError("optimizer_fn of Tensorflow backend should be callable without args. Please "
                                      "make sure model and optimizer_fn are using the same backend")
+            if sys.platform == 'darwin' and hasattr(optimizer, 'jit_compile'):
+                # Mac doesn't support XLA acceleration as of TF 2.11
+                # TODO - check compatibility again in future release
+                global _MAC_BUILD_WARNING
+                if not _MAC_BUILD_WARNING:
+                    warn("JIT compiling of optimizers is not currently supported by MacOS and will be disabled. You "
+                         "may want to use an optimizer from tf.optimizers.legacy instead for better speed.")
+                    _MAC_BUILD_WARNING = True
+                optimizer.jit_compile = False
             # initialize optimizer variables
-            _ = optimizer.iterations
-            optimizer._create_hypers()
-            optimizer._create_slots(model.trainable_variables)
+            if hasattr(optimizer, 'build'):
+                optimizer.build(var_list=model.trainable_variables)
+            else:
+                _ = optimizer.iterations
+                if hasattr(optimizer, '_create_hypers'):
+                    optimizer._create_hypers()
+                if hasattr(optimizer, '_create_slots'):
+                    optimizer._create_slots(model.trainable_variables)
+            assert isinstance(optimizer, (tf.optimizers.Optimizer, tf.keras.optimizers.experimental.Optimizer,
+                                          tf.optimizers.legacy.Optimizer)), \
+                f"optimizer_fn should generate tensorflow optimizer, but got {type(optimizer)}"
             # handle mixed precision loss scaling
             if mixed_precision:
-                optimizer = mixed_precision_tf.LossScaleOptimizer(optimizer)
-            assert isinstance(optimizer, tf.optimizers.Optimizer), "optimizer_fn should generate tensorflow optimizer"
+                if isinstance(optimizer, tf.optimizers.legacy.Optimizer):
+                    optimizer = LossScaleOptimizer(optimizer)
+                else:
+                    optimizer = LossScaleOptimizerV3(optimizer)
         else:
             try:
                 optimizer = optimizer_fn(model.parameters())
             except Exception as e:
                 print("optimizer_fn of Pytorch backend should be callable with single arg. Please sure model and \
                 optimizer_fn are using the same backend")
                 raise ValueError(repr(e))
```

### Comparing `fastestimator-1.5.2/fastestimator/op/__init__.py` & `fastestimator-1.6.0/fastestimator/op/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/__init__.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/meta/__init__.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/meta/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/meta/fuse.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/meta/fuse.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/meta/one_of.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/meta/one_of.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,19 +20,19 @@
 from fastestimator.op.numpyop.numpyop import Batch, NumpyOp
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class OneOf(NumpyOp):
     """Perform one of several possible NumpyOps.
+
     Args:
         *numpy_ops: Ops to choose between with a specified (or uniform) probability.
         probs: List of probabilities, must sum to 1. When None, the probabilities will be equally distributed.
     """
-
     def __init__(self, *numpy_ops: NumpyOp, probs: Optional[List[float]] = None) -> None:
         inputs = numpy_ops[0].inputs
         outputs = numpy_ops[0].outputs
         mode = numpy_ops[0].mode
         ds_id = numpy_ops[0].ds_id
         super().__init__(inputs=inputs, outputs=outputs, mode=mode, ds_id=ds_id)
         self.in_list = numpy_ops[0].in_list
@@ -52,35 +52,41 @@
         self.probs = probs
 
     def __getstate__(self) -> Dict[str, List[Dict[Any, Any]]]:
         return {'ops': [elem.__getstate__() if hasattr(elem, '__getstate__') else {} for elem in self.ops]}
 
     def set_rua_level(self, magnitude_coef: float) -> None:
         """Set the augmentation intensity based on the magnitude_coef.
+
         This method is specifically designed to be invoked by the RUA Op.
+
         Args:
             magnitude_coef: The desired augmentation intensity (range [0-1]).
+
         Raises:
             AttributeError: If ops don't have a 'set_rua_level' method.
         """
         for op in self.ops:
             if hasattr(op, "set_rua_level") and inspect.ismethod(getattr(op, "set_rua_level")):
                 op.set_rua_level(magnitude_coef=magnitude_coef)
             else:
                 raise AttributeError(
                     "RUA Augmentations should have a 'set_rua_level' method but it's not present in Op: {}".format(
                         op.__class__.__name__))
 
     def forward(self, data: Union[np.ndarray, List[np.ndarray]],
                 state: Dict[str, Any]) -> Union[np.ndarray, List[np.ndarray]]:
         """Execute a randomly selected op from the list of `numpy_ops`.
+
         Args:
             data: The information to be passed to one of the wrapped operators.
             state: Information about the current execution context, for example {"mode": "train"}.
+
         Returns:
             The `data` after application of one of the available numpyOps.
         """
         return np.random.choice(self.ops, p=self.probs).forward(data, state)
 
-    def forward_batch(self, data: Union[np.ndarray, List[np.ndarray]],
+    def forward_batch(self,
+                      data: Union[np.ndarray, List[np.ndarray]],
                       state: Dict[str, Any]) -> Union[np.ndarray, List[np.ndarray]]:
         return np.random.choice(self.ops, p=self.probs).forward_batch(data, state)
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/meta/repeat.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/meta/repeat.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 # ==============================================================================
 import inspect
 from typing import Any, Callable, Dict, List, Optional, Union
 
 import numpy as np
 
 from fastestimator.op.numpyop.numpyop import Batch, NumpyOp, forward_numpyop
-from fastestimator.util.data import FilteredData
+from fastestimator.types import FilteredData
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class Repeat(NumpyOp):
     """Repeat a NumpyOp several times in a row.
 
@@ -103,16 +103,15 @@
                     break
                 filtered = forward_numpyop(self.ops, data, state)
                 if filtered:
                     return filtered
                 i += 1
         return [data[key] for key in self.outputs]
 
-    def forward_batch(self,
-                      data: Union[np.ndarray, List[np.ndarray]],
+    def forward_batch(self, data: Union[np.ndarray, List[np.ndarray]],
                       state: Dict[str, Any]) -> Union[FilteredData, np.ndarray, List[np.ndarray]]:
         data = {key: elem for key, elem in zip(self.inputs, data)}
         if isinstance(self.repeat, int):
             for i in range(self.repeat):
                 filtered = forward_numpyop(self.ops, data, state, batched='np')
                 if filtered:
                     return filtered
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/meta/sometimes.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/meta/sometimes.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 # ==============================================================================
 import inspect
 from typing import Any, Dict, List, Union
 
 import numpy as np
 
 from fastestimator.op.numpyop.numpyop import Batch, NumpyOp
-from fastestimator.util.data import FilteredData
+from fastestimator.types import FilteredData
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class Sometimes(NumpyOp):
     """Perform a NumpyOp with a given probability.
 
@@ -92,16 +92,15 @@
                 return data
             if not self.op.out_list:
                 data = [data]
         else:
             data = [data[self.inputs.index(out)] for out in self.outputs]
         return data
 
-    def forward_batch(self,
-                      data: Union[np.ndarray, List[np.ndarray]],
+    def forward_batch(self, data: Union[np.ndarray, List[np.ndarray]],
                       state: Dict[str, Any]) -> Union[FilteredData, List[np.ndarray]]:
         if self.prob > np.random.uniform():
             data = data[:self.inp_idx]  # Cut off the unnecessary inputs
             if not self.op.in_list:
                 data = data[0]
             data = self.op.forward_batch(data, state)
             if isinstance(data, FilteredData):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/__init__.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/affine.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/affine.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/center_crop.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/center_crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/crop.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/crop_non_empty_mask_if_exists.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/crop_non_empty_mask_if_exists.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/elastic_transform.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/elastic_transform.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/flip.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/flip.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, Optional, Union
 
 from albumentations import BboxParams, KeypointParams
-from albumentations.augmentations.transforms import Flip as FlipAlb
+from albumentations.augmentations.geometric.transforms import Flip as FlipAlb
 
 from fastestimator.op.numpyop.multivariate.multivariate import MultiVariateAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class Flip(MultiVariateAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/grid_distortion.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/grid_distortion.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, List, Optional, Tuple, Union
 
 import cv2
-from albumentations.augmentations.transforms import GridDistortion as GridDistortionAlb
+from albumentations.augmentations.geometric.transforms import GridDistortion as GridDistortionAlb
 
 from fastestimator.op.numpyop.multivariate.multivariate import MultiVariateAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class GridDistortion(MultiVariateAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/horizontal_flip.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/horizontal_flip.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, Optional, Union
 
 from albumentations import BboxParams, KeypointParams
-from albumentations.augmentations.transforms import HorizontalFlip as FlipAlb
+from albumentations.augmentations.geometric.transforms import HorizontalFlip as FlipAlb
 
 from fastestimator.op.numpyop.multivariate.multivariate import MultiVariateAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class HorizontalFlip(MultiVariateAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/iaa_crop_and_pad.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/iaa_crop_and_pad.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/longest_max_size.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/longest_max_size.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, Optional, Union
 
 import cv2
 from albumentations import BboxParams, KeypointParams
-from albumentations.augmentations import LongestMaxSize as LongestMaxSizeAlb
+from albumentations.augmentations.geometric import LongestMaxSize as LongestMaxSizeAlb
 
 from fastestimator.op.numpyop.multivariate.multivariate import MultiVariateAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class LongestMaxSize(MultiVariateAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/mask_dropout.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/mask_dropout.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, Optional, Tuple, Union
 
-from albumentations.augmentations.transforms import MaskDropout as MaskDropoutAlb
+from albumentations.augmentations.dropout import MaskDropout as MaskDropoutAlb
 
 from fastestimator.op.numpyop.multivariate.multivariate import MultiVariateAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class MaskDropout(MultiVariateAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/multivariate.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/multivariate.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/optical_distortion.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/optical_distortion.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, List, Optional, Tuple, Union
 
 import cv2
-from albumentations.augmentations.transforms import OpticalDistortion as OpticalDistortionAlb
+from albumentations.augmentations import OpticalDistortion as OpticalDistortionAlb
 
 from fastestimator.op.numpyop.multivariate.multivariate import MultiVariateAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class OpticalDistortion(MultiVariateAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/pad_if_needed.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/pad_if_needed.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,19 +8,19 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Iterable, List, Optional, Union
+from typing import Iterable, Optional, Sequence, Union
 
 import cv2
 from albumentations import BboxParams, KeypointParams
-from albumentations.augmentations.transforms import PadIfNeeded as PadIfNeededAlb
+from albumentations.augmentations.geometric.transforms import PadIfNeeded as PadIfNeededAlb
 
 from fastestimator.op.numpyop.multivariate.multivariate import MultiVariateAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class PadIfNeeded(MultiVariateAlbumentation):
@@ -43,26 +43,27 @@
         bbox_out: The key to write the modified bounding box(es) (defaults to `bbox_in` if None).
         keypoints_out: The key to write the modified keypoints (defaults to `keypoints_in` if None).
         bbox_params: Parameters defining the type of bounding box ('coco', 'pascal_voc', 'albumentations' or 'yolo').
         keypoint_params: Parameters defining the type of keypoints ('xy', 'yx', 'xya', 'xys', 'xyas', 'xysa').
         min_height: Minimal result image height.
         min_width: Minimal result image width.
         border_mode: Flag that is used to specify the pixel extrapolation method. Should be one of:
-            cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101.        value: Padding value if border_mode is cv2.BORDER_CONSTANT.
+            cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101.
+        value: Padding value if border_mode is cv2.BORDER_CONSTANT.
         mask_value: Padding value for mask if border_mode is cv2.BORDER_CONSTANT.
 
     Image types:
         uint8, float32
     """
     def __init__(self,
                  min_height: int = 1024,
                  min_width: int = 1024,
                  border_mode: int = cv2.BORDER_REFLECT_101,
-                 value: Union[None, int, float, List[int], List[float]] = None,
-                 mask_value: Union[None, int, float, List[int], List[float]] = None,
+                 value: Union[None, int, float, Sequence[int], Sequence[float]] = None,
+                 mask_value: Union[None, int, float, Sequence[int], Sequence[float]] = None,
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None,
                  image_in: Optional[str] = None,
                  mask_in: Optional[str] = None,
                  masks_in: Optional[str] = None,
                  bbox_in: Optional[str] = None,
                  keypoints_in: Optional[str] = None,
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_crop.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_crop_near_bbox.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_crop_near_bbox.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_grid_shuffle.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_grid_shuffle.py`

 * *Files 6% similar despite different names*

```diff
@@ -47,14 +47,16 @@
                  ds_id: Union[None, str, Iterable[str]] = None,
                  image_in: Optional[str] = None,
                  mask_in: Optional[str] = None,
                  masks_in: Optional[str] = None,
                  image_out: Optional[str] = None,
                  mask_out: Optional[str] = None,
                  masks_out: Optional[str] = None):
+        import numpy as np  # Albumentations 1.3.0 is relying on deprecated np.int alias.
+        np.int = np.int32  # TODO - Remove this after they upgrade
         super().__init__(RandomGridShuffleAlb(grid=grid, always_apply=True),
                          image_in=image_in,
                          mask_in=mask_in,
                          masks_in=masks_in,
                          bbox_in=None,
                          keypoints_in=None,
                          image_out=image_out,
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_resized_crop.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_resized_crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_rotate_90.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_rotate_90.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_scale.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_scale.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_sized_bbox_safe_crop.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_sized_bbox_safe_crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/random_sized_crop.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/random_sized_crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/read_mat.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/read_mat.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/resize.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/resize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/rotate.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/rotate.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/shift_scale_rotate.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/shift_scale_rotate.py`

 * *Files 0% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, List, Optional, Tuple, Union
 
 import cv2
 from albumentations import BboxParams, KeypointParams
-from albumentations.augmentations import ShiftScaleRotate as ShiftScaleRotateAlb
+from albumentations.augmentations.geometric import ShiftScaleRotate as ShiftScaleRotateAlb
 
 from fastestimator.op.numpyop.multivariate.multivariate import MultiVariateAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class ShiftScaleRotate(MultiVariateAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/smallest_max_size.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/smallest_max_size.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/transpose.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/transpose.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, Optional, Union
 
 from albumentations import BboxParams, KeypointParams
-from albumentations.augmentations.transforms import Transpose as TransposeAlb
+from albumentations.augmentations import Transpose as TransposeAlb
 
 from fastestimator.op.numpyop.multivariate.multivariate import MultiVariateAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class Transpose(MultiVariateAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/multivariate/vertical_flip.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/multivariate/vertical_flip.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, Optional, Union
 
 from albumentations import BboxParams, KeypointParams
-from albumentations.augmentations.transforms import VerticalFlip as VerticalFlipAlb
+from albumentations.augmentations.geometric.transforms import VerticalFlip as VerticalFlipAlb
 
 from fastestimator.op.numpyop.multivariate.multivariate import MultiVariateAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class VerticalFlip(MultiVariateAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/numpyop.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/numpyop.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,24 +8,24 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Any, Callable, Dict, Iterable, List, MutableMapping, Optional, TypeVar, Union
+from typing import Any, Callable, Dict, Iterable, List, MutableMapping, Optional, Sequence, TypeVar, Union
 
 import numpy as np
 import tensorflow as tf
 import torch
 from torch.utils.data.dataloader import default_collate
 
 from fastestimator.backend._to_tensor import to_tensor
 from fastestimator.op.op import Op, get_inputs_by_op, write_outputs_by_op
-from fastestimator.util.data import FilteredData
+from fastestimator.types import FilteredData
 from fastestimator.util.traceability_util import traceable
 from fastestimator.util.util import pad_batch
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor, np.ndarray)
 
 
 @traceable()
@@ -67,16 +67,15 @@
 
         Returns:
             The `data` after applying whatever transform this Op is responsible for. It will be written into the data
             dictionary based on whatever keys this Op declares as its `outputs`.
         """
         return data
 
-    def forward_batch(self,
-                      data: Union[np.ndarray, List[np.ndarray]],
+    def forward_batch(self, data: Union[np.ndarray, List[np.ndarray]],
                       state: Dict[str, Any]) -> Union[None, FilteredData, np.ndarray, List[np.ndarray]]:
         """A method which will be invoked in order to transform a batch of data.
 
         This method will be invoked on batches of data during network postprocessing. It should expect to receive
         batched data and should itself return batched data.
 
         Args:
@@ -118,14 +117,16 @@
             `pad_value`.
         mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
             regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
             like "!infer" or "!train".
         ds_id: What dataset id(s) to execute this Op in. To execute regardless of ds_id, pass None. To execute in all
             ds_ids except for a particular one, you can pass an argument like "!ds1".
     """
+    collate_fn: Callable[[List[MutableMapping[str, Any]]], Dict[str, Any]]
+
     def __init__(self,
                  batch_size: Optional[int] = None,
                  drop_last: bool = False,
                  pad_value: Optional[Union[int, float]] = None,
                  collate_fn: Optional[Callable[[List[Dict[str, Any]]], Dict[str, Any]]] = None,
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None) -> None:
@@ -172,15 +173,15 @@
         mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
             regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
             like "!infer" or "!train".
         ds_id: What dataset id(s) to execute this Op in. To execute regardless of ds_id, pass None. To execute in all
             ds_ids except for a particular one, you can pass an argument like "!ds1".
     """
     def __init__(self,
-                 keys: Union[str, List[str]],
+                 keys: Union[str, Sequence[str]],
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None) -> None:
         super().__init__(inputs=keys, mode=mode, ds_id=ds_id)
 
     def forward(self, data: Union[np.ndarray, List[np.ndarray]], state: Dict[str, Any]) -> None:
         pass
 
@@ -259,31 +260,33 @@
         self.replacement = replacement
 
     def forward(self, data: List[np.ndarray], state: Dict[str, Any]) -> Optional[FilteredData]:
         if self.filter_fn(*data):
             return FilteredData(replacement=self.replacement)
         return None
 
-    def forward_batch(self, data: Union[Tensor, List[Tensor]], state: Dict[str,
-                                                                           Any]) -> Optional[FilteredData]:
+    def forward_batch(self, data: Union[Tensor, List[Tensor]], state: Dict[str, Any]) -> Optional[FilteredData]:
         return self.forward(data, state)
 
 
 def forward_numpyop(ops: List[NumpyOp],
                     data: MutableMapping[str, Any],
                     state: Dict[str, Any],
-                    batched: Optional[str] = None) -> Optional[FilteredData]:
+                    batched: Optional[str] = None,
+                    shared: bool = True) -> Optional[FilteredData]:
     """Call the forward function for list of NumpyOps, and modify the data dictionary in place.
 
     Args:
         ops: A list of NumpyOps to execute.
         data: The data dictionary.
         state: Information about the current execution context, ex. {"mode": "train"}. Must contain at least the mode.
         batched: Whether the `data` is batched or not. If it is batched, provide the string ('tf', 'torch', or 'np')
             indicating which type of tensors the batch contains.
+        shared: Whether you want to place the resulting data into multi-processing shared memory. Only applicable when
+            `batched` is 'torch'.
     """
     if not ops:
         # Shortcut to prevent wasting time in to_tensor calls if there aren't any ops
         return None
     if batched:
         # Cast data to Numpy before performing batch forward
         for key, val in data.items():
@@ -306,9 +309,9 @@
             for key in op.inputs:
                 del data[key]
         if op.outputs:
             write_outputs_by_op(op, data, op_data)
     if batched:
         # Cast data back to original tensor type after performing batch forward
         for key, val in data.items():
-            data[key] = to_tensor(val, target_type=batched, shared_memory=True)
+            data[key] = to_tensor(val, target_type=batched, shared_memory=shared)
     return None
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/__init__.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/autocontrast.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/autocontrast.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/binarize.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/binarize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/blur.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/motion_blur.py`

 * *Files 5% similar despite different names*

```diff
@@ -10,37 +10,41 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, Tuple, Union
 
-from albumentations.augmentations.transforms import Blur as BlurAlb
+from albumentations.augmentations.blur import MotionBlur as MotionBlurAlb
 
 from fastestimator.op.numpyop.univariate.univariate import ImageOnlyAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
-class Blur(ImageOnlyAlbumentation):
-    """Blur the image with a randomly-sized kernel
+class MotionBlur(ImageOnlyAlbumentation):
+    """Motion Blur the image with a randomly-sized kernel.
 
     Args:
         inputs: Key(s) of images to be modified.
         outputs: Key(s) into which to write the modified images.
         mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
             regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
             like "!infer" or "!train".
         ds_id: What dataset id(s) to execute this Op in. To execute regardless of ds_id, pass None. To execute in all
             ds_ids except for a particular one, you can pass an argument like "!ds1".
-        blur_limit: maximum kernel size for blurring the input image. Should be in range [3, inf).
+        blur_limit: maximum kernel size for blurring the input image. Should be in the range [3, inf).
 
     Image types:
         uint8, float32
     """
     def __init__(self,
                  inputs: Union[str, Iterable[str]],
                  outputs: Union[str, Iterable[str]],
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None,
                  blur_limit: Union[int, Tuple[int, int]] = 7):
-        super().__init__(BlurAlb(blur_limit=blur_limit, always_apply=True), inputs=inputs, outputs=outputs, mode=mode, ds_id=ds_id)
+        super().__init__(MotionBlurAlb(blur_limit=blur_limit, always_apply=True),
+                         inputs=inputs,
+                         outputs=outputs,
+                         mode=mode,
+                         ds_id=ds_id)
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/brightness.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/brightness.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/calibate.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/calibate.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/channel_dropout.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/channel_dropout.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,17 +8,17 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Iterable, Tuple, Union
+from typing import Iterable, Sequence, Tuple, Union
 
-from albumentations.augmentations.transforms import ChannelDropout as ChannelDropoutAlb
+from albumentations.augmentations.dropout import ChannelDropout as ChannelDropoutAlb
 
 from fastestimator.op.numpyop.univariate.univariate import ImageOnlyAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class ChannelDropout(ImageOnlyAlbumentation):
@@ -35,16 +35,16 @@
         channel_drop_range: Range from which we choose the number of channels to drop.
         fill_value: Pixel values for the dropped channel.
 
     Image types:
         int8, uint16, unit32, float32
     """
     def __init__(self,
-                 inputs: Union[str, Iterable[str]],
-                 outputs: Union[str, Iterable[str]],
+                 inputs: Union[str, Sequence[str]],
+                 outputs: Union[str, Sequence[str]],
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None,
                  channel_drop_range: Tuple[int, int] = (1, 1),
                  fill_value: Union[int, float] = 0):
         super().__init__(
             ChannelDropoutAlb(channel_drop_range=channel_drop_range, fill_value=fill_value, always_apply=True),
             inputs=inputs,
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/channel_shuffle.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/channel_shuffle.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/channel_transpose.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/channel_transpose.py`

 * *Files 10% similar despite different names*

```diff
@@ -35,14 +35,14 @@
         axes: The permutation order.
     """
     def __init__(self,
                  inputs: Union[str, Iterable[str]],
                  outputs: Union[str, Iterable[str]],
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None,
-                 axes: List[int] = (2, 0, 1)):
+                 axes: Iterable[int] = (2, 0, 1)):
         super().__init__(inputs=inputs, outputs=outputs, mode=mode, ds_id=ds_id)
         self.axes = axes
         self.in_list, self.out_list = True, True
 
     def forward(self, data: List[np.ndarray], state: Dict[str, Any]) -> List[np.ndarray]:
         return [np.transpose(elem, self.axes) for elem in data]
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/clahe.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/clahe.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/coarse_dropout.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/coarse_dropout.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, List, Optional, Union
 
-from albumentations.augmentations.transforms import CoarseDropout as CoarseDropoutAlb
+from albumentations.augmentations.dropout import CoarseDropout as CoarseDropoutAlb
 
 from fastestimator.op.numpyop.univariate.univariate import ImageOnlyAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class CoarseDropout(ImageOnlyAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/color.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/color.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/color_jitter.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/color_jitter.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/contrast.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/contrast.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/downscale.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/downscale.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/equalize.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/equalize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/expand_dims.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/expand_dims.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/from_float.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/from_float.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/gaussian_blur.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/gaussian_blur.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, Tuple, Union
 
-from albumentations.augmentations.transforms import GaussianBlur as GaussianBlurAlb
+from albumentations.augmentations import GaussianBlur as GaussianBlurAlb
 
 from fastestimator.op.numpyop.univariate.univariate import ImageOnlyAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class GaussianBlur(ImageOnlyAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/gaussian_noise.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/gaussian_noise.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/hadamard.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/hadamard.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/hue_saturation_value.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/hue_saturation_value.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/iaa_additive_gaussian_noise.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/iaa_additive_gaussian_noise.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/image_compression.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/image_compression.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/invert_img.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/invert_img.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/iso_noise.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/iso_noise.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/median_blur.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/median_blur.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, Tuple, Union
 
-from albumentations.augmentations.transforms import MedianBlur as MedianBlurAlb
+from albumentations.augmentations.blur import MedianBlur as MedianBlurAlb
 
 from fastestimator.op.numpyop.univariate.univariate import ImageOnlyAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class MedianBlur(ImageOnlyAlbumentation):
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/minmax.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/minmax.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/motion_blur.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/blur.py`

 * *Files 6% similar despite different names*

```diff
@@ -10,41 +10,41 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Iterable, Tuple, Union
 
-from albumentations.augmentations.transforms import MotionBlur as MotionBlurAlb
+from albumentations.augmentations.blur.transforms import Blur as BlurAlb
 
 from fastestimator.op.numpyop.univariate.univariate import ImageOnlyAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
-class MotionBlur(ImageOnlyAlbumentation):
-    """Motion Blur the image with a randomly-sized kernel.
+class Blur(ImageOnlyAlbumentation):
+    """Blur the image with a randomly-sized kernel
 
     Args:
         inputs: Key(s) of images to be modified.
         outputs: Key(s) into which to write the modified images.
         mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
             regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
             like "!infer" or "!train".
         ds_id: What dataset id(s) to execute this Op in. To execute regardless of ds_id, pass None. To execute in all
             ds_ids except for a particular one, you can pass an argument like "!ds1".
-        blur_limit: maximum kernel size for blurring the input image. Should be in the range [3, inf).
+        blur_limit: maximum kernel size for blurring the input image. Should be in range [3, inf).
 
     Image types:
         uint8, float32
     """
     def __init__(self,
                  inputs: Union[str, Iterable[str]],
                  outputs: Union[str, Iterable[str]],
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None,
                  blur_limit: Union[int, Tuple[int, int]] = 7):
-        super().__init__(MotionBlurAlb(blur_limit=blur_limit, always_apply=True),
+        super().__init__(BlurAlb(blur_limit=blur_limit, always_apply=True),
                          inputs=inputs,
                          outputs=outputs,
                          mode=mode,
                          ds_id=ds_id)
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/multiplicative_noise.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/multiplicative_noise.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/normalize.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/normalize.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,16 +8,17 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Iterable, Tuple, Union
+from typing import Any, Dict, Iterable, List, Sequence, Tuple, Union
 
+import numpy as np
 from albumentations.augmentations.transforms import Normalize as NormalizeAlb
 
 from fastestimator.op.numpyop.univariate.univariate import ImageOnlyAlbumentation
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
@@ -36,19 +37,24 @@
         std: The divisor.
         max_pixel_value: Maximum possible pixel value.
 
     Image types:
         uint8, float32
     """
     def __init__(self,
-                 inputs: Union[str, Iterable[str]],
-                 outputs: Union[str, Iterable[str]],
+                 inputs: Union[str, Sequence[str]],
+                 outputs: Union[str, Sequence[str]],
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None,
                  mean: Union[float, Tuple[float, ...]] = (0.485, 0.456, 0.406),
                  std: Union[float, Tuple[float, ...]] = (0.229, 0.224, 0.225),
                  max_pixel_value: float = 255.0):
         super().__init__(NormalizeAlb(mean=mean, std=std, max_pixel_value=max_pixel_value, always_apply=True),
                          inputs=inputs,
                          outputs=outputs,
                          mode=mode,
                          ds_id=ds_id)
+
+    def forward(self, data: List[np.ndarray], state: Dict[str, Any]) -> List[np.ndarray]:
+        results = super().forward(data, state)
+        # Albumentation library casts the result to float64 iff the image is HxWx3, but we want consistent output
+        return [result.astype(np.float32) for result in results]
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/onehot.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/onehot.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2019 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2022 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,15 +18,15 @@
 
 from fastestimator.op.numpyop.numpyop import NumpyOp
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class Onehot(NumpyOp):
-    """Transform an integer label to one-hot-encoding.
+    """Transform an integer label to one-hot-encoding.The label value start from 0.
 
     This can be desirable for increasing robustness against incorrect labels:
     https://towardsdatascience.com/label-smoothing-making-model-robust-to-incorrect-labels-2fae037ffbd0
 
     Args:
         inputs: Input key(s) of labels to be onehot encoded.
         outputs: Output key(s) of labels.
@@ -51,15 +51,23 @@
         self.label_smoothing = label_smoothing
         self.in_list, self.out_list = True, True
 
     def forward(self, data: List[Union[int, np.ndarray]], state: Dict[str, Any]) -> List[np.ndarray]:
         return [self._apply_onehot(elem) for elem in data]
 
     def _apply_onehot(self, data: Union[int, np.ndarray]) -> np.ndarray:
-        class_index = np.array(data)
-        assert "int" in str(class_index.dtype)
-        assert class_index.size == 1, "data must have only one item"
-        class_index = class_index.item()
-        assert class_index < self.num_classes, "label value should be smaller than num_classes"
-        output = np.full((self.num_classes), fill_value=self.label_smoothing / self.num_classes, dtype="float32")
-        output[class_index] = 1.0 - self.label_smoothing + self.label_smoothing / self.num_classes
+        data = np.atleast_1d(data)
+        assert "int" in str(data.dtype).lower(), "data type must be an integer"
+
+        max_class = np.max(data)
+        assert max_class < self.num_classes, "label value should be smaller than num_classes"
+
+        if data.size == 1:
+            output = np.eye(self.num_classes, dtype=np.float32)[data[0]]
+        else:
+            output = np.eye(self.num_classes, dtype=np.float32)[data]
+
+        if self.label_smoothing != 0:
+            smooth_label = self.label_smoothing / self.num_classes
+            output = np.where(output != 0, 1.0 - self.label_smoothing + smooth_label, smooth_label).astype(np.float32)
+
         return output
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/pad_sequence.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/pad_sequence.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/posterize.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/posterize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_brightness_contrast.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_brightness_contrast.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_fog.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_fog.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_gamma.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_gamma.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_rain.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_rain.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_shadow.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_shadow.py`

 * *Files 3% similar despite different names*

```diff
@@ -8,19 +8,20 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Iterable, Tuple, Union
+from typing import Iterable, Sequence, Tuple, Union
 
 from albumentations.augmentations.transforms import RandomShadow as RandomShadowAlb
 
 from fastestimator.op.numpyop.univariate.univariate import ImageOnlyAlbumentation
+from fastestimator.util.base_util import warn
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
 class RandomShadow(ImageOnlyAlbumentation):
     """Add shadows to an image
 
@@ -39,25 +40,24 @@
             Should be in range [`num_shadows_lower`, inf].
         shadow_dimension: Number of edges in the shadow polygons.
 
     Image types:
         uint8, float32
     """
     def __init__(self,
-                 inputs: Union[str, Iterable[str]],
-                 outputs: Union[str, Iterable[str]],
+                 inputs: Union[str, Sequence[str]],
+                 outputs: Union[str, Sequence[str]],
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None,
                  shadow_roi: Tuple[float, float, float, float] = (0.0, 0.5, 1.0, 1.0),
                  num_shadows_lower: int = 1,
                  num_shadows_upper: int = 2,
                  shadow_dimension: int = 5):
-        print("\033[93m {}\033[00m".format(
-            "Warning! RandomShadow does not work with multi-threaded Pipelines. Either do not use this Op or else " +
-            "set your Pipeline num_process=0"))
+        warn("RandomShadow does not work with multi-threaded Pipelines. Either do not use this Op or else " +
+             "set your Pipeline num_process=0")
         # TODO - Have pipeline look for bad ops and auto-magically set num_process correctly
         super().__init__(
             RandomShadowAlb(shadow_roi=shadow_roi,
                             num_shadows_lower=num_shadows_lower,
                             num_shadows_upper=num_shadows_upper,
                             shadow_dimension=shadow_dimension,
                             always_apply=True),
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_shapes.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_shapes.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_snow.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_snow.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/random_sun_flare.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/random_sun_flare.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/read_image.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/read_image.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/reshape.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/reshape.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/rgb_shift.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/rgb_shift.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/rua.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/rua.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/sharpness.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/sharpness.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/shear_x.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/shear_x.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/shear_y.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/shear_y.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/solarize.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/solarize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/to_array.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/to_array.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/to_float.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/to_float.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/to_gray.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/to_gray.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/to_sepia.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/to_sepia.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/tokenize.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/tokenize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/translate_x.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/translate_x.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/translate_y.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/translate_y.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/univariate.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/univariate.py`

 * *Files 6% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from copy import deepcopy
-from typing import Any, Dict, Iterable, List, Union
+from typing import Any, Dict, Iterable, List, Sequence, Union
 
 import numpy as np
 from albumentations import Compose, ImageOnlyTransform, ReplayCompose
 
 from fastestimator.op.numpyop.numpyop import NumpyOp
 from fastestimator.util.traceability_util import traceable
 
@@ -39,16 +39,16 @@
             regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
             like "!infer" or "!train".
         ds_id: What dataset id(s) to execute this Op in. To execute regardless of ds_id, pass None. To execute in all
             ds_ids except for a particular one, you can pass an argument like "!ds1".
     """
     def __init__(self,
                  func: ImageOnlyTransform,
-                 inputs: Union[str, List[str]],
-                 outputs: Union[str, List[str]],
+                 inputs: Union[str, Sequence[str]],
+                 outputs: Union[str, Sequence[str]],
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None):
         super().__init__(inputs=inputs, outputs=outputs, mode=mode, ds_id=ds_id)
         assert len(self.inputs) == len(self.outputs), "Input and Output lengths must match"
         self.func = Compose(transforms=[func])
         self.replay_func = ReplayCompose(transforms=[deepcopy(func)])
         self.in_list, self.out_list = True, True
```

### Comparing `fastestimator-1.5.2/fastestimator/op/numpyop/univariate/word_to_id.py` & `fastestimator-1.6.0/fastestimator/op/numpyop/univariate/word_to_id.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/op.py` & `fastestimator-1.6.0/fastestimator/op/op.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/__init__.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -16,28 +16,26 @@
 
 import lazy_loader as lazy
 
 __getattr__, __dir__, __all__ = lazy.attach(__name__,
                                             submodules={'augmentation', 'gradient', 'loss', 'meta', 'model'},
                                             submod_attrs={'argmax': ['Argmax'],
                                                           'average': ['Average'],
-                                                          'dice': ['Dice'],
                                                           'gather': ['Gather'],
                                                           'normalize': ['Normalize'],
                                                           'permute': ['Permute'],
                                                           'reshape': ['Reshape'],
                                                           'resize3d': ['Resize3D'],
                                                           'tensorop': ['LambdaOp', 'TensorOp'],
                                                           'un_hadamard': ['UnHadamard']})
 
 if TYPE_CHECKING:
     from fastestimator.op.tensorop import augmentation, gradient, loss, meta, model
     from fastestimator.op.tensorop.argmax import Argmax
     from fastestimator.op.tensorop.average import Average
-    from fastestimator.op.tensorop.dice import Dice
     from fastestimator.op.tensorop.gather import Gather
     from fastestimator.op.tensorop.normalize import Normalize
     from fastestimator.op.tensorop.permute import Permute
     from fastestimator.op.tensorop.reshape import Reshape
     from fastestimator.op.tensorop.resize3d import Resize3D
     from fastestimator.op.tensorop.tensorop import LambdaOp, TensorOp
     from fastestimator.op.tensorop.un_hadamard import UnHadamard
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/argmax.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/argmax.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 from fastestimator.util.traceability_util import traceable
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
 
 
 @traceable()
 class Argmax(TensorOp):
-    """Get the argmax from a tensor.
+    """Get the argmax from a tensor (supports multi-io).
 
     Args:
         inputs: The tensor(s) to gather values from.
         outputs: The key(s) under which to save the output.
         axis: The axis along which to collect the argmax.
         mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
             regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/augmentation/__init__.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/augmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/augmentation/cutmix_batch.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/augmentation/cutmix_batch.py`

 * *Files 2% similar despite different names*

```diff
@@ -30,16 +30,16 @@
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
 
 
 class CutMixBatch(TensorOp):
     """This class performs cutmix augmentation on a batch of tensors.
 
     In this augmentation technique patches are cut and pasted among training images where the ground truth labels are
-    also mixed proportionally to the area of the patches. This class should be used in conjunction with MixLoss to
-    perform CutMix training, which helps to reduce over-fitting, perform object detection, and against adversarial
+    also mixed proportionally to the area of the patches. This class helps to reduce over-fitting, perform object
+    detection, and against adversarial
     attacks (https://arxiv.org/pdf/1905.04899.pdf).
 
     Args:
         inputs: Keys of the image batch and label batch to be cut-mixed.
         outputs: Keys under which to store the cut-mixed images and cut-mixed label.
         mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
             regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
@@ -130,11 +130,11 @@
                              mode="CONSTANT",
                              constant_values=0)
             x = x + patches
         else:
             rolled_x = roll(x, shift=1, axis=0)
             x[:, :, bbox_y1:bbox_y2, bbox_x1:bbox_x2] = rolled_x[:, :, bbox_y1:bbox_y2, bbox_x1:bbox_x2]
         # adjust lambda to match pixel ratio
-        lam = 1 - cast(((bbox_x2 - bbox_x1) * (bbox_y2 - bbox_y1)), dtype="float32") / cast((width * height), "float32")
+        lam = 1 - cast(((bbox_x2 - bbox_x1) * (bbox_y2 - bbox_y1)), dtype=y) / cast((width * height), dtype=y)
         rolled_y = roll(y, shift=1, axis=0) * (1. - lam)
         mixed_y = (y * lam) + rolled_y
         return x, mixed_y
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/augmentation/mixup_batch.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/augmentation/mixup_batch.py`

 * *Files 3% similar despite different names*

```diff
@@ -26,16 +26,16 @@
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
 
 
 class MixUpBatch(TensorOp):
     """MixUp augmentation for tensors.
 
-    This class should be used in conjunction with MixLoss to perform mix-up training, which helps to reduce
-    over-fitting, stabilize GAN training, and against adversarial attacks (https://arxiv.org/abs/1710.09412).
+    This class helps to reduce over-fitting, stabilize GAN training, and against adversarial attacks
+    (https://arxiv.org/abs/1710.09412).
 
     Args:
         inputs: Keys of the image batch and label batch to be mixed up.
         outputs: Keys under which to store the mixed up images and mixed up label.
         mode: What mode to execute in. Probably 'train'.
         ds_id: What dataset id(s) to execute this Op in. To execute regardless of ds_id, pass None. To execute in all
             ds_ids except for a particular one, you can pass an argument like "!ds1".
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/average.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/average.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/dice.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/loss/l1_loss.py`

 * *Files 24% similar despite different names*

```diff
@@ -10,64 +10,72 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 from typing import Any, Dict, Iterable, List, Tuple, TypeVar, Union
 
-import numpy as np
 import tensorflow as tf
 import torch
 
-from fastestimator.backend._dice_score import dice_score
-from fastestimator.op.tensorop.tensorop import TensorOp
-
-Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor, np.array)
-
-
-class Dice(TensorOp):
+from fastestimator.backend._huber import huber
+from fastestimator.backend._l1_loss import l1_loss
+from fastestimator.backend._reduce_mean import reduce_mean
+from fastestimator.backend._smooth_l1_loss import smooth_l1_loss
+from fastestimator.op.tensorop.loss.loss import LossOp
+from fastestimator.util.traceability_util import traceable
+
+Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
+
+
+@traceable()
+class L1_Loss(LossOp):
+    """Calculate the L1 loss between two tensors.
+
+    This LossOp can be used to Implement:
+        L1 loss: Is a criterion that calculates Mean Absolute Error between the elements ([y_pred, y_true]).
+        Smooth_L1 loss: Is a criterion that uses squared loss if absolute element wise subtraction (y_pred - y_true) is less than
+                        'beta' and vanilla L1 loss otherwise.
+        Huber loss: Is a criterion that uses squared loss if absolute element wise subtraction (y_pred - y_true) is less than
+                    'beta' and a 'beta' scaled L1 loss otherwise.
+
+
+    Args:
+        inputs: A tuple or list like: [y_pred, y_true].
+        outputs: String key under which to store the computed loss.
+        mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
+            regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
+            like "!infer" or "!train".
+        ds_id: What dataset id(s) to execute this Op in. To execute regardless of ds_id, pass None. To execute in all
+            ds_ids except for a particular one, you can pass an argument like "!ds1".
+        average_loss: Whether to average the element-wise loss after the Loss Op.
+        loss_type: What type of L1 loss. Can either be 'L1' (L1 Loss), 'Smooth' (Smooth L1 Loss) or 'Huber' (Huber loss). Default:'L1'
+        beta: A threshold at which to change between L1 and L2 loss. Needs to be a positive number. Default:1.0 . dtype: float16 or float32.
     """
-    Calculate Element-Wise Dice Score.
-
-        Args:
-            inputs: A tuple or list of keys representing prediction and ground truth, like: ("y_pred", "y_true").
-            outputs: The key under which to save the output.
-            mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
-                regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
-                like "!infer" or "!train".
-            ds_id: What dataset id(s) to execute this Op in. To execute regardless of ds_id, pass None. To execute in all
-                ds_ids except for a particular one, you can pass an argument like "!ds1".
-            soft_dice: Whether to square elements. If True, square of elements is added.
-            sample_average: Whether to average the element-wise dice score.
-            channel_average: Whether to average the channel wise dice score.
-            negate: Whether to negate dice score.
-            epsilon: A small value to prevent numeric instability in the division.
-
-        Returns:
-            The dice loss between `y_pred` and `y_true`. A scalar if `average_sample` is True, else a
-            tensor with the shape (Batch).
-
-        Raises:
-            AssertionError: If `y_true` or `y_pred` are unacceptable data types.
-    """
-
     def __init__(self,
                  inputs: Union[Tuple[str, str], List[str]],
                  outputs: str,
                  mode: Union[None, str, Iterable[str]] = "!infer",
                  ds_id: Union[None, str, Iterable[str]] = None,
-                 soft_dice: bool = False,
-                 sample_average: bool = False,
-                 channel_average: bool = False,
-                 negate: bool = False,
-                 epsilon: float = 1e-6):
+                 average_loss: bool = True,
+                 loss_type: str = 'L1',
+                 beta: Union[None, float] = 1.0):
+        self.average_loss = average_loss
+        self.loss_type = loss_type
+        self.beta = beta
         super().__init__(inputs=inputs, outputs=outputs, mode=mode, ds_id=ds_id)
-        self.channel_average = channel_average
-        self.soft_dice = soft_dice
-        self.epsilon = epsilon
-        self.sample_average = sample_average
-        self.negate = negate
 
     def forward(self, data: List[Tensor], state: Dict[str, Any]) -> Tensor:
         y_pred, y_true = data
-        dice = dice_score(y_pred, y_true, self.soft_dice, self.sample_average, self.channel_average, self.epsilon)
-        return -dice if self.negate else dice
+        if self.loss_type == 'L1':
+            loss = l1_loss(y_true=y_true, y_pred=y_pred)
+        elif self.loss_type == 'Smooth':
+            loss = smooth_l1_loss(y_true=y_true, y_pred=y_pred, beta=self.beta)
+        elif self.loss_type == 'Huber':
+            loss = huber(y_true=y_true, y_pred=y_pred, beta=self.beta)
+        else:
+            raise ValueError(
+                "Unrecognized Loss type. Can either be None (L1 Loss), 'Smooth' (Smooth L1 Loss) or 'Huber' (Huber loss)"
+            )
+        if self.average_loss:
+            loss = reduce_mean(loss)
+        return loss
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/gather.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/gather.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/gradient/__init__.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/gradient/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/gradient/fgsm.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/gradient/fgsm.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/gradient/gradient.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/gradient/gradient.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/gradient/watch.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/gradient/watch.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/loss/__init__.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/loss/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -14,27 +14,27 @@
 # ==============================================================================
 from typing import TYPE_CHECKING
 
 import lazy_loader as lazy
 
 __getattr__, __dir__, __all__ = lazy.attach(__name__,
                                             submod_attrs={'cross_entropy': ['CrossEntropy'],
+                                                          'dice_loss': ['DiceLoss'],
                                                           'hinge': ['Hinge'],
                                                           'focal_loss': ['FocalLoss'],
                                                           'l2_regularization': ['L2Regularizaton'],
                                                           'loss': ['LossOp'],
                                                           'mean_squared_error': ['MeanSquaredError'],
-                                                          'mix_loss': ['MixLoss'],
                                                           'super_loss': ['SuperLoss'],
                                                           'l1_loss': ['L1_Loss']
                                                           })
 
 if TYPE_CHECKING:
     from fastestimator.op.tensorop.loss.cross_entropy import CrossEntropy
+    from fastestimator.op.tensorop.loss.dice_loss import DiceLoss
     from fastestimator.op.tensorop.loss.focal_loss import FocalLoss
     from fastestimator.op.tensorop.loss.hinge import Hinge
     from fastestimator.op.tensorop.loss.l1_loss import L1_Loss
     from fastestimator.op.tensorop.loss.l2_regularization import L2Regularizaton
     from fastestimator.op.tensorop.loss.loss import LossOp
     from fastestimator.op.tensorop.loss.mean_squared_error import MeanSquaredError
-    from fastestimator.op.tensorop.loss.mix_loss import MixLoss
     from fastestimator.op.tensorop.loss.super_loss import SuperLoss
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/loss/cross_entropy.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/loss/cross_entropy.py`

 * *Files 5% similar despite different names*

```diff
@@ -37,15 +37,17 @@
             regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
             like "!infer" or "!train".
         ds_id: What dataset id(s) to execute this Op in. To execute regardless of ds_id, pass None. To execute in all
             ds_ids except for a particular one, you can pass an argument like "!ds1".
         from_logits: Whether y_pred is logits (without softmax).
         average_loss: Whether to average the element-wise loss after the Loss Op.
         form: What form of cross entropy should be performed ('binary', 'categorical', 'sparse', or None). None will
-            automatically infer the correct form based on tensor shape.
+            automatically infer the correct form based on tensor shape: if the both y_pred and y_true are rank-2 tensors
+            then 'categorical' will be used, if y_pred is rank-2 tensors but y_true is rank-1 tensor, then `sparse` will
+            be chosen, otherwise `binary` will be applied.
         class_weights: Dictionary mapping class indices to a weight for weighting the loss function. Useful when you
             need to pay more attention to samples from an under-represented class.
 
     Raises:
         AssertionError: If `class_weights` or it's keys and values are of unacceptable data types.
     """
     def __init__(self,
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/loss/focal_loss.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/loss/focal_loss.py`

 * *Files 19% similar despite different names*

```diff
@@ -34,43 +34,50 @@
     Args:
         inputs: A tuple or list like: [<y_pred>, <y_true>].
         outputs: String key under which to store the computed loss value.
         alpha: Weighting factor in range (0,1) to balance
                 positive vs negative examples or -1 to ignore. Default = 0.25
         gamma: Exponent of the modulating factor (1 - p_t) to
                balance easy vs hard examples.
-        reduction: 'none' | 'mean' | 'sum'
+        sample_reduction: 'none' | 'mean' | 'sum'
                  'none': No reduction will be applied to the output.
                  'mean': The output will be averaged.
                  'sum': The output will be summed.
+        shape_reduction:
+                 'none' | 'mean' | 'sum'
+                 'none': No reduction will be applied to the output.
+                 'mean': The output will be averaged across classes.
+                 'sum': The output will be summed across classes.
         from_logits: Whether y_pred is logits (without sigmoid).
         normalize: Whether to normalize focal loss along samples based on number of positive classes per samples.
         mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
             regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an
             argument like "!infer" or "!train".
     """
-
     def __init__(self,
                  inputs: Union[Tuple[str, str], List[str]],
                  outputs: str,
                  gamma: float = 2.0,
                  alpha: float = 0.25,
-                 reduction: str = 'mean',
+                 sample_reduction: str = 'mean',
+                 shape_reduction: str = 'sum',
                  from_logits: bool = False,
                  normalize: bool = True,
-                 mode: Union[None, str, Iterable[str]] = None,):
+                 mode: Union[None, str, Iterable[str]] = "!infer"):
         super().__init__(inputs=inputs, outputs=outputs, mode=mode)
         self.gamma = gamma
         self.alpha = alpha
-        self.reduction = reduction
+        self.sample_reduction = sample_reduction
+        self.shape_reduction = shape_reduction
         self.from_logits = from_logits
         self.normalize = normalize
 
     def forward(self, data: Union[Tensor, List[Tensor]], state: Dict[str, Any]) -> Tensor:
         y_pred, y_true = data
         return focal_loss(y_true,
                           y_pred,
                           gamma=self.gamma,
                           alpha=self.alpha,
                           from_logits=self.from_logits,
-                          reduction=self.reduction,
+                          sample_reduction=self.sample_reduction,
+                          shape_reduction=self.shape_reduction,
                           normalize=self.normalize)
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/loss/hinge.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/loss/hinge.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/loss/l1_loss.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/meta/sometimes.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,81 +1,97 @@
-# Copyright 2022 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2019 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Any, Dict, Iterable, List, Tuple, TypeVar, Union
+from typing import Any, Dict, List, Optional, Set, TypeVar
 
 import tensorflow as tf
+import tensorflow_probability as tfp
 import torch
 
-from fastestimator.backend._huber import huber
-from fastestimator.backend._l1_loss import l1_loss
-from fastestimator.backend._reduce_mean import reduce_mean
-from fastestimator.backend._smooth_l1_loss import smooth_l1_loss
-from fastestimator.op.tensorop.loss.loss import LossOp
+from fastestimator.op.tensorop.tensorop import TensorOp
 from fastestimator.util.traceability_util import traceable
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
+Model = TypeVar('Model', tf.keras.Model, torch.nn.Module)
 
 
 @traceable()
-class L1_Loss(LossOp):
-    """Calculate the L1 loss between two tensors.
-
-    This LossOp can be used to Implement:
-        L1 loss: Is a criterion that calculates Mean Absolute Error between the elements ([<y_pred>, <y_true>]).
-        Smooth_L1 loss: Is a criterion that uses squared loss if absolute element wise subtraction ('y_pred - y_true') is less than
-                        'beta' and vanilla L1 loss otherwise.
-        Huber loss: Is a criterion that uses squared loss if absolute element wise subtraction ('y_pred - y_true') is less than
-                    'beta' and a 'beta' scaled L1 loss otherwise.
+class Sometimes(TensorOp):
+    """Perform a NumpyOp with a given probability.
 
+    Note that Sometimes should not be used to wrap an op whose output key(s) do not already exist in the data
+    dictionary. This would result in a problem when future ops / traces attempt to reference the output key, but
+    Sometimes declined to generate it. If you want to create a default value for a new key, simply use a LambdaOp before
+    invoking the Sometimes.
 
     Args:
-        inputs: A tuple or list like: [<y_pred>, <y_true>].
-        outputs: String key under which to store the computed loss.
-        mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
-            regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
-            like "!infer" or "!train".
-        ds_id: What dataset id(s) to execute this Op in. To execute regardless of ds_id, pass None. To execute in all
-            ds_ids except for a particular one, you can pass an argument like "!ds1".
-        average_loss: Whether to average the element-wise loss after the Loss Op.
-        loss_type: What type of L1 loss. Can either be 'L1' (L1 Loss), 'Smooth' (Smooth L1 Loss) or 'Huber' (Huber loss). Default:'L1'
-        beta: A threshold at which to change between L1 and L2 loss. Needs to be a positive number. Default:1.0 . dtype: float16 or float32.
+        tensor_op: The operator to be performed.
+        prob: The probability of execution, which should be in the range: [0-1).
     """
-    def __init__(self,
-                 inputs: Union[Tuple[str, str], List[str]],
-                 outputs: str,
-                 mode: Union[None, str, Iterable[str]] = "!infer",
-                 ds_id: Union[None, str, Iterable[str]] = None,
-                 average_loss: bool = True,
-                 loss_type: str = 'L1',
-                 beta: Union[None, float] = 1.0):
-        self.average_loss = average_loss
-        self.loss_type = loss_type
-        self.beta = beta
-        super().__init__(inputs=inputs, outputs=outputs, mode=mode, ds_id=ds_id)
-
-    def forward(self, data: List[Tensor], state: Dict[str, Any]) -> Tensor:
-        y_pred, y_true = data
-        if self.loss_type == 'L1':
-            loss = l1_loss(y_true=y_true, y_pred=y_pred)
-        elif self.loss_type == 'Smooth':
-            loss = smooth_l1_loss(y_true=y_true, y_pred=y_pred, beta=self.beta)
-        elif self.loss_type == 'Huber':
-            loss = huber(y_true=y_true, y_pred=y_pred, beta=self.beta)
+    def __init__(self, tensor_op: TensorOp, prob: float = 0.5) -> None:
+        # We're going to try to collect any missing output keys from the data dictionary so that they don't get
+        # overridden when Sometimes chooses not to execute.
+        inps = set(tensor_op.inputs)
+        outs = set(tensor_op.outputs)
+        self.extra_inputs = list(outs - inps)  # Used by traceability
+        self.inp_idx = len(tensor_op.inputs)
+        super().__init__(inputs=tensor_op.inputs + self.extra_inputs,
+                         outputs=tensor_op.outputs,
+                         mode=tensor_op.mode,
+                         ds_id=tensor_op.ds_id)
+        # Note that in_list and out_list will always be true
+        self.op = tensor_op
+        self.prob = prob
+        self.prob_fn = None
+
+    def build(self, framework: str, device: Optional[torch.device] = None) -> None:
+        self.op.build(framework, device)
+        if framework == 'tf':
+            self.prob_fn = tfp.distributions.Uniform()
+        elif framework == 'torch':
+            self.prob_fn = torch.distributions.uniform.Uniform(low=0, high=1)
+        else:
+            raise ValueError("unrecognized framework: {}".format(framework))
+
+    def get_fe_loss_keys(self) -> Set[str]:
+        return self.op.get_fe_loss_keys()
+
+    def get_fe_models(self) -> Set[Model]:
+        return self.op.get_fe_models()
+
+    def fe_retain_graph(self, retain: Optional[bool] = None) -> Optional[bool]:
+        return self.op.fe_retain_graph(retain)
+
+    def __getstate__(self) -> Dict[str, Dict[Any, Any]]:
+        return {'op': self.op.__getstate__() if hasattr(self.op, '__getstate__') else {}}
+
+    def forward(self, data: List[Tensor], state: Dict[str, Any]) -> List[Tensor]:
+        """Execute the wrapped operator a certain fraction of the time.
+
+        Args:
+            data: The information to be passed to the wrapped operator.
+            state: Information about the current execution context, for example {"mode": "train"}.
+
+        Returns:
+            The original `data`, or the `data` after running it through the wrapped operator.
+        """
+        if self.prob > self.prob_fn.sample():
+            data = data[:self.inp_idx]  # Cut off the unnecessary inputs
+            if not self.op.in_list:
+                data = data[0]
+            data = self.op.forward(data, state)
+            if not self.op.out_list:
+                data = [data]
         else:
-            raise ValueError(
-                "Unrecognized Loss type. Can either be None (L1 Loss), 'Smooth' (Smooth L1 Loss) or 'Huber' (Huber loss)"
-            )
-        if self.average_loss:
-            loss = reduce_mean(loss)
-        return loss
+            data = [data[self.inputs.index(out)] for out in self.outputs]
+        return data
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/loss/l2_regularization.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/loss/l2_regularization.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/loss/loss.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/loss/loss.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/loss/mean_squared_error.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/loss/mean_squared_error.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/loss/super_loss.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/loss/super_loss.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/meta/__init__.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/meta/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/meta/fuse.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/meta/fuse.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/meta/one_of.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/meta/one_of.py`

 * *Files 1% similar despite different names*

```diff
@@ -25,19 +25,19 @@
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
 Model = TypeVar('Model', tf.keras.Model, torch.nn.Module)
 
 
 @traceable()
 class OneOf(TensorOp):
     """Perform one of several possible TensorOps.
+
     Args:
         *tensor_ops: Ops to choose between with a specified (or uniform) probability.
         probs: List of probabilities, must sum to 1. When None, the probabilities will be equally distributed.
     """
-
     def __init__(self, *tensor_ops: TensorOp, probs: Optional[List[float]] = None) -> None:
         inputs = tensor_ops[0].inputs
         outputs = tensor_ops[0].outputs
         mode = tensor_ops[0].mode
         ds_id = tensor_ops[0].ds_id
         super().__init__(inputs=inputs, outputs=outputs, mode=mode, ds_id=ds_id)
         self.in_list = tensor_ops[0].in_list
@@ -77,17 +77,19 @@
         return resp
 
     def __getstate__(self) -> Dict[str, List[Dict[Any, Any]]]:
         return {'ops': [elem.__getstate__() if hasattr(elem, '__getstate__') else {} for elem in self.ops]}
 
     def forward(self, data: Union[Tensor, List[Tensor]], state: Dict[str, Any]) -> Union[Tensor, List[Tensor]]:
         """Execute a randomly selected op from the list of `numpy_ops`.
+
         Args:
             data: The information to be passed to one of the wrapped operators.
             state: Information about the current execution context, for example {"mode": "train"}.
+
         Returns:
             The `data` after application of one of the available numpyOps.
         """
         if self.framework == 'tf':
             idx = cast(tf.random.categorical(tf.math.log([self.probs]), 1), dtype='int32')[0, 0]
             results = tf.switch_case(idx, [lambda op=op: op.forward(data, state) for op in self.ops])
         else:
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/meta/sometimes.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_best_model_saver.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,97 +1,96 @@
-# Copyright 2019 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2020 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Any, Dict, List, Optional, Set, TypeVar
+import os
+import tempfile
+import unittest
 
 import tensorflow as tf
-import tensorflow_probability as tfp
 import torch
 
-from fastestimator.op.tensorop.tensorop import TensorOp
-from fastestimator.util.traceability_util import traceable
-
-Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
-Model = TypeVar('Model', tf.keras.Model, torch.nn.Module)
-
-
-@traceable()
-class Sometimes(TensorOp):
-    """Perform a NumpyOp with a given probability.
-
-    Note that Sometimes should not be used to wrap an op whose output key(s) do not already exist in the data
-    dictionary. This would result in a problem when future ops / traces attempt to reference the output key, but
-    Sometimes declined to generate it. If you want to create a default value for a new key, simply use a LambdaOp before
-    invoking the Sometimes.
-
-    Args:
-        tensor_op: The operator to be performed.
-        prob: The probability of execution, which should be in the range: [0-1).
-    """
-    def __init__(self, tensor_op: TensorOp, prob: float = 0.5) -> None:
-        # We're going to try to collect any missing output keys from the data dictionary so that they don't get
-        # overridden when Sometimes chooses not to execute.
-        inps = set(tensor_op.inputs)
-        outs = set(tensor_op.outputs)
-        self.extra_inputs = list(outs - inps)  # Used by traceability
-        self.inp_idx = len(tensor_op.inputs)
-        super().__init__(inputs=tensor_op.inputs + self.extra_inputs,
-                         outputs=tensor_op.outputs,
-                         mode=tensor_op.mode,
-                         ds_id=tensor_op.ds_id)
-        # Note that in_list and out_list will always be true
-        self.op = tensor_op
-        self.prob = prob
-        self.prob_fn = None
-
-    def build(self, framework: str, device: Optional[torch.device] = None) -> None:
-        self.op.build(framework, device)
-        if framework == 'tf':
-            self.prob_fn = tfp.distributions.Uniform()
-        elif framework == 'torch':
-            self.prob_fn = torch.distributions.uniform.Uniform(low=0, high=1)
-        else:
-            raise ValueError("unrecognized framework: {}".format(framework))
-
-    def get_fe_loss_keys(self) -> Set[str]:
-        return self.op.get_fe_loss_keys()
-
-    def get_fe_models(self) -> Set[Model]:
-        return self.op.get_fe_models()
-
-    def fe_retain_graph(self, retain: Optional[bool] = None) -> Optional[bool]:
-        return self.op.fe_retain_graph(retain)
-
-    def __getstate__(self) -> Dict[str, Dict[Any, Any]]:
-        return {'op': self.op.__getstate__() if hasattr(self.op, '__getstate__') else {}}
-
-    def forward(self, data: List[Tensor], state: Dict[str, Any]) -> List[Tensor]:
-        """Execute the wrapped operator a certain fraction of the time.
-
-        Args:
-            data: The information to be passed to the wrapped operator.
-            state: Information about the current execution context, for example {"mode": "train"}.
-
-        Returns:
-            The original `data`, or the `data` after running it through the wrapped operator.
-        """
-        if self.prob > self.prob_fn.sample():
-            data = data[:self.inp_idx]  # Cut off the unnecessary inputs
-            if not self.op.in_list:
-                data = data[0]
-            data = self.op.forward(data, state)
-            if not self.op.out_list:
-                data = [data]
+import fastestimator as fe
+from fastestimator.op.tensorop.model import UpdateOp
+from fastestimator.test.unittest_util import MultiLayerTorchModel, is_equal, one_layer_tf_model
+from fastestimator.trace.io import BestModelSaver
+from fastestimator.util.data import Data
+
+
+def one_layer_model_without_weights():
+    input = tf.keras.layers.Input([3])
+    x = tf.keras.layers.Dense(units=1, use_bias=False)(input)
+    model = tf.keras.models.Model(inputs=input, outputs=x)
+    return model
+
+
+class MultiLayerTorchModelWithoutWeights(torch.nn.Module):
+    def __init__(self) -> None:
+        super().__init__()
+        self.fc1 = torch.nn.Linear(4, 2, bias=False)
+        self.fc2 = torch.nn.Linear(2, 1, bias=False)
+
+    def forward(self, x: torch.Tensor) -> torch.Tensor:
+        x = self.fc1(x)
+        x = self.fc2(x)
+        return x
+
+
+class TestBestModelSaver(unittest.TestCase):
+    @classmethod
+    def setUpClass(cls):
+        cls.save_dir = tempfile.mkdtemp()
+        cls.tf_model = fe.build(model_fn=one_layer_tf_model, optimizer_fn='adam', model_name='tf')
+        cls.torch_model = fe.build(model_fn=MultiLayerTorchModel, optimizer_fn='adam', model_name='torch')
+        cls.data = Data({'loss': 0.5})
+        cls.state = {'mode': 'train', 'epoch': 1, 'warmup': False, 'deferred': {}, "scaler": None, "tape": None}
+        cls.tf_input_data = tf.Variable([[2.0, 1.5, 1.0], [1.0, -1.0, -0.5]])
+        cls.tf_y = tf.constant([[-6], [1]])
+        cls.torch_input_data = torch.tensor([[1.0, 1.0, 1.0, -0.5], [0.5, 1.0, -1.0, -0.5]], dtype=torch.float32)
+        cls.torch_y = torch.tensor([[5], [7]], dtype=torch.float32)
+
+    def test_tf_model(self):
+        def update():
+            with tf.GradientTape(persistent=True) as tape:
+                self.state['tape'] = tape
+                pred = fe.backend.feed_forward(self.tf_model, self.tf_input_data)
+                loss = fe.backend.mean_squared_error(y_pred=pred, y_true=self.tf_y)
+                op.forward(data=loss, state=self.state)
+
+        op = UpdateOp(model=self.tf_model, loss_name='loss')
+        op.build("tf")
+        strategy = tf.distribute.get_strategy()
+        if isinstance(strategy, tf.distribute.MirroredStrategy):
+            strategy.run(update, args=())
         else:
-            data = [data[self.inputs.index(out)] for out in self.outputs]
-        return data
+            update()
+        bms = BestModelSaver(model=self.tf_model, save_dir=self.save_dir)
+        bms.on_epoch_end(data=self.data)
+        m2 = fe.build(model_fn=one_layer_model_without_weights, optimizer_fn='adam')
+        fe.backend.load_model(m2, os.path.join(self.save_dir, 'tf_best_loss.h5'))
+        self.assertTrue(is_equal(m2.trainable_variables, self.tf_model.trainable_variables))
+
+    def test_torch_model(self):
+        op = UpdateOp(model=self.torch_model, loss_name='loss')
+        op.build("torch", "cuda:0" if torch.cuda.is_available() else "cpu")
+        self.torch_model.to("cuda:0" if torch.cuda.is_available() else "cpu")
+        self.torch_input_data = self.torch_input_data.to("cuda:0" if torch.cuda.is_available() else "cpu")
+        self.torch_y = self.torch_y.to("cuda:0" if torch.cuda.is_available() else "cpu")
+        pred = fe.backend.feed_forward(self.torch_model, self.torch_input_data)
+        loss = fe.backend.mean_squared_error(y_pred=pred, y_true=self.torch_y)
+        op.forward(data=loss, state=self.state)
+        bms = BestModelSaver(model=self.torch_model, save_dir=self.save_dir)
+        bms.on_epoch_end(data=self.data)
+        m2 = fe.build(model_fn=MultiLayerTorchModelWithoutWeights, optimizer_fn='adam')
+        fe.backend.load_model(m2, os.path.join(self.save_dir, 'torch_best_loss.pt'))
+        self.torch_model.to("cpu")
+        self.assertTrue(is_equal(list(m2.parameters()), list(self.torch_model.parameters())))
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/model/__init__.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/model/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/model/model.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/model/model.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,27 +10,25 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import inspect
 from functools import partial
-from typing import Any, Dict, Iterable, List, Optional, Set, Tuple, TypeVar, Union
+from typing import Any, Dict, Iterable, List, Optional, Set, Tuple, Union
 
 import tensorflow as tf
 import torch
 
 from fastestimator.backend._feed_forward import feed_forward
 from fastestimator.op.tensorop.tensorop import TensorOp
+from fastestimator.types import Model, Tensor
+from fastestimator.util.base_util import to_list, warn
 from fastestimator.util.traceability_util import FeInputSpec, traceable
 from fastestimator.util.util import get_num_devices
-from fastestimator.util.base_util import to_list
-
-Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
-Model = TypeVar('Model', tf.keras.Model, torch.nn.Module)
 
 
 @traceable()
 class ModelOp(TensorOp):
     """This class performs forward passes of a neural network over batch data to generate predictions.
 
     Args:
@@ -51,28 +49,27 @@
             a name will be autogenerated for you (ex. conv2d_2). This autogenerated name will change if you build a new
             model within the same python session (for example, if you re-run a Jupyter notebook cell, the name could now
             be conv2d_5). Any `intermediate_layers` you request will be appended in order to the end of the Op output,
             so you must provide output key names for them within the `outputs` argument. Note that layer names may be
             different between single-gpu and multi-gpu environments, though we attempt to prevent this.
     """
     def __init__(self,
-                 model: Union[tf.keras.Model, torch.nn.Module],
+                 model: Model,
                  inputs: Union[None, str, Iterable[str]] = None,
                  outputs: Union[None, str, Iterable[str]] = None,
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None,
                  trainable: bool = True,
                  intermediate_layers: Union[None, str, int, List[Union[str, int]]] = None):
         super().__init__(inputs=inputs, outputs=outputs, mode=mode, ds_id=ds_id)
         assert hasattr(model, "fe_compiled"), "must use fe.build to compile the model before use"
         self.intermediate_outputs = []  # [{device: Tensor}]
         intermediate_layers = to_list(intermediate_layers)
         if intermediate_layers and get_num_devices() > 1:
-            print("\033[93m {}\033[00m".format(
-                "FastEstimator-Warn: Layer names / ids may be different between single-gpu and multi-gpu environments"))
+            warn("Layer names / ids may be different between single-gpu and multi-gpu environments")
         for intermediate_layer in intermediate_layers:
             storage = {}
             if isinstance(model, tf.keras.Model):
                 layers = list(model._flatten_layers(include_self=False, recursive=True))
                 if isinstance(intermediate_layer, int):
                     intermediate_layer = layers[intermediate_layer]
                 else:
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/model/update.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/model/update.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,16 +17,17 @@
 import tensorflow as tf
 import torch
 
 from fastestimator.backend._get_gradient import get_gradient
 from fastestimator.backend._reduce_mean import reduce_mean
 from fastestimator.backend._update_model import update_model
 from fastestimator.op.tensorop.tensorop import TensorOp
+from fastestimator.util.base_util import to_set, warn
 from fastestimator.util.traceability_util import traceable
-from fastestimator.util.base_util import to_set
+from fastestimator.util.util import get_num_gpus
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
 Model = TypeVar('Model', tf.keras.Model, torch.nn.Module)
 
 
 @traceable()
 class UpdateOp(TensorOp):
@@ -55,14 +56,16 @@
     Raise:
         ValueError: When model is mixed-precision and `gradients` is provided.
         ValueError: Network framework is not one of "tf" or "torch".
         ValueError: `merge_grad` is larger than 1 in multi-GPU configuration.
         RuntimeError: If attempting to modify a PyTorch model which relied on gradients within a different PyTorch model
             which has in turn already undergone a non-deferred update.
     """
+    _old_defer: bool  # Used by the Network to automagically fix defer values
+
     def __init__(self,
                  model: Union[tf.keras.Model, torch.nn.Module],
                  loss_name: str,
                  gradients: Optional[str] = None,
                  mode: Union[None, str, Iterable[str]] = "train",
                  ds_id: Union[None, str, Iterable[str]] = None,
                  merge_grad: int = 1,
@@ -71,19 +74,19 @@
         if gradients is None:
             super().__init__(inputs=loss_name, outputs=None, mode=mode, ds_id=ds_id)
         else:
             if model.mixed_precision:
                 raise ValueError("Mixed precision training cannot take input gradients, because the gradients need to "
                                  "be computed in this module")
             if self.extra_loss:
-                print("FastEstimator-Warn: Extra model losses are detected and they will be ignored since the gradients"
-                      " are not computed in UpdateOp class.")
+                warn("Extra model losses are detected and they will be ignored since the gradients are not computed " +
+                     "in UpdateOp class.")
             super().__init__(inputs=gradients, outputs=None, mode=mode, ds_id=ds_id)
 
-        if torch.cuda.device_count() > 1 and merge_grad > 1:
+        if get_num_gpus() > 1 and merge_grad > 1:
             raise ValueError("Currently FastEstimator doesn't support merge_grad feature in multi-GPU configuration "
                              "and thus 'merge_grad' cannot be larger than 1")
 
         if not hasattr(model, "loss_name"):
             model.loss_name = {loss_name}
         else:
             model.loss_name.add(loss_name)
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/normalize.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/normalize.py`

 * *Files 4% similar despite different names*

```diff
@@ -23,19 +23,19 @@
 from fastestimator.util.traceability_util import traceable
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor, np.ndarray)
 
 
 @traceable()
 class Normalize(TensorOp):
-    """Normalize a input tensor.
+    """Normalize a input tensor (supports multi-io).
 
     Args:
-        inputs: Key of the input tensor that is to be normalized.
-        outputs: Key of the output tensor that has been normalized.
+        inputs: Key(s) of the input tensor that is to be normalized.
+        outputs: Key(s) of the output tensor that has been normalized.
         mean: The mean which needs to applied (eg: None, 0.54, (0.24, 0.34, 0.35))
         std: The standard deviation which needs to applied (eg: None, 0.4, (0.1, 0.25, 0.45))
         max_pixel_value: The max value of the input data(eg: 255, 65025) to be multipled with mean and std to get actual mean and std.
                             To directly use the mean and std provide set max_pixel_value as 1.
         mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
             regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
             like "!infer" or "!train".
@@ -46,14 +46,15 @@
                  inputs: Union[str, Iterable[str]],
                  outputs: Union[str, Iterable[str]],
                  mean: Union[float, Sequence[float]] = (0.485, 0.456, 0.406),
                  std: Union[float, Sequence[float]] = (0.229, 0.224, 0.225),
                  max_pixel_value: float = 255.0,
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None):
-        super().__init__(inputs=inputs, outputs=outputs, mode=mode)
+        super().__init__(inputs=inputs, outputs=outputs, mode=mode, ds_id=ds_id)
         self.mean = mean
         self.std = std
         self.max_pixel_value = max_pixel_value
+        self.in_list, self.out_list = True, True
 
-    def forward(self, data: List[Tensor], state: Dict[str, Any]) -> Union[Tensor, List[Tensor]]:
-        return normalize(data, self.mean, self.std, self.max_pixel_value)
+    def forward(self, data: List[Tensor], state: Dict[str, Any]) -> List[Tensor]:
+        return [normalize(elem, self.mean, self.std, self.max_pixel_value) for elem in data]
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/permute.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/permute.py`

 * *Files 1% similar despite different names*

```diff
@@ -41,12 +41,12 @@
     """
     def __init__(self,
                  inputs: Union[str, Iterable[str]],
                  outputs: Union[str, Iterable[str]],
                  permutation: Sequence[int] = (0, 3, 1, 2),
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None) -> None:
-        super().__init__(inputs=inputs, outputs=outputs, mode=mode)
+        super().__init__(inputs=inputs, outputs=outputs, mode=mode, ds_id=ds_id)
         self.permutation = permutation
 
     def forward(self, data: List[Tensor], state: Dict[str, Any]) -> Union[Tensor, List[Tensor]]:
         return permute(data, self.permutation)
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/reshape.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/reshape.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/resize3d.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/resize3d.py`

 * *Files 9% similar despite different names*

```diff
@@ -15,43 +15,48 @@
 from typing import Any, Dict, Iterable, List, Sequence, TypeVar, Union
 
 import tensorflow as tf
 import torch
 
 from fastestimator.backend._resize3d import resize_3d
 from fastestimator.op.tensorop.tensorop import TensorOp
-from fastestimator.util.traceability_util import traceable
 from fastestimator.util.base_util import to_list
+from fastestimator.util.traceability_util import traceable
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
 
 
 @traceable()
 class Resize3D(TensorOp):
-    """Resize a 3D tensor.
+    """Resize a 3D tensor (supports multi-io).
 
         Args:
-            inputs: Key of the input tensor.
-            outputs: Key of the output tensor.
-            output_shape: The desired output shape for the input tensor.
+            inputs: Key(s) of the input tensor.
+            outputs: Key(s) of the output tensor.
+            output_shape: The desired output shape for the input tensor exculding batch and channels (H, W, D).
             resize_mode: The resize mode of the operation ('area' or 'nearest').
+                'area' : Uses pixel area relation for resampling. This is best suited for reducing the size of an image
+                        (shrinking). When used for zooming into the image, it uses the nearest method.
+                'nearest' : Uses the nearest neighbor concept for interpolation.
             mode: What mode(s) to execute this Op in. For example, "train", "eval", "test", or "infer". To execute
                 regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
                 like "!infer" or "!train".
             ds_id: What dataset id(s) to execute this Op in. To execute regardless of ds_id, pass None. To execute in all
                 ds_ids except for a particular one, you can pass an argument like "!ds1".
     """
     def __init__(self,
                  inputs: Union[str, Iterable[str]],
                  outputs: Union[str, Iterable[str]],
                  output_shape: Sequence[int],
                  resize_mode: str = 'nearest',
                  mode: Union[None, str, Iterable[str]] = None,
                  ds_id: Union[None, str, Iterable[str]] = None):
 
-        super().__init__(inputs=to_list(inputs), outputs=to_list(outputs), mode=mode)
+        super().__init__(inputs=to_list(inputs), outputs=to_list(outputs), mode=mode, ds_id=ds_id)
         assert resize_mode in ['nearest', 'area'], "Only following resize modes are supported: 'nearest', 'area' "
+        if len(output_shape) != 3:
+            raise ValueError("The output shape is expected to be (H, W, D) excluding batch size and channels.")
         self.output_shape = output_shape
-        self.reize_mode = resize_mode
+        self.resize_mode = resize_mode
 
     def forward(self, data: List[Tensor], state: Dict[str, Any]) -> Union[Tensor, List[Tensor]]:
         return [resize_3d(elem, self.output_shape, self.resize_mode) for elem in data]
```

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/tensorop.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/tensorop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/op/tensorop/un_hadamard.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/un_hadamard.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/pipeline.py` & `fastestimator-1.6.0/fastestimator/pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -16,34 +16,35 @@
 import gc
 import multiprocessing as mp
 import os
 import time
 from copy import deepcopy
 from operator import mul
 from threading import Lock
-from typing import Any, Dict, List, Optional, Set, Tuple, Type, TypeVar, Union
+from typing import Any, Dict, Iterable, List, Literal, Optional, Set, Tuple, Type, TypeVar, Union, cast, overload
 
 import numpy as np
 import tensorflow as tf
 from torch.utils.data import DataLoader, Dataset
+from typing_extensions import Self
 
 from fastestimator.backend._to_tensor import to_tensor
 from fastestimator.dataset.dataloader import FEDataLoader
-from fastestimator.dataset.op_dataset import OpDataset, _DelayedDeepDict
+from fastestimator.dataset.interleave_dataset import InterleaveDataset
+from fastestimator.dataset.op_dataset import OpDataset
 from fastestimator.op.numpyop.meta.fuse import Fuse
 from fastestimator.op.numpyop.meta.one_of import OneOf
 from fastestimator.op.numpyop.meta.repeat import Repeat
 from fastestimator.op.numpyop.meta.sometimes import Sometimes
-from fastestimator.op.numpyop.numpyop import NumpyOp, forward_numpyop, Batch
-from fastestimator.schedule.schedule import Scheduler, get_current_items, EpochScheduler, \
-    RepeatScheduler
-from fastestimator.util.data import FilteredData
+from fastestimator.op.numpyop.numpyop import Batch, NumpyOp, forward_numpyop
+from fastestimator.schedule.schedule import EpochScheduler, RepeatScheduler, Scheduler, get_current_items
+from fastestimator.types import FilteredData
+from fastestimator.util.base_util import filter_nones, to_list, to_set, warn
 from fastestimator.util.traceability_util import traceable
 from fastestimator.util.util import cpu_count, get_num_devices
-from fastestimator.util.base_util import to_set, to_list
 
 DataSource = TypeVar('DataSource', Dataset, DataLoader, tf.data.Dataset)
 
 
 @traceable(blacklist=('ctx_loader', 'ctx_lock'))
 class Pipeline:
     """A data pipeline class that takes care of data pre-processing.
@@ -51,43 +52,53 @@
     Args:
         train_data: The training data, or None if no training data is available.
         eval_data: The evaluation data, or None if no evaluation data is available.
         test_data: The testing data, or None if no evaluation data is available.
         batch_size: The batch size to be used by the pipeline. If the batch_size is also set by a Batch Op, that value
             will take precedence over this one (for example, if you want to set the batch_size based on mode or ds_is).
             NOTE: This argument is only applicable when using a FastEstimator Dataset.
+            NOTE: This is the global batch size regardless of the number of GPUs available in the machine. If you have
+                multiple (N) GPUs, each will receive batch_size/N elements during a training step.
         ops: NumpyOps to be used for pre-processing. NOTE: This argument is only applicable when using a FastEstimator
             Dataset.
         num_process: Number of CPU threads to use for data pre-processing. NOTE: This argument is only applicable when
             using a FastEstimator Dataset. None will default to min(n_cpus, max(32, 32*n_gpus)). Multiprocessing can be
             disabled by passing 0 here, which can be useful for debugging.
     """
+    mp_warned: bool = False
     ops: List[Union[NumpyOp, Scheduler[NumpyOp]]]
-    data: Dict[str, Dict[Optional[str], Union[DataSource, Scheduler[DataSource]]]]  # {"mode": {"ds_id": ds}}
+    data: Dict[str, Dict[str, Union[DataSource, Scheduler[DataSource]]]]  # {"mode": {"ds_id": ds}}
 
     def __init__(self,
                  train_data: Union[None,
                                    DataSource,
                                    Scheduler[DataSource],
-                                   Dict[str, Union[DataSource, Scheduler[DataSource]]]] = None,
-                 eval_data: Union[None, DataSource, Scheduler[DataSource], Dict[str, DataSource]] = None,
-                 test_data: Union[None, DataSource, Scheduler[DataSource], Dict[str, DataSource]] = None,
+                                   Dict[str, Union[None, DataSource, Scheduler[DataSource]]]] = None,
+                 eval_data: Union[None,
+                                  DataSource,
+                                  Scheduler[DataSource],
+                                  Dict[str, Union[None, DataSource, Scheduler[DataSource]]]] = None,
+                 test_data: Union[None,
+                                  DataSource,
+                                  Scheduler[DataSource],
+                                  Dict[str, Union[None, DataSource, Scheduler[DataSource]]]] = None,
                  batch_size: Union[None, int, Scheduler[int]] = None,
-                 ops: Union[None, NumpyOp, Scheduler[NumpyOp], List[Union[NumpyOp, Scheduler[NumpyOp]]]] = None,
+                 ops: Union[None, NumpyOp, Scheduler[NumpyOp], List[Union[None, NumpyOp, Scheduler[NumpyOp]]]] = None,
                  num_process: Optional[int] = None):
         data = {x: y for (x, y) in zip(["train", "eval", "test"], [train_data, eval_data, test_data]) if y}
         self.data = self._register_ds_ids(data)
         self.batch_size = batch_size
-        self.ops = to_list(ops)
+        self.ops = filter_nones(to_list(ops))
         if mp.get_start_method(allow_none=True) is None and os.name != 'nt':
             mp.set_start_method('fork')
-        if mp.get_start_method(allow_none=True) != 'fork':
-            print("FastEstimator-Warn: Pipeline multiprocessing is disabled. OS must support the 'fork' start method.")
-            num_process = 0
         self.num_process = num_process if num_process is not None else min(cpu_count(), 32 * get_num_devices())
+        if mp.get_start_method(allow_none=True) != 'fork' and self.num_process > 0 and not self.mp_warned:
+            warn("Pipeline multiprocessing is disabled. OS must support the 'fork' start method.")
+            self.num_process = 0
+            self.mp_warned = True
         self._verify_inputs(**{k: v for k, v in locals().items() if k != 'self'})
         # Loader Variables
         self.ctx_lock = Lock()
         self.ctx_mode = 'train'
         self.ctx_epoch = 1
         self.ctx_shuffle = True
         self.ctx_output_keys = None
@@ -97,50 +108,51 @@
         self.ctx_ops = []
         self.ctx_batch_info = Batch()
         self.ctx_batch_ops = []
         self.ctx_batch_input_keys = set()
 
     @staticmethod
     def _register_ds_ids(
-            data: Dict[
-                str, Union[DataSource, Scheduler[DataSource], Dict[str, Union[DataSource, Scheduler[DataSource]]]]]
-    ) -> Dict[str, Dict[Optional[str], Union[DataSource, Scheduler[DataSource]]]]:
+        data: Dict[str,
+                   Union[DataSource, Scheduler[DataSource], Dict[str, Union[None, DataSource, Scheduler[DataSource]]]]]
+    ) -> Dict[str, Dict[str, Union[DataSource, Scheduler[DataSource]]]]:
         """Associate dataset of each mode with a `ds_id`.
 
         Args:
             data: A dictionary with mode as key, dataset as value.
         """
         forbidden_ds_id_chars = {":", "!", ";", "|"}
         for mode, dataset in data.items():
             if isinstance(dataset, dict):
                 for ds_name in dataset:
                     assert isinstance(ds_name, str) and len(ds_name) > 0, \
                         "dataset id must be a string, found {}".format(ds_name)
                     assert not any(char in ds_name for char in forbidden_ds_id_chars), \
                         "dataset id should not contain forbidden characters like ':', ';', '!', '|', " + \
                         "found {} in pipeline".format(ds_name)
+                data[mode] = filter_nones(dataset)
             else:
                 # Empty string is special, matches against ops which require '!ds1' but not 'ds1'
                 data[mode] = {"": dataset}
-        return data
+        return cast(Dict[str, Dict[str, Union[DataSource, Scheduler[DataSource]]]], data)
 
     def _verify_inputs(self, **kwargs) -> None:
         """A helper method to ensure that the Pipeline inputs are valid.
 
         Args:
             **kwargs: A collection of variable / value pairs to validate.
 
         Raises:
             AssertionError: If `batch_size`, `ops`, or `num_process` were specified in the absence of a FastEstimator
                 Dataset.
         """
         fe_dataset = False
         for dataset in get_current_items(set(d for ds in self.data.values() for d in ds.values())):
             fe_dataset = self._verify_dataset(dataset, **kwargs) or fe_dataset
-        if not fe_dataset:
+        if self.data and not fe_dataset:  # If the user provided no datasets at all, still let them use ops for infer
             assert kwargs['batch_size'] is None, "Pipeline only supports batch_size with built-in (FE) datasets"
             assert kwargs['ops'] is None, "Pipeline only supports ops with built-in (FE) datasets"
             assert kwargs['num_process'] is None, "Pipeline only support num_process with built-in (FE) datasets"
         # Make sure that the user provides at most 1 Batch Op for a given epoch/mode/ds_id
         batch_ops = []
         schedule_epochs = {1}
         schedule_cycles = set()
@@ -160,17 +172,20 @@
                         else:
                             # Some unknown scheduler, no known shortcuts so just try first 100 epochs to be safe
                             schedule_epochs |= {*range(1, 100)}
                         break
         # After m*n steps all possible m and n combinations will be visited
         schedule_cycles = functools.reduce(mul, schedule_cycles, 1)
         # Consider x + m*n epochs for each epoch scheduler x value
-        schedule_epochs = sorted({epoch for base_epoch in schedule_epochs for epoch in
-                                  list(range(base_epoch, base_epoch + schedule_cycles))})
-        for mode, id_ds in self.data.items():
+        schedule_epochs = sorted({
+            epoch
+            for base_epoch in schedule_epochs
+            for epoch in list(range(base_epoch, base_epoch + schedule_cycles))
+        })
+        for mode, id_ds in list(self.data.items()) + [('infer', {'': None})]:
             for ds_id in id_ds.keys():
                 for epoch in schedule_epochs:
                     ops = get_current_items(batch_ops, run_modes=mode, epoch=epoch, ds_id=ds_id)
                     # We have to do an instance check again since the user could technically use a scheduler that has a
                     # Batch Op at one point, but some other Op (or None) at a different point
                     ops = [op for op in ops if isinstance(op, Batch)]
                     assert len(ops) < 2, "You may provide at most 1 batch op for a given epoch/mode/ds_id combination"
@@ -197,30 +212,31 @@
             for op in get_current_items(self.ops):
                 assert isinstance(op, NumpyOp), "unsupported op format, must provide NumpyOp in Pipeline"
             # num_process check
             assert isinstance(self.num_process, int), "number of processes must be an integer"
             return True
         elif isinstance(dataset, (DataLoader, tf.data.Dataset)):
             if kwargs['batch_size'] is not None:
-                print("FastEstimator-Warn: batch_size will only be used for built-in dataset")
+                warn("batch_size will only be used for built-in dataset")
             if kwargs['ops'] is not None:
-                print("FastEstimator-Warn: ops will only be used for built-in dataset")
+                warn("ops will only be used for built-in dataset")
             if kwargs['num_process'] is not None:
-                print("FastEstimator-Warn: num_process will only be used for built-in dataset")
+                warn("num_process will only be used for built-in dataset")
             return False
         else:
             raise ValueError("Unsupported dataset type: {}".format(type(dataset)))
 
-    def _get_op_split(self, mode: str, epoch: int, ds_id: str) -> Tuple[List[NumpyOp], Batch, List[NumpyOp]]:
+    def _get_op_split(self, mode: str, epoch: int,
+                      ds_id: Union[str, Iterable[str]]) -> Tuple[List[NumpyOp], Batch, List[NumpyOp]]:
         """Figure out which ops are pre-batch vs post-batch.
 
         Args:
             mode: The current mode.
             epoch: The current epoch.
-            ds_id: The current dataset.
+            ds_id: The current dataset id(s).
 
         Returns:
             (instance ops, batch info, batch ops).
         """
         batch_info = Batch()
         instance_ops = []
         batch_ops = []
@@ -251,15 +267,15 @@
                 for dataset in datasets.values():
                     if isinstance(dataset, Scheduler):
                         dataset = dataset.get_current_value(epoch)
                     if dataset:
                         all_modes.append(mode)
         return to_set(all_modes)
 
-    def get_ds_ids(self, epoch: int, mode: str) -> List[Union[str, None]]:
+    def get_ds_ids(self, epoch: int, mode: str) -> List[str]:
         """Get the ds_ids for a given epoch and mode.
 
         Args:
             epoch: The current epoch index.
             mode: The current execution mode.
 
         Returns:
@@ -406,18 +422,20 @@
                                             ", ".join([sub_op.__class__.__name__ for sub_op in op.ops]) + ")")
                         elif isinstance(op, Batch):
                             op_names.append("<Collating Batch>")
                         else:
                             op_names.append(op.__class__.__name__)
 
                     max_op_len = max(len(op_name) for op_name in op_names)
-                    max_in_len = max([len(", ".join(op.inputs)) for op in
-                                      self.ctx_ops + [self.ctx_batch_info] + self.ctx_batch_ops] + [len("Inputs")])
-                    max_out_len = max([len(", ".join(op.outputs)) for op in
-                                       self.ctx_ops + [self.ctx_batch_info] + self.ctx_batch_ops] + [len("Outputs")])
+                    max_in_len = max(
+                        [len(", ".join(op.inputs))
+                         for op in self.ctx_ops + [self.ctx_batch_info] + self.ctx_batch_ops] + [len("Inputs")])
+                    max_out_len = max([
+                        len(", ".join(op.outputs)) for op in self.ctx_ops + [self.ctx_batch_info] + self.ctx_batch_ops
+                    ] + [len("Outputs")])
                     ms_visit_len = max(len("{:.3f}".format(max(normalized_times_ms))), len("ms / Visit"))
                     visit_len = max(len(f"{int(np.max(duration_list[:, 0]))}"), len("Visits"))
 
                     print("{}: {}: {}: {}: {}: {}".format("Op".ljust(max_op_len + 1),
                                                           "Inputs".ljust(max_in_len + 1),
                                                           "Outputs".ljust(max_out_len + 1),
                                                           "ms / Visit".ljust(ms_visit_len + 1),
@@ -429,16 +447,18 @@
                             op_names[i + 1].ljust(max_op_len + 1),
                             ", ".join(op.inputs).ljust(max_in_len + 1),
                             ", ".join(op.outputs).ljust(max_out_len + 1),
                             "{:.3f}".format(normalized_times_ms[i]).ljust(ms_visit_len + 1),
                             str(int(duration_list[i][0])).ljust(visit_len + 1),
                             100 * duration_list[i][1] / total_time))
                     if self.ctx_batch_ops:
-                        penalty = round(100*(duration_list[len(self.ctx_ops)][1] - extra_memory_management_time) /
-                                        duration_list[len(self.ctx_ops)][1], 1)
+                        penalty = round(
+                            100 * (duration_list[len(self.ctx_ops)][1] - extra_memory_management_time) /
+                            duration_list[len(self.ctx_ops)][1],
+                            1)
                         print(f"\nNote that collation time would be cut by ~{penalty}% if there were no batched ops.")
                 print("\n")  # to make printing more obvious
 
     def get_scheduled_items(self, mode: str) -> List[Any]:
         """Get a list of items considered for scheduling.
 
         Args:
@@ -469,19 +489,15 @@
                 epochs_with_data = epochs_with_data | epochs_with_data_ds
             elif dataset:
                 epochs_with_data_ds = set(range(1, total_epochs + 1))
                 epochs_with_data = epochs_with_data | epochs_with_data_ds
                 break
         return epochs_with_data
 
-    def transform(self,
-                  data: Dict[str, Any],
-                  mode: str,
-                  epoch: int = 1,
-                  ds_id: str = '',
+    def transform(self, data: Dict[str, Any], mode: str, epoch: int = 1, ds_id: str = '',
                   target_type: str = 'np') -> Union[Dict[str, Any], FilteredData]:
         """Apply all pipeline operations on a given data instance for the specified `mode` and `epoch`.
 
         Args:
             data: Input data in dictionary format.
             mode: The execution mode in which to run. This can be "train", "eval", "test" or "infer".
             epoch: The epoch index to run. Note that epoch indices are 1-indexed.
@@ -499,14 +515,32 @@
             return op_data
         data = batch_spec.collate_fn([data])
         op_data = forward_numpyop(batch_ops, data, state, batched='torch')
         if isinstance(op_data, FilteredData):
             return op_data
         return to_tensor(data, target_type=target_type)
 
+    @overload
+    def get_results(self,
+                    mode: str = "train",
+                    epoch: int = 1,
+                    ds_id: str = '',
+                    num_steps: Literal[1] = 1,
+                    shuffle: bool = False) -> Dict[str, Any]:
+        ...
+
+    @overload
+    def get_results(self,
+                    mode: str = "train",
+                    epoch: int = 1,
+                    ds_id: str = '',
+                    num_steps: int = 1,
+                    shuffle: bool = False) -> List[Dict[str, Any]]:
+        ...
+
     def get_results(self,
                     mode: str = "train",
                     epoch: int = 1,
                     ds_id: str = '',
                     num_steps: int = 1,
                     shuffle: bool = False) -> Union[List[Dict[str, Any]], Dict[str, Any]]:
         """Get sample Pipeline outputs.
@@ -536,15 +570,15 @@
 
     def __call__(self,
                  mode: str,
                  epoch: int = 1,
                  ds_id: str = '',
                  shuffle: Optional[bool] = None,
                  steps_per_epoch: Optional[int] = None,
-                 output_keys: Optional[Set[str]] = None) -> 'Pipeline':
+                 output_keys: Optional[Set[str]] = None) -> Self:
         """Prepare this Pipeline for a given `mode` and `epoch`.
 
         A given pipeline can only provide one loader at a time. This helps to prevent issues with multi-threading.
 
         ```python
         pipe = Pipeline(...)
         with pipe(mode='eval', epoch=2) as loader:
@@ -574,29 +608,72 @@
             raise ValueError("You cannot invoke a Pipeline's __call__ method while it already has an active loader.")
         self.ctx_mode = mode
         self.ctx_epoch = epoch
         self.ctx_ds_id = ds_id
         self.ctx_shuffle = mode == 'train' if shuffle is None else shuffle
         self.ctx_steps_per_epoch = steps_per_epoch
         self.ctx_output_keys = output_keys or set()
-        self.ctx_ops, self.ctx_batch_info, self.ctx_batch_ops = self._get_op_split(mode=mode, epoch=epoch, ds_id=ds_id)
+        dataset = self.data[self.ctx_mode][self.ctx_ds_id]
+        if isinstance(dataset, Scheduler):
+            dataset = dataset.get_current_value(self.ctx_epoch)
+        self.ctx_dataset = dataset
+        if isinstance(dataset, InterleaveDataset):
+            # if this is InterleaveDataset, then build multiple ops, batch_info, and batch_ops.
+            self.ctx_ops = []
+            ctx_batch_infos: List[Batch] = []
+            ctx_batch_ops_lists: List[List[NumpyOp]] = []
+            for tag in dataset.tags:
+                id_tags = {ds_id, tag} if isinstance(tag, str) else ds_id
+                ctx_ops, ctx_batch_info, ctx_batch_ops = self._get_op_split(mode=mode, epoch=epoch, ds_id=id_tags)
+                self.ctx_ops.append(ctx_ops)
+                ctx_batch_infos.append(ctx_batch_info)
+                ctx_batch_ops_lists.append(ctx_batch_ops)
+            # Decide on the batch size (this might still be ignored later if the user is using a BatchDataset)
+            self.ctx_batch_size = [ctx_batch_info.batch_size for ctx_batch_info in ctx_batch_infos]
+            # drop_last and collate_fn for different dataset must be the same, since it is the same dataloader.
+            same_drop_last = len(set(ctx_batch_info.drop_last for ctx_batch_info in ctx_batch_infos)) == 1
+            same_collate = len(set(ctx_batch_info.collate_fn for ctx_batch_info in ctx_batch_infos)) == 1
+            if not same_collate:
+                pad_val_0 = ctx_batch_infos[0]._pad_value
+                if pad_val_0 is not None and all([pad_val_0 == pv._pad_value for pv in ctx_batch_infos[1:]]):
+                    # If the user is using pad values and all the pad values are the same, then even though the
+                    # collate functions are bound to different instances, they are all effectively the same function
+                    same_collate = True
+            assert same_drop_last and same_collate, \
+                "when using InterleaveDataset, the drop_last and collate behavior for all datasets must be the same"
+            # Interleave dataset at current scope does not support batch level, need to make sure batchops are the same
+            assert all(ctx_batch_ops_lists[0] == batch_ops for batch_ops in ctx_batch_ops_lists[1:]), \
+                "Current InterleaveDataset does not support different dataset behaviors after the BatchOp."
+            self.ctx_batch_ops = ctx_batch_ops_lists[0]
+            self.ctx_batch_info = ctx_batch_infos[0]
+            # fill in the correct batch sizes
+            for idx, batch_size in enumerate(self.ctx_batch_size):
+                if batch_size is None:
+                    batch_size = self.batch_size
+                    if isinstance(batch_size, Scheduler):
+                        batch_size = batch_size.get_current_value(self.ctx_epoch)
+                    self.ctx_batch_size[idx] = batch_size
+        else:
+            self.ctx_ops, self.ctx_batch_info, self.ctx_batch_ops = self._get_op_split(mode=mode,
+                                                                                       epoch=epoch,
+                                                                                       ds_id=ds_id)
+            # Decide on the batch size (this might still be ignored later if the user is using a BatchDataset)
+            self.ctx_batch_size = self.ctx_batch_info.batch_size
+            if self.ctx_batch_size is None:
+                # batch size
+                batch_size = self.batch_size
+                if isinstance(batch_size, Scheduler):
+                    batch_size = batch_size.get_current_value(self.ctx_epoch)
+                self.ctx_batch_size = batch_size
         # Figure out which input keys are required by the batch ops (so they don't get pruned too early)
         self.ctx_batch_input_keys = set()
         batch_produced_keys = set()
         for op in get_current_items(self.ctx_batch_ops, mode, epoch, ds_id=ds_id):
             self.ctx_batch_input_keys.update(set(key for key in op.inputs if key not in batch_produced_keys))
             batch_produced_keys.update(op.outputs)
-        # Decide on the batch size (this might still be ignored later if the user is using a BatchDataset)
-        self.ctx_batch_size = self.ctx_batch_info.batch_size
-        if self.ctx_batch_size is None:
-            # batch size
-            batch_size = self.batch_size
-            if isinstance(batch_size, Scheduler):
-                batch_size = batch_size.get_current_value(self.ctx_epoch)
-            self.ctx_batch_size = batch_size
         self.ctx_lock.release()
         return self
 
     def __enter__(self) -> Union[DataLoader, tf.data.Dataset]:
         """Get a data loader from the Pipeline for the current epoch and mode.
 
         A given pipeline can only provide one loader at a time. This helps to prevent issues with multi-threading.
@@ -620,20 +697,49 @@
         # Release the lock if arguments are invalid so that people in Jupyter / debug consoles don't get stuck
         if self.ctx_mode not in self.data:
             self.ctx_lock.release()
             raise KeyError(f"Pipeline has no data for mode '{self.ctx_mode}'")
         if self.ctx_ds_id not in self.data[self.ctx_mode]:
             self.ctx_lock.release()
             raise KeyError(f"The dataset id '{self.ctx_ds_id}' is not present in {self.ctx_mode} mode")
-        data = self.data[self.ctx_mode][self.ctx_ds_id]
-        if isinstance(data, Scheduler):
-            data = data.get_current_value(self.ctx_epoch)
-        if isinstance(data, Dataset):
+        if isinstance(self.ctx_dataset, InterleaveDataset):
+            # Results will be immediately converted to tensors, so don't need deep_remainder
+            op_datasets = [
+                OpDataset(ds,
+                          ctx_ops,
+                          self.ctx_mode,
+                          self.ctx_output_keys | self.ctx_batch_input_keys if self.ctx_output_keys else None,
+                          deep_remainder=False) for ds,
+                ctx_ops in zip(self.ctx_dataset.datasets, self.ctx_ops)
+            ]
+            self.ctx_dataset.op_datasets = op_datasets
+            # when batch_size is None, then it indicates each sample is a batch
+            self.ctx_dataset.set_batch_sizes([batch_size or 1 for batch_size in self.ctx_batch_size])
+            postprocess_fn = None
+            if self.ctx_batch_ops:
+                postprocess_fn = functools.partial(_batch_postprocess,
+                                                   ops=self.ctx_batch_ops,
+                                                   output_keys=self.ctx_output_keys,
+                                                   mode=self.ctx_mode)
+            try:
+                data = FEDataLoader(self.ctx_dataset,
+                                    postprocess_fn=postprocess_fn,
+                                    batch_size=None,
+                                    shuffle=self.ctx_shuffle,
+                                    steps_per_epoch=self.ctx_steps_per_epoch,
+                                    num_workers=self.num_process,
+                                    drop_last=self.ctx_batch_info.drop_last,
+                                    collate_fn=self.ctx_batch_info.collate_fn)
+            except ValueError as err:
+                self.ctx_lock.release()
+                raise err
+            self.ctx_loader = data
+        elif isinstance(self.ctx_dataset, Dataset):
             # Results will be immediately converted to tensors, so don't need deep_remainder
-            op_dataset = OpDataset(data,
+            op_dataset = OpDataset(self.ctx_dataset,
                                    self.ctx_ops,
                                    self.ctx_mode,
                                    self.ctx_output_keys | self.ctx_batch_input_keys if self.ctx_output_keys else None,
                                    deep_remainder=False)
             # check whether to batch the data
             batch_size = None if op_dataset.fe_batch else self.ctx_batch_size
             # Figure out whether a postprocessing function is needed (for batched ops)
@@ -652,32 +758,32 @@
                                     num_workers=self.num_process,
                                     drop_last=self.ctx_batch_info.drop_last,
                                     collate_fn=self.ctx_batch_info.collate_fn)
             except ValueError as err:
                 self.ctx_lock.release()
                 raise err
             self.ctx_loader = data
-        return data
+        else:
+            self.ctx_loader = self.ctx_dataset
+        return self.ctx_loader
 
     def __exit__(self, *exc: Tuple[Optional[Type], Optional[Exception], Optional[Any]]) -> None:
-        if self.ctx_loader is not None:
+        if self.ctx_loader is not None and hasattr(self.ctx_loader, 'shutdown'):
             self.ctx_loader.shutdown()
             self.ctx_loader = None
         # Manually triggering gc here seems to be necessary in order to avoid problems with repeated invocations of FE
         # killing one another through multi-processing.
         gc.collect()
         self.ctx_lock.release()
 
 
-def _batch_postprocess(data: Dict[str, Any], ops: List[NumpyOp], output_keys: Set[str], mode: str) -> \
+def _batch_postprocess(data: Dict[str, Any], ops: List[NumpyOp], output_keys: Set[str], mode: str, shared: bool = True) -> \
         Union[Dict[str, Any], FilteredData]:
-    op_data = forward_numpyop(ops=ops, data=data, state={'mode': mode}, batched='torch')
+    op_data = forward_numpyop(ops=ops, data=data, state={'mode': mode}, batched='torch', shared=shared)
     if isinstance(op_data, FilteredData):
         return op_data
     if output_keys:
-        for key in data.keys() - output_keys:
-            if key not in _DelayedDeepDict.warned:
-                _DelayedDeepDict.warned.add(key)
-                print("FastEstimator-Warn: the key '{}' is being pruned since it is unused outside of the Pipeline."
-                      " To prevent this, you can declare the key as an input of a Trace or TensorOp.".format(key))
+        unused_keys = data.keys() - output_keys
+        OpDataset.handle_warning(unused_keys)
+        for key in unused_keys:
             data.pop(key)
     return data
```

### Comparing `fastestimator-1.5.2/fastestimator/schedule/__init__.py` & `fastestimator-1.6.0/fastestimator/schedule/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,16 +14,16 @@
 # ==============================================================================
 from typing import TYPE_CHECKING
 
 import lazy_loader as lazy
 
 __getattr__, __dir__, __all__ = lazy.attach(__name__,
                                             submod_attrs={
-                                                'lr_shedule': ['ARC', 'cosine_decay'],
+                                                'lr_schedule': ['ARC', 'cosine_decay'],
                                                 'schedule': ['EpochScheduler', 'RepeatScheduler', 'Scheduler',
                                                              'get_current_items', 'get_signature_epochs'],
                                             })
 
 if TYPE_CHECKING:
-    from fastestimator.schedule.lr_shedule import ARC, cosine_decay
+    from fastestimator.schedule.lr_schedule import ARC, cosine_decay
     from fastestimator.schedule.schedule import EpochScheduler, RepeatScheduler, Scheduler, get_current_items, \
         get_signature_epochs
```

### Comparing `fastestimator-1.5.2/fastestimator/schedule/lr_shedule.py` & `fastestimator-1.6.0/fastestimator/schedule/lr_schedule.py`

 * *Files 1% similar despite different names*

```diff
@@ -28,15 +28,16 @@
 
 
 def cosine_decay(time: int,
                  cycle_length: int,
                  init_lr: float,
                  min_lr: float = 1e-6,
                  start: int = 1,
-                 cycle_multiplier: int = 1):
+                 cycle_multiplier: int = 1,
+                 warmup: bool = False):
     """Learning rate cosine decay function (using half of cosine curve).
 
     This method is useful for scheduling learning rates which oscillate over time:
     ```python
     s = fe.schedule.LRScheduler(model=model, lr_fn=lambda step: cosine_decay(step, cycle_length=3750, init_lr=1e-3))
     fe.Estimator(..., traces=[s])
     ```
@@ -46,20 +47,24 @@
     Args:
         time: The current step or epoch during training starting from 1.
         cycle_length: The decay cycle length.
         init_lr: Initial learning rate to decay from.
         min_lr: Minimum learning rate.
         start: The step or epoch to start the decay schedule.
         cycle_multiplier: The factor by which next cycle length will be multiplied.
+        warmup: Whether to do a linear warmup from 0 up until `start'.
 
     Returns:
         lr: learning rate given current step or epoch.
     """
     if time < start:
-        lr = init_lr
+        if warmup:
+            lr = init_lr * time / start
+        else:
+            lr = init_lr
     else:
         time = time - start + 1
         if cycle_multiplier > 1:
             current_cycle_idx = math.ceil(
                 math.log(time * (cycle_multiplier - 1) / cycle_length + 1) / math.log(cycle_multiplier)) - 1
             cumulative = cycle_length * (cycle_multiplier**current_cycle_idx - 1) / (cycle_multiplier - 1)
         elif cycle_multiplier == 1:
```

### Comparing `fastestimator-1.5.2/fastestimator/schedule/schedule.py` & `fastestimator-1.6.0/fastestimator/schedule/schedule.py`

 * *Files 11% similar despite different names*

```diff
@@ -8,20 +8,21 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Any, Dict, Generic, Iterable, List, Optional, TypeVar, Union
+from typing import Any, Dict, Generic, Iterable, List, Optional, TypeVar, Union, overload
 
-from fastestimator.util.traceability_util import is_restorable, traceable
 from fastestimator.util.base_util import to_set
+from fastestimator.util.traceability_util import is_restorable, traceable
 
 T = TypeVar('T')
+T2 = TypeVar('T2')
 
 
 @traceable()
 class Scheduler(Generic[T]):
     """A class which can wrap things like Datasets and Ops to make their behavior epoch-dependent.
     """
     def get_current_value(self, epoch: int) -> Optional[T]:
@@ -181,34 +182,59 @@
         epoch_config = get_current_items(items, run_modes=mode, epoch=epoch, ds_id=ds_id)
         if epoch_config not in unique_configs:
             unique_configs.append(epoch_config)
             signature_epochs.append(epoch)
     return signature_epochs
 
 
+@overload
+def get_current_items(items: Iterable[Union[T, Scheduler[T], T2, Scheduler[T2]]],
+                      run_modes: Optional[Union[str, Iterable[str]]] = None,
+                      epoch: Optional[int] = None,
+                      ds_id: Optional[str] = None) -> List[Union[T, T2]]:
+    ...
+
+
+@overload
 def get_current_items(items: Iterable[Union[T, Scheduler[T]]],
                       run_modes: Optional[Union[str, Iterable[str]]] = None,
                       epoch: Optional[int] = None,
-                      ds_id: Optional[str] = None) -> List[T]:
-    """Select items which should be executed for given mode and epoch.
+                      ds_id: Optional[Union[str, Iterable[str]]] = None) -> List[T]:
+    ...
+
+
+@overload
+def get_current_items(items: Iterable[Union[T, T2, Scheduler[T], Scheduler[T2]]],
+                      run_modes: Optional[Union[str, Iterable[str]]] = None,
+                      epoch: Optional[int] = None,
+                      ds_id: Optional[Union[str, Iterable[str]]] = None) -> List[Union[T, T2]]:
+    ...
+
+
+def get_current_items(items: Iterable[Union[Any, Scheduler[Any]]],
+                      run_modes: Optional[Union[str, Iterable[str]]] = None,
+                      epoch: Optional[int] = None,
+                      ds_id: Optional[Union[str, Iterable[str]]] = None) -> List[Any]:
+    """Select items which should be executed for given mode, epoch, and ds_id.
 
     Args:
         items: A list of possible items or Schedulers of items to choose from.
         run_modes: The desired execution mode. One or more of "train", "eval", "test", or "infer". If None, items of
             all modes will be returned.
         epoch: The desired execution epoch. If None, items across all epochs will be returned.
-        ds_id: The desired execution dataset id. If None, items across all ds_ids will be returned. An empty string
-            indicates that positive matches should be excluded ('' != 'ds1'), but that negative matches are satisfied
-            ('' == '!ds1').
+        ds_id: The desired one or more execution dataset id(s). If None, items across all ds_ids will be returned. An
+            empty string indicates that positive matches should be excluded ('' != 'ds1'), but that negative matches are
+            satisfied ('' == '!ds1').
 
     Returns:
         The items which should be executed.
     """
     selected_items = []
     run_modes = to_set(run_modes)
+    ds_id = to_set(ds_id)
     for item in items:
         if isinstance(item, Scheduler):
             if epoch is None:
                 item = item.get_all_values()
             else:
                 item = [item.get_current_value(epoch)]
         else:
@@ -224,25 +250,25 @@
                 if not item_.mode:
                     mode_match = True
                 elif item_.mode.intersection(run_modes):
                     mode_match = True
 
             # ds_id matching
             ds_id_match = False
-            if ds_id is None:
+            if not ds_id:
                 ds_id_match = True
             if not hasattr(item_, "ds_id"):
                 ds_id_match = True
             else:
                 # If the object has no requirements, then allow it
                 if not item_.ds_id:
                     ds_id_match = True
                 # blacklist check (before whitelist due to desired empty string behavior)
                 # if any of ds_id starts with "!", then they will all start with "!"
-                elif any([x.startswith("!") for x in item_.ds_id]) and all([ds_id != x[1:] for x in item_.ds_id]):
+                elif any([x.startswith("!") for x in item_.ds_id]) and all([x[1:] not in ds_id for x in item_.ds_id]):
                     ds_id_match = True  # Note that empty string will pass this check (unless target is literally "!")
                 # whitelist check
-                elif ds_id in item_.ds_id:
+                elif item_.ds_id.intersection(ds_id):
                     ds_id_match = True  # Note that empty string will fail this check
             if item_ and mode_match and ds_id_match:
                 selected_items.append(item_)
     return selected_items
```

### Comparing `fastestimator-1.5.2/fastestimator/search/__init__.py` & `fastestimator-1.6.0/fastestimator/search/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/search/golden_section.py` & `fastestimator-1.6.0/fastestimator/search/golden_section.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/search/grid_search.py` & `fastestimator-1.6.0/fastestimator/search/grid_search.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/search/search.py` & `fastestimator-1.6.0/fastestimator/search/search.py`

 * *Files 5% similar despite different names*

```diff
@@ -172,14 +172,15 @@
             self.__dict__.update(state)
             # restore evaluation cache and search_idx
             for summary in self.search_summary:
                 kwargs = summary['param'].copy()
                 search_idx = kwargs.pop('search_idx')  # This won't appear in the hash later
                 self.search_idx = self.search_idx if self.search_idx > search_idx else search_idx
                 # Each python session uses a unique salt for hash, so can't save the hashes to disk for re-use
+                self._make_hashable(kwargs)
                 self.evaluation_cache[hash(tuple(sorted(kwargs.items())))] = summary['result']
             print("FastEstimator-Search: Loading the search state from {}".format(file_path))
         elif not not_exist_ok:
             raise ValueError("cannot find file to load in {}".format(file_path))
 
     def fit(self, save_dir: str = None) -> None:
         """Start the search.
@@ -195,7 +196,12 @@
             self.save_dir = save_dir
             os.makedirs(save_dir, exist_ok=True)
             self.load(save_dir, not_exist_ok=True)
         self._fit()
 
     def _fit(self) -> None:
         raise NotImplementedError
+
+    def _make_hashable(self, kwargs):
+        for key in kwargs:
+            if isinstance(kwargs[key], list):
+                kwargs[key] = tuple(kwargs[key])
```

### Comparing `fastestimator-1.5.2/fastestimator/search/visualize/__init__.py` & `fastestimator-1.6.0/fastestimator/search/visualize/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/search/visualize/cartesian.py` & `fastestimator-1.6.0/fastestimator/search/visualize/cartesian.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/search/visualize/heatmap.py` & `fastestimator-1.6.0/fastestimator/search/visualize/heatmap.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/search/visualize/parallel_coordinate_plot.py` & `fastestimator-1.6.0/fastestimator/search/visualize/parallel_coordinate_plot.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/search/visualize/vis_util.py` & `fastestimator-1.6.0/fastestimator/search/visualize/vis_util.py`

 * *Files 2% similar despite different names*

```diff
@@ -56,14 +56,17 @@
         self.results = set(example_item['result'].keys())
 
         ignore_keys = to_set(ignore_keys) | {'search_idx'}
         for key in ignore_keys:
             self.params.discard(key)
             self.results.discard(key)
 
+        # Check if any results left to use
+        assert len(self.results) != 0, f"No results found after ignoring keys: {ignore_keys}"
+
         # Keep a sample parameter value to catch boring parameters
         param_samples = {}
 
         for elem in search:
             pars = elem['param']
             for k, v in pars.items():
                 if k in ignore_keys:
```

### Comparing `fastestimator-1.5.2/fastestimator/search/visualize/visualize.py` & `fastestimator-1.6.0/fastestimator/search/visualize/visualize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/summary/__init__.py` & `fastestimator-1.6.0/fastestimator/summary/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/summary/history.py` & `fastestimator-1.6.0/fastestimator/summary/history.py`

 * *Files 0% similar despite different names*

```diff
@@ -19,28 +19,27 @@
 import sys
 import threading
 import traceback
 from collections import defaultdict
 from contextlib import closing
 from datetime import datetime
 from pathlib import Path
-from typing import Any, Dict, Iterable, List, Optional, Type
+from typing import Any, Dict, Iterable, List, Optional, TextIO, Type
 
-import tensorflow.keras.mixed_precision as mixed_precision
-import torch
+from keras import mixed_precision
 from prettytable import PrettyTable, from_db_cursor
 
 from fastestimator.schedule.schedule import Scheduler
 from fastestimator.summary.logs.log_parse import parse_log_iter
 from fastestimator.summary.logs.log_plot import visualize_logs
 from fastestimator.summary.summary import Summary, average_summaries
 from fastestimator.summary.system import System
+from fastestimator.util.base_util import NonContext, warn
 from fastestimator.util.cli_util import SaveAction, parse_string_to_python
-from fastestimator.util.util import cpu_count
-from fastestimator.util.base_util import NonContext
+from fastestimator.util.util import cpu_count, get_num_gpus
 
 _MAKE_HIST_TABLE = 'CREATE TABLE IF NOT EXISTS history (' \
                    'file TEXT, ' \
                    'experiment TEXT, ' \
                    'status TEXT, ' \
                    'args LIST[STR], ' \
                    'fe_version TEXT, ' \
@@ -125,23 +124,23 @@
     if db_path != ':memory:':  # This is a reserved keyword to create an in-memory database
         os.makedirs(os.path.dirname(db_path), exist_ok=True)  # Make sure folders exist before creating disk file
     connection = sql.connect(db_path, detect_types=sql.PARSE_DECLTYPES | sql.PARSE_COLNAMES)
     if db_path != ":memory:":
         # Check to ensure the database isn't corrupted
         cur = connection.execute("PRAGMA integrity_check")
         response = cur.fetchall()[0]
-        if response != ('ok',):
+        if response != ('ok', ):
             connection.close()
-            corrupt_path = os.path.join(os.path.dirname(db_path),
-                                        f"corrupt_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}_"
-                                        f"{os.path.basename(db_path)}")
+            corrupt_path = os.path.join(
+                os.path.dirname(db_path),
+                f"corrupt_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}_"
+                f"{os.path.basename(db_path)}")
             os.renames(db_path, corrupt_path)
-            print(f"FastEstimator-Warn: The FastEstimator history database has been corrupted. It has been moved to "
-                  f"{corrupt_path} and a new one has been automatically created. The integrity check output is: "
-                  f"{response}")
+            warn(f"The FastEstimator history database has been corrupted. It has been moved to {corrupt_path} and " +
+                 f"a new one has been automatically created. The integrity check output is: {response}")
             connection = sql.connect(db_path, detect_types=sql.PARSE_DECLTYPES | sql.PARSE_COLNAMES)
     connection.execute("PRAGMA foreign_keys = 1")  # Enable FK constraints
     connection.row_factory = sql.Row  # Get nice query return objects
     # Build the schema if it doesn't exist
     connection.execute(_MAKE_HIST_TABLE)
     connection.execute(_MAKE_FEAT_TABLE)
     connection.execute(_MAKE_DS_TABLE)
@@ -203,18 +202,19 @@
                    {'keep': n_keep})
     elif n_keep_logs is not None:
         db.execute("UPDATE settings SET n_keep_logs = MIN(n_keep, (?)) WHERE pk = 0", [n_keep_logs])
     db.commit()
     with closing(db.cursor()) as cursor:
         cursor.execute("SELECT * FROM settings")
         response = from_db_cursor(cursor)
-    # Hide implementation details from end user
-    response.del_column('pk')
-    response.del_column('schema_version')
-    print(response)
+    if response is not None:
+        # Hide implementation details from end user
+        response.del_column('pk')
+        response.del_column('schema_version')
+        print(response)
     db.close()
 
 
 class HistoryRecorder:
     """A class to record what you're doing.
 
     This class is intentionally not @traceable.
@@ -224,25 +224,28 @@
 
     Args:
         system: The system object corresponding to the current training.
         est_path: The path to the file responsible for creating the current estimator (this is for bookkeeping, it can
             technically be any string).
         db_path: The path to the database, or None to use the default location.
     """
+    db: sql.Connection
+    stdout: TextIO
+
     def __init__(self, system: System, est_path: str, db_path: Optional[str] = None):
         # Prepare db adapters
         sql.register_adapter(bool, int)
         sql.register_converter("BOOL", lambda v: bool(int(v)))
         sql.register_adapter(list, str)
         sql.register_converter("LIST[STR]", lambda v: parse_string_to_python(v))
         # Prepare variables
         self.filename = os.path.basename(est_path)
         self.db_path = db_path if db_path else os.path.join(str(Path.home()), 'fastestimator_data', 'history.db')
         self.system = system
-        self.db = None
+        self.db = None  # type: ignore
         self.ident = (multiprocessing.current_process().pid, threading.get_ident())
         self.pk = None
         self.stdout = None
 
     def __enter__(self) -> None:
         self.db = connect(self.db_path)
         self.ident = (multiprocessing.current_process().pid, threading.get_ident())
@@ -258,15 +261,15 @@
                     'pk': self.pk,
                     'fname': self.filename,
                     'status': 'Launched',
                     'exp': self.system.summary.name,
                     'args': sys.argv[1:],
                     'version': sys.modules['fastestimator'].__version__,
                     'start': datetime.now(),
-                    'gpus': torch.cuda.device_count(),
+                    'gpus': get_num_gpus(),
                     'cpus': cpu_count(),
                     'workers': self.system.pipeline.num_process
                 })
             self.db.executemany(_MAKE_FEAT_ENTRY, self._get_features_in_use())
             self.db.executemany(_MAKE_DS_ENTRY, self._get_datasets_in_use())
             self.db.executemany(_MAKE_PIPE_ENTRY, self._get_items_in_use(self.system.pipeline.ops))
             self.db.executemany(_MAKE_NET_ENTRY, self._get_items_in_use(self.system.network.ops))
@@ -304,16 +307,15 @@
                 self.db.execute(_MAKE_ERR_ENTRY_P2, args)
             self.db.commit()
             self._apply_limits()
         except (sql.OperationalError, sql.DatabaseError) as err:
             # This could happen if user has multiple trainings running simultaneously, the database becomes corrupted,
             # and then a new training is launched which detects the corrupted database of the old training and re-names
             # the old database before the old job completes.
-            print(f"FastEstimator-Warn: FastEstimator history tracking failed to capture the final status of the "
-                  f"experiment: {err}")
+            warn(f"FastEstimator history tracking failed to capture the final status of the experiment: {err}")
         self.db.close()
 
     def _check_for_restart(self) -> None:
         """Determine whether a training has been restarted via RestoreWizard. If so, update the history accordingly.
 
         If RestoreWizard has been invoked, then the system exp_id will have changed since self.pk was initialized. This
         method will do related bookkeeping, and then swap self.pk for the restored id.
@@ -409,16 +411,16 @@
             # dropped.
             try:
                 self._check_for_restart()  # Check here instead of waiting for __exit__ in case system powers off later
                 self.db.execute('UPDATE logs SET log = log || (?) WHERE fk = (?)', [output, self.pk])
                 self.db.commit()
             except (sql.OperationalError, sql.DatabaseError) as err:
                 self.ident = (-2, -2)  # No threads should match this identity in the future
-                print(f"\nFastEstimator-Warn: There was a problem writing to the FastEstimator history database. Log "
-                      f"capture will be disabled for the rest of this experiment. Error: {err}")
+                warn("There was a problem writing to the FastEstimator history database. Log " +
+                     f"capture will be disabled for the rest of this experiment. Error: {err}")
 
     def flush(self) -> None:
         self.stdout.flush()
 
 
 class HistoryReader:
     """A class to read history information from the database.
@@ -431,17 +433,19 @@
     with HistoryReader() as reader:
         reader.read_basic()
     ```
 
     Args:
         db_path: The path to the database, or None to use the default location.
     """
+    db: sql.Connection
+
     def __init__(self, db_path: Optional[str] = None):
         self.db_path = db_path
-        self.db = None  # sql.Connection
+        self.db = None  # type: ignore
         self.response = None  # List[sql.Row]
 
     def __enter__(self) -> 'HistoryReader':
         self.db = connect(self.db_path)
         self.db.set_trace_callback(print)  # Show the query in case user wants to adapt it later
         return self
 
@@ -606,15 +610,15 @@
 
         Args:
             subparsers: The parser object to be appended to.
         """
         p_log = subparsers.add_parser(
             'log',
             description='Retrieve one or more output logs. This command requires '
-                        'that you currently have experiments selected.',
+            'that you currently have experiments selected.',
             formatter_class=argparse.ArgumentDefaultsHelpFormatter,
             allow_abbrev=False)
         p_log.add_argument('indices',
                            metavar='I',
                            type=int,
                            nargs='+',
                            help="Indices of experiments for which to print logs")
@@ -633,16 +637,16 @@
         """Add an error parser to an existing argparser.
 
         Args:
             subparsers: The parser object to be appended to.
         """
         p_err = subparsers.add_parser(
             'err',
-            description='Retrieve one or more error tracebacks. This command requires '
-                        'that you currently have experiments selected.',
+            description='Retrieve one or more error tracebacks. This command requires that you currently have \
+                experiments selected.',
             formatter_class=argparse.ArgumentDefaultsHelpFormatter,
             allow_abbrev=False)
         p_err.add_argument('indices',
                            metavar='I',
                            type=int,
                            nargs='+',
                            help="Indices of experiments for which to print error tracebacks")
@@ -652,16 +656,16 @@
         """Add a visualization parser to an existing argparser.
 
         Args:
             subparsers: The parser object to be appended to.
         """
         p_vis = subparsers.add_parser(
             'vis',
-            description='Visualize logs for one or more experiments. This command requires '
-                        'that you currently have experiments selected.',
+            description='Visualize logs for one or more experiments. This command requires that you currently '
+            'have experiments selected.',
             formatter_class=argparse.ArgumentDefaultsHelpFormatter,
             allow_abbrev=False)
         p_vis.add_argument('indices',
                            metavar='idx',
                            type=int,
                            nargs='*',
                            help="Indices of experiments for which to print logs")
@@ -824,15 +828,14 @@
             for group_name, group_indices in args['groups'].items():
                 if idx in group_indices:
                     groups[group_name].append(experiment)
         experiments = [average_summaries(name, exps) for name, exps in groups.items()]
         visualize_logs(experiments,
                        save_path=save_dir,
                        smooth_factor=args['smooth'],
-                       share_legend=args['share_legend'],
                        pretty_names=args['pretty_names'],
                        ignore_metrics=args['ignore'],
                        include_metrics=args['include'])
 
 
 class _GroupAction(argparse._AppendAction):
     """An argparse action which can be invoked multiple times in order to build a dictionary of entries.
```

### Comparing `fastestimator-1.5.2/fastestimator/summary/logs/__init__.py` & `fastestimator-1.6.0/fastestimator/summary/logs/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/summary/logs/log_parse.py` & `fastestimator-1.6.0/fastestimator/summary/logs/log_parse.py`

 * *Files 2% similar despite different names*

```diff
@@ -155,27 +155,31 @@
                   ignore_metrics: Optional[Set[str]] = None,
                   include_metrics: Optional[Set[str]] = None,
                   pretty_names: bool = False,
                   group_by: Optional[str] = None) -> None:
     """A function which will gather all log files within a given folder and pass them along for visualization.
 
     Args:
-        dir_path: The path to a directory containing log files.
+        dir_path: The path to a directory containing log files (or the path to a specific single log file).
         log_extension: The extension of the log files.
         recursive_search: Whether to recursively search sub-directories for log files.
         smooth_factor: A non-negative float representing the magnitude of gaussian smoothing to apply (zero for none).
         save: Whether to save (True) or display (False) the generated graph.
         save_path: Where to save the image if save is true. Defaults to dir_path if not provided.
         ignore_metrics: Any metrics within the log files which will not be visualized.
         include_metrics: A whitelist of metric keys (None whitelists all keys).
         pretty_names: Whether to modify the metric names in graph titles (True) or leave them alone (False).
         group_by: Combine multiple log files by a regex to visualize their mean+-stddev. For example, to group together
             files like [a_1.txt, a_2.txt] vs [b_1.txt, b_2.txt] you can use: r'(.*)_[\d]+\.txt'.
     """
-    file_paths = list_files(root_dir=dir_path, file_extension=log_extension, recursive_search=recursive_search)
+    if os.path.isdir(dir_path):
+        file_paths = list_files(root_dir=dir_path, file_extension=log_extension, recursive_search=recursive_search)
+    else:
+        file_paths = [dir_path]
+        log_extension = os.path.splitext(dir_path)[1]
 
     parse_log_files(file_paths,
                     log_extension,
                     smooth_factor,
                     save,
                     save_path,
                     ignore_metrics,
```

### Comparing `fastestimator-1.5.2/fastestimator/summary/logs/log_plot.py` & `fastestimator-1.6.0/fastestimator/summary/logs/log_plot.py`

 * *Files 5% similar despite different names*

```diff
@@ -13,26 +13,26 @@
 # limitations under the License.
 # ==============================================================================
 import math
 import re
 import tempfile
 from collections import defaultdict
 from itertools import cycle
-from typing import Any, Dict, List, Optional, Set, Union, Tuple
+from typing import Any, Dict, List, Optional, Set, Tuple, Union
 
 import numpy as np
 import plotly.graph_objects as go
 from natsort import humansorted
 from plotly.io import _html, _kaleido
 from plotly.offline.offline import get_plotlyjs
 from plotly.subplots import make_subplots
 from scipy.ndimage.filters import gaussian_filter1d
 
 from fastestimator.summary.summary import Summary, ValWithError
-from fastestimator.util.base_util import get_colors, to_set, to_list, prettify_metric_name, in_notebook, FigureFE
+from fastestimator.util.base_util import FigureFE, get_colors, in_notebook, prettify_metric_name, to_list, to_set, warn
 
 
 class _MetricGroup:
     """A class for wrapping the values recorded for a given metric based on its experiment id and mode.
 
     This class is intentionally not @traceable.
     """
@@ -235,16 +235,15 @@
 
     metric_list = list(sorted(metric_histories.keys()))
     if len(metric_list) == 0:
         return FigureFE.from_figure(make_subplots())
     ds_ids = humansorted(ds_ids)  # Sort them to have consistent ordering (and thus symbols) between plot runs
     n_plots = len(metric_list)
     if len(ds_ids) > 9:  # 9 b/c None is included
-        print("FastEstimator-Warn: Plotting more than 8 different datasets isn't well supported. Symbols will be "
-              "reused.")
+        warn("Plotting more than 8 different datasets isn't well supported. Symbols will be reused.")
 
     # Non-Shared legends aren't supported yet. If they get supported then maybe can have that feature here too.
     #  https://github.com/plotly/plotly.js/issues/5099
     #  https://github.com/plotly/plotly.js/issues/5098
 
     # map the metrics into an n x n grid, then remove any extra columns. Final grid will be n x m with m <= n
     n_rows = math.ceil(math.sqrt(n_plots))
@@ -263,21 +262,29 @@
         metric_grid_location[metric] = (idx // n_cols, idx % n_cols)
         idx += 1
     titles = [k for k, v in sorted(list(metric_grid_location.items()), key=lambda e: e[1][0] * n_cols + e[1][1])]
     if pretty_names:
         titles = [prettify_metric_name(title) for title in titles]
 
     fig = make_subplots(rows=n_rows, cols=n_cols, subplot_titles=titles, shared_xaxes='all')
-    fig.update_layout({'plot_bgcolor': '#FFF',
-                       'hovermode': 'closest',
-                       'margin': {'t': 50},
-                       'modebar': {'add': ['hoverclosest', 'hovercompare'],
-                                   'remove': ['select2d', 'lasso2d']},
-                       'legend': {'tracegroupgap': 5,
-                                  'font': {'size': 11}}})
+    fig.update_layout({
+        'plot_bgcolor': '#FFF',
+        'hovermode': 'closest',
+        'margin': {
+            't': 50
+        },
+        'modebar': {
+            'add': ['hoverclosest', 'hovercompare'], 'remove': ['select2d', 'lasso2d']
+        },
+        'legend': {
+            'tracegroupgap': 5, 'font': {
+                'size': 11
+            }
+        }
+    })
 
     # Set x-labels
     for idx, metric in enumerate(titles, start=1):
         plotly_idx = idx if idx > 1 else ""
         x_axis_name = f'xaxis{plotly_idx}'
         y_axis_name = f'yaxis{plotly_idx}'
         if metric_histories[metric].ndim() > 1:
@@ -372,44 +379,46 @@
                                 y_max = y.y_max
                                 y = y.y
                             marker_style = 'circle' if mode == 'train' else 'diamond' if mode == 'eval' \
                                 else 'square' if mode == 'test' else 'hexagram'
                             limit_data = [(y_max, y_min)] if y_max is not None and y_min is not None else None
                             tip_text = "%{x}: (%{customdata[1]:.3f}, %{y:.3f}, %{customdata[0]:.3f})" if \
                                 limit_data is not None else "%{x}: %{y:.3f}"
-                            error_y = None if limit_data is None else {'type': 'data',
-                                                                       'symmetric': False,
-                                                                       'array': [y_max - y],
-                                                                       'arrayminus': [y - y_min]}
-                            z_order[2].append((go.Scatter(x=[x],
-                                                          y=[y],
-                                                          name=title,
-                                                          legendgroup=title,
-                                                          customdata=limit_data,
-                                                          hovertemplate=tip_text,
-                                                          mode='markers',
-                                                          marker={'color': color,
-                                                                  'size': 12,
-                                                                  'symbol': _symbol_mash(marker_style,
-                                                                                         ds_id_markers[ds_id]),
-                                                                  'line': {'width': 1.5,
-                                                                           'color': 'White'}},
-                                                          error_y=error_y,
-                                                          showlegend=add_label[exp_idx][mode][ds_id]['patch'],
-                                                          legendrank=legend_order[title]),
+                            error_y = None if limit_data is None else {
+                                'type': 'data', 'symmetric': False, 'array': [y_max - y], 'arrayminus': [y - y_min]
+                            }
+                            z_order[2].append((go.Scatter(
+                                x=[x],
+                                y=[y],
+                                name=title,
+                                legendgroup=title,
+                                customdata=limit_data,
+                                hovertemplate=tip_text,
+                                mode='markers',
+                                marker={
+                                    'color': color,
+                                    'size': 12,
+                                    'symbol': _symbol_mash(marker_style, ds_id_markers[ds_id]),
+                                    'line': {
+                                        'width': 1.5, 'color': 'White'
+                                    }
+                                },
+                                error_y=error_y,
+                                showlegend=add_label[exp_idx][mode][ds_id]['patch'],
+                                legendrank=legend_order[title]),
                                                row,
                                                col))
                             add_label[exp_idx][mode][ds_id]['patch'] = False
                         else:
                             # We can draw a line
                             y = data[:, 1]
                             y_min = None
                             y_max = None
                             if isinstance(y[0], ValWithError):
-                                y = np.stack(y)
+                                y = np.stack([e.as_tuple() for e in y])
                                 y_min = y[:, 0]
                                 y_max = y[:, 2]
                                 y = y[:, 1]
                                 if smooth_factor != 0:
                                     y_min = gaussian_filter1d(y_min, sigma=smooth_factor)
                                     y_max = gaussian_filter1d(y_max, sigma=smooth_factor)
                             # TODO - for smoothed lines, plot original data in background but greyed out
@@ -418,31 +427,36 @@
                             x = data[:, 0]
                             linestyle = 'solid' if mode == 'train' else 'dash' if mode == 'eval' else 'dot' if \
                                 mode == 'test' else 'dashdot'
                             limit_data = [(mx, mn) for mx, mn in zip(y_max, y_min)] if y_max is not None and y_min is \
                                                                                        not None else None
                             tip_text = "%{x}: (%{customdata[1]:.3f}, %{y:.3f}, %{customdata[0]:.3f})" if \
                                 limit_data is not None else "%{x}: %{y:.3f}"
-                            z_order[1].append((go.Scatter(x=x,
-                                                          y=y,
-                                                          name=title,
-                                                          legendgroup=title,
-                                                          mode="lines+markers" if ds_id_markers[ds_id] else 'lines',
-                                                          marker={'color': color,
-                                                                  'size': 8,
-                                                                  'line': {'width': 2,
-                                                                           'color': 'DarkSlateGrey'},
-                                                                  'maxdisplayed': 10,
-                                                                  'symbol': ds_id_markers[ds_id]},
-                                                          line={'dash': linestyle,
-                                                                'color': color},
-                                                          customdata=limit_data,
-                                                          hovertemplate=tip_text,
-                                                          showlegend=add_label[exp_idx][mode][ds_id]['line'],
-                                                          legendrank=legend_order[title]),
+                            z_order[1].append((go.Scatter(
+                                x=x,
+                                y=y,
+                                name=title,
+                                legendgroup=title,
+                                mode="lines+markers" if ds_id_markers[ds_id] else 'lines',
+                                marker={
+                                    'color': color,
+                                    'size': 8,
+                                    'line': {
+                                        'width': 2, 'color': 'DarkSlateGrey'
+                                    },
+                                    'maxdisplayed': 10,
+                                    'symbol': ds_id_markers[ds_id]
+                                },
+                                line={
+                                    'dash': linestyle, 'color': color
+                                },
+                                customdata=limit_data,
+                                hovertemplate=tip_text,
+                                showlegend=add_label[exp_idx][mode][ds_id]['line'],
+                                legendrank=legend_order[title]),
                                                row,
                                                col))
                             add_label[exp_idx][mode][ds_id]['line'] = False
                             if limit_data is not None:
                                 z_order[0].append((go.Scatter(x=x,
                                                               y=y_max,
                                                               mode='lines',
@@ -518,18 +532,17 @@
     """
     base_table = {'circle': 0, 'diamond': 2, 'square': 1, 'hexagram': 18}
     if ds_symbol is None:
         return base_table[base_symbol]
     ds_offsets = {37: 0, 38: 1, 39: 2, 40: 3, 34: 4, 33: 5, 35: 6, 36: 7}
     slots = {i for i in range(53)} - set(base_table.values()) - set(ds_offsets.keys())
     slots = sorted(list(slots))
-    base_offsets = {'circle': 0,
-                    'diamond': len(ds_offsets),
-                    'square': 2 * len(ds_offsets),
-                    'hexagram': 3 * len(ds_offsets)}
+    base_offsets = {
+        'circle': 0, 'diamond': len(ds_offsets), 'square': 2 * len(ds_offsets), 'hexagram': 3 * len(ds_offsets)
+    }
     mashed_symbol = slots[base_offsets[base_symbol] + ds_offsets[ds_symbol]]
     return mashed_symbol
 
 
 def _get_vars(symbol: Union[str, int]) -> str:
     """Get the javascript variable declarations associated with a given symbol.
 
@@ -538,53 +551,65 @@
     Args:
         symbol: The symbol whose variables should be retrieved.
 
     Returns:
         A minified string representation of the variables to be declared in javascript.
     """
     if isinstance(symbol, str):
-        return {'circle': 'var b1=n.round(t,2);',
-                'square': 'var b1=n.round(t,2);',
-                'diamond': 'var b1=n.round(t*1.3,2);',
-                'hexagram': 'var b1=n.round(t,2);var b2=n.round(t/2,2);var b3=n.round(t*Math.sqrt(3)/2,2);'}[symbol]
-    return {37: 'var d1=n.round(t*1.2,2);var d2=n.round(t*1.6,2);var d3=n.round(t*0.8,2);',
-            38: 'var d1=n.round(t*1.2,2);var d2=n.round(t*1.6,2);var d3=n.round(t*0.8,2);',
-            39: 'var d1=n.round(t*1.2,2);var d2=n.round(t*1.6,2);var d3=n.round(t*0.8,2);',
-            40: 'var d1=n.round(t*1.2,2);var d2=n.round(t*1.6,2);var d3=n.round(t*0.8,2);',
-            34: 'var d1=n.round(t,2);',
-            33: 'var d1=n.round(t*1.4,2);',
-            35: 'var d1=n.round(t*1.2,2);var d2=n.round(t*0.85,2);',
-            36: 'var d1=n.round(t/2,2);var d2=n.round(t,2);'}[symbol]
+        return {
+            'circle': 'var b1=n.round(t,2);',
+            'square': 'var b1=n.round(t,2);',
+            'diamond': 'var b1=n.round(t*1.3,2);',
+            'hexagram': 'var b1=n.round(t,2);var b2=n.round(t/2,2);var b3=n.round(t*Math.sqrt(3)/2,2);'
+        }[symbol]
+    return {
+        37: 'var d1=n.round(t*1.2,2);var d2=n.round(t*1.6,2);var d3=n.round(t*0.8,2);',
+        38: 'var d1=n.round(t*1.2,2);var d2=n.round(t*1.6,2);var d3=n.round(t*0.8,2);',
+        39: 'var d1=n.round(t*1.2,2);var d2=n.round(t*1.6,2);var d3=n.round(t*0.8,2);',
+        40: 'var d1=n.round(t*1.2,2);var d2=n.round(t*1.6,2);var d3=n.round(t*0.8,2);',
+        34: 'var d1=n.round(t,2);',
+        33: 'var d1=n.round(t*1.4,2);',
+        35: 'var d1=n.round(t*1.2,2);var d2=n.round(t*0.85,2);',
+        36: 'var d1=n.round(t/2,2);var d2=n.round(t,2);'
+    }[symbol]
 
 
 def _get_paths(symbol: Union[str, int]) -> str:
     """Get the javascript pen paths associated with a given symbol.
 
     These are adapted from plotly.js -> src/components/drawing/symbol_defs.js
 
     Args:
         symbol: The symbol whose pen paths should be retrieved.
 
     Returns:
         A minified string representation of the paths to be declared in javascript.
     """
     if isinstance(symbol, str):
-        return {'circle': '"M"+b1+",0A"+b1+","+b1+" 0 1,1 0,-"+b1+"A"+b1+","+b1+" 0 0,1 "+b1+",0Z"',
-                'square': '"M"+b1+","+b1+"H-"+b1+"V-"+b1+"H"+b1+"Z"',
-                'diamond': '"M"+b1+",0L0,"+b1+"L-"+b1+",0L0,-"+b1+"Z"',
-                'hexagram': '"M-"+b3+",0l-"+b2+",-"+b1+"h"+b3+"l"+b2+",-"+b1+"l"+b2+","+b1+"h"+b3+"l-"+b2+","+b1+"l"+'
-                            'b2+","+b1+"h-"+b3+"l-"+b2+","+b1+"l-"+b2+",-"+b1+"h-"+b3+"Z"'}[symbol]
-    return {37: '"M-"+d1+","+d3+"L0,0M"+d1+","+d3+"L0,0M0,-"+d2+"L0,0"',
-            38: '"M-"+d1+",-"+d3+"L0,0M"+d1+",-"+d3+"L0,0M0,"+d2+"L0,0"',
-            39: '"M"+d3+","+d1+"L0,0M"+d3+",-"+d1+"L0,0M-"+d2+",0L0,0"',
-            40: '"M-"+d3+","+d1+"L0,0M-"+d3+",-"+d1+"L0,0M"+d2+",0L0,0"',
-            34: '"M"+d1+","+d1+"L-"+d1+",-"+d1+"M"+d1+",-"+d1+"L-"+d1+","+d1',
-            33: '"M0,"+d1+"V-"+d1+"M"+d1+",0H-"+d1',
-            35: '"M0,"+d1+"V-"+d1+"M"+d1+",0H-"+d1+"M"+d2+","+d2+"L-"+d2+",-"+d2+"M"+d2+",-"+d2+"L-"+d2+","+d2',
-            36: '"M"+d1+","+d2+"V-"+d2+"m-"+d2+",0V"+d2+"M"+d2+","+d1+"H-"+d2+"m0,-"+d2+"H"+d2'}[symbol]
+        return {
+            'circle':
+            '"M"+b1+",0A"+b1+","+b1+" 0 1,1 0,-"+b1+"A"+b1+","+b1+" 0 0,1 "+b1+",0Z"',
+            'square':
+            '"M"+b1+","+b1+"H-"+b1+"V-"+b1+"H"+b1+"Z"',
+            'diamond':
+            '"M"+b1+",0L0,"+b1+"L-"+b1+",0L0,-"+b1+"Z"',
+            'hexagram':
+            '"M-"+b3+",0l-"+b2+",-"+b1+"h"+b3+"l"+b2+",-"+b1+"l"+b2+","+b1+"h"+b3+"l-"+b2+","+b1+"l"+'
+            'b2+","+b1+"h-"+b3+"l-"+b2+","+b1+"l-"+b2+",-"+b1+"h-"+b3+"Z"'
+        }[symbol]
+    return {
+        37: '"M-"+d1+","+d3+"L0,0M"+d1+","+d3+"L0,0M0,-"+d2+"L0,0"',
+        38: '"M-"+d1+",-"+d3+"L0,0M"+d1+",-"+d3+"L0,0M0,"+d2+"L0,0"',
+        39: '"M"+d3+","+d1+"L0,0M"+d3+",-"+d1+"L0,0M-"+d2+",0L0,0"',
+        40: '"M-"+d3+","+d1+"L0,0M-"+d3+",-"+d1+"L0,0M"+d2+",0L0,0"',
+        34: '"M"+d1+","+d1+"L-"+d1+",-"+d1+"M"+d1+",-"+d1+"L-"+d1+","+d1',
+        33: '"M0,"+d1+"V-"+d1+"M"+d1+",0H-"+d1',
+        35: '"M0,"+d1+"V-"+d1+"M"+d1+",0H-"+d1+"M"+d2+","+d2+"L-"+d2+",-"+d2+"M"+d2+",-"+d2+"L-"+d2+","+d2',
+        36: '"M"+d1+","+d2+"V-"+d2+"m-"+d2+",0V"+d2+"M"+d2+","+d1+"H-"+d2+"m0,-"+d2+"H"+d2'
+    }[symbol]
 
 
 def _draw_mash(base_symbol: str, ds_symbol: int) -> Tuple[str, str]:
     """Figure out how to draw one symbol on top of another, and propose an existing symbol to overwrite to make room.
 
     The names in this function were extracted from plotly/validators/scatter/marker/_symbol.py
 
@@ -592,25 +617,69 @@
         base_symbol: The symbol to go on the bottom.
         ds_symbol: The symbol to go on the top.
 
     Returns:
         (A regex pattern corresponding to an existing symbol to be replaced, a new javascript string to replace the old
          symbol)
     """
-    id_to_name = {0: 'circle', 1: 'square', 2: 'diamond', 3: 'cross', 4: 'x', 5: '"triangle-up"', 6: '"triangle-down"',
-                  7: '"triangle-left"', 8: '"triangle-right"', 9: '"triangle-ne"', 10: '"triangle-se"',
-                  11: '"triangle-sw"', 12: '"triangle-nw"', 13: 'pentagon', 14: 'hexagon', 15: 'hexagon2',
-                  16: 'octagon', 17: 'star', 18: 'hexagram', 19: '"star-triangle-up"', 20: '"star-triangle-down"',
-                  21: '"star-square"', 22: '"star-diamond"', 23: '"diamond-tall"', 24: '"diamond-wide"',
-                  25: 'hourglass', 26: 'bowtie', 27: '"circle-cross"', 28: '"circle-x"', 29: '"square-cross"',
-                  30: '"square-x"', 31: '"diamond-cross"', 32: '"diamond-x"', 33: '"cross-thin"', 34: '"x-thin"',
-                  35: 'asterisk', 36: 'hash', 37: '"y-up"', 38: '"y-down"', 39: '"y-left"', 40: '"y-right"',
-                  41: '"line-ew"', 42: '"line-ns"', 43: '"line-ne"', 44: '"line-nw"', 45: '"arrow-up"',
-                  46: '"arrow-down"', 47: '"arrow-left"', 48: '"arrow-right"', 49: '"arrow-bar-up"',
-                  50: '"arrow-bar-down"', 51: '"arrow-bar-left"', 52: '"arrow-bar-right"'}
+    id_to_name = {
+        0: 'circle',
+        1: 'square',
+        2: 'diamond',
+        3: 'cross',
+        4: 'x',
+        5: '"triangle-up"',
+        6: '"triangle-down"',
+        7: '"triangle-left"',
+        8: '"triangle-right"',
+        9: '"triangle-ne"',
+        10: '"triangle-se"',
+        11: '"triangle-sw"',
+        12: '"triangle-nw"',
+        13: 'pentagon',
+        14: 'hexagon',
+        15: 'hexagon2',
+        16: 'octagon',
+        17: 'star',
+        18: 'hexagram',
+        19: '"star-triangle-up"',
+        20: '"star-triangle-down"',
+        21: '"star-square"',
+        22: '"star-diamond"',
+        23: '"diamond-tall"',
+        24: '"diamond-wide"',
+        25: 'hourglass',
+        26: 'bowtie',
+        27: '"circle-cross"',
+        28: '"circle-x"',
+        29: '"square-cross"',
+        30: '"square-x"',
+        31: '"diamond-cross"',
+        32: '"diamond-x"',
+        33: '"cross-thin"',
+        34: '"x-thin"',
+        35: 'asterisk',
+        36: 'hash',
+        37: '"y-up"',
+        38: '"y-down"',
+        39: '"y-left"',
+        40: '"y-right"',
+        41: '"line-ew"',
+        42: '"line-ns"',
+        43: '"line-ne"',
+        44: '"line-nw"',
+        45: '"arrow-up"',
+        46: '"arrow-down"',
+        47: '"arrow-left"',
+        48: '"arrow-right"',
+        49: '"arrow-bar-up"',
+        50: '"arrow-bar-down"',
+        51: '"arrow-bar-left"',
+        52: '"arrow-bar-right"'
+    }
     mash_id = _symbol_mash(base_symbol, ds_symbol)
     mash_name = id_to_name[mash_id]
     target_str = mash_name + r':{n.*?}(,needLine:!0)?(,noDot:!0)?(,noFill:!0)?}'
     swap_str = mash_name + r':{n:' + str(mash_id) + ',f:function(t){' + _get_vars(base_symbol) + _get_vars(
         ds_symbol) + f'return{_get_paths(ds_symbol)}+{_get_paths(base_symbol)};' + '}}'
     return target_str, swap_str
```

### Comparing `fastestimator-1.5.2/fastestimator/summary/summary.py` & `fastestimator-1.6.0/fastestimator/summary/summary.py`

 * *Files 24% similar despite different names*

```diff
@@ -11,30 +11,112 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import re
 import statistics
 from collections import defaultdict
-from typing import Any, Dict, List, NamedTuple, Optional, TYPE_CHECKING, Union
+from typing import Any, Dict, List, Optional, Tuple, TYPE_CHECKING, Union
 
 if TYPE_CHECKING:
     from fastestimator.util.traceability_util import FeSummaryTable
 
 
-class ValWithError(NamedTuple):
+class ValWithError:
     """A class to record values with error bars (for special visualization in the logger).
     """
-    y_min: float
-    y: float
-    y_max: float
+    __slots__ = 'y_min', 'y', 'y_max'
+
+    def __init__(self, y_min: float, y: float, y_max: float):
+        self.y_min = y_min
+        self.y = y
+        self.y_max = y_max
+
+    def __getitem__(self, idx: int):
+        if idx == 0:
+            return self.y_min
+        elif idx == 1:
+            return self.y
+        elif idx == 2:
+            return self.y_max
+        else:
+            raise IndexError()
+
+    def as_tuple(self) -> Tuple[float, float, float]:
+        return self.y_min, self.y, self.y_max
+
+    def __getstate__(self):
+        return {'y_min': self.y_min, 'y': self.y, 'y_max': self.y_max}
+
+    def __setstate__(self, state):
+        self.y_min = state['y_min']
+        self.y = state['y']
+        self.y_max = state['y_max']
 
     def __str__(self):
         return f"({self.y_min}, {self.y}, {self.y_max})"
 
+    def __lt__(self, other):
+        if isinstance(other, ValWithError):
+            return self.y < other.y
+        return self.y < other
+
+    def __le__(self, other):
+        if isinstance(other, ValWithError):
+            return self.y <= other.y
+        return self.y <= other
+
+    def __ge__(self, other):
+        if isinstance(other, ValWithError):
+            return self.y >= other.y
+        return self.y >= other
+
+    def __gt__(self, other):
+        if isinstance(other, ValWithError):
+            return self.y > other.y
+        return self.y > other
+
+    def __eq__(self, other):
+        if isinstance(other, ValWithError):
+            return self.y == other.y
+        return self.y == other
+
+    def __add__(self, other):
+        if isinstance(other, ValWithError):
+            return self.y + other.y
+        return self.y + other
+
+    def __sub__(self, other):
+        if isinstance(other, ValWithError):
+            return self.y - other.y
+        return self.y - other
+
+    def __mul__(self, other):
+        if isinstance(other, ValWithError):
+            return self.y * other.y
+        return self.y * other
+
+    def __abs__(self):
+        return abs(self.y)
+
+    def __radd__(self, other):
+        if isinstance(other, ValWithError):
+            return other.y + self.y
+        return other + self.y
+
+    def __rsub__(self, other):
+        if isinstance(other, ValWithError):
+            return other.y - self.y
+        return other - self.y
+
+    def __rmul__(self, other):
+        if isinstance(other, ValWithError):
+            return other.y * self.y
+        return other * self.y
+
 
 class Summary:
     """A summary object that records training history.
 
     This class is intentionally not @traceable.
 
     Args:
```

### Comparing `fastestimator-1.5.2/fastestimator/summary/system.py` & `fastestimator-1.6.0/fastestimator/summary/system.py`

 * *Files 3% similar despite different names*

```diff
@@ -26,15 +26,17 @@
 
 from fastestimator.backend._load_model import load_model
 from fastestimator.backend._save_model import save_model
 from fastestimator.network import BaseNetwork
 from fastestimator.pipeline import Pipeline
 from fastestimator.schedule.schedule import Scheduler
 from fastestimator.summary.summary import Summary
+from fastestimator.util.base_util import to_list
 from fastestimator.util.traceability_util import FeSummaryTable, is_restorable
+from fastestimator.util.util import get_num_gpus
 
 if TYPE_CHECKING:
     from fastestimator.trace.trace import Trace
 
 Model = TypeVar('Model', tf.keras.Model, torch.nn.Module)
 
 
@@ -86,57 +88,60 @@
         network: A reference to the network being used.
         pipeline: A reference to the pipeline being used.
         traces: The traces being used.
         train_steps_per_epoch: Training will be cut short or extended to complete N steps even if loader is not yet
             exhausted. If None, all data will be used.
         eval_steps_per_epoch: Evaluation will be cut short or extended to complete N steps even if loader is not yet
             exhausted. If None, all data will be used.
-        eval_log_steps: The list of steps on which evaluation progress logs need to be printed.
+        eval_log_steps_request: The list of steps on which the user wants eval log printing.
+        eval_log_steps: The steps on which eval logs will be printed, The total number of eval steps in this epoch.
         summary: An object to write experiment results to.
         experiment_time: A timestamp indicating when this model was trained.
         custom_graphs: A place to store extra graphs which are too complicated for the primary history.
     """
 
     mode: Optional[str]
     ds_id: str
     exp_id: int
     global_step: Optional[int]
     num_devices: int
     log_steps: Optional[int]
     total_epochs: int
-    epoch_idx: Optional[int]
+    epoch_idx: int
     batch_idx: Optional[int]
     stop_training: bool
     network: BaseNetwork
     pipeline: Pipeline
     traces: List[Union['Trace', Scheduler['Trace']]]
     train_steps_per_epoch: Optional[int]
     eval_steps_per_epoch: Optional[int]
-    eval_log_steps: Sequence[int]
+    eval_log_steps_request: List[int]
+    eval_log_steps: Tuple[List[int], int]
     summary: Summary
     experiment_time: str
     custom_graphs: Dict[str, List[Summary]]
 
     def __init__(self,
                  network: BaseNetwork,
                  pipeline: Pipeline,
                  traces: List[Union['Trace', Scheduler['Trace']]],
                  mode: Optional[str] = None,
                  ds_id: str = '',
-                 num_devices: int = torch.cuda.device_count(),
+                 num_devices: int = get_num_gpus(),
                  log_steps: Optional[int] = None,
                  total_epochs: int = 0,
                  train_steps_per_epoch: Optional[int] = None,
                  eval_steps_per_epoch: Optional[int] = None,
                  eval_log_steps: Sequence[int] = (),
                  system_config: Optional[List[FeSummaryTable]] = None) -> None:
 
         self.network = network
         self.pipeline = pipeline
-        self.eval_log_steps = eval_log_steps
+        self.eval_log_steps_request = to_list(eval_log_steps)
+        self.eval_log_steps = ([], 0)
         self.traces = traces
         self.mode = mode
         self.ds_id = ds_id
         self.num_devices = num_devices
         self.log_steps = log_steps
         self.total_epochs = total_epochs
         self.batch_idx = None
@@ -248,26 +253,29 @@
         os.makedirs(save_dir, exist_ok=True)
         # Start with the high-level info. We could use pickle for this but having it human readable is nice.
         state = {key: value for key, value in self.__dict__.items() if is_restorable(value)[0]}
         with open(os.path.join(save_dir, 'system.json'), 'w') as fp:
             json.dump(state, fp, indent=4)
         # Save all of the models / optimizer states
         for model in self.network.models:
-            save_model(model, save_dir=save_dir, save_optimizer=True)
+            save_model(model, save_dir=save_dir, save_optimizer=hasattr(model, "optimizer") and model.optimizer)
         # Save everything else
         objects = {
             'summary': self.summary,
             'custom_graphs': self.custom_graphs,
             'traces': [trace.__getstate__() if hasattr(trace, '__getstate__') else {} for trace in self.traces],
             'tops': [op.__getstate__() if hasattr(op, '__getstate__') else {} for op in self.network.ops],
+            'slops': [sl.__getstate__() if hasattr(sl, '__getstate__') else {} for sl in self.network.slicers],
             'pops': [op.__getstate__() if hasattr(op, '__getstate__') else {} for op in self.network.postprocessing],
             'nops': [op.__getstate__() if hasattr(op, '__getstate__') else {} for op in self.pipeline.ops],
             'ds': {
-                mode: {key: value.__getstate__()
-                       for key, value in ds.items() if hasattr(value, '__getstate__')}
+                mode: {
+                    key: value.__getstate__()
+                    for key, value in ds.items() if hasattr(value, '__getstate__')
+                }
                 for mode,
                 ds in self.pipeline.data.items()
             }
         }
         with open(os.path.join(save_dir, 'objects.pkl'), 'wb') as file:
             # We need to use a custom pickler here to handle MirroredStrategy, which will show up inside of tf
             # MirroredVariables in multi-gpu systems.
@@ -301,14 +309,15 @@
             raise FileNotFoundError(f"Could not find the objects summary file at {objects_path}")
         with open(objects_path, 'rb') as file:
             objects = pickle.load(file)
         self.summary.__dict__.update(objects['summary'].__dict__)
         self.custom_graphs = objects['custom_graphs']
         self._load_list(objects, 'traces', self.traces)
         self._load_list(objects, 'tops', self.network.ops)
+        self._load_list(objects, 'slops', self.network.slicers)
         self._load_list(objects, 'pops', self.network.postprocessing)
         self._load_list(objects, 'nops', self.pipeline.ops)
         self._load_dict(objects, 'ds', self.pipeline.data)
 
     @staticmethod
     def _load_model(model: Model, base_path: str) -> None:
         """Load model and optimizer weights from disk.
@@ -327,17 +336,15 @@
             model_ext, optimizer_ext = 'pt', 'pt'
         else:
             raise ValueError(f"Unknown model type: {type(model)}")
         weights_path = os.path.join(base_path, f"{model.model_name}.{model_ext}")
         if not os.path.exists(weights_path):
             raise FileNotFoundError(f"Cannot find model weights file at {weights_path}")
         optimizer_path = os.path.join(base_path, f"{model.model_name}_opt.{optimizer_ext}")
-        if not os.path.exists(optimizer_path):
-            raise FileNotFoundError(f"Cannot find model optimizer file at {optimizer_path}")
-        load_model(model, weights_path=weights_path, load_optimizer=True)
+        load_model(model, weights_path=weights_path, load_optimizer=os.path.exists(optimizer_path))
 
     @staticmethod
     def _load_list(states: Dict[str, Any], state_key: str, in_memory_objects: List[Any]) -> None:
         """Load a list of pickled states from the disk.
 
         Args:
             states: The states to be restored.
```

### Comparing `fastestimator-1.5.2/fastestimator/test/__init__.py` & `fastestimator-1.6.0/fastestimator/test/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/test/nightly_util.py` & `fastestimator-1.6.0/fastestimator/test/nightly_util.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/test/unittest_util.py` & `fastestimator-1.6.0/fastestimator/test/unittest_util.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/__init__.py` & `fastestimator-1.6.0/fastestimator/trace/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/adapt/__init__.py` & `fastestimator-1.6.0/fastestimator/trace/adapt/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/adapt/early_stopping.py` & `fastestimator-1.6.0/fastestimator/trace/adapt/early_stopping.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
+from operator import lt, gt
 from typing import Optional
 
 import numpy as np
 
 from fastestimator.trace.trace import Trace
 from fastestimator.util.data import Data
 from fastestimator.util.traceability_util import traceable
@@ -59,25 +60,25 @@
         self.fe_monitor_names.add(monitor)
         self.min_delta = abs(min_delta)
         self.wait = 0
         self.best = 0
         self.patience = patience
         self.baseline = baseline
         if compare == 'min':
-            self.monitor_op = np.less
+            self.monitor_op = lt
             self.min_delta *= -1
         else:
-            self.monitor_op = np.greater
+            self.monitor_op = gt
 
     def on_begin(self, data: Data) -> None:
         self.wait = 0
         if self.baseline is not None:
             self.best = self.baseline
         else:
-            self.best = np.Inf if self.monitor_op == np.less else -np.Inf
+            self.best = np.Inf if self.monitor_op == lt else -np.Inf
 
     def on_epoch_end(self, data: Data) -> None:
         current = data[self.monitored_key]
         if current is None:
             return
         if self.monitor_op(current - self.min_delta, self.best):
             self.best = current
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/adapt/lr_scheduler.py` & `fastestimator-1.6.0/fastestimator/trace/adapt/lr_scheduler.py`

 * *Files 0% similar despite different names*

```diff
@@ -17,15 +17,15 @@
 
 import numpy as np
 import tensorflow as tf
 import torch
 
 from fastestimator.backend._get_lr import get_lr
 from fastestimator.backend._set_lr import set_lr
-from fastestimator.schedule.lr_shedule import ARC
+from fastestimator.schedule.lr_schedule import ARC
 from fastestimator.summary.system import System
 from fastestimator.trace.trace import Trace
 from fastestimator.util.data import Data
 from fastestimator.util.traceability_util import traceable
 
 
 @traceable()
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/adapt/pbm_calibrator.py` & `fastestimator-1.6.0/fastestimator/trace/adapt/pbm_calibrator.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/adapt/reduce_lr_on_plateau.py` & `fastestimator-1.6.0/fastestimator/trace/adapt/reduce_lr_on_plateau.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
+from operator import lt, gt
 from typing import Optional, Union
 
 import numpy as np
 import tensorflow as tf
 import torch
 
 from fastestimator.backend._get_lr import get_lr
@@ -61,18 +62,18 @@
         self.patience = patience
         self.factor = factor
         self.best_mode = best_mode
         self.min_lr = min_lr
         self.wait = 0
         if self.best_mode == "min":
             self.best = np.Inf
-            self.monitor_op = np.less
+            self.monitor_op = lt
         elif self.best_mode == "max":
             self.best = -np.Inf
-            self.monitor_op = np.greater
+            self.monitor_op = gt
         else:
             raise ValueError("best_mode must be either 'min' or 'max'")
 
     def on_epoch_end(self, data: Data) -> None:
         if self.monitor_op(data[self.inputs[0]], self.best):
             self.best = data[self.inputs[0]]
             self.wait = 0
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/adapt/terminate_on_nan.py` & `fastestimator-1.6.0/fastestimator/trace/adapt/terminate_on_nan.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/io/__init__.py` & `fastestimator-1.6.0/fastestimator/trace/io/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -21,19 +21,23 @@
                                                           'csv_logger': ['CSVLogger'],
                                                           'image_saver': ['ImageSaver'],
                                                           'image_viewer': ['ImageViewer'],
                                                           'model_saver': ['ModelSaver'],
                                                           'restore_wizard': ['RestoreWizard'],
                                                           'tensorboard': ['TensorBoard'],
                                                           'test_report': ['TestReport'],
-                                                          'traceability': ['Traceability'], })
+                                                          'traceability': ['Traceability'],
+                                                          'batch_display': ['BatchDisplay'],
+                                                          'grid_display': ['GridDisplay']})
 
 if TYPE_CHECKING:
+    from fastestimator.trace.io.batch_display import BatchDisplay
     from fastestimator.trace.io.best_model_saver import BestModelSaver
     from fastestimator.trace.io.csv_logger import CSVLogger
+    from fastestimator.trace.io.grid_display import GridDisplay
     from fastestimator.trace.io.image_saver import ImageSaver
     from fastestimator.trace.io.image_viewer import ImageViewer
     from fastestimator.trace.io.model_saver import ModelSaver
     from fastestimator.trace.io.restore_wizard import RestoreWizard
     from fastestimator.trace.io.tensorboard import TensorBoard
     from fastestimator.trace.io.test_report import TestReport
     from fastestimator.trace.io.traceability import Traceability
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/io/best_model_saver.py` & `fastestimator-1.6.0/fastestimator/trace/io/best_model_saver.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
+from operator import lt, gt
 from typing import Optional, Union
 
 import numpy as np
 import tensorflow as tf
 import torch
 
 from fastestimator.backend._load_model import load_model
@@ -68,18 +69,18 @@
         self.save_architecture = save_architecture
         if save_architecture and isinstance(model, torch.nn.Module):
             raise ValueError("Sorry, architecture saving is not currently enabled for PyTorch")
         self.model_path = None
         self.since_best = 0
         if self.save_best_mode == "min":
             self.best = np.Inf
-            self.monitor_op = np.less
+            self.monitor_op = lt
         elif self.save_best_mode == "max":
             self.best = -np.Inf
-            self.monitor_op = np.greater
+            self.monitor_op = gt
         else:
             raise ValueError("save_best_mode must be either 'min' or 'max'")
 
     @property
     def metric(self) -> str:
         return self.inputs[0]
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/io/csv_logger.py` & `fastestimator-1.6.0/fastestimator/trace/io/batch_display.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,161 +1,129 @@
-# Copyright 2019 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2022 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import os
-from typing import Any, Iterable, List, Optional, Union
+from typing import Iterable, Optional, Sequence, Tuple, Union
 
-import numpy as np
-import pandas as pd
-
-from fastestimator.summary import ValWithError
-from fastestimator.trace.trace import Trace
+from fastestimator.trace import Trace
+from fastestimator.trace.trace import parse_freq
+from fastestimator.util.base_util import to_list
 from fastestimator.util.data import Data
+from fastestimator.util.img_data import BatchDisplay as BatchDisplayF
 from fastestimator.util.traceability_util import traceable
-from fastestimator.util.util import to_number
-from fastestimator.util.base_util import to_list
 
 
 @traceable()
-class CSVLogger(Trace):
-    """Log monitored quantities in a CSV file.
+class BatchDisplay(Trace):
+    """A Trace to display a batch of images.
 
     Args:
-        filename: Output filename.
-        monitor_names: List of keys to monitor. If None then all metrics will be recorded.
-        instance_id_key: A key corresponding to data instance ids. If provided, the CSV logger will record per-instance
-            metric information into a second csv file.
+        image: Key corresponding to a batch of images to be displayed.
+        text: Key corresponding to text to be printed in the center of the figure.
+        masks: Key corresponding to masks to be displayed over an image. May be accompanied by a sequence of mask labels
+            (1 per channel) if desired: (<mask_key>, [<c1_name>, <c2_name>, ...])
+        bboxes: Key corresponding to bounding boxes to be displayed over the image.
+        keypoints: Key corresponding to keypoints to be displayed over the image. May be accompanied by a sequence of
+            keypoint labels (1 per keypoint) if desired: (<kp_key>, [<kp1_name>, <kp2_name>, ...])
+        mask_threshold: If provided, any masks will be binarized based on the given threshold value (1 if > t, else 0).
+        color_map: How to color 1-channel images. Options from: https://plotly.com/python/builtin-colorscales/. If 2
+            strings are provided, the first will be used to color grey-scale images and the second will be used to color
+            continuous (non-thresholded) masks. If a single string is provided it will be used for both image and masks.
+        title: The title of the generated figure. If None it defaults to any image/text/mask/bbox/keypoint key which was
+            provided (in that order).
+        batch_limit: A limit on the number of batch elements to display.
+        frequency: 'batch', 'epoch', integer, or strings like '10s', '15e'. When using 'batch', writes the losses and
+            metrics to TensorBoard after each batch. The same applies for 'epoch'. If using an integer, let's say 1000,
+            the callback will write the metrics and losses to TensorBoard every 1000 samples. You can also use strings
+            like '8s' to indicate every 8 steps or '5e' to indicate every 5 epochs. You can use None to default to
+            matching the log printing frequency.
+        save_dir: A directory into which to save images rather than displaying them. The file names will be formatted
+            as <title>_<mode>_<epoch>_<batch_idx>.html
         mode: What mode(s) to execute this Trace in. For example, "train", "eval", "test", or "infer". To execute
             regardless of mode, pass None. To execute in all modes except for a particular one, you can pass an argument
             like "!infer" or "!train".
+        ds_id: What dataset id(s) to execute this Trace in. To execute regardless of ds_id, pass None. To execute in all
+            ds_ids except for a particular one, you can pass an argument like "!ds1".
     """
     def __init__(self,
-                 filename: str,
-                 monitor_names: Optional[Union[List[str], str]] = None,
-                 instance_id_key: Optional[str] = None,
-                 mode: Union[None, str, Iterable[str]] = None) -> None:
-        self.instance_id_key = instance_id_key
-        monitor_names = to_list(monitor_names)
-        instance_id_key = to_list(instance_id_key)
-        inputs = monitor_names if monitor_names else ["*"]
-        inputs.extend(instance_id_key)
-        super().__init__(inputs=inputs, mode=mode)
-        self.filename = filename
-        self.df_agg = None  # DataFrame for aggregate metrics
-        self.df_ins = None  # DataFrame for instance metrics
+                 image: Optional[str] = None,
+                 text: Optional[str] = None,
+                 masks: Union[None, str, Tuple[str, Sequence[str]]] = None,
+                 bboxes: Optional[str] = None,
+                 keypoints: Union[None, str, Tuple[str, Sequence[str]]] = None,
+                 mask_threshold: Optional[float] = None,
+                 color_map: Union[str, Tuple[str, str]] = ("gray", "turbo"),
+                 title: Optional[str] = None,
+                 batch_limit: Optional[int] = None,
+                 frequency: Union[None, int, str] = None,
+                 save_dir: Optional[str] = None,
+                 mode: Union[None, str, Iterable[str]] = None,
+                 ds_id: Union[None, str, Iterable[str]] = None):
+        self._image = image
+        self._text = text
+        self._masks, self._mask_labels, *_ = to_list(masks) + [None, None]
+        self._bboxes = bboxes
+        self._keypoints, self._keypoint_labels, *_ = to_list(keypoints) + [None, None]
+        inputs = {self._image, self._text, self._masks, self._bboxes, self._keypoints}
+        inputs.discard(None)
+        assert inputs, "At least one input key must be specified"
+        super().__init__(inputs=inputs, mode=mode, ds_id=ds_id)
+        self._title = title or image or text or masks or bboxes or keypoints or None
+        self._color_map = color_map
+        self._mask_threshold = mask_threshold
+        self.save_dir = save_dir
+        if self.save_dir is not None:
+            self.save_dir = os.path.normpath(os.path.abspath(self.save_dir))
+            os.makedirs(self.save_dir, exist_ok=True)
+        self.frequency = None if frequency is None else parse_freq(frequency)
+        self.batch_limit = batch_limit
 
     def on_begin(self, data: Data) -> None:
-        base_keys = ["instance_id", "mode", "step", "epoch"] if self.instance_id_key else ["mode", "step", "epoch"]
-        self.df_agg = pd.DataFrame(columns=base_keys)
-        self.df_ins = pd.DataFrame(columns=base_keys)
-
-    def on_epoch_end(self, data: Data) -> None:
-        tmpdic = {"mode": self.system.mode, "step": self.system.global_step, "epoch": self.system.epoch_idx}
+        if self.frequency is None:
+            self.frequency = parse_freq(self.system.log_steps)
 
-        if "*" in self.inputs:
-            for key, value in data.read_logs().items():
-                tmpdic[key] = self._parse_val(value)
-                if key not in self.df_agg.columns:
-                    self.df_agg[key] = ''
-        else:
-            for key in self.inputs:
-                if key == self.instance_id_key:
-                    continue
-                tmpdic[key] = self._parse_val(data[key])
-                if key not in self.df_agg.columns:
-                    self.df_agg[key] = ''
-        for col in self.df_agg.columns:
-            if col not in tmpdic.keys():
-                tmpdic[col] = ''
-
-        self.df_agg = self.df_agg.append(tmpdic, ignore_index=True)
-        self._save()  # Write on epoch end so that people can see results sooner if debugging
+    def make_image(self, data: Data, batch_limit: Optional[int] = None) -> BatchDisplayF:
+        display = BatchDisplayF(image=data[self._image] if self._image else None,
+                                text=data[self._text] if self._text else None,
+                                masks=(data[self._masks], self._mask_labels) if self._masks else None,
+                                bboxes=data[self._bboxes] if self._bboxes else None,
+                                keypoints=(data[self._keypoints], self._keypoint_labels) if self._keypoints else None,
+                                mask_threshold=self._mask_threshold,
+                                color_map=self._color_map,
+                                title=self._title)
+        if batch_limit and batch_limit < display.batch_size:
+            display.batch = display.batch[:batch_limit]
+            display.batch_size = batch_limit
+        return display
 
     def on_batch_end(self, data: Data) -> None:
-        if self.instance_id_key:
-            ins_data = data.read_per_instance_logs()
-            if ins_data:
-                keys = list((ins_data.keys() if "*" in self.inputs else set(self.inputs)) - {self.instance_id_key})
-                ids = data[self.instance_id_key]
-                vals = [ins_data.get(key, data.get(key, '')) for key in keys]
-                for key in keys:
-                    if key not in self.df_ins.columns:
-                        self.df_ins[key] = ''
-                rows = []
-                for sample in zip(ids, *vals):
-                    row = {"instance_id": self._parse_val(sample[0]),
-                           "mode": self.system.mode,
-                           "step": self.system.global_step,
-                           "epoch": self.system.epoch_idx,
-                           **{key: self._parse_val(val) for key, val in zip(keys, sample[1:])}}
-                    for col in self.df_ins.columns:
-                        if col not in row.keys():
-                            row[col] = ''
-                    rows.append(row)
-                self.df_ins = self.df_ins.append(rows, ignore_index=True)
-
-        if self.system.mode == "train" and self.system.log_steps and (self.system.global_step % self.system.log_steps
-                                                                      == 0 or self.system.global_step == 1):
-
-            tmpdic = {"mode": self.system.mode, "step": self.system.global_step, "epoch": self.system.epoch_idx}
-
-            if "*" in self.inputs:
-                for key, value in data.read_logs().items():
-                    tmpdic[key] = self._parse_val(value)
-                    if key not in self.df_agg.columns:
-                        self.df_agg[key] = ''
+        # Use the global step to match system logging behavior during train, but fall back to batch_idx for eval/test
+        current_step = self.system.global_step if self.system.mode == 'train' else self.system.batch_idx
+        if self.frequency.freq and self.frequency.is_step and current_step % self.frequency.freq == 0:
+            display = self.make_image(data, batch_limit=self.batch_limit)
+            if self.save_dir is None:
+                display.show()
+            else:
+                title = self._title or self._image
+                filename = f'{title}_{self.system.mode}_{self.system.epoch_idx}_{self.system.batch_idx}.html'
+                display.show(save_path=os.path.join(self.save_dir, filename))
+
+    def on_epoch_end(self, data: Data) -> None:
+        if self.frequency.freq and not self.frequency.is_step and self.system.epoch_idx % self.frequency.freq == 0:
+            display = self.make_image(data, batch_limit=self.batch_limit)
+            if self.save_dir is None:
+                display.show()
             else:
-                for key in self.inputs:
-                    if key == self.instance_id_key:
-                        continue
-                    tmpdic[key] = self._parse_val(data[key])
-                    if key not in self.df_agg.columns:
-                        self.df_agg[key] = ''
-            for col in self.df_agg.columns:
-                if col not in tmpdic.keys():
-                    tmpdic[col] = ''
-
-            self.df_agg = self.df_agg.append(tmpdic, ignore_index=True)
-
-    def _save(self) -> None:
-        """Write the current state to disk.
-        """
-        stack = [self.df_ins, self.df_agg]
-        if self.system.mode == "test":
-            if os.path.exists(self.filename):
-                df1 = pd.read_csv(self.filename)
-                stack.insert(0, df1)
-        stack = pd.concat(stack, axis=0, ignore_index=True)
-        stack.to_csv(self.filename, index=False)
-
-    @staticmethod
-    def _parse_val(val: Any) -> str:
-        """Convert values into string representations.
-
-        Args:
-            val: A value to be printed.
-
-        Returns:
-            A formatted version of `val` appropriate for a csv file.
-        """
-        if isinstance(val, str):
-            return val
-        if isinstance(val, ValWithError):
-            return str(val).replace(',', ';')
-        val = to_number(val)
-        if val.size > 1:
-            return np.array2string(val, separator=';')
-        if val.dtype.kind in {'U', 'S'}:  # Unicode or String
-            # remove the b'' from strings stored in tensors
-            return str(val, 'utf-8')
-        return str(val)
+                title = self._title or self._image
+                filename = f'{title}_{self.system.mode}_{self.system.epoch_idx}_{self.system.batch_idx}.html'
+                display.show(save_path=os.path.join(self.save_dir, filename))
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/io/image_saver.py` & `fastestimator-1.6.0/fastestimator/trace/io/image_saver.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/io/image_viewer.py` & `fastestimator-1.6.0/fastestimator/trace/io/image_viewer.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/io/model_saver.py` & `fastestimator-1.6.0/fastestimator/trace/io/model_saver.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/io/restore_wizard.py` & `fastestimator-1.6.0/fastestimator/trace/io/restore_wizard.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/io/tensorboard.py` & `fastestimator-1.6.0/fastestimator/trace/io/tensorboard.py`

 * *Files 4% similar despite different names*

```diff
@@ -9,48 +9,44 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import os
-import re
-from collections import defaultdict, namedtuple
+from collections import defaultdict
 from typing import Any, Dict, Iterable, List, Optional, Tuple, TypeVar, Union
 
 import cv2
 import numpy as np
 import tensorboard as tb
 import tensorflow as tf
 import torch
+from keras import backend
+from keras.callbacks import keras_model_summary
 from plotly.graph_objs import Figure
-from tensorflow.keras import backend
 from tensorflow.python.framework import ops as tfops
-from tensorflow.python.keras.callbacks import keras_model_summary
 from tensorflow.python.ops import summary_ops_v2
 from torch.utils.tensorboard import SummaryWriter
 
 from fastestimator.backend._abs import abs
 from fastestimator.backend._concat import concat
 from fastestimator.backend._expand_dims import expand_dims
 from fastestimator.backend._permute import permute
 from fastestimator.backend._reduce_sum import reduce_sum
 from fastestimator.backend._reshape import reshape
 from fastestimator.backend._squeeze import squeeze
 from fastestimator.backend._to_tensor import to_tensor
 from fastestimator.network import BaseNetwork, TFNetwork
-from fastestimator.trace.trace import Trace
-from fastestimator.util.base_util import to_set, to_list, is_number, DefaultKeyDict
+from fastestimator.trace.trace import Trace, parse_freq
+from fastestimator.util.base_util import DefaultKeyDict, is_number, to_list, to_set
 from fastestimator.util.data import Data
 from fastestimator.util.img_data import Display
 from fastestimator.util.traceability_util import traceable
-from fastestimator.util.util import to_number
-
-# https://github.com/pytorch/pytorch/issues/30966
-tf.io.gfile = tb.compat.tensorflow_stub.io.gfile
+from fastestimator.util.util import get_num_gpus, to_number
 
 Model = TypeVar('Model', tf.keras.Model, torch.nn.Module)
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
 
 
 class _BaseWriter:
     """A class to write various types of data into TensorBoard summary files.
@@ -147,20 +143,26 @@
                     label_imgs = permute(label_imgs, [0, 3, 1, 2])
             self.summary_writers[mode].add_embedding(mat=flat,
                                                      metadata=labels,
                                                      label_img=label_imgs,
                                                      tag=key,
                                                      global_step=step)
 
+    def flush(self) -> None:
+        """Flush all of the associated writers.
+        """
+        for writer in self.summary_writers.values():
+            writer.flush()
+
     def close(self) -> None:
         """A method to flush and close all connections to the files on disk.
         """
         modes = list(self.summary_writers.keys())  # break connection with dictionary so can delete in iteration
         for mode in modes:
-            self.summary_writers[mode].close()
+            self.summary_writers[mode].close()  # Close also flushes
             del self.summary_writers[mode]
 
     @staticmethod
     def _weight_to_image(weight: Tensor, kernel_channels_last: bool = False) -> Optional[Tensor]:
         """Logs a weight as a TensorBoard image.
 
         Implementation from TensorFlow codebase, would have invoked theirs directly but they didn't make it a static
@@ -212,15 +214,15 @@
     def write_epoch_models(self, mode: str, epoch: int) -> None:
         with self.tf_summary_writers[mode].as_default(), summary_ops_v2.always_record_summaries():
             # Record the overall execution summary
             if hasattr(self.network._forward_step_static, '_concrete_stateful_fn'):
                 # noinspection PyProtectedMember
                 summary_ops_v2.graph(self.network._forward_step_static._concrete_stateful_fn.graph)
             # Record the individual model summaries
-            for model in self.network.epoch_models:
+            for model in self.network.ctx_models:
                 summary_writable = (model.__class__.__name__ == 'Sequential'
                                     or (hasattr(model, '_is_graph_network') and model._is_graph_network))
                 if summary_writable:
                     keras_model_summary(model.model_name, model, step=epoch)
 
     def write_weights(self, mode: str, models: Iterable[Model], step: int, visualize: bool) -> None:
         # Similar to TF implementation, but multiple models
@@ -248,18 +250,17 @@
 
 class _TorchWriter(_BaseWriter):
     """A class to write various Pytorch data into TensorBoard summary files.
 
     This class is intentionally not @traceable.
     """
     def write_epoch_models(self, mode: str, epoch: int) -> None:
-        for model in self.network.epoch_models:
+        for model in self.network.ctx_models:
             inputs = model.fe_input_spec.get_dummy_input()
-            self.summary_writers[mode].add_graph(model.module if torch.cuda.device_count() > 1 else model,
-                                                 input_to_model=inputs)
+            self.summary_writers[mode].add_graph(model.module if get_num_gpus() > 1 else model, input_to_model=inputs)
 
     def write_weights(self, mode: str, models: Iterable[Model], step: int, visualize: bool) -> None:
         for model in models:
             for name, params in model.named_parameters():
                 name = name.replace(".", "/")
                 name = "{}_{}".format(model.model_name, name)
                 weight = params.data
@@ -297,15 +298,14 @@
             of the model. Same argument format as `update_freq`.
         paint_weights: If True the system will attempt to visualize model weights as an image.
         write_embeddings: If a string or list of strings is provided, the corresponding keys will be written to
             TensorBoard embeddings.
         embedding_labels: Keys corresponding to label information for the `write_embeddings`.
         embedding_images: Keys corresponding to raw images to be associated with the `write_embeddings`.
     """
-    Freq = namedtuple('Freq', ['is_step', 'freq'])
     writer: _BaseWriter
 
     # TODO - support for per-instance tracking
 
     def __init__(self,
                  log_dir: str = 'logs',
                  update_freq: Union[None, int, str] = 100,
@@ -314,29 +314,29 @@
                  weight_histogram_freq: Union[None, int, str] = None,
                  paint_weights: bool = False,
                  embedding_freq: Union[None, int, str] = 'epoch',
                  write_embeddings: Union[None, str, List[str]] = None,
                  embedding_labels: Union[None, str, List[str]] = None,
                  embedding_images: Union[None, str, List[str]] = None) -> None:
         super().__init__(inputs=["*"] + to_list(write_images) + to_list(write_embeddings) + to_list(embedding_labels) +
-                                to_list(embedding_images))
+                         to_list(embedding_images))
         self.root_log_dir = log_dir
-        self.update_freq = self._parse_freq(update_freq)
+        self.update_freq = parse_freq(update_freq)
         self.write_graph = write_graph
         self.painted_graphs = set()
         self.write_images = to_set(write_images)
-        self.histogram_freq = self._parse_freq(weight_histogram_freq)
+        self.histogram_freq = parse_freq(weight_histogram_freq)
         if paint_weights and self.histogram_freq.freq == 0:
             self.histogram_freq.is_step = False
             self.histogram_freq.freq = 1
         self.paint_weights = paint_weights
         if write_embeddings is None and embedding_labels is None and embedding_images is None:
             # Speed up if-check short-circuiting later
             embedding_freq = None
-        self.embedding_freq = self._parse_freq(embedding_freq)
+        self.embedding_freq = parse_freq(embedding_freq)
         write_embeddings = to_list(write_embeddings)
         embedding_labels = to_list(embedding_labels)
         if embedding_labels:
             assert len(embedding_labels) == len(write_embeddings), \
                 f"Expected {len(write_embeddings)} embedding_labels keys, but recieved {len(embedding_labels)}. Use \
                 None to pad out the list if you have labels for only a subset of all embeddings."
 
@@ -347,71 +347,41 @@
             assert len(embedding_images) == len(write_embeddings), \
                 f"Expected {len(write_embeddings)} embedding_images keys, but recieved {len(embedding_images)}. Use \
                 None to pad out the list if you have labels for only a subset of all embeddings."
 
         else:
             embedding_images = [None for _ in range(len(write_embeddings))]
         self.write_embeddings = [(feature, label, img_label) for feature,
-                                                                 label,
-                                                                 img_label in
-                                 zip(write_embeddings, embedding_labels, embedding_images)]
+                                 label,
+                                 img_label in zip(write_embeddings, embedding_labels, embedding_images)]
         self.collected_embeddings = defaultdict(list)
 
-    def _parse_freq(self, freq: Union[None, str, int]) -> Freq:
-        """A helper function to convert string based frequency inputs into epochs or steps
-
-        Args:
-            freq: One of either None, "step", "epoch", "#s", "#e", or #, where # is an integer.
-
-        Returns:
-            A `Freq` object recording whether the trace should run on an epoch basis or a step basis, as well as the
-            frequency with which it should run.
-        """
-        if freq is None:
-            return self.Freq(False, 0)
-        if isinstance(freq, int):
-            if freq < 1:
-                raise ValueError(f"Tensorboard frequency argument must be a positive integer but got {freq}")
-            return self.Freq(True, freq)
-        if isinstance(freq, str):
-            if freq in {'step', 's'}:
-                return self.Freq(True, 1)
-            if freq in {'epoch', 'e'}:
-                return self.Freq(False, 1)
-            parts = re.match(r"^([0-9]+)([se])$", freq)
-            if parts is None:
-                raise ValueError(f"Tensorboard frequency argument must be formatted like <int><s|e> but got {freq}")
-            freq = int(parts[1])
-            if freq < 1:
-                raise ValueError(f"Tensorboard frequency argument must be a positive integer but got {freq}")
-            return self.Freq(parts[2] == 's', freq)
-        else:
-            raise ValueError(f"Unrecognized type passed as Tensorboard frequency: {type(freq)}")
-
     def on_begin(self, data: Data) -> None:
         print("FastEstimator-Tensorboard: writing logs to {}".format(
             os.path.abspath(os.path.join(self.root_log_dir, self.system.experiment_time))))
         self.writer = _TfWriter(self.root_log_dir, self.system.experiment_time, self.system.network) if isinstance(
             self.system.network, TFNetwork) else _TorchWriter(
-            self.root_log_dir, self.system.experiment_time, self.system.network)
+                self.root_log_dir, self.system.experiment_time, self.system.network)
         if self.write_graph and self.system.global_step == 1:
             self.painted_graphs = set()
 
     def on_batch_end(self, data: Data) -> None:
-        if self.write_graph and self.system.network.epoch_models.symmetric_difference(self.painted_graphs):
+        if self.write_graph and self.system.network.ctx_models.symmetric_difference(self.painted_graphs):
             self.writer.write_epoch_models(mode=self.system.mode, epoch=self.system.epoch_idx)
-            self.painted_graphs = self.system.network.epoch_models
+            self.painted_graphs = self.system.network.ctx_models
         # Collect embeddings if present in batch but viewing per epoch. Don't aggregate during training though
-        if self.system.mode != 'train' and self.embedding_freq.freq and not self.embedding_freq.is_step and self.system.epoch_idx % self.embedding_freq.freq == 0:
+        if self.system.mode != 'train' and self.embedding_freq.freq and not self.embedding_freq.is_step and \
+                self.system.epoch_idx % self.embedding_freq.freq == 0:
             for elem in self.write_embeddings:
                 name, lbl, img = elem
                 if name in data:
                     self.collected_embeddings[name].append((data.get(name), data.get(lbl), data.get(img)))
         # Handle embeddings if viewing per step
-        if self.embedding_freq.freq and self.embedding_freq.is_step and self.system.global_step % self.embedding_freq.freq == 0:
+        if self.embedding_freq.freq and self.embedding_freq.is_step and \
+                self.system.global_step % self.embedding_freq.freq == 0:
             self.writer.write_embeddings(
                 mode=self.system.mode,
                 step=self.system.global_step,
                 embeddings=filter(
                     lambda x: x[1] is not None,
                     map(lambda t: (t[0], data.get(t[0]), data.get(t[1]), data.get(t[2])), self.write_embeddings)))
         if self.system.mode != 'train':
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/io/test_report.py` & `fastestimator-1.6.0/fastestimator/trace/io/test_report.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/io/traceability.py` & `fastestimator-1.6.0/fastestimator/trace/io/traceability.py`

 * *Files 3% similar despite different names*

```diff
@@ -18,57 +18,65 @@
 import os
 import platform
 import re
 import shutil
 import sys
 import types
 from collections import defaultdict
-from typing import Any, Dict, List, Set, Tuple, Union, Optional
-from unittest.mock import Base, MagicMock
+from typing import Any, Dict, List, Optional, Set, Tuple, Union
+from unittest.mock import Base
 
 import dot2tex as d2t
 import jsonpickle
-import matplotlib
 import numpy as np
 import pydot
-import pytorch_model_summary as pms
 import tensorflow as tf
 import torch
+from cpuinfo import get_cpu_info
 from natsort import humansorted
 from pylatex import Command, Document, Figure, Hyperref, Itemize, Label, LongTable, Marker, MultiColumn, NoEscape, \
     Package, Section, Subsection, Subsubsection, Tabularx, escape_latex
 from pylatex.base_classes import Arguments
 from pylatex.section import Paragraph
 from pylatex.utils import bold
 from torch.utils.data import Dataset
+from torchinfo import summary as pms
+from torchview import draw_graph
 
 import fastestimator as fe
 from fastestimator.dataset.dataset import FEDataset
 from fastestimator.network import BaseNetwork
-from fastestimator.op.numpyop.numpyop import Batch
 from fastestimator.op.numpyop.meta.fuse import Fuse
 from fastestimator.op.numpyop.meta.one_of import OneOf
 from fastestimator.op.numpyop.meta.repeat import Repeat
 from fastestimator.op.numpyop.meta.sometimes import Sometimes
+from fastestimator.op.numpyop.numpyop import Batch
 from fastestimator.op.op import Op
 from fastestimator.op.tensorop.meta.fuse import Fuse as FuseT
 from fastestimator.op.tensorop.meta.one_of import OneOf as OneOfT
 from fastestimator.op.tensorop.meta.repeat import Repeat as RepeatT
 from fastestimator.op.tensorop.meta.sometimes import Sometimes as SometimesT
 from fastestimator.op.tensorop.model import ModelOp
 from fastestimator.pipeline import Pipeline
 from fastestimator.schedule.schedule import Scheduler, get_current_items, get_signature_epochs
+from fastestimator.slicer.slicer import Slicer
 from fastestimator.summary.logs.log_plot import visualize_logs
 from fastestimator.trace.io.restore_wizard import RestoreWizard
 from fastestimator.trace.trace import Trace, sort_traces
+from fastestimator.util.base_util import FEID, DefaultKeyDict, LogSplicer, NonContext, prettify_metric_name, to_list, \
+    warn
 from fastestimator.util.data import Data
 from fastestimator.util.latex_util import AdjustBox, Center, ContainerList, HrefFEID, Verbatim
 from fastestimator.util.traceability_util import FeSummaryTable, traceable
-from fastestimator.util.base_util import to_list, NonContext, Suppressor, LogSplicer, prettify_metric_name, \
-    DefaultKeyDict, FEID
+from fastestimator.util.util import Suppressor, cpu_count, get_gpu_info, get_num_gpus
+
+
+class _UnslicerWrapper():
+    def __init__(self, slicer: Slicer) -> None:
+        self.slicer = slicer
 
 
 @traceable()
 class Traceability(Trace):
     """Automatically generate summary reports of the training.
 
     Args:
@@ -295,14 +303,15 @@
             start = self._loop_tables(start,
                                       classes=Scheduler,
                                       name="Schedulers",
                                       model_ids=model_ids,
                                       datasets=datasets)
             start = self._loop_tables(start, classes=Trace, name="Traces", model_ids=model_ids, datasets=datasets)
             start = self._loop_tables(start, classes=Op, name="Operators", model_ids=model_ids, datasets=datasets)
+            start = self._loop_tables(start, classes=Slicer, name="Slicers", model_ids=model_ids, datasets=datasets)
             start = self._loop_tables(start,
                                       classes=(Dataset, tf.data.Dataset),
                                       name="Datasets",
                                       model_ids=model_ids,
                                       datasets=datasets)
             start = self._loop_tables(start,
                                       classes=(tf.keras.Model, torch.nn.Module),
@@ -398,15 +407,15 @@
         """Add model summaries to the traceability document.
         """
         with self.doc.create(Section("Models")):
             for model in humansorted(self.system.network.models, key=lambda m: m.model_name):
                 if not isinstance(model, (tf.keras.Model, torch.nn.Module)):
                     continue
                 self.doc.append(NoEscape(r'\FloatBarrier'))
-                with self.doc.create(Subsection(f"{model.model_name.capitalize()}")):
+                with self.doc.create(Subsection(f"{model.model_name.capitalize()}", label=model.model_name)):
                     if isinstance(model, tf.keras.Model):
                         # Text Summary
                         summary = []
                         model.summary(line_length=92, print_fn=lambda x: summary.append(x))
                         summary = "\n".join(summary)
                         self.doc.append(Verbatim(summary))
                         with self.doc.create(Center()):
@@ -421,61 +430,62 @@
                             # LaTeX \maxdim is around 575cm (226 inches), so the image must have max dimension less than
                             # 226 inches. However, the 'size' parameter doesn't account for the whole node height, so
                             # set the limit lower (100 inches) to leave some wiggle room.
                             dot.set('size', '100')
                             dot.write(file_path, format='pdf')
                         except Exception:
                             file_path = None
-                            print(
-                                f"FastEstimator-Warn: Model {model.model_name} could not be visualized by Traceability")
+                            warn(f"Model {model.model_name} could not be visualized by Traceability")
                     elif isinstance(model, torch.nn.Module):
                         if hasattr(model, 'fe_input_spec'):
                             # Text Summary
                             # noinspection PyUnresolvedReferences
                             inputs = model.fe_input_spec.get_dummy_input()
-                            self.doc.append(
-                                Verbatim(
-                                    pms.summary(model.module if self.system.num_devices > 1 else model,
-                                                inputs,
-                                                print_summary=False)))
+                            with Suppressor():
+                                self.doc.append(
+                                    Verbatim(
+                                        str(
+                                            pms(model.module if self.system.num_devices > 1 else model,
+                                                input_data=inputs,
+                                                col_names=("output_size", "num_params", "trainable"),
+                                                col_width=20,
+                                                row_settings=["ascii_only"],
+                                                verbose=0))))
+
                             with self.doc.create(Center()):
                                 self.doc.append(HrefFEID(FEID(id(model)), model.model_name))
                             # Visual Summary
-                            # Import has to be done while matplotlib is using the Agg backend
-                            old_backend = matplotlib.get_backend() or 'Agg'
-                            matplotlib.use('Agg')
                             # noinspection PyBroadException
                             try:
-                                # Fake the IPython import when user isn't running from Jupyter
-                                sys.modules.setdefault('IPython', MagicMock())
-                                sys.modules.setdefault('IPython.display', MagicMock())
-                                import hiddenlayer as hl
-                                with Suppressor():
-                                    graph = hl.build_graph(model.module if self.system.num_devices > 1 else model,
-                                                           inputs)
-                                graph = graph.build_dot()
-                                graph.attr(rankdir='TB')  # Switch it to Top-to-Bottom instead of Left-to-Right
+                                model.to(inputs.device)
+                                graph = draw_graph(
+                                    model.module if isinstance(model, torch.nn.parallel.DataParallel) else model,
+                                    input_data=inputs,
+                                    device=inputs.device,
+                                    graph_dir='TB',
+                                    expand_nested=True,
+                                    depth=7).visual_graph
                                 # LaTeX \maxdim is around 575cm (226 inches), so the image must have max dimension less
                                 # than 226 inches. However, the 'size' parameter doesn't account for the whole node
                                 # height, so set the limit lower (100 inches) to leave some wiggle room.
                                 graph.attr(size="100,100")
                                 graph.attr(margin='0')
                                 file_path = graph.render(filename="{}_{}".format(self.report_name, model.model_name),
                                                          directory=self.resource_dir,
                                                          format='pdf',
                                                          cleanup=True)
                             except Exception:
                                 file_path = None
-                                print("FastEstimator-Warn: Model {} could not be visualized by Traceability".format(
-                                    model.model_name))
-                            finally:
-                                matplotlib.use(old_backend)
+                                warn("Model {} could not be visualized by Traceability".format(model.model_name))
                         else:
                             file_path = None
                             self.doc.append("This model was not used by the Network during training.")
+                    else:
+                        file_path = None
+                        self.doc.append(f"Model format: {type(model)} not recognized.")
                     if file_path:
                         with self.doc.create(Figure(position='ht!')) as fig:
                             fig.append(Label(Marker(name=str(FEID(id(model))), prefix="model")))
                             fig.add_image(os.path.relpath(file_path, start=self.save_dir),
                                           width=NoEscape(r'1.0\textwidth,height=0.95\textheight,keepaspectratio'))
                             fig.add_caption(NoEscape(HrefFEID(FEID(id(model)), model.model_name).dumps()))
 
@@ -483,15 +493,24 @@
         """Add a system config summary to the traceability document.
         """
         with self.doc.create(Section("System Configuration")):
             with self.doc.create(Itemize()) as itemize:
                 itemize.add_item(escape_latex(f"FastEstimator {fe.__version__}"))
                 itemize.add_item(escape_latex(f"Python {platform.python_version()}"))
                 itemize.add_item(escape_latex(f"OS: {sys.platform}"))
-                itemize.add_item(f"Number of GPUs: {torch.cuda.device_count()}")
+                cpu = get_cpu_info()
+                itemize.add_item(f"CPU Used: {cpu_count()} Threads")
+                with self.doc.create(Itemize()) as subitem:
+                    subitem.add_item(f"{cpu['brand_raw']} ({cpu['count']} Threads)")
+                itemize.add_item(f"GPU(s) Used: {get_num_gpus()}")
+                gpus = get_gpu_info()
+                if gpus:
+                    with self.doc.create(Itemize()) as subitem:
+                        for gpu in gpus:
+                            subitem.add_item(gpu)
                 if fe.fe_deterministic_seed is not None:
                     itemize.add_item(escape_latex(f"Deterministic Seed: {fe.fe_deterministic_seed}"))
             with self.doc.create(LongTable('|lr|', pos=['h!'], booktabs=True)) as tabular:
                 tabular.add_row((bold("Module"), bold("Version")))
                 tabular.add_hline()
                 tabular.end_table_header()
                 tabular.add_hline()
@@ -529,14 +548,15 @@
         """
         ds = self.system.pipeline.data[mode][ds_id]
         if isinstance(ds, Scheduler):
             ds = ds.get_current_value(epoch)
         pipe_ops = get_current_items(self.system.pipeline.ops, run_modes=mode, epoch=epoch, ds_id=ds_id) if isinstance(
             ds, Dataset) else []
         net_ops = get_current_items(self.system.network.ops, run_modes=mode, epoch=epoch, ds_id=ds_id)
+        net_slicers = get_current_items(self.system.network.slicers, run_modes=mode, epoch=epoch, ds_id=ds_id)
         net_post = get_current_items(self.system.network.postprocessing, run_modes=mode, epoch=epoch, ds_id=ds_id)
         traces = sort_traces(get_current_items(self.system.traces, run_modes=mode, epoch=epoch, ds_id=ds_id),
                              ds_ids=self.system.pipeline.get_ds_ids(epoch=epoch, mode=mode))
         diagram = pydot.Dot(compound='true')  # Compound lets you draw edges which terminate at sub-graphs
         diagram.set('rankdir', 'TB')
         diagram.set('dpi', 300)
         diagram.set_node_defaults(shape='box')
@@ -554,15 +574,20 @@
                 if isinstance(batch_size, Scheduler):
                     batch_size = batch_size.get_current_value(epoch)
                 if isinstance(batch_size, dict):
                     batch_size = batch_size[mode]
         if batch_size is not None:
             batch_size = f" (Batch Size: {batch_size})"
         self._draw_subgraph(diagram, diagram, label_last_seen, f'Pipeline{batch_size}', pipe_ops, ds_id)
-        self._draw_subgraph(diagram, diagram, label_last_seen, 'Network', net_ops + net_post, ds_id)
+        self._draw_subgraph(diagram,
+                            diagram,
+                            label_last_seen,
+                            'Network',
+                            net_slicers + net_ops + [_UnslicerWrapper(slicer) for slicer in net_slicers] + net_post,
+                            ds_id)
         self._draw_subgraph(diagram, diagram, label_last_seen, 'Traces', traces, ds_id)
         return diagram
 
     def _draw_subgraph(self,
                        progenitor: pydot.Dot,
                        diagram: Union[pydot.Dot, pydot.Cluster],
                        label_last_seen: DefaultKeyDict[str, str],
@@ -668,19 +693,29 @@
                 texlbl = HrefFEID(FEID(id(op)), name=op.__class__.__name__, color='purple').dumps()
                 if op.batch_size is not None:
                     diagram.set_label(f"Pipeline (Batch Size: {op.batch_size})")
                 label_last_seen.factory = functools.partial(self._delayed_edge,
                                                             progenitor=progenitor,
                                                             old_source=label_last_seen.factory(''),
                                                             new_source=str(id(op)))
+            elif isinstance(op, Slicer):
+                label = f"{op.__class__.__name__} ({FEID(id(op))})"
+                texlbl = HrefFEID(FEID(id(op)), name=op.__class__.__name__, color='purple').dumps()
+                if op.minibatch_size:
+                    diagram.set_label(f"Network (Slices Per Step: {op.minibatch_size})")
+            elif isinstance(op, _UnslicerWrapper):
+                # The corresponding Slicer is already in the graph earlier
+                label = None
+                texlbl = None
             else:
                 label = f"{op.__class__.__name__} ({FEID(id(op))})"
                 texlbl = HrefFEID(FEID(id(op)), name=op.__class__.__name__).dumps()
-            diagram.add_node(pydot.Node(node_id, label=label, texlbl=texlbl))
-            if isinstance(op, (Op, Trace)) and edges:
+            if label is not None:
+                diagram.add_node(pydot.Node(node_id, label=label, texlbl=texlbl))
+            if isinstance(op, (Op, Trace, Slicer, _UnslicerWrapper)) and edges:
                 # Need the instance check since subgraph_ops might contain a tf dataset or torch data loader
                 self._add_edge(progenitor, op, label_last_seen, ds_id)
 
     @staticmethod
     def _delayed_edge(key: str, progenitor: pydot.Dot, old_source: str, new_source: str) -> str:
         """Draw a specific edge between two nodes, modifying the old label if applicable.
 
@@ -700,38 +735,40 @@
             edge.set_label(label)
         else:
             progenitor.add_edge(pydot.Edge(src=old_source, dst=new_source, label=f" {key}"))
         return new_source
 
     def _add_edge(self,
                   progenitor: pydot.Dot,
-                  op: Union[Trace, Op],
+                  op: Union[Trace, Op, Slicer, _UnslicerWrapper],
                   label_last_seen: Dict[str, str],
                   ds_id: Optional[str]):
         """Draw edges into a given Node.
 
         Args:
             progenitor: The very top level diagram onto which Edges should be written.
             op: The op (or trace) to be visualized.
             label_last_seen: A mapping of {data_dict_key: node_id} indicating the last node which generated the key.
             ds_id: The ds_id under which the node is currently running.
         """
-        node_id = str(id(op))
+        node_id = str(id(op.slicer)) if isinstance(op, _UnslicerWrapper) else str(id(op))
         edge_srcs = defaultdict(lambda: [])
         global_ds_ids = {key for vals in self.system.pipeline.data.values() for key in vals.keys() if key is not None}
-        for inp in label_last_seen.keys() if isinstance(op, Batch) else op.inputs:
+        for inp in label_last_seen.keys() if isinstance(op, Batch) else op.slice_inputs if isinstance(
+                op, Slicer) else op.slicer.unslice_inputs if isinstance(op, _UnslicerWrapper) else op.inputs:
             if inp == '*':
                 continue
             _, candidate_id, *_ = f"{inp}|".split('|')
             if candidate_id in global_ds_ids and candidate_id != ds_id:
                 continue  # Skip inputs which will be provided in other ds_id plots
             edge_srcs[label_last_seen[inp]].append(inp)
         for src, labels in edge_srcs.items():
             progenitor.add_edge(pydot.Edge(src=src, dst=node_id, label=f" {', '.join(labels)} "))
-        outputs = op.get_outputs(ds_ids=ds_id) if isinstance(op, Trace) else op.outputs
+        outputs = op.get_outputs(ds_ids=ds_id) if isinstance(op, Trace) else op.slice_inputs if isinstance(
+            op, Slicer) else op.slicer.unslice_inputs if isinstance(op, _UnslicerWrapper) else op.outputs
         for out in label_last_seen.keys() if isinstance(op, Batch) else outputs:
             label_last_seen[out] = node_id
 
     @staticmethod
     def _get_all_nodes(diagram: Union[pydot.Dot, pydot.Cluster]) -> List[pydot.Node]:
         """Recursively search through a `diagram` looking for Nodes.
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/meta/__init__.py` & `fastestimator-1.6.0/fastestimator/xai/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2021 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2019 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,11 +13,12 @@
 # limitations under the License.
 # ==============================================================================
 from typing import TYPE_CHECKING
 
 import lazy_loader as lazy
 
 __getattr__, __dir__, __all__ = lazy.attach(__name__,
-                                            submod_attrs={'_per_ds': ['per_ds']})
+                                            submod_attrs={'saliency': ['SaliencyNet'],
+                                                          })
 
 if TYPE_CHECKING:
-    from fastestimator.trace.meta._per_ds import per_ds
+    from fastestimator.xai.saliency import SaliencyNet
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/meta/_per_ds.py` & `fastestimator-1.6.0/fastestimator/trace/meta/_per_ds.py`

 * *Files 14% similar despite different names*

```diff
@@ -8,61 +8,59 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Union, List
-
 import functools
+from typing import List, Union
 
-from fastestimator.trace.trace import Trace, PerDSTrace
-from fastestimator.util.data import Data, DSData
+from fastestimator.trace.trace import PerDSTrace
 from fastestimator.util.base_util import to_list
+from fastestimator.util.data import Data, DSData
 
 
-def per_ds(clz: type(Trace)):
+def per_ds(clz):
     """A class annotation which will convert regular traces into dataset-sensitive traces.
 
     Args:
         clz: The base class to be converted.
 
     Returns:
         A dataset aware version of the class. Note that if the annotated class instance has a 'per_ds' member variable
         which is set to False, or has outputs containing the '|' character, then a normal (non-ds-aware) instance will
         be returned instead.
     """
+    @functools.wraps(clz, updated=())
     class PerDS(clz, PerDSTrace):
-        @functools.wraps(clz.__new__)
         def __new__(cls, *args, **kwargs):
             # We will dynamically determine whether to return a base object or a PerDS variant
             # If any of the outputs already use the | character then we cannot make this a PerDS variant
             base_obj = clz.__new__(clz)
             base_obj.__init__(*args, **kwargs)
             for output in base_obj.outputs:
                 if '|' in output:
                     return base_obj
             # If the user set per_ds to False in the constructor then we will not make this a PerDS variant
             if hasattr(base_obj, 'per_ds') and base_obj.per_ds is False:
                 return base_obj
             # Otherwise we are good to go with the PerDS variant
             return super().__new__(cls)
 
-        @functools.wraps(clz.__init__)
         def __init__(self, *args, **kwargs):
             super().__init__(*args, **kwargs)
             self.fe_per_ds_trace = clz.__new__(clz)
             self.fe_per_ds_trace.__init__(*args, **kwargs)
 
         def get_outputs(self, ds_ids: Union[None, str, List[str]]) -> List[str]:
-            ds_ids = to_list(ds_ids)
+            ids = to_list(ds_ids)
             outputs = list(self.outputs)
             for output in self.outputs:
-                for ds_id in ds_ids:
+                for ds_id in ids:
                     outputs.append(f"{output}|{ds_id}")
             return outputs
 
         def on_begin(self, data: Data) -> None:
             super().on_begin(data)
             self.fe_per_ds_trace.on_begin(data)
 
@@ -87,12 +85,8 @@
             if self.system.ds_id != '':
                 self.fe_per_ds_trace.on_epoch_end(DSData(self.system.ds_id, data))
 
         def on_end(self, data: Data) -> None:
             super().on_end(data)
             self.fe_per_ds_trace.on_end(data)
 
-    PerDS.__name__ = clz.__name__
-    PerDS.__qualname__ = clz.__qualname__
-    PerDS.__module__ = clz.__module__
-    PerDS.__doc__ = clz.__doc__  # We want to preserve the docstring of the original class
     return PerDS
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/metric/__init__.py` & `fastestimator-1.6.0/fastestimator/trace/metric/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,25 +13,27 @@
 # limitations under the License.
 # ==============================================================================
 from typing import TYPE_CHECKING
 
 import lazy_loader as lazy
 
 __getattr__, __dir__, __all__ = lazy.attach(__name__,
-                                            submod_attrs={'accuracy': ['Accuracy'],
+                                            submod_attrs={#'accuracy': ['Accuracy'],
                                                           'bleu_score': ['BleuScore'],
                                                           'calibration_error': ['CalibrationError'],
                                                           'confusion_matrix': ['ConfusionMatrix'],
                                                           'dice': ['Dice'],
                                                           'f1_score': ['F1Score'],
                                                           'mcc': ['MCC'],
                                                           'mean_average_precision': ['MeanAveragePrecision'],
                                                           'precision': ['Precision'],
                                                           'recall': ['Recall'], })
 
+from fastestimator.trace.metric.accuracy import Accuracy
+
 if TYPE_CHECKING:
     from fastestimator.trace.metric.accuracy import Accuracy
     from fastestimator.trace.metric.bleu_score import BleuScore
     from fastestimator.trace.metric.calibration_error import CalibrationError
     from fastestimator.trace.metric.confusion_matrix import ConfusionMatrix
     from fastestimator.trace.metric.dice import Dice
     from fastestimator.trace.metric.f1_score import F1Score
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/metric/accuracy.py` & `fastestimator-1.6.0/fastestimator/trace/metric/accuracy.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/metric/bleu_score.py` & `fastestimator-1.6.0/fastestimator/trace/metric/bleu_score.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/metric/calibration_error.py` & `fastestimator-1.6.0/fastestimator/trace/metric/calibration_error.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/metric/confusion_matrix.py` & `fastestimator-1.6.0/fastestimator/trace/metric/confusion_matrix.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/metric/f1_score.py` & `fastestimator-1.6.0/fastestimator/trace/metric/f1_score.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/metric/mcc.py` & `fastestimator-1.6.0/fastestimator/trace/metric/mcc.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,22 +8,22 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Union, Iterable
+from typing import Any, Dict, Union, Iterable
 
 import numpy as np
 from sklearn.metrics import matthews_corrcoef
 
 from fastestimator.trace.meta._per_ds import per_ds
 from fastestimator.trace.trace import Trace
-from fastestimator.util.data import Any, Data, Dict
+from fastestimator.util.data import Data
 from fastestimator.util.traceability_util import traceable
 from fastestimator.util.util import to_number
 
 
 @per_ds
 @traceable()
 class MCC(Trace):
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/metric/mean_average_precision.py` & `fastestimator-1.6.0/fastestimator/trace/metric/mean_average_precision.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 """COCO Mean average precisin (mAP) implementation."""
 from collections import defaultdict
-from typing import Dict, List, Union, Iterable
+from typing import Dict, Iterable, List, Optional, Union
 
 import numpy as np
 from pycocotools import mask as maskUtils
 
 from fastestimator.trace.meta._per_ds import per_ds
 from fastestimator.trace.trace import Trace
 from fastestimator.util.data import Data
@@ -61,16 +61,16 @@
                  ds_id: Union[None, str, Iterable[str]] = None,
                  output_name=("mAP", "AP50", "AP75"),
                  per_ds: bool = True) -> None:
         super().__init__(inputs=(true_key, pred_key), outputs=output_name, mode=mode, ds_id=ds_id)
 
         assert len(self.outputs) == 3, 'MeanAvgPrecision trace adds 3 fields mAP AP50 AP75 to state dict'
 
-        self.iou_thres = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05).astype(np.int) + 1, endpoint=True)
-        self.recall_thres = np.linspace(.0, 1.00, np.round((1.00 - .0) / .01).astype(np.int) + 1, endpoint=True)
+        self.iou_thres = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05).astype(np.int32) + 1, endpoint=True)
+        self.recall_thres = np.linspace(.0, 1.00, np.round((1.00 - .0) / .01).astype(np.int32) + 1, endpoint=True)
         self.categories = range(num_classes)
         self.max_detection = 100
         self.image_ids = []
         self.per_ds = per_ds
 
         # eval
         self.evalimgs = {}
@@ -339,16 +339,16 @@
             # for all images no gt inside this category
             if num_all_gt == 0:
                 continue
 
             tps = det_match > 0
             fps = det_match == 0
 
-            tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)
-            fp_sum = np.cumsum(fps, axis=1).astype(dtype=np.float)
+            tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float32)
+            fp_sum = np.cumsum(fps, axis=1).astype(dtype=np.float32)
 
             for index, (true_positives, false_positives) in enumerate(zip(tp_sum, fp_sum)):
                 true_positives = np.array(true_positives)
                 false_positives = np.array(false_positives)
                 nd = len(true_positives)
                 recall = true_positives / num_all_gt
                 precision = true_positives / (false_positives + true_positives + np.spacing(1))
@@ -384,15 +384,15 @@
         self.eval = {
             'counts': [num_iou_thresh, num_recall_thresh, num_categories],
             'precision': precision_matrix,
             'recall': recall_matrix,
             'scores': scores_matrix,
         }
 
-    def summarize(self, iou: float = None) -> float:
+    def summarize(self, iou: Optional[float] = None) -> float:
         """Compute average precision given one intersection union threshold.
 
         Args:
             iou: Intersection over union threshold. If this value is `None`, then average all iou thresholds. The result
                 is the mean average precision.
 
         Returns:
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/metric/precision.py` & `fastestimator-1.6.0/fastestimator/trace/metric/precision.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/metric/recall.py` & `fastestimator-1.6.0/fastestimator/trace/metric/recall.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/trace.py` & `fastestimator-1.6.0/fastestimator/trace/trace.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,16 +8,17 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
+import re
 import time
-from collections import defaultdict, deque
+from collections import defaultdict, deque, namedtuple
 from typing import Iterable, List, Set, Union
 
 import numpy as np
 from natsort import humansorted
 
 from fastestimator.backend._get_lr import get_lr
 from fastestimator.summary.summary import ValWithError
@@ -192,21 +193,21 @@
                 data.write_with_log("steps/sec", round(self.system.log_steps / np.sum(self.elapse_times), 2))
             self.elapse_times = []
             self.step_start = time.perf_counter()
 
     def on_epoch_end(self, data: Data) -> None:
         if self.system.log_steps:
             self.elapse_times.append(time.perf_counter() - self.step_start)
-            data.write_with_log("epoch_time", "{} sec".format(round(time.perf_counter() - self.epoch_start, 2)))
+            data.write_with_log("epoch_time(sec)", "{}".format(round(time.perf_counter() - self.epoch_start, 2)))
 
     def on_end(self, data: Data) -> None:
         self.system.mode = 'train'  # Set mode to 'train' for better log visualization
-        data.write_with_log("total_time", "{} sec".format(round(time.perf_counter() - self.train_start, 2)))
+        data.write_with_log("total_time(sec)", "{}".format(round(time.perf_counter() - self.train_start, 2)))
         for model in self.system.network.models:
-            if hasattr(model, "current_optimizer"):
+            if hasattr(model, "current_optimizer") and model.current_optimizer:
                 data.write_with_log(model.model_name + "_lr", get_lr(model))
 
 
 @traceable()
 class EvalEssential(Trace):
     """A trace to collect important information during evaluation.
 
@@ -216,35 +217,35 @@
         monitor_names: Any keys which should be collected over the course of an eval epoch.
     """
 
     def __init__(self, monitor_names: Set[str]) -> None:
         super().__init__(mode="eval", inputs=monitor_names, outputs=["steps/sec"])
         self.step_start = time.perf_counter()
         self.eval_results = defaultdict(lambda: defaultdict(list))
+        self.eval_steps = defaultdict(lambda: 0)
+        self.elapsed_step = 0
 
     def on_epoch_begin(self, data: Data) -> None:
         self.eval_results = defaultdict(lambda: defaultdict(list))
-        self.eval_step = 0
+        self.eval_steps.clear()
         self.elapsed_step = 0
         self.step_start = time.perf_counter()
 
-    def on_batch_begin(self, data: Data) -> None:
-        self.eval_step += 1
-
     def on_batch_end(self, data: Data) -> None:
         for key in self.inputs:
             if key in data:
                 self.eval_results[key][self.system.ds_id].append(data[key])
 
-        if self.system.mode == "eval" and self.eval_step in self.system.eval_log_steps:
-            if self.eval_step > 1:
+        self.eval_steps[self.system.ds_id] += 1
+        if self.eval_steps[self.system.ds_id] in self.system.eval_log_steps[0]:
+            if self.eval_steps[self.system.ds_id] > 1:
                 elapsed_time = time.perf_counter() - self.step_start
-                elapsed_step = self.eval_step - self.elapsed_step
+                elapsed_step = self.eval_steps[self.system.ds_id] - self.elapsed_step
                 data.write_with_log("steps/sec", round(elapsed_step / elapsed_time, 2))
-            self.elapsed_step = self.eval_step
+            self.elapsed_step = self.eval_steps[self.system.ds_id]
             self.step_start = time.perf_counter()
 
     def on_epoch_end(self, data: Data) -> None:
         for key, ds_vals in self.eval_results.items():
             for ds_id, vals in ds_vals.items():
                 if ds_id != '':
                     d = DSData(ds_id, data)
@@ -285,42 +286,41 @@
 
 @traceable()
 class Logger(Trace):
     """A Trace that prints log messages.
 
     Please don't add this trace into an estimator manually. FastEstimator will add it automatically.
     """
-
     def __init__(self) -> None:
         super().__init__(inputs="*")
+        self.eval_steps = defaultdict(lambda: 0)
 
     def on_begin(self, data: Data) -> None:
         if not self.system.mode == "test":
             start_step = 1 if not self.system.global_step else self.system.global_step
             self._print_message("FastEstimator-Start: step: {}; ".format(start_step), data)
 
-    def on_epoch_begin(self, data: Data) -> None:
-        if self.system.mode == 'eval':
-            self.eval_step = 0
-
     def on_batch_end(self, data: Data) -> None:
         if self.system.mode == "train" and self.system.log_steps and (self.system.global_step % self.system.log_steps
                                                                       == 0 or self.system.global_step == 1):
             self._print_message("FastEstimator-Train: step: {}; ".format(self.system.global_step), data)
 
         if self.system.mode == "eval":
-            self.eval_step += 1
-            if self.eval_step in self.system.eval_log_steps:
-                self._print_message("Eval Progress: {}/{}; ".format(self.eval_step, self.system.eval_log_steps[-1]),
+            self.eval_steps[self.system.ds_id] += 1
+            step = self.eval_steps[self.system.ds_id]
+            if step in self.system.eval_log_steps[0]:
+                ds_str = f" ({self.system.ds_id})" if self.system.ds_id else ''
+                self._print_message(f"Eval Progress{ds_str}: {step}/{self.system.eval_log_steps[1]}; ",
                                     data)
 
     def on_epoch_end(self, data: Data) -> None:
         if self.system.mode == "train":
             self._print_message("FastEstimator-Train: step: {}; ".format(self.system.global_step), data, True)
         elif self.system.mode == 'eval':
+            self.eval_steps.clear()
             self._print_message("FastEstimator-Eval: step: {}; ".format(self.system.global_step), data, True)
         elif self.system.mode == "test":
             self._print_message("FastEstimator-Test: step: {}; ".format(self.system.global_step), data, True)
 
     def on_end(self, data: Data) -> None:
         if not self.system.mode == "test":
             self._print_message("FastEstimator-Finish: step: {}; ".format(self.system.global_step), data)
@@ -443,7 +443,42 @@
         """Runs at the beginning of each dataset.
 
         Args:
             data: A dictionary through which traces can communicate with each other. Output here will be accumulated
                 across all available datasets and then logged during on_epoch_end.
         """
         pass
+
+
+Freq = namedtuple('Freq', ['is_step', 'freq'])
+
+
+def parse_freq(freq: Union[None, str, int]) -> Freq:
+    """A helper function to convert string based frequency inputs into epochs or steps
+
+    Args:
+        freq: One of either None, "step", "epoch", "#s", "#e", or #, where # is an integer.
+
+    Returns:
+        A `Freq` object recording whether the trace should run on an epoch basis or a step basis, as well as the
+        frequency with which it should run.
+    """
+    if freq is None:
+        return Freq(False, 0)
+    if isinstance(freq, int):
+        if freq < 1:
+            raise ValueError(f"Frequency argument must be a positive integer but got {freq}")
+        return Freq(True, freq)
+    if isinstance(freq, str):
+        if freq in {'step', 's'}:
+            return Freq(True, 1)
+        if freq in {'epoch', 'e'}:
+            return Freq(False, 1)
+        parts = re.match(r"^([0-9]+)([se])$", freq)
+        if parts is None:
+            raise ValueError(f"Frequency argument must be formatted like <int><s|e> but got {freq}")
+        freq = int(parts[1])
+        if freq < 1:
+            raise ValueError(f"Frequency argument must be a positive integer but got {freq}")
+        return Freq(parts[2] == 's', freq)
+    else:
+        raise ValueError(f"Unrecognized type passed as frequency: {type(freq)}")
```

### Comparing `fastestimator-1.5.2/fastestimator/trace/xai/__init__.py` & `fastestimator-1.6.0/fastestimator/trace/xai/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/xai/eigen_cam.py` & `fastestimator-1.6.0/fastestimator/trace/xai/eigen_cam.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/xai/grad_cam.py` & `fastestimator-1.6.0/fastestimator/trace/xai/grad_cam.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/xai/instance_tracker.py` & `fastestimator-1.6.0/fastestimator/trace/xai/instance_tracker.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/xai/label_tracker.py` & `fastestimator-1.6.0/fastestimator/trace/xai/label_tracker.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/trace/xai/saliency.py` & `fastestimator-1.6.0/fastestimator/trace/xai/saliency.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/util/__init__.py` & `fastestimator-1.6.0/fastestimator/util/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -20,32 +20,36 @@
                                             submod_attrs={'data': ['Data'],
                                                           'img_data': ['ImageDisplay', 'BatchDisplay', 'GridDisplay'],
                                                           'latex_util': ['AdjustBox', 'Center', 'ContainerList',
                                                                          'HrefFEID', 'PyContainer', 'Verbatim'],
                                                           'traceability_util': ['FeSplitSummary', 'trace_model',
                                                                                 'traceable'],
                                                           'base_util': ['to_set', 'to_list', 'param_to_range',
-                                                                        'NonContext', 'Suppressor', 'LogSplicer',
+                                                                        'NonContext', 'LogSplicer', 'IfElse',
                                                                         'prettify_metric_name', 'strip_suffix',
                                                                         'strip_prefix', 'get_type', 'check_io_names',
-                                                                        'parse_modes', 'check_ds_id', 'is_number',
-                                                                        'DefaultKeyDict', 'FEID', 'Flag', 'in_notebook',
-                                                                        'get_shape', 'get_colors', 'list_files'],
-                                                          'util': ['Timer', 'cpu_count', 'draw', 'get_batch_size',
-                                                                   'get_num_devices', 'pad_batch', 'pad_data',
-                                                                   'to_number'],
+                                                                        'filter_nones', 'parse_modes', 'check_ds_id',
+                                                                        'is_number', 'DefaultKeyDict', 'FEID', 'Flag',
+                                                                        'in_notebook', 'get_shape', 'get_colors',
+                                                                        'list_files', 'warn'],
+                                                          'util': ['Suppressor', 'Timer', 'cpu_count', 'draw',
+                                                                   'get_batch_size', 'get_device', 'get_num_devices',
+                                                                   'get_num_gpus', 'pad_batch', 'pad_data',
+                                                                   'to_number', 'move_tensors_to_device',
+                                                                   'detach_tensors', 'is_valid_file'],
                                                           'cli_util': ['parse_string_to_python'],
                                                           'wget_util': ['bar_custom', 'callback_progress']
                                                           })
 
 if TYPE_CHECKING:
+    from fastestimator.util.base_util import FEID, DefaultKeyDict, Flag, IfElse, LogSplicer, NonContext, check_ds_id, \
+        check_io_names, filter_nones, get_colors, get_shape, get_type, in_notebook, is_number, list_files, \
+        param_to_range, parse_modes, prettify_metric_name, strip_prefix, strip_suffix, to_list, to_set, warn
+    from fastestimator.util.cli_util import parse_string_to_python
     from fastestimator.util.data import Data
-    from fastestimator.util.img_data import ImageDisplay, BatchDisplay, GridDisplay
+    from fastestimator.util.img_data import BatchDisplay, GridDisplay, ImageDisplay
     from fastestimator.util.latex_util import AdjustBox, Center, ContainerList, HrefFEID, PyContainer, Verbatim
     from fastestimator.util.traceability_util import FeSplitSummary, trace_model, traceable
-    from fastestimator.util.base_util import to_set, to_list, param_to_range, NonContext, Suppressor, LogSplicer, \
-        prettify_metric_name, strip_suffix, strip_prefix, get_type, check_io_names, parse_modes, check_ds_id, \
-        is_number, DefaultKeyDict, FEID, Flag, in_notebook, get_shape, get_colors, list_files
-    from fastestimator.util.cli_util import parse_string_to_python
-    from fastestimator.util.util import Timer, cpu_count, draw, get_batch_size, get_num_devices, pad_batch, pad_data, \
+    from fastestimator.util.util import Suppressor, Timer, cpu_count, detach_tensors, draw, get_batch_size, \
+        get_device, get_num_devices, get_num_gpus, is_valid_file, move_tensors_to_device, pad_batch, pad_data, \
         to_number
     from fastestimator.util.wget_util import bar_custom, callback_progress
```

### Comparing `fastestimator-1.5.2/fastestimator/util/base_util.py` & `fastestimator-1.6.0/fastestimator/util/util.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,682 +1,565 @@
-# Copyright 2022 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2019 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
-# DO NOT IMPORT FE, TF, Torch, Numpy, Seaborn, OR Matplotlib IN THIS FILE
-import colorsys
+"""Utilities for FastEstimator."""
+import atexit
 import os
 import re
-import string
+import shutil
+import subprocess
 import sys
-from typing import Any, Set, KeysView, List, Union, Tuple, Optional, Type, TypeVar, Dict, Callable
-# DO NOT IMPORT FE, TF, Torch, Numpy, Seaborn, OR Matplotlib IN THIS FILE
-from plotly.graph_objs import Figure
-# DO NOT IMPORT FE, TF, Torch, Numpy, Seaborn, OR Matplotlib IN THIS FILE
-
-KT = TypeVar('KT')  # Key type.
-VT = TypeVar('VT')  # Value type.
-
-
-def to_set(data: Any) -> Set[Any]:
-    """Convert data to a set. A single None value will be converted to the empty set.
-
-    ```python
-    x = fe.util.to_set(None)  # set()
-    x = fe.util.to_set([None])  # {None}
-    x = fe.util.to_set(7)  # {7}
-    x = fe.util.to_set([7, 8])  # {7,8}
-    x = fe.util.to_set({7})  # {7}
-    x = fe.util.to_set((7))  # {7}
-    ```
-
-    Args:
-        data: Input data, within or without a python container. The `data` must be hashable.
-
-    Returns:
-        The input `data` but inside a set instead of whatever other container type used to hold it.
-    """
-    if data is None:
-        return set()
-    if not isinstance(data, set):
-        if isinstance(data, (tuple, list, KeysView)):
-            data = set(data)
-        else:
-            data = {data}
-    return data
-
-
-def to_list(data: Any) -> List[Any]:
-    """Convert data to a list. A single None value will be converted to the empty list.
-
-    ```python
-    x = fe.util.to_list(None)  # []
-    x = fe.util.to_list([None])  # [None]
-    x = fe.util.to_list(7)  # [7]
-    x = fe.util.to_list([7, 8])  # [7,8]
-    x = fe.util.to_list({7})  # [7]
-    x = fe.util.to_list((7))  # [7]
-    x = fe.util.to_list({'a': 7})  # [{'a': 7}]
-    ```
-
-    Args:
-        data: Input data, within or without a python container.
-
-    Returns:
-        The input `data` but inside a list instead of whatever other container type used to hold it.
-    """
-    if data is None:
-        return []
-    if not isinstance(data, list):
-        if isinstance(data, (tuple, set)):
-            data = list(data)
-        else:
-            data = [data]
-    return data
-
-
-def param_to_range(
-        data: Union[int, float, Tuple[int, int], Tuple[float, float]]) -> Union[Tuple[int, int], Tuple[float, float]]:
-    """Convert a single int or float value to a tuple signifying a range.
-
-    ```python
-    x = fe.util.param_to_tuple(7)  # (-7, 7)
-    x = fe.util.param_to_tuple([7, 8])  # (7,8))
-    x = fe.util.param_to_tuple((3.1, 4.3))  # (3.1, 4.3)
-    x = fe.util.to_set((-3.2))  # (-3.2, 3.2)
-    ```
-
-    Args:
-        data: Input data.
-
-    Returns:
-        The input `data` but in tuple form for a range.
-    """
-    if isinstance(data, (int, float)):
-        if data > 0:
-            data = -data, data
-        else:
-            data = data, -data
-    elif isinstance(data, (list, tuple)):
-        data = tuple(data)
-
-    return data
+import tempfile
+import time
+from contextlib import ContextDecorator
+from functools import lru_cache
+from pathlib import Path
+from typing import Any, Dict, List, MutableMapping, Optional, Tuple, Type, TypeVar, Union
+
+import numpy as np
+import tensorflow as tf
+import torch
+import torch.backends.mps
+from cpuinfo import get_cpu_info
+from pyfiglet import Figlet
+from tensorflow.python.ops.logging_ops import print_v2
+
+from fastestimator.util.base_util import warn
+
+STRING_TO_TORCH_DTYPE = {
+    None: None,
+    'float32': torch.float32,
+    'float': torch.float,
+    'float64': torch.float64,
+    'double': torch.double,
+    'float16': torch.float16,
+    'half': torch.half,
+    'uint8': torch.uint8,
+    'int8': torch.int8,
+    'int16': torch.int16,
+    'short': torch.short,
+    'int32': torch.int32,
+    'int': torch.int,
+    'int64': torch.int64,
+    'long': torch.long,
+    'bool': torch.bool
+}
+
+STRING_TO_TF_DTYPE = {
+    None: None,
+    "string": tf.string,
+    "int8": tf.int8,
+    "uint8": tf.uint8,
+    "int16": tf.int16,
+    "uint16": tf.uint16,
+    "int32": tf.int32,
+    "uint32": tf.uint32,
+    "int64": tf.int64,
+    "uint64": tf.uint64,
+    "float16": tf.float16,
+    "float32": tf.float32,
+    "float64": tf.float64
+}
+
+TENSOR_TO_NP_DTYPE = {
+    # Abstract types like 'float' and 'long' are intentionally not included here since they are never actually a
+    # tensor's dtype and they interfere with the finer-grained keys (torch.float intercepts torch.float32, for example)
+    None: None,
+    torch.float32: np.float32,
+    torch.float64: np.float64,
+    torch.float16: np.float16,
+    torch.uint8: np.uint8,
+    torch.int8: np.int8,
+    torch.int16: np.int16,
+    torch.int32: np.int32,
+    torch.int64: np.int64,
+    torch.bool: bool,
+    tf.float32: np.float32,
+    tf.float64: np.float64,
+    tf.float16: np.float16,
+    tf.uint8: np.uint8,
+    tf.int8: np.int8,
+    tf.int16: np.int16,
+    tf.int32: np.int32,
+    tf.int64: np.int64,
+    tf.bool: bool,
+    np.dtype('float32'): np.float32,
+    np.dtype('float64'): np.float64,
+    np.dtype('float16'): np.float16,
+    np.dtype('uint8'): np.uint8,
+    np.dtype('int8'): np.int8,
+    np.dtype('int16'): np.int16,
+    np.dtype('int32'): np.int32,
+    np.dtype('int64'): np.int64,
+    np.dtype('bool'): bool,
+}
 
-
-class NonContext(object):
-    """A class which is used to make nothing unusual happen.
-
-    This class is intentionally not @traceable.
-
-    ```python
-    a = 5
-    with fe.util.NonContext():
-        a = a + 37
-    print(a)  # 42
-    ```
-    """
-
-    def __enter__(self) -> None:
-        pass
-
-    def __exit__(self, *exc: Tuple[Optional[Type], Optional[Exception], Optional[Any]]) -> None:
-        pass
+Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
+T = TypeVar('T')
 
 
 class Suppressor(object):
     """A class which can be used to silence output of function calls.
 
     This class is intentionally not @traceable.
 
     Args:
         allow_pyprint: Whether to allow python printing to occur still within this scope (and therefore only silence
             printing from non-python sources like c).
+        show_if_exception: Whether to retroactively show print messages if an exception is raised from within the
+            suppressor scope.
 
     ```python
     x = lambda: print("hello")
     x()  # "hello"
     with fe.util.Suppressor():
         x()  #
     x()  # "hello"
     ```
     """
-    def __init__(self, allow_pyprint: bool = False):
+    # Only create one file to save on disk IO
+    stash_fd, stash_name = tempfile.mkstemp()
+    os.close(stash_fd)
+    tf_print_fd, tf_print_name = tempfile.mkstemp()
+    os.close(tf_print_fd)
+    tf_print_name_f = 'file://' + tf_print_name
+
+    def __init__(self, allow_pyprint: bool = False, show_if_exception: bool = False):
         self.allow_pyprint = allow_pyprint
+        self.show_if_exception = show_if_exception
 
     def __enter__(self) -> None:
         # This is not necessary to block printing, but lets the system know what's happening
         self.py_reals = [sys.stdout, sys.stderr]
         sys.stdout = sys.stderr = self
         # This part does the heavy lifting
-        self.fakes = [os.open(os.devnull, os.O_RDWR), os.open(os.devnull, os.O_RDWR)]
+        if self.show_if_exception:
+            self.fake = os.open(self.stash_name, os.O_RDWR)
+        else:
+            self.fake = os.open(os.devnull, os.O_RDWR)
         self.reals = [os.dup(1), os.dup(2)]  # [stdout, stderr]
-        os.dup2(self.fakes[0], 1)
-        os.dup2(self.fakes[1], 2)
+        os.dup2(self.fake, 1)
+        os.dup2(self.fake, 2)
+        # This avoids "OSError: [WinError 6] The handle is invalid" while logging tensorflow information in windows
+        for handler in tf.get_logger().handlers:
+            handler.setStream(sys.stderr)
+        if self.allow_pyprint:
+            tf.print = _custom_tf_print
 
     def __exit__(self, *exc: Tuple[Optional[Type], Optional[Exception], Optional[Any]]) -> None:
+        # If there was an error, display any print messages
+        if exc[0] is not None and self.show_if_exception and not isinstance(exc[1],
+                                                                            (StopIteration, StopAsyncIteration)):
+            for line in open(self.stash_name):
+                os.write(self.reals[0], line.encode('utf-8'))
+        # Set the print pointers back
         os.dup2(self.reals[0], 1)
         os.dup2(self.reals[1], 2)
-        for fd in self.fakes + self.reals:
-            os.close(fd)
         # Set the python pointers back too
         sys.stdout, sys.stderr = self.py_reals[0], self.py_reals[1]
 
+        for handler in tf.get_logger().handlers:
+            handler.setStream(sys.stderr)
+
+        # Clean up the descriptors
+        for fd in self.reals:
+            os.close(fd)
+        os.close(self.fake)
+        if self.show_if_exception:
+            # Clear the file
+            open(self.stash_name, 'w').close()
+        if self.allow_pyprint:
+            tf.print = print_v2
+            with open(self.tf_print_name, 'r') as f:
+                for line in f:
+                    print(line, end='')  # Endings already included from tf.print
+            open(self.tf_print_name, 'w').close()
+
     def write(self, dummy: str) -> None:
         """A function which is invoked during print calls.
 
         Args:
             dummy: The string which wanted to be printed.
         """
         if self.allow_pyprint:
             os.write(self.reals[0], dummy.encode('utf-8'))
+        elif self.show_if_exception:
+            os.write(self.fake, dummy.encode('utf-8'))
 
     def flush(self) -> None:
         """A function to empty the current print buffer. No-op in this case.
         """
 
+    @staticmethod
+    @atexit.register
+    def teardown() -> None:
+        """Clean up the stash files when the program exists
+        """
+        try:
+            os.remove(Suppressor.stash_name)
+            os.remove(Suppressor.tf_print_name)
+        except FileNotFoundError:
+            pass
 
-class LogSplicer:
-    """A class to send stdout information into a file before passing it along to the normal stdout.
-
-    Args:
-        log_path: The path/filename into which to append the current stdout.
-    """
-
-    def __init__(self, log_path: str):
-        self.log_path = log_path
-        self.stdout = None
-        self.log_file = None
-
-    def __enter__(self) -> None:
-        self.log_file = open(self.log_path, 'a')
-        self.stdout = sys.stdout
-        sys.stdout = self
-
-    def __exit__(self, *exc: Tuple[Optional[Type], Optional[Exception], Optional[Any]]) -> None:
-        sys.stdout = self.stdout
-        self.log_file.close()
-
-    def write(self, output: str) -> None:
-        self.log_file.write(output)
-        self.stdout.write(output)
-
-    def flush(self) -> None:
-        self.stdout.flush()
-        self.log_file.flush()
 
-    def getvalue(self) -> str:
-        return self.stdout.getvalue()
+def _custom_tf_print(*args, **kwargs):
+    kwargs['output_stream'] = Suppressor.tf_print_name_f
+    print_v2(*args, **kwargs)
 
 
-def prettify_metric_name(metric: str) -> str:
-    """Add spaces to camel case words, then swap _ for space, and capitalize each word.
-
-    ```python
-    x = fe.util.prettify_metric_name("myUgly_loss")  # "My Ugly Loss"
-    ```
+def is_valid_file(file_path: str) -> bool:
+    """Validate whether file is valid or not.
 
     Args:
-        metric: A string to be formatted.
+        file_path: location of the input file.
 
     Returns:
-        The formatted version of 'metric'.
+        Whether the file is valid.
     """
-    return string.capwords(re.sub("([a-z])([A-Z])", r"\g<1> \g<2>", metric).replace("_", " "))
+    if not os.path.exists(file_path):
+        return False
+    suffix = Path(file_path).suffix
+    try:
+        if suffix == '.zip':
+            import zipfile
+            zip_file = zipfile.ZipFile(file_path)
+            _ = zip_file.namelist()
+        elif suffix == '.gz':
+            if file_path.endswith('.tar.gz'):
+                import tarfile
+                with tarfile.open(file_path) as img_tar:
+                    _ = img_tar.getmembers()
+            else:
+                import gzip
+                f = gzip.open(file_path, 'rb')
+                _ = f.read()
+        return True
+    except Exception as e:
+        print(e)
+        return False
+
 
+class Timer(ContextDecorator):
+    """A class that can be used to time things.
 
-def strip_suffix(target: Optional[str], suffix: Optional[str]) -> Optional[str]:
-    """Remove the given `suffix` from the `target` if it is present there.
+    This class is intentionally not @traceable.
 
     ```python
-    x = fe.util.strip_suffix("astring.json", ".json")  # "astring"
-    x = fe.util.strip_suffix("astring.json", ".yson")  # "astring.json"
-    ```
+    x = lambda: list(map(lambda i: i + i/2, list(range(int(1e6)))))
+    with fe.util.Timer():
+        x()  # Task took 0.1639 seconds
+    @fe.util.Timer("T2")
+    def func():
+        return x()
+    func()  # T2 took 0.14819 seconds
+    ```
+    """
+    def __init__(self, name="Task") -> None:
+        self.name = name
+        self.start = None
+        self.end = None
+        self.interval = None
+
+    def __enter__(self) -> 'Timer':
+        self.start = time.perf_counter()
+        return self
 
-    Args:
-        target: A string to be formatted.
-        suffix: A string to be removed from `target`.
+    def __exit__(self, *exc: Tuple[Optional[Type], Optional[Exception], Optional[Any]]) -> None:
+        self.end = time.perf_counter()
+        self.interval = self.end - self.start
+        tf.print("{} took {} seconds".format(self.name, self.interval))
 
-    Returns:
-        The formatted version of `target`.
+
+def draw() -> None:
+    """Print our name.
     """
-    if suffix is None or target is None:
-        return target
-    s_len = len(suffix)
-    if target[-s_len:] == suffix:
-        return target[:-s_len]
-    return target
+    print(Figlet(font="slant").renderText("FastEstimator"))
 
 
-def strip_prefix(target: Optional[str], prefix: Optional[str]) -> Optional[str]:
-    """Remove the given `prefix` from the `target` if it is present there.
+def pad_batch(batch: List[MutableMapping[str, np.ndarray]], pad_value: Union[float, int]) -> None:
+    """A function to pad a batch of data in-place by appending to the ends of the tensors. Tensor type needs to be
+    numpy array otherwise would get ignored. (tf.Tensor and torch.Tensor will cause error)
 
     ```python
-    x = fe.util.strip_prefix("astring.json", "ast")  # "ring.json"
-    x = fe.util.strip_prefix("astring.json", "asa")  # "astring.json"
+    data = [{"x": np.ones((2, 2)), "y": 8}, {"x": np.ones((3, 1)), "y": 4}]
+    fe.util.pad_batch(data, pad_value=0)
+    print(data)  # [{'x': [[1., 1.], [1., 1.], [0., 0.]], 'y': 8}, {'x': [[1., 0.], [1., 0.], [1., 0.]]), 'y': 4}]
     ```
 
     Args:
-        target: A string to be formatted.
-        prefix: A string to be removed from `target`.
+        batch: A list of data to be padded.
+        pad_value: The value to pad with.
 
-    Returns:
-        The formatted version of `target`.
+    Raises:
+        AssertionError: If the data within the batch do not have matching rank, or have different keys
     """
-    if prefix is None or target is None:
-        return target
-    s_len = len(prefix)
-    if target[:s_len] == prefix:
-        return target[s_len:]
-    return target
+    keys = batch[0].keys()
+    for one_batch in batch:
+        assert one_batch.keys() == keys, "data within batch must have same keys"
 
+    for key in keys:
+        shapes = [data[key].shape for data in batch if hasattr(data[key], "shape")]
+        if len(set(shapes)) > 1:
+            assert len(set(len(shape) for shape in shapes)) == 1, "data within batch must have same rank"
+            max_shapes = tuple(np.max(np.array(shapes), axis=0))
+            for data in batch:
+                data[key] = pad_data(data[key], max_shapes, pad_value)
 
-def get_type(obj: Any) -> str:
-    """A function to try and infer the types of data within containers.
 
-    ```python
-    x = fe.util.get_type(np.ones((10, 10), dtype='int32'))  # "int32"
-    x = fe.util.get_type(tf.ones((10, 10), dtype='float16'))  # "<dtype: 'float16'>"
-    x = fe.util.get_type(torch.ones((10, 10)).type(torch.float))  # "torch.float32"
-    x = fe.util.get_type([np.ones((10,10)) for i in range(4)])  # "List[float64]"
-    x = fe.util.get_type(27)  # "int"
-    ```
-
-    For container to look into its element's type, its type needs to be either list or tuple, and the return string will
-    be List[...]. All container elements need to have the same data type becuase it will only check its first element.
+def pad_data(data: np.ndarray, target_shape: Tuple[int, ...], pad_value: Union[float, int]) -> np.ndarray:
+    """Pad `data` by appending `pad_value`s along it's dimensions until the `target_shape` is reached. All entries of
+    target_shape should be larger than the data.shape, and have the same rank.
 
     ```python
-    x = fe.util.get_type({"a":1, "b":2})  # "dict"
-    x = fe.util.get_type([1, "a"]) # "List[int]"
-    x = fe.util.get_type([[[1]]]) # "List[List[List[int]]]"
+    x = np.ones((1,2))
+    x = fe.util.pad_data(x, target_shape=(3, 3), pad_value = -2)  # [[1, 1, -2], [-2, -2, -2], [-2, -2, -2]]
+    x = fe.util.pad_data(x, target_shape=(3, 3, 3), pad_value = -2) # error
+    x = fe.util.pad_data(x, target_shape=(4, 1), pad_value = -2) # error
     ```
 
     Args:
-        obj: Data which may be wrapped in some kind of container.
+        data: The data to be padded.
+        target_shape: The desired shape for `data`. Should have the same rank as `data`, with each dimension being >=
+            the size of the `data` dimension.
+        pad_value: The value to insert into `data` if padding is required to achieve the `target_shape`.
 
     Returns:
-        A string representation of the data type of the `obj`.
+        The `data`, padded to the `target_shape`.
     """
-    if hasattr(obj, "dtype"):
-        result = str(obj.dtype)
-    elif isinstance(obj, (List, Tuple)):
-        if len(obj) > 0:
-            result = "List[{}]".format(get_type(obj[0]))
-        else:
-            result = strip_suffix(strip_prefix(str(type(obj)), "<class '"), "'>")
-    else:
-        result = strip_suffix(strip_prefix(str(type(obj)), "<class '"), "'>")
-    return result
-
+    shape_difference = np.array(target_shape) - np.array(data.shape)
+    padded_shape = np.array([np.zeros_like(shape_difference), shape_difference]).T
+    return np.pad(data, padded_shape, 'constant', constant_values=pad_value)
 
-def check_io_names(names: List[Optional[str]]) -> List[Optional[str]]:
-    forbidden_chars = {":", ";"}
-    for name in names:
-        assert not any(char in name for char in forbidden_chars), \
-            "inputs/outputs name cannot contain characters like ':', ';', found {}".format(name)
-        assert len(name) > 0, "inputs/outputs cannot be an empty string"
-        assert len(name.split('|')) < 3, f"inputs/outputs cannot contain more than one '|' character, found {name}"
-    return names
 
-
-def parse_modes(modes: Set[str]) -> Set[str]:
-    """A function to determine which modes to run on based on a set of modes potentially containing blacklist values.
-
-    ```python
-    m = fe.util.parse_modes({"train"})  # {"train"}
-    m = fe.util.parse_modes({"!train"})  # {"eval", "test", "infer"}
-    m = fe.util.parse_modes({"train", "eval"})  # {"train", "eval"}
-    m = fe.util.parse_modes({"!train", "!infer"})  # {"eval", "test"}
-    ```
+def move_tensors_to_device(data: T, device: Union[str, torch.device]) -> T:
+    """Move torch tensor (collections) between gpu and cpu recursively.
 
     Args:
-        modes: The desired modes to run on (possibly containing blacklisted modes).
+        data: The input data to be moved.
+        device: The target device.
 
     Returns:
-        The modes to run on (converted to a whitelist).
-
-    Raises:
-        AssertionError: If invalid modes are detected, or if blacklisted modes and whitelisted modes are mixed.
+        Output data.
     """
-    valid_fields = {"train", "eval", "test", "infer", "!train", "!eval", "!test", "!infer"}
-    assert modes.issubset(valid_fields), "Invalid modes argument {}".format(modes - valid_fields)
-    negation = set([mode.startswith("!") for mode in modes])
-    assert len(negation) < 2, "cannot mix !mode with mode, found {}".format(modes)
-    if True in negation:
-        new_modes = {"train", "eval", "test", "infer"}
-        for mode in modes:
-            new_modes.discard(mode.strip("!"))
-        modes = new_modes
-    return modes
-
-
-def check_ds_id(ds_ids: Set[str]) -> Set[str]:
-    """A function to check whether ds_ids inputs are correct inputs.
+    if isinstance(data, dict):
+        return {key: move_tensors_to_device(value, device) for (key, value) in data.items()}
+    elif isinstance(data, list):
+        return [move_tensors_to_device(val, device) for val in data]
+    elif isinstance(data, tuple):
+        return tuple([move_tensors_to_device(val, device) for val in data])
+    elif isinstance(data, set):
+        return set([move_tensors_to_device(val, device) for val in data])
+    elif isinstance(data, torch.Tensor):
+        return data.to(device)
+    else:
+        return data
 
-    ds_ids should either be defined through whitelist, like {"ds1", "ds2"} or blacklist, like {"!ds1", "!ds2"}.
 
-    ```python
-    m = fe.util.parse_ds_id({"ds1"})  # {"ds1"}
-    m = fe.util.parse_ds_id({"!ds1"})  # {"!ds1"}
-    m = fe.util.parse_ds_id({"ds1", "ds2"})  # {"ds1", "ds2"}
-    m = fe.util.parse_ds_id({"!ds1", "!ds2"})  # {"!ds1", "!ds2"}
-    m = fe.util.parse_ds_id({"!ds1", "ds2"})  # Raises Assertion
-    ```
+def detach_tensors(data: T) -> T:
+    """Detach tensor (collections) from current graph recursively.
 
     Args:
-        ds_ids: The desired ds_id to run on (possibly containing blacklisted ds_ids).
+        data: The data to be detached.
 
     Returns:
-        The ds_ids to run or to avoid.
-
-    Raises:
-        AssertionError: if blacklisted modes and whitelisted modes are mixed.
+        Output data.
     """
-    negation = set([ds_id.startswith("!") for ds_id in ds_ids])
-    assert len(negation) < 2, "cannot mix !ds_id with ds_id, found {}".format(ds_ids)
-    forbidden_ds_id_chars = {":", ";", "|"}
-    for ds_id in ds_ids:
-        assert isinstance(ds_id, str) and len(ds_id) > 0, "dataset id must be a string, found {}".format(ds_id)
-        assert not any(char in ds_id for char in forbidden_ds_id_chars), \
-            "dataset id should not contain forbidden characters like ':', ';', '|', found {}".format(ds_id)
-    return ds_ids
+    if isinstance(data, dict):
+        return {key: detach_tensors(value) for (key, value) in data.items()}
+    elif isinstance(data, list):
+        return [detach_tensors(val) for val in data]
+    elif isinstance(data, tuple):
+        return tuple([detach_tensors(val) for val in data])
+    elif isinstance(data, set):
+        return set([detach_tensors(val) for val in data])
+    elif isinstance(data, torch.Tensor):
+        return data.detach()
+    return data
 
 
-def is_number(arg: str) -> bool:
-    """Check if a given string can be converted into a number.
-
-    ```python
-    x = fe.util.is_number("13.7")  # True
-    x = fe.util.is_number("ae13.7")  # False
-    ```
-
-    Args:
-        arg: A potentially numeric input string.
+@lru_cache()
+def get_device() -> torch.device:
+    """Get the torch device for the current hardware.
 
     Returns:
-        True iff `arg` represents a number.
+        The torch device most appropriate for the current hardware.
     """
-    try:
-        float(arg)
-        return True
-    except (ValueError, TypeError):
-        return False
-
+    if torch.backends.mps.is_available():
+        device = torch.device("mps")
+    elif torch.cuda.is_available():
+        device = torch.device("cuda:0")
+    else:
+        device = torch.device("cpu")
+    return device
 
-class DefaultKeyDict(Dict[KT, VT]):
-    """Like collections.defaultdict but it passes the key argument to the default function.
 
-    This class is intentionally not @traceable.
+@lru_cache()
+def get_num_gpus() -> int:
+    """Get the number of GPUs available.
 
-    ```python
-    d = fe.util.DefaultKeyDict(default=lambda x: x+x, a=4, b=6)
-    print(d["a"])  # 4
-    print(d["c"])  # "cc"
-    ```
-
-    Args:
-        default: A function which takes a key and returns a default value based on the key.
-        **kwargs: Initial key/value pairs for the dictionary.
+    Returns:
+        The number of GPUs available.
     """
+    if torch.backends.mps.is_available():
+        return 1
+    elif torch.cuda.is_available():
+        return torch.cuda.device_count()
+    else:
+        return 0
 
-    def __init__(self, default: Callable[[Any], Any], **kwargs) -> None:
-        super().__init__(**kwargs)
-        self.factory = default
-
-    def __missing__(self, key: Any) -> Any:
-        res = self[key] = self.factory(key)
-        return res
-
-
-class FEID:
-    """An int wrapper class that can change how it's values are printed.
 
-    This class is intentionally not @traceable.
+@lru_cache()
+def get_gpu_info() -> List[str]:
+    """Get summaries of all of the GPUs accessible on this machine.
 
-    Args:
-        val: An integer id to be wrapped.
+    Returns:
+        A formatted summary of the GPUs available on the machine (one list entry per GPU).
     """
-    __slots__ = ['_val']
-    _translation_dict = {}
+    if shutil.which('nvidia-smi') is not None:
+        nvidia_command = ['nvidia-smi', '--query-gpu=gpu_name,memory.total,driver_version', '--format=csv']
+        output = subprocess.check_output(nvidia_command)
+        output = output.decode('utf-8')
+        lines = output.strip().split(os.linesep)[1:]
+        names = []
+        for line in lines:
+            name, mem, driver = line.strip().split(',')
+            names.append(f"{name.strip()} ({mem.strip()}, Driver={driver.strip()})")
+        return names
+    elif torch.backends.mps.is_available():
+        output = subprocess.check_output(["ioreg", "-l"])
+        output = output.decode('utf-8')
+        core_count = re.search(r'"gpu-core-count"[ ]*=[ ]*(\d*)', output)
+        core_count = "???" if not core_count else core_count.group(1)
+        output = subprocess.check_output(["sysctl", "-n", "hw.memsize"])
+        output = output.decode('utf-8')
+        gpu_mem = f"{float(output)*1e-9:0.2f} GB"  # Convert from bytes to GB
+        return [f"{get_cpu_info()['brand_raw']} ({gpu_mem}, {core_count} Cores)"]  # On mac the CPU name is the GPU name
+    return []
 
-    def __init__(self, val: int):
-        self._val = val
 
-    def __hash__(self) -> int:
-        return hash(self._val)
+@lru_cache()
+def get_num_devices() -> int:
+    """Determine the number of available GPUs.
 
-    def __eq__(self, other: Any) -> bool:
-        if isinstance(other, FEID):
-            return self._val == other._val
-        else:
-            return int.__eq__(self._val, other)
-
-    def __lt__(self, other: Any) -> bool:
-        if isinstance(other, FEID):
-            other = other._val
-        return int.__lt__(self._val, other)
-
-    def __str__(self) -> str:
-        return f"{self._translation_dict.get(self._val, self._val)}"
-
-    def __repr__(self) -> str:
-        return f"{self._translation_dict.get(self._val, self._val)}"
-
-    @classmethod
-    def set_translation_dict(cls, mapping: Dict[int, Any]) -> None:
-        """Provide a lookup table to be invoked during value printing.
-
-        Args:
-            mapping: A mapping of id: printable id.
-        """
-        cls._translation_dict.clear()
-        cls._translation_dict.update(mapping)
-
-
-class Flag:
-    """A mutable wrapper around a boolean.
-
-    This class is intentionally not @traceable.
-
-    Args:
-        val: The initial value for the Flag.
+    Returns:
+        The number of available GPUs, or 1 if none are found.
     """
-    __slots__ = ['_val']
-
-    def __init__(self, val: bool = False):
-        self._val = val
-
-    def set_true(self):
-        self._val = True
+    return max(torch.cuda.device_count(), 1)
 
-    def set_false(self):
-        self._val = False
 
-    def __bool__(self):
-        return self._val
+@lru_cache()
+def cpu_count(limit: Optional[int] = None) -> int:
+    """Determine the number of available CPUs (correcting for docker container limits).
 
-
-def in_notebook() -> bool:
-    """Determine whether the code is running inside a jupyter notebook
+    Args:
+        limit: If provided, the TF and Torch backends will be told to use `limit` number of threads, or the available
+            number of cpus if the latter is lower (`limit` cannot raise the number of threads). A limit can only be
+            enforced once per python session, before starting anything like pipeline which requires multiprocessing.
 
     Returns:
-        True iff the code is executing inside a Jupyter notebook
+        The nuber of available CPUs (correcting for docker container limits), or the user provided `limit`.
+
+    Raises:
+        ValueError: If a `limit` is provided which doesn't match previously enforced limits.
     """
+    existing_limit = os.environ.get('FE_NUM_THREADS_', None)  # This variable is used internally to indicate whether cpu
+    # limits have already been enforced in this python session
+    if existing_limit:
+        try:
+            existing_limit = int(existing_limit)
+        except ValueError as err:
+            print("FastEstimator-Error: FE_NUM_THREADS_ is an internal variable. Use FE_NUM_THREADS (no underscore)")
+            raise err
+        if limit and limit != existing_limit:
+            raise ValueError(f"Tried to enforce a cpu limit of {limit}, but {existing_limit} was already set.")
+        return existing_limit
+    # Check if user provided an environment variable limit on the number of threads
+    env_limit = os.environ.get('FE_NUM_THREADS', None)  # User might set this one in a bash script
+    if env_limit:
+        try:
+            env_limit = int(env_limit)
+        except ValueError as err:
+            warn(f"FE_NUM_THREADS variable must be an integer, but was set to: {env_limit}")
+            raise err
     try:
-        from IPython import get_ipython
-        shell = get_ipython().__class__.__name__
-        if shell == 'ZMQInteractiveShell':
-            return True  # Jupyter notebook or qtconsole
-        return False
-    except (ImportError, NameError):
-        return False
+        # In docker containers which have --cpuset-cpus, the limit won't be reflected by normal os.cpu_count() call
+        cores = len(os.sched_getaffinity(0))
+    except AttributeError:
+        # Running on Mac or Windows where the above method isn't available, so use the regular way
+        cores = os.cpu_count()
+    cores = min(cores, limit or cores, env_limit or cores)
+    if cores < 1:
+        raise ValueError(f"At least 1 core is required for training, but found {cores}")
+    os.environ['FE_NUM_THREADS_'] = f"{cores}"  # Remember the value so we don't try to re-set the frameworks later
+    os.environ['OMP_NUM_THREADS'] = f"{cores}"
+    os.environ['MKL_NUM_THREADS'] = f"{cores}"
+    os.environ['TF_NUM_INTEROP_THREADS'] = f"{cores}"
+    os.environ['TF_NUM_INTRAOP_THREADS'] = f"{cores}"
+    torch.set_num_threads(cores)
+    torch.set_num_interop_threads(cores)
+    return cores
 
 
-def get_shape(obj: Any) -> List[Optional[int]]:
-    """A function to find the shapes of an object or sequence of objects.
-
-    Lists or Tuples will assume that the zeroth dimension is ragged (shape==None). If entries in the list have
-    mismatched ranks, then only the list dimension will be considered as part of the shape. If all ranks are equal, an
-    attempt will be made to determine which of the interior dimensions are ragged.
-
-    ```python
-    x = fe.util.get_shape(np.ones((12,22,11)))  # [12, 22, 11]
-    x = fe.util.get_shape([np.ones((12,22,11)), np.ones((18, 5))])  # [None]
-    x = fe.util.get_shape([np.ones((12,22,11)), np.ones((18, 5, 4))])  # [None, None, None, None]
-    x = fe.util.get_shape([np.ones((12,22,11)), np.ones((12, 22, 4))])  # [None, 12, 22, None]
-    x = fe.util.get_shape({"a": np.ones((12,22,11))})  # []
-    ```
+def get_batch_size(data: Dict[str, Any]) -> int:
+    """Infer batch size from a batch dictionary. It will ignore all dictionary value with data type that
+    doesn't have "shape" attribute.
 
     Args:
-        obj: Data to infer the shape of.
+        data: The batch dictionary.
 
     Returns:
-        A list representing the shape of the data.
+        batch size.
     """
-    if hasattr(obj, "shape"):
-        result = list(obj.shape)
-    elif isinstance(obj, (List, Tuple)):
-        shapes = [get_shape(ob) for ob in obj]
-        result = [None]
-        if shapes:
-            rank = len(shapes[0])
-            if any((len(shape) != rank for shape in shapes)):
-                return result
-            result.extend(shapes[0])
-            for shape in shapes[1:]:
-                for idx, dim in enumerate(shape):
-                    if result[idx + 1] != dim:
-                        result[idx + 1] = None
-    else:
-        result = []
-    return result
+    assert isinstance(data, dict), "data input must be a dictionary"
+    batch_size = set(data[key].shape[0] for key in data if hasattr(data[key], "shape") and list(data[key].shape))
+    assert len(batch_size) == 1, "invalid batch size: {}".format(batch_size)
+    return batch_size.pop()
 
 
-def list_files(root_dir: str,
-               file_extension: Optional[str] = None,
-               recursive_search: bool = True) -> List[str]:
-    """Get the paths of all files in a particular root directory subject to a particular file extension.
+def to_number(data: Union[tf.Tensor, torch.Tensor, np.ndarray, int, float, str]) -> np.ndarray:
+    """Convert an input value into a Numpy ndarray.
 
-    Args:
-        root_dir: The path to the directory containing data.
-        file_extension: If provided then only files ending with the file_extension will be included.
-        recursive_search: Whether to search within subdirectories for files.
+    This method can be used with Python and Numpy data:
+    ```python
+    b = fe.backend.to_number(5)  # 5 (type==np.ndarray)
+    b = fe.backend.to_number(4.0)  # 4.0 (type==np.ndarray)
+    n = np.array([1, 2, 3])
+    b = fe.backend.to_number(n)  # [1, 2, 3] (type==np.ndarray)
+    ```
 
-    Returns:
-        A list of file paths found within the directory.
+    This method can be used with TensorFlow tensors:
+    ```python
+    t = tf.constant([1, 2, 3])
+    b = fe.backend.to_number(t)  # [1, 2, 3] (type==np.ndarray)
+    ```
 
-    Raises:
-        AssertionError: If the provided path isn't a directory.
-        ValueError: If the directory has an invalid structure.
-    """
-    paths = []
-    root_dir = os.path.normpath(root_dir)
-    if not os.path.isdir(root_dir):
-        raise AssertionError("Provided path is not a directory")
-    try:
-        for root, _, files in os.walk(root_dir):
-            for file_name in files:
-                if file_name.startswith(".") or (file_extension is not None
-                                                 and not file_name.endswith(file_extension)):
-                    continue
-                paths.append(os.path.join(root, file_name))
-            if not recursive_search:
-                break
-    except StopIteration:
-        raise ValueError("Invalid directory structure for DirDataset at root: {}".format(root_dir))
-    return paths
-
-
-def get_colors(n_colors: int,
-               alpha: float = 1.0,
-               as_numbers: bool = False) -> List[Union[str, Tuple[float, float, float, float]]]:
-    """Get a list of colors to use in plotting.
+    This method can be used with PyTorch tensors:
+    ```python
+    p = torch.tensor([1, 2, 3])
+    b = fe.backend.to_number(p)  # [1, 2, 3] (type==np.ndarray)
+    ```
 
     Args:
-        n_colors: How many colors to return.
-        alpha: What opacity value to use (0 to 1).
-        as_numbers: Whether to return the values as a list of numbers [r,g,b,a] or as a string
+        data: The value to be converted into a np.ndarray.
 
     Returns:
-        A list of rgba string colors.
-    """
-    if n_colors <= 10:
-        colors = [f'rgba(1,115,178,{alpha})', f'rgba(222,143,5,{alpha})', f'rgba(2,158,115,{alpha})',
-                  f'rgba(213,94,0,{alpha})', f'rgba(204,120,188,{alpha})', f'rgba(202,145,97,{alpha})',
-                  f'rgba(251,175,228,{alpha})', f'rgba(148,148,148,{alpha})', f'rgba(236,225,51,{alpha})',
-                  f'rgba(86,180,233,{alpha})']
-    else:
-        colors = [(i + 0.01) / n_colors for i in range(n_colors)]
-        colors = [color - 1 if color >= 1 else color for color in colors]
-        colors = [colorsys.hls_to_rgb(color, 0.6, 0.95) for color in colors]
-        colors = [f'rgba({int(256*r)},{int(256*g)},{int(256*b)},{alpha})' for r, g, b in colors]
-    colors = colors[:n_colors]
-    if as_numbers:
-        colors = [[float(x) for x in elem.strip('rgba(').strip(')').split(',')] for elem in colors]
-    return colors
-
-
-class FigureFE(Figure):
-    @classmethod
-    def from_figure(cls, fig: Figure) -> 'FigureFE':
-        new_fig = FigureFE()
-        new_fig.__dict__ = fig.__dict__.copy()
-        return new_fig
-
-    def show(self,
-             save_path: Optional[str] = None,
-             verbose: bool = True,
-             scale: int = 1,
-             interactive: bool = True) -> None:
-        """A function which will save or display plotly figures.
-
-        Args:
-            save_path: The path where the figure should be saved, or None to display the figure to the screen.
-            verbose: Whether to print out the save location.
-            scale: A scaling factor to apply when exporting to static images (to increase resolution).
-            interactive: Whether the figure should be interactive or static. This is only applicable when
-                save_path is None and when running inside a jupyter notebook. The advantage is that the file size of the
-                resulting jupyter notebook can be dramatically reduced.
-        """
-        config = {
-            'displaylogo': False,
-            'toImageButtonOptions': {
-                'format': 'png',  # one of png, svg, jpeg, webp
-                'height': None,
-                'width': None,
-                'filename': 'figure',
-                'scale': scale  # Multiply title/legend/axis/canvas sizes by this factor (high resolution save)
-            }}
-        if save_path is None:
-            if not interactive and in_notebook():
-                from IPython.display import Image, display
-                display(Image(self.to_image(format='png', scale=scale)))
-            else:
-                super().show(config=config)
+        An ndarray corresponding to the given `data`.
+    """
+    if tf.is_tensor(data):
+        data = data.numpy()
+    elif isinstance(data, torch.Tensor):
+        if data.requires_grad:
+            data = data.detach().numpy()
         else:
-            save_path = os.path.normpath(save_path)
-            root_dir = os.path.dirname(save_path)
-            if root_dir == "":
-                root_dir = "."
-            os.makedirs(root_dir, exist_ok=True)
-            save_file = os.path.join(root_dir, os.path.basename(save_path) or 'figure.html')
-            config['toImageButtonOptions']['filename'] = os.path.splitext(os.path.basename(save_file))[0]
-            ext = os.path.splitext(save_file)[1]
-            if ext == '':
-                ext = '.html'
-                save_file = save_file + ext  # Use html by default
-            if verbose:
-                print("Saving to {}".format(save_file))
-            if ext == '.html':
-                self.write_html(save_file, config=config)
-            else:
-                self.write_image(save_file, width=1920, height=1080, scale=scale)
+            data = data.numpy()
+    return np.array(data)
```

### Comparing `fastestimator-1.5.2/fastestimator/util/cli_util.py` & `fastestimator-1.6.0/fastestimator/util/cli_util.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/util/data.py` & `fastestimator-1.6.0/fastestimator/util/data.py`

 * *Files 22% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import Any, ChainMap, Dict, List, MutableMapping, Optional
+from typing import Any, ChainMap, List, MutableMapping, Optional
 
 
 class Data(ChainMap[str, Any]):
     """A class which contains prediction and batch data.
 
     This class is intentionally not @traceable.
 
@@ -101,27 +101,7 @@
         super().write_with_log(key=f'{key}|{self.ds_id}', value=value)
 
     def write_without_log(self, key: str, value: Any) -> None:
         super().write_without_log(key=f'{key}|{self.ds_id}', value=value)
 
     def write_per_instance_log(self, key: str, value: Any) -> None:
         super().write_per_instance_log(key=f'{key}|{self.ds_id}', value=value)
-
-
-class FilteredData:
-    """A placeholder to indicate that this data instance should not be used.
-
-    This class is intentionally not @traceable.
-
-    Args:
-        replacement: Whether to replace the filtered element with another (thus maintaining the number of steps in an
-            epoch but potentially increasing data repetition) or else shortening the epoch by the number of filtered
-            data points (fewer steps per epoch than expected, but no extra data repetition). Either way, the number of
-            data points within an individual batch will remain the same. Even if `replacement` is true, data will not be
-            repeated until all of the given epoch's data has been traversed (except for at most 1 batch of data which
-            might not appear until after the re-shuffle has occurred).
-    """
-    def __init__(self, replacement: bool = True):
-        self.replacement = replacement
-
-    def __repr__(self):
-        return "FilteredData"
```

### Comparing `fastestimator-1.5.2/fastestimator/util/img_data.py` & `fastestimator-1.6.0/fastestimator/util/img_data.py`

 * *Files 24% similar despite different names*

```diff
@@ -8,48 +8,42 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from itertools import zip_longest
-from typing import Optional, Sequence, Tuple, TypeVar, TYPE_CHECKING, Union
 from abc import ABC, abstractmethod
+from itertools import zip_longest
+from typing import TYPE_CHECKING, Optional, Sequence, Tuple, TypeVar, Union
 
 import numpy as np
 import torch
 from plotly.colors import sample_colorscale
-from plotly.graph_objects import Figure, Image
+from plotly.graph_objects import Figure, Image, Scatter
 from plotly.subplots import make_subplots
 
-from fastestimator.util.base_util import to_list, FigureFE, in_notebook, get_colors
+from fastestimator.util.base_util import FigureFE, in_notebook, to_list
 from fastestimator.util.util import to_number
 
 if TYPE_CHECKING:
     import tensorflow as tf
 
     Tensor = TypeVar('Tensor', np.ndarray, tf.Tensor, torch.Tensor)
     BoundingBox = TypeVar('BoundingBox',
                           Tuple[Union[int, float], Union[int, float], Union[int, float], Union[int, float]],
                           Tuple[Union[int, float], Union[int, float], Union[int, float], Union[int, float], str])
-    KeyPoint = TypeVar('KeyPoint',
-                       Tuple[Union[int, float], Union[int, float]],
-                       Tuple[Union[int, float], Union[int, float], str])
 
 
 class Display(ABC):
     @abstractmethod
     def prepare(self, **kwargs) -> FigureFE:
         raise NotImplementedError()
 
-    def show(self,
-             save_path: Optional[str] = None,
-             verbose: bool = True,
-             scale: int = 1,
+    def show(self, save_path: Optional[str] = None, verbose: bool = True, scale: int = 1,
              interactive: bool = False) -> None:
         """A function which will save or display the image as a plotly figure.
 
         Args:
             save_path: The path where the figure should be saved, or None to display the figure to the screen.
             verbose: Whether to print out the save location.
             scale: A scaling factor to apply when exporting to static images (to increase resolution).
@@ -64,36 +58,40 @@
 class ImageDisplay(Display):
     """An object to combine various image components for visualization
 
     Args:
         image: An image to be displayed. 3-dimensional torch tensors are generally assumed to be channel first,
             while tf and np are assumed to be channel last. Either way, only 1 or 3 channel images are supported.
         text: Text which will be printed in the center of this figure.
-        masks: One or more 2-dimensional tensors. They may be combined with labels if desired (<mask>, <label>).
-            Tensors may be 3-dimensional with the last dimension indicating multiple different masks.
+        masks: A 2D tensor representing a mask, or a 3D tensor indicating multiple 2D masks. They may be combined with
+            label(s) if desired (<mask>, <label>).
         bboxes: One or more bounding boxes of the form (x0, y0, width, height [, label]), where (x0, y0) is the top
             left corner of the box. These may also be encoded in a tensor of shape (4,) or (N,4) for multiple boxes.
-        keypoints: One or more keypoints of the form (x, y [, label]). These may also be encoded in a tensor of shape
-            (2,) or (N,2) for multiple keypoints.
+        keypoints: A 1D tensor representing a keypoint of shape (2,), or a 2D tensor of shape (N,2) indicating multiple
+            1D keypoints. They may be combined with label(s) if desired: (<keypoint>, <label>). (x,y) coordinates
+            indicate distance from the top left of an image, with negative or None values indicating that a keypoint
+            was not detected.
         title: What should the title of this figure be.
-        color_map: How to color 1-channel images. Options from: https://plotly.com/python/builtin-colorscales/
+        mask_threshold: If provided, any masks will be binarized based on the given threshold value (1 if > t, else 0).
+        color_map: How to color 1-channel images. Options from: https://plotly.com/python/builtin-colorscales/. If 2
+            strings are provided, the first will be used to color grey-scale images and the second will be used to color
+            continuous (non-thresholded) masks. If a single string is provided it will be used for both image and masks.
 
     Raises:
         AssertionError: If the provided arguments violate expected type/shape constraints.
     """
     def __init__(self,
                  image: Union[None, 'Tensor'] = None,
                  text: Union[None, str, 'Tensor'] = None,
-                 masks: Union[None, 'Tensor', Tuple['Tensor', str], Sequence['Tensor'],
-                              Sequence[Tuple['Tensor', str]]] = None,
-                 bboxes: Union[None, 'BoundingBox', 'Tensor', Sequence['BoundingBox'], Sequence['Tensor']] = None,
-                 keypoints: Union[None, 'KeyPoint', 'Tensor', Sequence['KeyPoint'], Sequence['Tensor']] = None,
+                 masks: Union[None, 'Tensor', Tuple['Tensor', Union[str, Sequence[str]]]] = None,
+                 bboxes: Union[None, 'Tensor', Sequence['BoundingBox'], Sequence['Tensor']] = None,
+                 keypoints: Union[None, 'Tensor', Tuple['Tensor', Union[str, Sequence[str]]]] = None,
                  title: Union[None, str] = None,
-                 color_map: str = "gray"
-                 ):
+                 mask_threshold: Optional[float] = None,
+                 color_map: Union[str, Tuple[str, str]] = ("gray", "turbo")):
 
         if image is not None:
             shape = image.shape
             assert len(shape) in (2, 3), f"Image must have 2 or 3 dimensions, but found {len(shape)}"
             if len(image.shape) == 3:
                 if isinstance(image, torch.Tensor) and image.shape[0] in (1, 3) and image.shape[2] > 3:
                     # Move channel first to channel last
@@ -117,35 +115,52 @@
                 text = text[0]
             text = text.item()
             if isinstance(text, bytes):
                 text = text.decode('utf8')
             text = "{}".format(text)
         self.text = text
 
-        masks = to_list(masks)
-        masks = [(mask, '') if not isinstance(mask, tuple) else mask for mask in masks]
-        self.masks = []
-        self.n_masks = 0
-        for mask_tuple in masks:
-            assert isinstance(mask_tuple, tuple), \
-                "Masks must be tuples of the form (<tensor>, <label>) or else simply a raw tensor"
-            assert len(mask_tuple) == 2, "Masks must be tuples of the form (<tensor>, <label>)"
-            assert isinstance(mask_tuple[1], str), "Masks must be tuples of the form (<tensor>, <label>)"
-            mask = to_number(mask_tuple[0])
-            assert len(mask.shape) in (2, 3), "Masks must be 2 dimensional, or 3 dimensional with the last " \
-                                              f"dimension indicating multiple masks, but found {len(mask.shape)}"
+        masks, mask_labels, *_ = to_list(masks) + [None, None]
+        mask_labels = to_list(mask_labels)
+        if masks is not None:
+            if isinstance(masks, torch.Tensor) and len(masks.shape) == 3 and self.image is not None:
+                # Unfortunately we can't just permute all torch tensors since TF users also might have torch tensors if
+                #  they were using pipeline.get_results(). If there's an accompanying image though we can figure it out
+                if masks.shape[1] == self.image.shape[0] and masks.shape[2] == self.image.shape[1]:
+                    # Move channel first to channel last
+                    masks = masks.permute(1, 2, 0)
+            masks = to_number(masks)
+            assert len(masks.shape) in (2, 3), "Masks must be 2 dimensional, or 3 dimensional with the last " \
+                                               f"dimension (tf/np) or first dimension (torch) indicating multiple " \
+                                               f"masks, but found {len(masks.shape)}"
             # Give all masks a channel dimension for consistency
-            if len(mask.shape) == 2:
-                mask = np.expand_dims(mask, axis=-1)
+            if len(masks.shape) == 2:
+                masks = np.expand_dims(masks, axis=-1)
             # Move the channels to the front for easy iteration
-            mask = np.moveaxis(mask, -1, 0)
-            self.n_masks = max(self.n_masks, mask.shape[0])
+            masks = np.moveaxis(masks, -1, 0)
+            if mask_threshold is not None:
+                masks = np.where(masks > mask_threshold, 1.0, 0.0)
+            # If there are multiple continuous probability masks, compress them into a single mask since overlaying
+            # solid color patches over the entire image is pointless
+            if np.unique(masks).size > 2:
+                masks = np.max(masks, axis=0, keepdims=True)
+                assert len(mask_labels) == 0, "When probabilistic masks are provided and no mask_threshold is set, " \
+                                              "then mask labels cannot be used"
             # Add an axis on the end which will be used for colors later
-            mask = np.expand_dims(mask, -1)
-            self.masks.append((mask, mask_tuple[1]))
+            masks = np.expand_dims(masks, -1)
+            # Ensure mask labels are sufficient if provided
+            if mask_labels:
+                assert len(mask_labels) == len(masks), "If mask labels are provided they must be 1-1 with the number " \
+                                                       f"of masks, but found {len(mask_labels)} labels and " \
+                                                       f"{len(masks)} masks"
+            else:
+                # Make default blank labels for easy zip later
+                mask_labels = [''] * len(masks)
+        self.masks = [] if masks is None else masks
+        self.mask_labels = [] if mask_labels is None else mask_labels
 
         bboxes = to_list(bboxes)
         self.bboxes = []
         self.n_bboxes = 0
         for bbox in bboxes:
             if hasattr(bbox, 'shape'):
                 assert len(bbox.shape) in (1, 2), "Bounding box tensors must be 1 dimensional, or 2 dimensional " \
@@ -162,18 +177,43 @@
                 self.n_bboxes = max(self.n_bboxes, 1)
                 assert len(bbox) in (4, 5), "Bounding boxes must contain either 4 or 5 elements: (x0, y0, width," \
                                             f" height [,label]), but found {len(bbox)}"
                 # Add a channel dimension for consistency
                 bbox = [bbox]  # TODO - non-tensor bbox should stack together to get different colors?
             self.bboxes.append(bbox)
 
-        # TODO - keypoint handling
-        self.keypoints = keypoints
+        keypoints, keypoint_labels, *_ = to_list(keypoints) + [None, None]
+        keypoint_labels = to_list(keypoint_labels)
+        if keypoints is not None:
+            keypoints = to_number(keypoints)
+            assert len(keypoints.shape) in (1, 2), "Keypoints must be 1 dimensional, or 2 dimensional with the first " \
+                                                   "dimension indicating multiple keypoints, but found " \
+                                                   f"{len(keypoints.shape)}"
+            # Give all keypoints a channel dimension for consistency
+            if len(keypoints.shape) == 1:
+                keypoints = np.expand_dims(keypoints, axis=0)
+
+            assert keypoints.shape[1] == 2, "Keypoints should contain 2 coordinates (x,y) but found " \
+                                            f"{keypoints.shape[1]}"
+            # Ensure keypoint labels are sufficient if provided
+            if keypoint_labels:
+                assert len(keypoint_labels) == len(keypoints), "If keypoint labels are provided they must be 1-1 " \
+                                                               "with the number of keypoints, but found " \
+                                                               f"{len(keypoint_labels)} labels and {len(keypoints)} " \
+                                                               f"keypoints"
+            else:
+                # Make default blank labels for easy zip later
+                keypoint_labels = [''] * len(keypoints)
+        self.keypoints = [] if keypoints is None else keypoints
+        self.keypoint_labels = [] if keypoint_labels is None else keypoint_labels
+
         self.title = title or ''
-        self.color_map = color_map
+        color_map = to_list(color_map)
+        self.img_color_map = color_map[0]
+        self.mask_color_map = color_map[-1]
 
     def _make_image(self, im: np.ndarray) -> Image:
         im_max = np.max(im)
         im_min = np.min(im)
         if np.issubdtype(im.dtype, np.integer):
             # im is already in int format
             im = im.astype(np.uint8)
@@ -188,238 +228,295 @@
             mi = abs(np.min(im, axis=tuple([i for i in range(len(im.shape) - 1)]) if len(im.shape) > 2 else None))
             im = (((im + mi) / (ma + mi)) * 255).astype(np.uint8)
         # Convert (x,y) into (x,y,1) for consistency
         if len(im.shape) == 2:
             im = np.expand_dims(im, axis=-1)
         # Manually apply a colormap to 1-channel images
         if im.shape[2] == 1:
-            im = np.array(sample_colorscale(colorscale=self.color_map,
-                                            samplepoints=np.reshape(im, (-1)) / 255.0,
-                                            colortype='tuple')).reshape((im.shape[0], im.shape[1], 3))
+            im = np.array(
+                sample_colorscale(colorscale=self.img_color_map,
+                                  samplepoints=np.reshape(im, (-1)) / 255.0,
+                                  colortype='tuple')).reshape((im.shape[0], im.shape[1], 3))
             im = np.rint(im * 255)
         return Image(z=im)
 
-    def prepare(self,
-                fig: Optional[Figure] = None,
-                axis: Optional[Tuple[int, int]] = None,
+    def prepare(self, fig: Optional[Figure] = None, axis: Optional[Tuple[int, int]] = None,
                 col_width: int = 280) -> FigureFE:
         if axis is None:
             axis = (1, 1)
         row, col = axis
         title_size = min(20, col_width // len(self.title or ' '))
         if fig is None:
             fig = make_subplots(rows=1, cols=1, subplot_titles=[self.title] if self.title else None)
             if self.title:
                 fig['layout']['annotations'][0]['font'] = {'size': title_size, 'family': 'monospace'}
+
+        if not isinstance(fig, FigureFE):
+            fig = FigureFE.from_figure(fig)
+
         fig.update_layout({'plot_bgcolor': '#FFF'})
+        fig.update_layout(legend=dict(itemsizing='constant'))  # Make lines in legend thicker for masks
         x_axis_name = fig.get_subplot(row=row, col=col).xaxis.plotly_name
         y_axis_name = fig.get_subplot(row=row, col=col).yaxis.plotly_name
         fig['layout'][x_axis_name]['showticklabels'] = False
         fig['layout'][y_axis_name]['showticklabels'] = False
         # make y0 the top of the image instead of bottom (this is done automatically for Image)
         fig['layout'][y_axis_name]['autorange'] = 'reversed'
         x_axis_domain = f"{x_axis_name.split('axis')[0]} domain"
         y_axis_domain = f"{y_axis_name.split('axis')[0]} domain"
         # Put an invisible element on the plot to make other stuff work
         fig.add_annotation(text='', showarrow=False, row=row, col=col)
 
         if self.image is not None:
             im = self._make_image(im=self.image)
-            fig.add_trace(im,
-                          row=row,
-                          col=col)
+            fig.add_trace(im, row=row, col=col)
 
         empty_color = np.array((0.0, 0.0, 0.0, 0.0))  # RGBA
-        mask_colors = get_colors(n_colors=self.n_masks, alpha=0.4, as_numbers=True)
-        mask_colors = [np.array(color) for color in mask_colors]
-        for mask_tuple in self.masks:
-            mask, label = mask_tuple
-            # Mask will be channel x width x height x 1
-            for color_idx, msk in enumerate(mask):
-                positive_color = mask_colors[color_idx]
-                msk = np.where(msk, positive_color, empty_color)
-                # TODO - handle labeling
-                msk = Image(z=msk, colormodel='rgba', hoverinfo=None)
-                fig.add_trace(msk, row=row, col=col)
-
-        # # Works, and legend interactivity, but slow
-        # mask_legend = defaultdict(lambda: True)
-        # mask_colors = get_colors(n_colors=self.n_masks, alpha=0.3)
-        # for mask_tuple in self.masks:
-        #     mask, label = mask_tuple
-        #     # Mask will be channel x width x height x 1
-        #     for color_idx, msk in enumerate(mask):
-        #         y, x = np.where(np.squeeze(msk))
-        #         mask_title = label or f"{color_idx}"
-        #         for y_c, x_c in zip(y, x):
-        #             point = Scatter(x=[x_c-0.5, x_c+0.5, x_c+0.5, x_c-0.5],
-        #                             y=[y_c+0.5, y_c+0.5, y_c-0.5, y_c-0.5],
-        #                             mode='lines',
-        #                             fill='toself',
-        #                             fillcolor=mask_colors[color_idx],
-        #                             name=mask_title,
-        #                             legendgroup=mask_title,
-        #                             showlegend=mask_legend[mask_title],
-        #                             text=mask_title,
-        #                             line={'width': 0})
-        #             mask_legend[mask_title] = False
-        #             fig.add_trace(point, row=row, col=col)
+        for color_idx, (mask, label) in enumerate(zip(self.masks, self.mask_labels)):
+            # Mask will be width x height x 1
+            if np.max(mask) > 1:
+                mask = mask / 255.0
+            if len(self.masks) == 1 and np.unique(mask).size > 2:
+                # continuous heatmap
+                msk_heatmap = np.array(
+                    sample_colorscale(colorscale=self.mask_color_map,
+                                      samplepoints=np.reshape(mask, (-1)),
+                                      colortype='tuple')).reshape((mask.shape[0], mask.shape[1], 3))
+                msk_heatmap = np.rint(msk_heatmap * 255)
+                # add alpha channel
+                mask = np.concatenate([msk_heatmap, 0.5 * np.ones_like(mask)], axis=-1)
+                fig.add_trace(Image(z=mask, colormodel='rgba', hoverinfo=None),
+                              row=row,
+                              col=col,
+                              exclude_empty_subplots=False)
+            else:
+                if label:
+                    # Draw the mask out dynamically to allow legend interactivity
+                    for row_idx, mask_row in enumerate(np.squeeze(mask)):
+                        start = 0
+                        active = False
+                        for col_idx, mask_col in enumerate(mask_row):
+                            if mask_col == 1:
+                                if not active:
+                                    active = True
+                                    start = col_idx
+                            else:
+                                if active:
+                                    # Only reserve a color once we know for sure that we're active to avoid a batch
+                                    # situation where no legend is displayed
+                                    color, show = fig._get_color(clazz='mask', label=label, n_colors=len(self.masks))
+                                    line = Scatter(x=[start, col_idx],
+                                                   y=[row_idx, row_idx],
+                                                   mode='lines',
+                                                   line={'width': 1,
+                                                         'color': color},
+                                                   name=label,
+                                                   legendgroup=f"mask_{label}",
+                                                   legendrank=0,  # Sort mask labels higher than bbox and keypoint
+                                                   showlegend=show,
+                                                   text=label)
+                                    active = False
+                                    fig.add_trace(line, row=row, col=col, exclude_empty_subplots=False)
+                        if active:
+                            # The mask went all the way to the right side of the image
+                            color, show = fig._get_color(clazz='mask', label=label, n_colors=len(self.masks))
+                            line = Scatter(x=[start, len(mask_row) - 1],
+                                           y=[row_idx, row_idx],
+                                           mode='lines',
+                                           line={'width': 1,
+                                                 'color': color},
+                                           name=label,
+                                           legendgroup=f"mask_{label}",
+                                           legendrank=0,
+                                           showlegend=show,
+                                           text=label)
+                            fig.add_trace(line, row=row, col=col, exclude_empty_subplots=False)
+                else:
+                    # Draw the mask as a static image for efficiency
+                    positive_color, _ = fig._get_color(clazz='mask',
+                                                       label=label or color_idx,
+                                                       n_colors=len(self.masks),
+                                                       as_numbers=True)
+                    mask = np.where(mask, np.array(positive_color), empty_color)
+                    fig.add_trace(Image(z=mask, colormodel='rgba', hoverinfo=None),
+                                  row=row,
+                                  col=col,
+                                  exclude_empty_subplots=False)
 
-        bbox_colors = get_colors(n_colors=self.n_bboxes)
         for bbox_set in self.bboxes:
             for color_idx, bbox in enumerate(bbox_set):
                 # Bounding Box Data. Should be (x0, y0, w, h, <label>)
                 # Unpack the box, which may or may not have a label
                 x0 = float(bbox[0])
                 y0 = float(bbox[1])
                 width = float(bbox[2])
                 height = float(bbox[3])
-                color = bbox_colors[color_idx]
                 label = None if len(bbox) < 5 else str(bbox[4])
+                color, show = fig._get_color(clazz='bbox', label=label or color_idx, n_colors=self.n_bboxes)
 
                 # Don't draw empty boxes, or invalid box
                 if width <= 0 or height <= 0:
                     continue
-                fig.add_shape({'type': 'rect',
-                               'x0': x0,
-                               'x1': x0 + width,
-                               'y0': y0,
-                               'y1': y0 + height,
-                               'line_color': color,
-                               'line_width': 3},
+                kwargs = {'x': [x0, x0, x0+width, x0+width, x0],
+                          'y': [y0, y0+height, y0+height, y0, y0],
+                          'mode': 'lines',
+                          'line': {'color': color, 'width': 3},
+                          'showlegend': False,
+                          }
+                if label:
+                    kwargs['name'] = label
+                    kwargs['legendrank'] = 1
+                    kwargs['legendgroup'] = f'bb_{label}'
+                    kwargs['showlegend'] = show
+                    # Add label text onto image
+                    font_size = max(8, min(14, int(width // len(label or ' '))))
+                    fig.add_trace(Scatter(x=[x0],
+                                          y=[y0-1],  # A slight offset to help text not run in to bbox
+                                          mode='text',
+                                          text='<span style="text-shadow: -1px 1px 0 #FFFFFF, '
+                                               '1px 1px 0px #FFFFFF, 1px -1px 0px #FFFFFF, -1px -1px 0px #FFFFFF;">'
+                                               f'{label}</span>',
+                                          textposition="top right",
+                                          legendgroup=f'bb_{label}',
+                                          hoverinfo='skip',
+                                          textfont={'size': font_size,
+                                                    'color': color,
+                                                    'family': 'monospace'},
+                                          showlegend=False,
+                                          legendrank=1),
+                                  row=row,
+                                  col=col,
+                                  exclude_empty_subplots=False)
+                fig.add_trace(Scatter(**kwargs),
                               row=row,
                               col=col,
                               exclude_empty_subplots=False)
-                if label is not None:
-                    font_size = max(8, min(14, int(width // len(label or ' '))))
-                    # One annotation with translucent background
-                    fig.add_annotation(x=x0,
-                                       y=y0,
-                                       xshift=len(label)*font_size/2,
-                                       yshift=font_size,
-                                       text=label,
-                                       showarrow=False,
-                                       font={'size': font_size,
-                                             'color': 'white',
-                                             'family': 'monospace'},
-                                       bgcolor='white',
-                                       opacity=0.6,
-                                       exclude_empty_subplots=False,
-                                       row=row,
-                                       col=col)
-                    # Another to make the text opaque
-                    fig.add_annotation(x=x0,
-                                       y=y0,
-                                       xshift=len(label)*font_size/2,
-                                       yshift=font_size,
-                                       text=label,
-                                       showarrow=False,
-                                       font={'size': font_size,
-                                             'color': color,
-                                             'family': 'monospace'},
-                                       exclude_empty_subplots=False,
-                                       row=row,
-                                       col=col)
 
-        if self.text:
-            fig.add_annotation(text=self.text,
-                               font={'size': min(45, col_width // len(self.text or ' ')),
-                                     'color': 'Black',
-                                     'family': 'monospace'},
-                               showarrow=False,
-                               xref=x_axis_domain,
-                               xanchor='center',
-                               x=0.5,
-                               yref=y_axis_domain,
-                               yanchor='middle',
-                               y=0.5,
-                               exclude_empty_subplots=False,
-                               row=row,
-                               col=col)
+        for keypoint, label in zip(self.keypoints, self.keypoint_labels):
+            x, y = keypoint
+            if (x is None) or (x < 0) or (y is None) or (y < 0):
+                # Skip negative or None key-points
+                continue
+            kwargs = {'x': [x],
+                      'y': [y],
+                      'mode': 'markers',
+                      'showlegend': False,
+                      'marker': {'color': 'red',
+                                 'size': 10,
+                                 'symbol': 'circle'}}
+            if label:
+                kwargs['name'] = label
+                kwargs['legendgroup'] = f"keypoint_{label}"
+                color, show = fig._get_color(clazz='keypoints', label=label, n_colors=len(self.keypoints))
+                kwargs['showlegend'] = show
+                kwargs['marker']['color'] = color
+            fig.add_trace(Scatter(**kwargs), row=row, col=col, exclude_empty_subplots=False)
 
-        if not isinstance(fig, FigureFE):
-            fig = FigureFE.from_figure(fig)
+        if self.text:
+            fig.add_annotation(
+                text=self.text,
+                font={
+                    'size': min(45, col_width // len(self.text or ' ')), 'color': 'Black', 'family': 'monospace'
+                },
+                showarrow=False,
+                xref=x_axis_domain,
+                xanchor='center',
+                x=0.5,
+                yref=y_axis_domain,
+                yanchor='middle',
+                y=0.5,
+                exclude_empty_subplots=False,
+                row=row,
+                col=col)
 
         return fig
 
 
 class BatchDisplay(Display):
     """An object to combine various batched image components for visualization
 
     Args:
         image: A batch of image to be displayed. 4-dimensional torch tensors are generally assumed to be channel first,
             while tf and np are assumed to be channel last. Either way, only 1 or 3 channel images are supported.
         text: Text which will be printed in the center of each figure.
-        masks: Batches of one or more 2-dimensional tensors. They may be combined with labels if desired:
-            Bx(<mask>, <label>). Tensors may be 3-dimensional with the second dimension indicating multiple different
-            masks: BxNx<mask>x<label>.
+        masks: A 3D tensor representing a batch of 2D masks, or a 4D tensor indicating a batch of 2D masks having
+            multiple channels. They may be combined with label(s) if desired (<mask>, <label>). For masks with C
+            channels, C labels should be provided (which will then be used for every element in the batch).
         bboxes: Batches of one or more bounding boxes of the form (x0, y0, width, height [, label]), where (x0, y0) is
             the top left corner of the box. These may also be encoded in a tensor of shape (4,) or (N,4) for multiple
             boxes.
-        keypoints: Batches of one or more keypoints of the form (x, y [, label]). These may also be encoded in a tensor
-            of shape (2,) or (N,2) for multiple keypoints.
+        keypoints: A 2D tensor representing a batch of 1D keypoints, or a 3D tensor indicating a batch of sets of
+            1D keypoints. They may be combined with label(s) if desired: (<keypoint>, <label>). For a batch N with C
+            keypoints per element, C labels should be provided (which will then be used for every element in the batch).
+            The keypoint shape should be (N, C, 2) or (N, 2). (x,y) coordinates indicate distance from the top left of
+            an image, with negative or None values indicating that a keypoint was not detected.
         title: What should the title of this figure be.
-        color_map: How to color 1-channel images. Options from: https://plotly.com/python/builtin-colorscales/
+        mask_threshold: If provided, any masks will be binarized based on the given threshold value (1 if > t, else 0).
+        color_map: How to color 1-channel images. Options from: https://plotly.com/python/builtin-colorscales/. If 2
+            strings are provided, the first will be used to color grey-scale images and the second will be used to color
+            continuous (non-thresholded) masks. If a single string is provided it will be used for both image and masks.
 
     Raises:
         AssertionError: If the provided arguments violate expected type/shape constraints.
     """
     def __init__(self,
                  image: Union[None, 'Tensor', Sequence['Tensor']] = None,
                  text: Union[None, Sequence[str], 'Tensor', Sequence['Tensor']] = None,
-                 masks: Union[None, 'Tensor', Sequence[Tuple['Tensor', str]], Sequence[Sequence['Tensor']],
-                              Sequence[Sequence[Tuple['Tensor', str]]]] = None,
-                 bboxes: Union[None, Sequence['BoundingBox'], 'Tensor', Sequence['Tensor'],
-                               Sequence[Sequence['BoundingBox']], Sequence[Sequence['Tensor']]] = None,
-                 keypoints: Union[None, Sequence['KeyPoint'], 'Tensor', Sequence['Tensor'],
-                                  Sequence[Sequence['KeyPoint']], Sequence[Sequence['Tensor']]] = None,
+                 masks: Union[None, 'Tensor', Tuple['Tensor', Union[str, Sequence[str]]]] = None,
+                 bboxes: Union[None,
+                               'Tensor',
+                               Sequence['Tensor'],
+                               Sequence[Sequence['BoundingBox']],
+                               Sequence[Sequence['Tensor']]] = None,
+                 keypoints: Union[None, 'Tensor', Tuple['Tensor', Union[str, Sequence[str]]]] = None,
                  title: Union[None, str] = None,
-                 color_map: str = "greys"
-                 ):
+                 mask_threshold: Optional[float] = None,
+                 color_map: Union[str, Tuple[str, str]] = ("gray", "turbo")):
         self.batch = []
+        masks, mask_labels, *_ = to_list(masks) + [None, None]
+        keypoints, keypoint_labels, *_ = to_list(keypoints) + [None, None]
+        mask_labels = to_list(mask_labels)
+        keypoint_labels = to_list(keypoint_labels)
         for img, txt, mask, bbox, keypoint in zip_longest([] if image is None else image,
                                                           [] if text is None else text,
                                                           [] if masks is None else masks,
                                                           [] if bboxes is None else bboxes,
                                                           [] if keypoints is None else keypoints,
                                                           fillvalue=None):
-            self.batch.append(ImageDisplay(image=img,
-                                           text=txt,
-                                           masks=mask,
-                                           bboxes=bbox,
-                                           keypoints=keypoint,
-                                           title=None,
-                                           color_map=color_map))
+            self.batch.append(
+                ImageDisplay(image=img,
+                             text=txt,
+                             masks=(mask, mask_labels) if mask_labels else mask,
+                             bboxes=bbox,
+                             keypoints=(keypoint, keypoint_labels) if keypoint_labels else keypoint,
+                             title=None,
+                             mask_threshold=mask_threshold,
+                             color_map=color_map))
         self.batch_size = len(self.batch) or 1
         self.title = title or ''
 
-    def prepare(self,
-                fig: Optional[Figure] = None,
-                col: Optional[int] = None,
-                col_width: int = 400) -> FigureFE:
+    def prepare(self, fig: Optional[Figure] = None, col: Optional[int] = None, col_width: int = 400) -> FigureFE:
 
         if fig is None:
-            fig = make_subplots(rows=self.batch_size,
-                                cols=1,
-                                column_titles=[self.title],
-                                vertical_spacing=0.005)
+            fig = make_subplots(rows=self.batch_size, cols=1, column_titles=[self.title], vertical_spacing=0.005)
             # Update the figure title text size
-            fig.for_each_annotation(lambda a: a.update(font={
-                'size': min(20, 3 + int(1 + col_width) // len(a.text or ' ')),
-                'family': 'monospace'
-            }))
+            fig.for_each_annotation(
+                lambda a: a.update(font={
+                    'size': min(20, 3 + int(1 + col_width) // len(a.text or ' ')), 'family': 'monospace'
+                }))
         if col is None:
             col = 1
         for row, elem in enumerate(self.batch, start=1):
             fig = elem.prepare(fig=fig, axis=(row, col), col_width=col_width)
 
         fig.update_layout(width=col_width,
                           height=col_width * self.batch_size,
-                          margin={'l': 0, 'r': 0, 'b': 40, 't': 60}
-                          )
+                          margin={
+                              'l': 0, 'r': 0, 'b': 40, 't': 60
+                          })
 
         if not isinstance(fig, FigureFE):
             fig = FigureFE.from_figure(fig)
 
         return fig
 
 
@@ -457,25 +554,22 @@
         fig = make_subplots(rows=self.batch_size,
                             cols=n_cols,
                             column_titles=[col.title for col in self.columns],
                             vertical_spacing=vertical_gap,
                             horizontal_spacing=horizontal_gap)
         # Update the figure title text size
         fig.for_each_annotation(lambda a: a.update(font={
-            'size': min(20, 3 + int(1 + col_width) // len(a.text or ' ')),
-            'family': 'monospace'
+            'size': min(20, 3 + int(1 + col_width) // len(a.text or ' ')), 'family': 'monospace'
         }))
 
         for col_idx, col in enumerate(self.columns, start=1):
             if isinstance(col, BatchDisplay):
                 fig = col.prepare(fig=fig, col=col_idx, col_width=col_width)
             else:
                 fig = col.prepare(fig=fig, axis=(1, col_idx), col_width=col_width)
 
-        fig.update_layout(width=im_width,
-                          height=im_height,
-                          margin={'l': 0, 'r': 0, 'b': 40, 't': 60})
+        fig.update_layout(width=im_width, height=im_height, margin={'l': 0, 'r': 0, 'b': 40, 't': 60})
 
         if not isinstance(fig, FigureFE):
             fig = FigureFE.from_figure(fig)
 
         return fig
```

### Comparing `fastestimator-1.5.2/fastestimator/util/latex_util.py` & `fastestimator-1.6.0/fastestimator/util/latex_util.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/util/traceability_util.py` & `fastestimator-1.6.0/fastestimator/util/traceability_util.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,28 +15,30 @@
 import dis
 import functools
 import inspect
 import re
 import sys
 import types
 from collections import ChainMap, deque, namedtuple
+from itertools import islice
 from typing import Any, Callable, Dict, List, Optional, Set, Tuple, Type, TypeVar, Union
 
 import numpy as np
 import pandas as pd
 import tensorflow as tf
 import torch
 from pylatex import Document, Label, Marker, MultiColumn, NoEscape, Package, Table, Tabularx, TextColor
 from pylatex.base_classes import LatexObject
 from pylatex.utils import bold, escape_latex, italic
 
 from fastestimator.backend._to_shape import to_shape
 from fastestimator.backend._to_type import to_type
+from fastestimator.summary.summary import ValWithError
+from fastestimator.util.base_util import FEID, Flag, strip_prefix
 from fastestimator.util.latex_util import ContainerList, HrefFEID, PyContainer
-from fastestimator.util.base_util import strip_prefix, FEID, Flag
 
 _Function = namedtuple('_Function', ['func', 'name'])
 _BoundFn = namedtuple('_BoundFn', ['func', 'args'])
 _PartialBind = namedtuple('_PartialBind', ['args', 'kwargs'])
 _Command = namedtuple('_Command', ['left', 'right', 'command'])
 _Condition = namedtuple('_Condition', ['left', 'right', 'condition'])
 _VarWrap = namedtuple('_VarWrap', ['var'])
@@ -69,14 +71,15 @@
 # method due to a formatting issue, though by externalizing them an end user also has more control if they want to add
 # something that was missed.
 _RestorableClasses = (int,
                       float,
                       bool,
                       str,
                       type(None),
+                      ValWithError,
                       tf.Tensor,
                       tf.Variable,
                       torch.Tensor,
                       np.ndarray,
                       np.number,
                       np.bool_,
                       np.flexible,
@@ -310,18 +313,22 @@
     """
     if isinstance(inp, str):
         inp = f"`{escape_latex(inp)}'" if wrap_str else escape_latex(inp)
         if wrap_str:
             # Prevent extremely long strings from overflowing the table
             return NoEscape(r'\seqsplit{' + inp + '}')
         return inp
-    elif isinstance(inp, (int, float, bool, type(None), HrefFEID, FEID, PyContainer)):
-        if isinstance(inp, (int, float)):
+    elif isinstance(inp, (int, float, bool, type(None), HrefFEID, FEID, PyContainer, np.number)):
+        if isinstance(inp, (int, float, np.number)):
             # Prevent extremely long numbers from overflowing the table
-            return NoEscape(r'\seqsplit{' + str(inp) + '}')
+            inp = str(inp)
+            if len(inp) < 2:
+                # Seqsplit doesn't wrap properly with single character inputs
+                return NoEscape(r'\seqsplit{\thinspace ' + inp + '}')
+            return NoEscape(r'\seqsplit{' + inp + '}')
         return inp
     elif hasattr(inp, '_fe_traceability_summary'):
         # The first time a traceable object goes through here it won't have it's summary instantiated yet, so it will
         # fall through to the class check at the end to get it's id.
         # noinspection PyProtectedMember,PyUnresolvedReferences
         tables.update(inp._fe_traceability_summary)
         inp_id = FEID(id(inp))
@@ -456,22 +463,27 @@
             name = tables[inp_id].name
         else:
             name = inp.model_name if hasattr(inp, 'model_name') else "<Unknown Model Name>"
             tables[inp_id] = FeSummaryTable(name=name, fe_id=inp_id, target_type=type(inp))
         ret_ref.set_true()
         return HrefFEID(inp_id, name)
     elif isinstance(inp, list):
-        return PyContainer(data=[_trace_value(x, tables, ret_ref, wrap_str) for x in inp],
+        # For list, tuple, and set, limit tracing to the first limit+1 elements so that constructing objects with huge
+        #  collections as input arguments doesn't take unnecessary long (ex. a NumpyDataset built using lists). Use N+1
+        #  rather than N so that the report shows an ellipse when it trucates the input.
+        return PyContainer(data=[_trace_value(x, tables, ret_ref, wrap_str) for x in inp[:_CollectionSizeLimit + 1]],
                            truncate=_CollectionSizeLimit)
     elif isinstance(inp, tuple):
-        return PyContainer(data=tuple([_trace_value(x, tables, ret_ref, wrap_str) for x in inp]),
-                           truncate=_CollectionSizeLimit)
+        return PyContainer(
+            data=tuple([_trace_value(x, tables, ret_ref, wrap_str) for x in inp[:_CollectionSizeLimit + 1]]),
+            truncate=_CollectionSizeLimit)
     elif isinstance(inp, set):
-        return PyContainer(data=set([_trace_value(x, tables, ret_ref, wrap_str) for x in inp]),
-                           truncate=_CollectionSizeLimit)
+        return PyContainer(
+            data=set([_trace_value(x, tables, ret_ref, wrap_str) for x in islice(inp, _CollectionSizeLimit + 1)]),
+            truncate=_CollectionSizeLimit)
     elif isinstance(inp, dict):
         return PyContainer(
             data={
                 _trace_value(k, tables, ret_ref, wrap_str=wrap_str): _trace_value(v, tables, ret_ref, wrap_str=True)
                 for k,
                 v in inp.items()
             },
@@ -500,16 +512,18 @@
         if inp_id not in tables:
             kwargs = {}
             path = None
             if hasattr(inp, '__dict__') and '_fe_state_whitelist' not in inp.__dict__:
                 # Prevent circular recursion
                 tables[inp_id] = FeSummaryTable(name=inp.__class__.__name__, target_type=type(inp), fe_id=inp_id)
                 # This object isn't @traceable but does have some stored variables that we can summarize.
-                kwargs = _trace_value({k: v
-                                       for k, v in inp.__dict__.items() if not k.startswith("_")},
+                kwargs = _trace_value({
+                    k: v
+                    for k, v in inp.__dict__.items() if not k.startswith("_")
+                },
                                       tables,
                                       ret_ref,
                                       wrap_str=False).raw_input
                 path = "Not @traceable, so summary is approximate"
             tables[inp_id] = FeSummaryTable(name=inp.__class__.__name__,
                                             target_type=type(inp),
                                             path=path,
@@ -1010,27 +1024,29 @@
     from torch.utils.data import Dataset
 
     from fastestimator.estimator import Estimator
     from fastestimator.network import TFNetwork, TorchNetwork
     from fastestimator.op.op import Op
     from fastestimator.pipeline import Pipeline
     from fastestimator.schedule.schedule import Scheduler
+    from fastestimator.slicer.slicer import Slicer
     from fastestimator.trace.trace import Trace
 
     # re-number the references for nicer viewing
     ordered_items = sorted(
         self._fe_traceability_summary.items(),
         key=lambda x: 0 if issubclass(x[1].type, Estimator) else 1
         if issubclass(x[1].type, (TFNetwork, TorchNetwork)) else 2 if issubclass(x[1].type, Pipeline) else 3
         if issubclass(x[1].type, Scheduler) else 4 if issubclass(x[1].type, Trace) else 5
-        if issubclass(x[1].type, Op) else 6 if issubclass(x[1].type, (Dataset, tf.data.Dataset)) else 7
-        if issubclass(x[1].type, (tf.keras.Model, torch.nn.Module)) else 8
-        if issubclass(x[1].type, types.FunctionType) else 9
-        if issubclass(x[1].type, (np.ndarray, tf.Tensor, tf.Variable, torch.Tensor)) else 10)
-    key_mapping = {fe_id: f"@FE{idx}" for idx, (fe_id, val) in enumerate(ordered_items)}
+        if issubclass(x[1].type, Op) else 6 if issubclass(x[1].type, Slicer) else 7
+        if issubclass(x[1].type, (Dataset, tf.data.Dataset)) else 8
+        if issubclass(x[1].type, (tf.keras.Model, torch.nn.Module)) else 9
+        if issubclass(x[1].type, types.FunctionType) else 10
+        if issubclass(x[1].type, (np.ndarray, tf.Tensor, tf.Variable, torch.Tensor)) else 11)
+    key_mapping = {fe_id: f"@FE{idx}" for idx, (fe_id, _) in enumerate(ordered_items)}
     FEID.set_translation_dict(key_mapping)
     return [item[1] for item in ordered_items]
 
 
 def __getstate__(self) -> Dict[str, Any]:
     """Return a summary of this class' state variables (for restore wizard).
 
@@ -1091,14 +1107,18 @@
     Returns:
         The object to be stored in place of the `current` one.
     """
     if isinstance(current, list) and isinstance(new, (tuple, list)) and len(current) == len(new):
         for idx, elem in enumerate(current):
             current[idx] = _setdata(elem, new[idx])
         return current
+    # Check for named tuple
+    if isinstance(current, tuple) and hasattr(current, '_fields') and hasattr(current, '_make') and \
+            isinstance(new, (tuple, list)) and len(current) == len(new):
+        return current._make([_setdata(cu, cr) for cu, cr in zip(current, new)])
     if isinstance(current, tuple) and isinstance(new, (tuple, list)) and len(current) == len(new):
         return tuple([_setdata(cu, cr) for cu, cr in zip(current, new)])
     if isinstance(current, dict) and isinstance(new, dict) and current.keys() == new.keys():
         # Might want to consider removing the key equality requirement, but unclear what ramifications that would have.
         for key in current.keys():
             current[key] = _setdata(current[key], new[key])
         return current
```

### Comparing `fastestimator-1.5.2/fastestimator/util/util.py` & `fastestimator-1.6.0/fastestimator/op/tensorop/meta/repeat.py`

 * *Files 24% similar despite different names*

```diff
@@ -8,296 +8,261 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-"""Utilities for FastEstimator."""
-import os
-import time
-from contextlib import ContextDecorator
-from typing import Any, Dict, List, MutableMapping, Optional, Tuple, Type, TypeVar, Union
+import functools
+import inspect
+from typing import Any, Callable, Dict, List, Optional, Set, Tuple, TypeVar, Union
 
-import numpy as np
 import tensorflow as tf
 import torch
-from pyfiglet import Figlet
-
-
-STRING_TO_TORCH_DTYPE = {
-    None: None,
-    'float32': torch.float32,
-    'float': torch.float,
-    'float64': torch.float64,
-    'double': torch.double,
-    'float16': torch.float16,
-    'half': torch.half,
-    'uint8': torch.uint8,
-    'int8': torch.int8,
-    'int16': torch.int16,
-    'short': torch.short,
-    'int32': torch.int32,
-    'int': torch.int,
-    'int64': torch.int64,
-    'long': torch.long,
-    'bool': torch.bool
-}
-
-STRING_TO_TF_DTYPE = {
-    None: None,
-    "string": tf.string,
-    "int8": tf.int8,
-    "uint8": tf.uint8,
-    "int16": tf.int16,
-    "uint16": tf.uint16,
-    "int32": tf.int32,
-    "uint32": tf.uint32,
-    "int64": tf.int64,
-    "uint64": tf.uint64,
-    "float16": tf.float16,
-    "float32": tf.float32,
-    "float64": tf.float64
-}
-
-TENSOR_TO_NP_DTYPE = {
-    # Abstract types like 'float' and 'long' are intentionally not included here since they are never actually a
-    # tensor's dtype and they interfere with the finer-grained keys (torch.float intercepts torch.float32, for example)
-    None: None,
-    torch.float32: np.float32,
-    torch.float64: np.float64,
-    torch.float16: np.float16,
-    torch.uint8: np.uint8,
-    torch.int8: np.int8,
-    torch.int16: np.int16,
-    torch.int32: np.int32,
-    torch.int64: np.int64,
-    torch.bool: np.bool,
-    tf.float32: np.float32,
-    tf.float64: np.float64,
-    tf.float16: np.float16,
-    tf.uint8: np.uint8,
-    tf.int8: np.int8,
-    tf.int16: np.int16,
-    tf.int32: np.int32,
-    tf.int64: np.int64,
-    tf.bool: np.bool,
-    np.dtype('float32'): np.float32,
-    np.dtype('float64'): np.float64,
-    np.dtype('float16'): np.float16,
-    np.dtype('uint8'): np.uint8,
-    np.dtype('int8'): np.int8,
-    np.dtype('int16'): np.int16,
-    np.dtype('int32'): np.int32,
-    np.dtype('int64'): np.int64,
-    np.dtype('bool'): np.bool,
-}
+from fastestimator.network import BaseNetwork
+from fastestimator.op.tensorop.tensorop import TensorOp
+from fastestimator.util.traceability_util import traceable
 
 Tensor = TypeVar('Tensor', tf.Tensor, torch.Tensor)
+Model = TypeVar('Model', tf.keras.Model, torch.nn.Module)
 
 
-class Timer(ContextDecorator):
-    """A class that can be used to time things.
+@traceable()
+class Repeat(TensorOp):
+    """Repeat a TensorOp several times in a row.
 
-    This class is intentionally not @traceable.
+    Repeat takes an Op and runs it multiple times in a row. It can be set to repeat for a fixed (static) number of
+    times, or to repeat until a given input function evaluates to False (dynamic).
 
-    ```python
-    x = lambda: list(map(lambda i: i + i/2, list(range(int(1e6)))))
-    with fe.util.Timer():
-        x()  # Task took 0.1639 seconds
-    @fe.util.Timer("T2")
-    def func():
-        return x()
-    func()  # T2 took 0.14819 seconds
-    ```
-    """
-    def __init__(self, name="Task") -> None:
-        self.name = name
-        self.start = None
-        self.end = None
-        self.interval = None
-
-    def __enter__(self) -> 'Timer':
-        self.start = time.perf_counter()
-        return self
-
-    def __exit__(self, *exc: Tuple[Optional[Type], Optional[Exception], Optional[Any]]) -> None:
-        self.end = time.perf_counter()
-        self.interval = self.end - self.start
-        tf.print("{} took {} seconds".format(self.name, self.interval))
+    Static example:
 
+        ops=[
+            LambdaOp(fn=lambda: 0, outputs="z"),
+            Repeat(AddOne(inputs="z", outputs="z"), repeat=5)
+            ]
 
-def draw() -> None:
-    """Print our name.
-    """
-    print(Figlet(font="slant").renderText("FastEstimator"))
+    Dynamic example:
 
+        ops=[
+            LambdaOp(fn=lambda: 0, outputs="z"),
+            Repeat(AddOne(inputs="z", outputs="z"), repeat=lambda z: z < 6.5)
+            ]
 
-def pad_batch(batch: List[MutableMapping[str, np.ndarray]], pad_value: Union[float, int]) -> None:
-    """A function to pad a batch of data in-place by appending to the ends of the tensors. Tensor type needs to be
-    numpy array otherwise would get ignored. (tf.Tensor and torch.Tensor will cause error)
-
-    ```python
-    data = [{"x": np.ones((2, 2)), "y": 8}, {"x": np.ones((3, 1)), "y": 4}]
-    fe.util.pad_batch(data, pad_value=0)
-    print(data)  # [{'x': [[1., 1.], [1., 1.], [0., 0.]], 'y': 8}, {'x': [[1., 0.], [1., 0.], [1., 0.]]), 'y': 4}]
-    ```
+        Note : Here the argument ('z') of the lambda function used as repeat callable function is the key used by the
+               ops passed to the Repeat Op.
 
     Args:
-        batch: A list of data to be padded.
-        pad_value: The value to pad with.
+        op: A TensorOp to be run one or more times in a row.
+        repeat: How many times to repeat the `op`. This can also be a function return, in which case the function input
+            names will be matched to keys in the data dictionary, and the `op` will be repeated until the function
+            evaluates to False. The function evaluation will happen at the end of a forward call, so the `op` will
+            always be evaluated at least once.
+        max_iter: A limit to how many iterations will be run (or None for no limit).
 
     Raises:
-        AssertionError: If the data within the batch do not have matching rank, or have different keys
+        ValueError: If `repeat`, `op`, or max_iter are invalid.
     """
-    keys = batch[0].keys()
-    for one_batch in batch:
-        assert one_batch.keys() == keys, "data within batch must have same keys"
-
-    for key in keys:
-        shapes = [data[key].shape for data in batch if hasattr(data[key], "shape")]
-        if len(set(shapes)) > 1:
-            assert len(set(len(shape) for shape in shapes)) == 1, "data within batch must have same rank"
-            max_shapes = tuple(np.max(np.array(shapes), axis=0))
-            for data in batch:
-                data[key] = pad_data(data[key], max_shapes, pad_value)
-
-
-def pad_data(data: np.ndarray, target_shape: Tuple[int, ...], pad_value: Union[float, int]) -> np.ndarray:
-    """Pad `data` by appending `pad_value`s along it's dimensions until the `target_shape` is reached. All entries of
-    target_shape should be larger than the data.shape, and have the same rank.
-
-    ```python
-    x = np.ones((1,2))
-    x = fe.util.pad_data(x, target_shape=(3, 3), pad_value = -2)  # [[1, 1, -2], [-2, -2, -2], [-2, -2, -2]]
-    x = fe.util.pad_data(x, target_shape=(3, 3, 3), pad_value = -2) # error
-    x = fe.util.pad_data(x, target_shape=(4, 1), pad_value = -2) # error
-    ```
-
-    Args:
-        data: The data to be padded.
-        target_shape: The desired shape for `data`. Should have the same rank as `data`, with each dimension being >=
-            the size of the `data` dimension.
-        pad_value: The value to insert into `data` if padding is required to achieve the `target_shape`.
-
-    Returns:
-        The `data`, padded to the `target_shape`.
-    """
-    shape_difference = np.array(target_shape) - np.array(data.shape)
-    padded_shape = np.array([np.zeros_like(shape_difference), shape_difference]).T
-    return np.pad(data, padded_shape, 'constant', constant_values=pad_value)
-
-
-def get_num_devices():
-    """Determine the number of available GPUs.
-
-    Returns:
-        The number of available GPUs, or 1 if none are found.
-    """
-    return max(torch.cuda.device_count(), 1)
-
+    def __init__(self, op: TensorOp, repeat: Union[int, Callable[..., bool]] = 1,
+                 max_iter: Optional[int] = None) -> None:
+        self.repeat_inputs = []
+        extra_reqs = []
+        if max_iter is None:
+            self.max_iter = max_iter
+        else:
+            if max_iter < 1:
+                raise ValueError(f"Repeat requires max_iter to be >=1, but got {max_iter}")
+            self.max_iter = max_iter - 1  # -1 b/c the first invocation happens outside the while loop
+        if isinstance(repeat, int):
+            if repeat < 1:
+                raise ValueError(f"Repeat requires repeat to be >= 1, but got {repeat}")
+            if max_iter:
+                raise ValueError("Do not set max_iter when repeat is an integer")
+        else:
+            self.repeat_inputs.extend(inspect.signature(repeat).parameters.keys())
+            extra_reqs = list(set(self.repeat_inputs) - set(op.outputs))
+        self.repeat = repeat
+        super().__init__(inputs=op.inputs + extra_reqs, outputs=op.outputs, mode=op.mode, ds_id=op.ds_id)
+        self.ops = [op]
+        self.retain_graph = None
+        self.while_fn = None
+
+    @property
+    def op(self) -> TensorOp:
+        return self.ops[0]
+
+    def build(self, framework: str, device: Optional[torch.device] = None) -> None:
+        self.op.build(framework, device)
+        # Below the while function is chosen based on framework
+        if framework == 'tf':
+            # For tensorflow the while function is decided based of object type of 'self.repeat'.
+            if isinstance(self.repeat, int):
+                self.while_fn = self._tf_while_int
+            else:
+                self.while_fn = self._tf_while
+        else:
+            self.while_fn = self._torch_while
 
-def cpu_count(limit: Optional[int] = None) -> int:
-    """Determine the nuber of available CPUs (correcting for docker container limits).
+    def get_fe_models(self) -> Set[Model]:
+        return self.op.get_fe_models()
 
-    Args:
-        limit: If provided, the TF and Torch backends will be told to use `limit` number of threads, or the available
-            number of cpus if the latter is lower (`limit` cannot raise the number of threads). A limit can only be
-            enforced once per python session, before starting anything like pipeline which requires multiprocessing.
+    def get_fe_loss_keys(self) -> Set[str]:
+        return self.op.get_fe_loss_keys()
 
-    Returns:
-        The nuber of available CPUs (correcting for docker container limits), or the user provided `limit`.
+    def fe_retain_graph(self, retain: Optional[bool] = None) -> Optional[bool]:
+        if retain is not None:
+            self.retain_graph = retain
+        return self.op.fe_retain_graph(retain)
 
-    Raises:
-        ValueError: If a `limit` is provided which doesn't match previously enforced limits.
-    """
-    existing_limit = os.environ.get('FE_NUM_THREADS_', None)  # This variable is used internally to indicate whether cpu
-    # limits have already been enforced in this python session
-    if existing_limit:
-        try:
-            existing_limit = int(existing_limit)
-        except ValueError as err:
-            print("FastEstimator-Error: FE_NUM_THREADS_ is an internal variable. Use FE_NUM_THREADS (no underscore)")
-            raise err
-        if limit and limit != existing_limit:
-            raise ValueError(f"Tried to enforce a cpu limit of {limit}, but {existing_limit} was already set.")
-        return existing_limit
-    # Check if user provided an environment variable limit on the number of threads
-    env_limit = os.environ.get('FE_NUM_THREADS', None)  # User might set this one in a bash script
-    if env_limit:
-        try:
-            env_limit = int(env_limit)
-        except ValueError as err:
-            print(f"FastEstimator-Warn: FE_NUM_THREADS variable must be an integer, but was set to: {env_limit}")
-            raise err
-    try:
-        # In docker containers which have --cpuset-cpus, the limit won't be reflected by normal os.cpu_count() call
-        cores = len(os.sched_getaffinity(0))
-    except AttributeError:
-        # Running on Mac or Windows where the above method isn't available, so use the regular way
-        cores = os.cpu_count()
-    cores = min(cores, limit or cores, env_limit or cores)
-    if cores < 1:
-        raise ValueError(f"At least 1 core is required for training, but found {cores}")
-    os.environ['FE_NUM_THREADS_'] = f"{cores}"  # Remember the value so we don't try to re-set the frameworks later
-    os.environ['OMP_NUM_THREADS'] = f"{cores}"
-    os.environ['MKL_NUM_THREADS'] = f"{cores}"
-    os.environ['TF_NUM_INTEROP_THREADS'] = f"{cores}"
-    os.environ['TF_NUM_INTRAOP_THREADS'] = f"{cores}"
-    torch.set_num_threads(cores)
-    torch.set_num_interop_threads(cores)
-    return cores
-
-
-def get_batch_size(data: Dict[str, Any]) -> int:
-    """Infer batch size from a batch dictionary. It will ignore all dictionary value with data type that
-    doesn't have "shape" attribute.
+    def __getstate__(self) -> Dict[str, List[Dict[Any, Any]]]:
+        return {'ops': [elem.__getstate__() if hasattr(elem, '__getstate__') else {} for elem in self.ops]}
 
-    Args:
-        data: The batch dictionary.
+    def forward(self, data: List[Tensor], state: Dict[str, Any]) -> List[Tensor]:
+        # Set retain to true since might loop over a gradient aware op
+        self.op.fe_retain_graph(True)
 
-    Returns:
-        batch size.
-    """
-    assert isinstance(data, dict), "data input must be a dictionary"
-    batch_size = set(data[key].shape[0] for key in data if hasattr(data[key], "shape") and list(data[key].shape))
-    assert len(batch_size) == 1, "invalid batch size: {}".format(batch_size)
-    return batch_size.pop()
-
-
-def to_number(data: Union[tf.Tensor, torch.Tensor, np.ndarray, int, float, str]) -> np.ndarray:
-    """Convert an input value into a Numpy ndarray.
-
-    This method can be used with Python and Numpy data:
-    ```python
-    b = fe.backend.to_number(5)  # 5 (type==np.ndarray)
-    b = fe.backend.to_number(4.0)  # 4.0 (type==np.ndarray)
-    n = np.array([1, 2, 3])
-    b = fe.backend.to_number(n)  # [1, 2, 3] (type==np.ndarray)
-    ```
-
-    This method can be used with TensorFlow tensors:
-    ```python
-    t = tf.constant([1, 2, 3])
-    b = fe.backend.to_number(t)  # [1, 2, 3] (type==np.ndarray)
-    ```
-
-    This method can be used with PyTorch tensors:
-    ```python
-    p = torch.tensor([1, 2, 3])
-    b = fe.backend.to_number(p)  # [1, 2, 3] (type==np.ndarray)
-    ```
-
-    Args:
-        data: The value to be converted into a np.ndarray.
+        data = {key: elem for key, elem in zip(self.inputs, data)}
+        if isinstance(self.repeat, int):
+            data = self.while_fn(data, state)
+        else:
+            BaseNetwork._forward_batch(data, state, self.ops)
+            data = self.while_fn(data, state)
+            # TODO - Find some magic way to invoke this at the right moment
+            self.op.fe_retain_graph(self.retain_graph)
+
+        return [data[key] for key in self.outputs]
+
+    def _torch_while(self, data: Dict[str, Tensor], state: Dict[str, Any]) -> Dict[str, Tensor]:
+        """A helper function to invoke a loop.
+
+        Args:
+            data: A data dictionary to be used during looping.
+            state: The state variables to be considered during looping.
+
+        Returns:
+            A reference to the updated data dictionary.
+        """
+        if isinstance(self.repeat, int):
+            for _ in range(self.repeat - 1):
+                # Perform n-1 rounds with all ops having retain_graph == True
+                BaseNetwork._forward_batch(data, state, self.ops)
+            # Let retain be whatever it was meant to be for the final sequence
+            self.op.fe_retain_graph(self.retain_graph)
+            # Final round of ops to ensure accurate graph building in case we dont retain the graph
+            BaseNetwork._forward_batch(data, state, self.ops)
 
-    Returns:
-        An ndarray corresponding to the given `data`.
-    """
-    if tf.is_tensor(data):
-        data = data.numpy()
-    elif isinstance(data, torch.Tensor):
-        if data.requires_grad:
-            data = data.detach().numpy()
         else:
-            data = data.numpy()
-    return np.array(data)
+            i = 0
+            while self.repeat(*[data[var_name] for var_name in self.repeat_inputs]):
+                if self.max_iter and i >= self.max_iter:
+                    break
+                BaseNetwork._forward_batch(data, state, self.ops)
+                i += 1
+        return data
+
+    def _tf_while_int(self, data: Dict[str, Tensor], state: Dict[str, Any]) -> Dict[str, Tensor]:
+        """A helper function to invoke a while loop in case self.repeat is an integer.
+
+        Experiment were conducted to compare performance of tf.while_loop() with tf.range(), where tf.range outperformed
+        tf.while_loop() in most scenarios. But it was found that tensors cannot be overwritten inside the scope of
+        tf.range() and hence the RepeatOp failed on few Ops (eg: Ops which were updating the inputs). Creating a copy
+        of tensor in every iteration of tf.range() resolved this issue, but also dissolved all the advantages of
+        tf.range().
+
+        Args:
+            data: A data dictionary to be used during looping.
+            state: The state variables to be considered during looping.
+
+        Returns:
+            A reference to the updated data dictionary.
+        """
+        if self.repeat == 1:
+            # Let retain be whatever it was meant to be for the final sequence
+            # This is done right before the only forward pass to ensure accurate graph building in case
+            # we dont retain the graph
+            self.op.fe_retain_graph(self.retain_graph)
+            # Final round of ops
+            BaseNetwork._forward_batch(data, state, self.ops)
+        elif self.repeat == 2:
+            BaseNetwork._forward_batch(data, state, self.ops)
+            # Let retain be whatever it was meant to be for the final sequence
+            # This is done right before the last forward pass to ensure accurate graph building in case
+            # we dont retain the graph
+            self.op.fe_retain_graph(self.retain_graph)
+            # Final round of ops
+            BaseNetwork._forward_batch(data, state, self.ops)
+        else:
+            # Run a forward pass to ensure that data dictionary structure doesn't change during while loop execution
+            BaseNetwork._forward_batch(data, state, self.ops)
+            args = (tf.constant(1), data)
+            # Use functools.partial since state may contain objects which cannot be cast to tensors (ex. gradient tape)
+            args = tf.while_loop(self._tf_cond,
+                                 functools.partial(self._tf_body, state=state),
+                                 args,
+                                 maximum_iterations=self.max_iter)
+            # Let retain be whatever it was meant to be for the final sequence
+            # This is done right before the last forward pass to ensure accurate graph building in case
+            # we dont retain the graph
+            self.op.fe_retain_graph(self.retain_graph)
+            data = args[1]
+            # Final round of ops
+            BaseNetwork._forward_batch(data, state, self.ops)
+        return data
+
+    def _tf_while(self, data: Dict[str, Tensor], state: Dict[str, Any]) -> Dict[str, Tensor]:
+        """A helper function to invoke a while loop in case self.repeat is a callable function.
+
+        Args:
+            data: A data dictionary to be used during looping.
+            state: The state variables to be considered during looping.
+
+        Returns:
+            A reference to the updated data dictionary.
+        """
+        args = ([data[var_name] for var_name in self.repeat_inputs], data)
+        # Use functools.partial since state may contain objects which cannot be cast to tensors (ex. gradient tape)
+        args = tf.while_loop(self._tf_cond,
+                             functools.partial(self._tf_body, state=state),
+                             args,
+                             maximum_iterations=self.max_iter,
+                             parallel_iterations=1)
+        return args[1]
+
+    def _tf_cond(self, cnd: Union[List[Tensor], Tensor], data: Dict[str, Tensor]) -> bool:
+        """A helper function determine whether to keep invoking the while method.
+
+        Note that `data` and `state` are unused here, but required since tf.while_loop needs the cond and body to have
+        the same input argument signatures.
+
+        Args:
+            cnd: A list of arguments to be passed to the condition function.
+            data: A data dictionary to be used during looping.
+
+        Returns:
+            Whether to continue looping.
+        """
+        if isinstance(self.repeat, int):
+            # In this case we have 2 Forward calls for tf (one before and one after the while loop
+            # (For accurate Tf while loop functioning))
+            return tf.less(cnd, self.repeat - 1)
+        return self.repeat(*cnd)
+
+    def _tf_body(self, cnd: Union[List[Tensor], Tensor], data: Dict[str, Tensor],
+                 state: Dict[str, Any]) -> Tuple[Union[List[Tensor], Tensor], Dict[str, Tensor]]:
+        """A helper function to execute the body of a while method.
+
+        Note that `cnd` is unused here, but required since tf.while_loop needs the cond and body to have the same input
+        argument signatures.
+
+        Args:
+            cnd: A list of arguments to be passed to the condition function.
+            data: A data dictionary to be used during looping.
+            state: The state variables to be considered during looping.
+
+        Returns:
+            The updated `cnd` values, along with the modified data and state dictionaries.
+        """
+        # Run a round of ops
+        BaseNetwork._forward_batch(data, state, self.ops)
+        if isinstance(self.repeat, int):
+            # Updating the while condition
+            return tf.add(cnd, 1), data
+        return [data[var_name] for var_name in self.repeat_inputs], data
```

### Comparing `fastestimator-1.5.2/fastestimator/util/wget_util.py` & `fastestimator-1.6.0/fastestimator/util/wget_util.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator/xai/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/util/test_wget_util.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,24 +1,26 @@
-# Copyright 2019 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2020 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-from typing import TYPE_CHECKING
+import unittest
 
-import lazy_loader as lazy
+import fastestimator as fe
 
-__getattr__, __dir__, __all__ = lazy.attach(__name__,
-                                            submod_attrs={'saliency': ['SaliencyNet'],
-                                                          })
 
-if TYPE_CHECKING:
-    from fastestimator.xai.saliency import SaliencyNet
+class TestWgetUtil(unittest.TestCase):
+    @classmethod
+    def setUpClass(cls):
+        cls.op = " 10% [......                                                        ] 0.00 / 0.00 MB"
+
+    def test_bar_custom(self):
+        self.assertEqual(fe.util.bar_custom(10, 100), self.op)
```

### Comparing `fastestimator-1.5.2/fastestimator/xai/saliency.py` & `fastestimator-1.6.0/fastestimator/xai/saliency.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/fastestimator.egg-info/SOURCES.txt` & `fastestimator-1.6.0/fastestimator.egg-info/SOURCES.txt`

 * *Files 1% similar despite different names*

```diff
@@ -75,53 +75,59 @@
 ./fastestimator/backend/_tensor_sqrt.py
 ./fastestimator/backend/_to_shape.py
 ./fastestimator/backend/_to_tensor.py
 ./fastestimator/backend/_to_type.py
 ./fastestimator/backend/_transpose.py
 ./fastestimator/backend/_update_model.py
 ./fastestimator/backend/_watch.py
+./fastestimator/backend/_where.py
 ./fastestimator/backend/_zeros_like.py
 ./fastestimator/backend/_zscore.py
 ./fastestimator/cli/__init__.py
 ./fastestimator/cli/history.py
 ./fastestimator/cli/logs.py
 ./fastestimator/cli/main.py
 ./fastestimator/cli/plot.py
 ./fastestimator/cli/run.py
 ./fastestimator/cli/train.py
 ./fastestimator/dataset/__init__.py
 ./fastestimator/dataset/batch_dataset.py
+./fastestimator/dataset/combined_dataset.py
 ./fastestimator/dataset/csv_dataset.py
 ./fastestimator/dataset/dataloader.py
 ./fastestimator/dataset/dataset.py
 ./fastestimator/dataset/dir_dataset.py
 ./fastestimator/dataset/extend_dataset.py
 ./fastestimator/dataset/generator_dataset.py
+./fastestimator/dataset/interleave_dataset.py
 ./fastestimator/dataset/labeled_dir_dataset.py
 ./fastestimator/dataset/numpy_dataset.py
 ./fastestimator/dataset/op_dataset.py
 ./fastestimator/dataset/pickle_dataset.py
 ./fastestimator/dataset/siamese_dir_dataset.py
 ./fastestimator/dataset/data/__init__.py
 ./fastestimator/dataset/data/breast_cancer.py
 ./fastestimator/dataset/data/cifair10.py
 ./fastestimator/dataset/data/cifair100.py
 ./fastestimator/dataset/data/cifar10.py
 ./fastestimator/dataset/data/cifar100.py
 ./fastestimator/dataset/data/cub200.py
+./fastestimator/dataset/data/em_3d.py
 ./fastestimator/dataset/data/food101.py
 ./fastestimator/dataset/data/horse2zebra.py
 ./fastestimator/dataset/data/imdb_review.py
+./fastestimator/dataset/data/medmnist.py
 ./fastestimator/dataset/data/mendeley.py
 ./fastestimator/dataset/data/mitmovie_ner.py
 ./fastestimator/dataset/data/mnist.py
 ./fastestimator/dataset/data/montgomery.py
 ./fastestimator/dataset/data/mscoco.py
 ./fastestimator/dataset/data/nih_chestxray.py
 ./fastestimator/dataset/data/omniglot.py
+./fastestimator/dataset/data/pascal_voc.py
 ./fastestimator/dataset/data/penn_treebank.py
 ./fastestimator/dataset/data/shakespeare.py
 ./fastestimator/dataset/data/skl_digits.py
 ./fastestimator/dataset/data/svhn.py
 ./fastestimator/dataset/data/svhn_cropped.py
 ./fastestimator/dataset/data/tednmt.py
 ./fastestimator/dataset/data/tiny_imagenet.py
@@ -231,15 +237,14 @@
 ./fastestimator/op/numpyop/univariate/translate_x.py
 ./fastestimator/op/numpyop/univariate/translate_y.py
 ./fastestimator/op/numpyop/univariate/univariate.py
 ./fastestimator/op/numpyop/univariate/word_to_id.py
 ./fastestimator/op/tensorop/__init__.py
 ./fastestimator/op/tensorop/argmax.py
 ./fastestimator/op/tensorop/average.py
-./fastestimator/op/tensorop/dice.py
 ./fastestimator/op/tensorop/gather.py
 ./fastestimator/op/tensorop/normalize.py
 ./fastestimator/op/tensorop/permute.py
 ./fastestimator/op/tensorop/reshape.py
 ./fastestimator/op/tensorop/resize3d.py
 ./fastestimator/op/tensorop/tensorop.py
 ./fastestimator/op/tensorop/un_hadamard.py
@@ -248,43 +253,48 @@
 ./fastestimator/op/tensorop/augmentation/mixup_batch.py
 ./fastestimator/op/tensorop/gradient/__init__.py
 ./fastestimator/op/tensorop/gradient/fgsm.py
 ./fastestimator/op/tensorop/gradient/gradient.py
 ./fastestimator/op/tensorop/gradient/watch.py
 ./fastestimator/op/tensorop/loss/__init__.py
 ./fastestimator/op/tensorop/loss/cross_entropy.py
+./fastestimator/op/tensorop/loss/dice_loss.py
 ./fastestimator/op/tensorop/loss/focal_loss.py
 ./fastestimator/op/tensorop/loss/hinge.py
 ./fastestimator/op/tensorop/loss/l1_loss.py
 ./fastestimator/op/tensorop/loss/l2_regularization.py
 ./fastestimator/op/tensorop/loss/loss.py
 ./fastestimator/op/tensorop/loss/mean_squared_error.py
-./fastestimator/op/tensorop/loss/mix_loss.py
 ./fastestimator/op/tensorop/loss/super_loss.py
 ./fastestimator/op/tensorop/meta/__init__.py
 ./fastestimator/op/tensorop/meta/fuse.py
 ./fastestimator/op/tensorop/meta/one_of.py
 ./fastestimator/op/tensorop/meta/repeat.py
 ./fastestimator/op/tensorop/meta/sometimes.py
 ./fastestimator/op/tensorop/model/__init__.py
 ./fastestimator/op/tensorop/model/model.py
 ./fastestimator/op/tensorop/model/update.py
 ./fastestimator/schedule/__init__.py
-./fastestimator/schedule/lr_shedule.py
+./fastestimator/schedule/lr_schedule.py
 ./fastestimator/schedule/schedule.py
 ./fastestimator/search/__init__.py
 ./fastestimator/search/golden_section.py
 ./fastestimator/search/grid_search.py
 ./fastestimator/search/search.py
 ./fastestimator/search/visualize/__init__.py
 ./fastestimator/search/visualize/cartesian.py
 ./fastestimator/search/visualize/heatmap.py
 ./fastestimator/search/visualize/parallel_coordinate_plot.py
 ./fastestimator/search/visualize/vis_util.py
 ./fastestimator/search/visualize/visualize.py
+./fastestimator/slicer/__init__.py
+./fastestimator/slicer/axis_slicer.py
+./fastestimator/slicer/mean_unslicer.py
+./fastestimator/slicer/slicer.py
+./fastestimator/slicer/sliding_slicer.py
 ./fastestimator/summary/__init__.py
 ./fastestimator/summary/history.py
 ./fastestimator/summary/summary.py
 ./fastestimator/summary/system.py
 ./fastestimator/summary/logs/__init__.py
 ./fastestimator/summary/logs/log_parse.py
 ./fastestimator/summary/logs/log_plot.py
@@ -296,27 +306,30 @@
 ./fastestimator/trace/adapt/__init__.py
 ./fastestimator/trace/adapt/early_stopping.py
 ./fastestimator/trace/adapt/lr_scheduler.py
 ./fastestimator/trace/adapt/pbm_calibrator.py
 ./fastestimator/trace/adapt/reduce_lr_on_plateau.py
 ./fastestimator/trace/adapt/terminate_on_nan.py
 ./fastestimator/trace/io/__init__.py
+./fastestimator/trace/io/batch_display.py
 ./fastestimator/trace/io/best_model_saver.py
 ./fastestimator/trace/io/csv_logger.py
+./fastestimator/trace/io/grid_display.py
 ./fastestimator/trace/io/image_saver.py
 ./fastestimator/trace/io/image_viewer.py
 ./fastestimator/trace/io/model_saver.py
 ./fastestimator/trace/io/restore_wizard.py
 ./fastestimator/trace/io/tensorboard.py
 ./fastestimator/trace/io/test_report.py
 ./fastestimator/trace/io/traceability.py
 ./fastestimator/trace/meta/__init__.py
 ./fastestimator/trace/meta/_per_ds.py
 ./fastestimator/trace/metric/__init__.py
 ./fastestimator/trace/metric/accuracy.py
+./fastestimator/trace/metric/auc.py
 ./fastestimator/trace/metric/bleu_score.py
 ./fastestimator/trace/metric/calibration_error.py
 ./fastestimator/trace/metric/confusion_matrix.py
 ./fastestimator/trace/metric/dice.py
 ./fastestimator/trace/metric/f1_score.py
 ./fastestimator/trace/metric/mcc.py
 ./fastestimator/trace/metric/mean_average_precision.py
@@ -324,18 +337,20 @@
 ./fastestimator/trace/metric/recall.py
 ./fastestimator/trace/xai/__init__.py
 ./fastestimator/trace/xai/eigen_cam.py
 ./fastestimator/trace/xai/grad_cam.py
 ./fastestimator/trace/xai/instance_tracker.py
 ./fastestimator/trace/xai/label_tracker.py
 ./fastestimator/trace/xai/saliency.py
+./fastestimator/types/__init__.py
 ./fastestimator/util/__init__.py
 ./fastestimator/util/base_util.py
 ./fastestimator/util/cli_util.py
 ./fastestimator/util/data.py
+./fastestimator/util/google_download_util.py
 ./fastestimator/util/img_data.py
 ./fastestimator/util/latex_util.py
 ./fastestimator/util/traceability_util.py
 ./fastestimator/util/util.py
 ./fastestimator/util/wget_util.py
 ./fastestimator/xai/__init__.py
 ./fastestimator/xai/saliency.py
@@ -352,14 +367,15 @@
 ./test/PR_test/integration_test/backend/test_set_lr.py
 ./test/PR_test/integration_test/backend/test_update_model.py
 ./test/PR_test/integration_test/cli/__init__.py
 ./test/PR_test/integration_test/cli/test_main.py
 ./test/PR_test/integration_test/cli/test_train.py
 ./test/PR_test/integration_test/dataset/__init__.py
 ./test/PR_test/integration_test/dataset/test_batch_dataset.py
+./test/PR_test/integration_test/dataset/test_interleave_dataset.py
 ./test/PR_test/integration_test/op/__init__.py
 ./test/PR_test/integration_test/op/test_op.py
 ./test/PR_test/integration_test/op/numpyop/__init__.py
 ./test/PR_test/integration_test/op/numpyop/meta/__init__.py
 ./test/PR_test/integration_test/op/numpyop/meta/test_fuse.py
 ./test/PR_test/integration_test/op/numpyop/meta/test_one_of.py
 ./test/PR_test/integration_test/op/numpyop/meta/test_repeat.py
@@ -399,14 +415,18 @@
 ./test/PR_test/integration_test/schedule/test_arc.py
 ./test/PR_test/integration_test/schedule/test_epoch_scheduler.py
 ./test/PR_test/integration_test/schedule/test_repeat_scheduler.py
 ./test/PR_test/integration_test/schedule/test_schedule.py
 ./test/PR_test/integration_test/search/__init__.py
 ./test/PR_test/integration_test/search/visualize/__init__.py
 ./test/PR_test/integration_test/search/visualize/test_visualize.py
+./test/PR_test/integration_test/slicer/__init__.py
+./test/PR_test/integration_test/slicer/test_axis_slicer.py
+./test/PR_test/integration_test/slicer/test_slicer.py
+./test/PR_test/integration_test/slicer/test_sliding_slicer.py
 ./test/PR_test/integration_test/summary/__init__.py
 ./test/PR_test/integration_test/summary/test_history.py
 ./test/PR_test/integration_test/summary/test_system.py
 ./test/PR_test/integration_test/trace/__init__.py
 ./test/PR_test/integration_test/trace/test_eval_essential.py
 ./test/PR_test/integration_test/trace/test_logger.py
 ./test/PR_test/integration_test/trace/test_test_essential.py
@@ -415,14 +435,15 @@
 ./test/PR_test/integration_test/trace/adapt/__init__.py
 ./test/PR_test/integration_test/trace/adapt/test_early_stopping.py
 ./test/PR_test/integration_test/trace/adapt/test_lr_scheduler.py
 ./test/PR_test/integration_test/trace/adapt/test_pbm_calibrator.py
 ./test/PR_test/integration_test/trace/adapt/test_reduce_lr_on_plateau.py
 ./test/PR_test/integration_test/trace/adapt/test_terminate_on_nan.py
 ./test/PR_test/integration_test/trace/io/__init__.py
+./test/PR_test/integration_test/trace/io/test_batch_display.py
 ./test/PR_test/integration_test/trace/io/test_best_model_saver.py
 ./test/PR_test/integration_test/trace/io/test_csv_logger.py
 ./test/PR_test/integration_test/trace/io/test_image_saver.py
 ./test/PR_test/integration_test/trace/io/test_image_viewer.py
 ./test/PR_test/integration_test/trace/io/test_model_saver.py
 ./test/PR_test/integration_test/trace/io/test_restore_wizard.py
 ./test/PR_test/integration_test/trace/io/test_saliency.py
@@ -505,25 +526,28 @@
 ./test/PR_test/unit_test/backend/test_tensor_round.py
 ./test/PR_test/unit_test/backend/test_tensor_sqrt.py
 ./test/PR_test/unit_test/backend/test_to_shape.py
 ./test/PR_test/unit_test/backend/test_to_tensor.py
 ./test/PR_test/unit_test/backend/test_to_type.py
 ./test/PR_test/unit_test/backend/test_transpose.py
 ./test/PR_test/unit_test/backend/test_watch.py
+./test/PR_test/unit_test/backend/test_where.py
 ./test/PR_test/unit_test/backend/test_zeros_like.py
 ./test/PR_test/unit_test/backend/test_zscore.py
 ./test/PR_test/unit_test/cli/__init__.py
 ./test/PR_test/unit_test/cli/test_cli_util.py
 ./test/PR_test/unit_test/dataset/__init__.py
 ./test/PR_test/unit_test/dataset/test_batch_dataset.py
+./test/PR_test/unit_test/dataset/test_combine_dataset.py
 ./test/PR_test/unit_test/dataset/test_csv_dataset.py
 ./test/PR_test/unit_test/dataset/test_data.py
 ./test/PR_test/unit_test/dataset/test_dir_dataset.py
 ./test/PR_test/unit_test/dataset/test_extend_dataset.py
 ./test/PR_test/unit_test/dataset/test_generator_dataset.py
+./test/PR_test/unit_test/dataset/test_interleave_dataset.py
 ./test/PR_test/unit_test/dataset/test_labeled_dir_dataset.py
 ./test/PR_test/unit_test/dataset/test_numpy_dataset.py
 ./test/PR_test/unit_test/dataset/test_pickle_dataset.py
 ./test/PR_test/unit_test/dataset/test_siamese_dir_dataset.py
 ./test/PR_test/unit_test/layers/__init__.py
 ./test/PR_test/unit_test/layers/pytorch/__init__.py
 ./test/PR_test/unit_test/layers/pytorch/test_cropping_2d.py
@@ -532,15 +556,14 @@
 ./test/PR_test/unit_test/layers/tensorflow/test_hadamard.py
 ./test/PR_test/unit_test/layers/tensorflow/test_instance_norm.py
 ./test/PR_test/unit_test/layers/tensorflow/test_reflection_padding_2d.py
 ./test/PR_test/unit_test/op/__init__.py
 ./test/PR_test/unit_test/op/test_op.py
 ./test/PR_test/unit_test/op/loss/__init__.py
 ./test/PR_test/unit_test/op/loss/test_focal_loss.py
-./test/PR_test/unit_test/op/loss/test_mix_loss.py
 ./test/PR_test/unit_test/op/numpyop/__init__.py
 ./test/PR_test/unit_test/op/numpyop/test_numpyop.py
 ./test/PR_test/unit_test/op/numpyop/meta/__init__.py
 ./test/PR_test/unit_test/op/numpyop/meta/test_fuse.py
 ./test/PR_test/unit_test/op/numpyop/meta/test_one_of.py
 ./test/PR_test/unit_test/op/numpyop/meta/test_repeat.py
 ./test/PR_test/unit_test/op/numpyop/meta/test_sometimes.py
@@ -626,14 +649,15 @@
 ./test/PR_test/unit_test/op/numpyop/univariate/test_to_sepia.py
 ./test/PR_test/unit_test/op/numpyop/univariate/test_tokenize.py
 ./test/PR_test/unit_test/op/numpyop/univariate/test_translate_x.py
 ./test/PR_test/unit_test/op/numpyop/univariate/test_translate_y.py
 ./test/PR_test/unit_test/op/numpyop/univariate/test_word_to_id.py
 ./test/PR_test/unit_test/op/tensorop/__init__.py
 ./test/PR_test/unit_test/op/tensorop/test_normalize.py
+./test/PR_test/unit_test/op/tensorop/test_resize3d.py
 ./test/PR_test/unit_test/op/tensorop/test_tensorop.py
 ./test/PR_test/unit_test/op/tensorop/augmentation/__init__.py
 ./test/PR_test/unit_test/op/tensorop/augmentation/test_mixup_batch.py
 ./test/PR_test/unit_test/op/tensorop/meta/__init__.py
 ./test/PR_test/unit_test/op/tensorop/meta/test_fuse.py
 ./test/PR_test/unit_test/op/tensorop/meta/test_one_of.py
 ./test/PR_test/unit_test/op/tensorop/meta/test_repeat.py
@@ -642,24 +666,32 @@
 ./test/PR_test/unit_test/schedule/test_epoch_scheduler.py
 ./test/PR_test/unit_test/schedule/test_lr_schedule.py
 ./test/PR_test/unit_test/schedule/test_repeat_scheduler.py
 ./test/PR_test/unit_test/search/__init__.py
 ./test/PR_test/unit_test/search/test_golden_section_search.py
 ./test/PR_test/unit_test/search/test_grid_search.py
 ./test/PR_test/unit_test/search/test_search.py
+./test/PR_test/unit_test/slicer/__init__.py
+./test/PR_test/unit_test/slicer/test_axis_slicer.py
+./test/PR_test/unit_test/slicer/test_mean_slicer.py
+./test/PR_test/unit_test/slicer/test_slicer.py
+./test/PR_test/unit_test/slicer/test_sliding_slicer.py
 ./test/PR_test/unit_test/summary/__init__.py
 ./test/PR_test/unit_test/summary/test_history.py
 ./test/PR_test/unit_test/summary/test_summary.py
 ./test/PR_test/unit_test/summary/logs/__init__.py
 ./test/PR_test/unit_test/summary/logs/test_metrics.py
 ./test/PR_test/unit_test/test/__init__.py
 ./test/PR_test/unit_test/test/test_unittest_util.py
 ./test/PR_test/unit_test/trace/__init__.py
 ./test/PR_test/unit_test/trace/metric/__init__.py
+./test/PR_test/unit_test/trace/metric/test_auc_score.py
 ./test/PR_test/unit_test/trace/metric/test_bleu_score.py
+./test/PR_test/unit_test/types/__init__.py
+./test/PR_test/unit_test/types/test_types.py
 ./test/PR_test/unit_test/util/__init__.py
 ./test/PR_test/unit_test/util/test_data.py
 ./test/PR_test/unit_test/util/test_traceability_util.py
 ./test/PR_test/unit_test/util/test_util.py
 ./test/PR_test/unit_test/util/test_wget_util.py
 ./test/PR_test/unit_test/xai/__init__.py
 ./test/PR_test/unit_test/xai/test_saliency.py
```

### Comparing `fastestimator-1.5.2/test/PR_test/__init__.py` & `fastestimator-1.6.0/test/PR_test/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/backend/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/backend/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/backend/test_get_lr.py` & `fastestimator-1.6.0/test/PR_test/integration_test/backend/test_get_lr.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/backend/test_save_model_load_model.py` & `fastestimator-1.6.0/test/PR_test/integration_test/backend/test_save_model_load_model.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/backend/test_set_lr.py` & `fastestimator-1.6.0/test/PR_test/integration_test/backend/test_set_lr.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/backend/test_update_model.py` & `fastestimator-1.6.0/test/PR_test/integration_test/backend/test_update_model.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/cli/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/cli/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/cli/test_main.py` & `fastestimator-1.6.0/test/PR_test/integration_test/cli/test_main.py`

 * *Files 16% similar despite different names*

```diff
@@ -59,14 +59,51 @@
 
             with self.subTest('args["hyperparameters_json"]'):
                 self.assertEqual(args["hyperparameters_json"], None)
 
             with self.subTest("unknown"):
                 self.assertEqual(unknown, ["--randon", "200"])
 
+    def test_cli_main_run_run(self):
+        with patch('fastestimator.cli.run.run') as fake:
+            fe.cli.run_main([
+                "run",
+                "example_entry.py",
+                "--randon",
+                "200",
+                "--warmup",
+                "False",
+                "--summary",
+                "example_summary",
+                "--eager",
+                "True"
+            ])
+            args, unknown = fake.call_args[0]
+
+            with self.subTest('args["mode"]'):
+                self.assertEqual(args["mode"], "run")
+
+            with self.subTest('args["entry_point"]'):
+                self.assertEqual(args["entry_point"], "example_entry.py")
+
+            with self.subTest('args["hyperparameters_json"]'):
+                self.assertEqual(args["hyperparameters_json"], None)
+
+            with self.subTest('args["warmup"]'):
+                self.assertEqual(args["warmup"], False)
+
+            with self.subTest('args["eager"]'):
+                self.assertEqual(args["eager"], True)
+
+            with self.subTest('args["summary"]'):
+                self.assertEqual(args["summary"], "example_summary")
+
+            with self.subTest("unknown"):
+                self.assertEqual(unknown, ["--randon", "200"])
+
     def test_cli_main_run_logs(self):
         with patch('fastestimator.cli.logs.logs') as fake:
             fe.cli.run_main(["logs", "example_entry.py", "-b", "-v"])
             args, unknown = fake.call_args[0]
 
             with self.subTest('args["mode"]'):
                 self.assertEqual(args["mode"], "logs")
```

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/cli/test_train.py` & `fastestimator-1.6.0/test/PR_test/integration_test/cli/test_train.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/dataset/test_batch_dataset.py` & `fastestimator-1.6.0/test/PR_test/integration_test/dataset/test_batch_dataset.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/meta/test_fuse.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/meta/test_fuse.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/meta/test_one_of.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/meta/test_one_of.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/meta/test_repeat.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/meta/test_repeat.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/meta/test_sometimes.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/meta/test_sometimes.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/multivariate/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/multivariate/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/multivariate/test_read_mat.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/multivariate/test_read_mat.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/univariate/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/univariate/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/univariate/test_hadamard.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/univariate/test_hadamard.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/numpyop/univariate/test_read_image.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/numpyop/univariate/test_read_image.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/augmentation/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/augmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/augmentation/test_cutmix_batch.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/augmentation/test_cutmix_batch.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/gradient/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/gradient/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/gradient/test_fgsm.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/gradient/test_fgsm.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/gradient/test_gradientop.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/gradient/test_gradientop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/gradient/test_watch.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/gradient/test_watch.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/test_cross_entropy.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/test_cross_entropy.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/test_hinge.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/test_hinge.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/test_l2_regularization.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/test_l2_regularization.py`

 * *Files 5% similar despite different names*

```diff
@@ -175,36 +175,33 @@
         # Get Data
         train_data, eval_data = mnist.load_data()
         t_d = train_data.split(128)
         # Initializing Pytorch model
         pytorch_l2 = fe.build(model_fn=MyNet_torch, optimizer_fn=lambda x: torch.optim.SGD(params=x, lr=0.01))
         # Initialize Pytorch pipeline
         pipeline = fe.Pipeline(train_data=t_d,
-                        eval_data=eval_data,
-                        batch_size=128,
-                        ops=[ExpandDims(inputs="x", outputs="x", axis=0),
-                                Minmax(inputs="x", outputs="x")])
+                               eval_data=eval_data,
+                               batch_size=128,
+                               ops=[ExpandDims(inputs="x", outputs="x", axis=0), Minmax(inputs="x", outputs="x")])
         # Initialize Pytorch Network
         network_l2 = fe.Network(ops=[
             ModelOp(model=pytorch_l2, inputs="x", outputs="y_pred"),
             CrossEntropy(inputs=("y_pred", "y"), outputs="ce"),
-            L2Regularizaton(inputs="ce",outputs="l2",model=pytorch_l2,beta = self.beta),
+            L2Regularizaton(inputs="ce", outputs="l2", model=pytorch_l2, beta=self.beta),
             UpdateOp(model=pytorch_l2, loss_name="l2")
         ])
         # step 3
-        traces = [
-            Accuracy(true_key="y", pred_key="y_pred")
-        ]
+        traces = [Accuracy(true_key="y", pred_key="y_pred")]
         # Initialize Pytorch estimator
         estimator_l2 = fe.Estimator(pipeline=pipeline,
-                            network=network_l2,
-                            epochs=1,
-                            traces=traces,
-                            train_steps_per_epoch=1,
-                            monitor_names=["ce","l2"])
+                                    network=network_l2,
+                                    epochs=1,
+                                    traces=traces,
+                                    train_steps_per_epoch=1,
+                                    monitor_names=["ce", "l2"])
         print('********************************Pytorch L2 Regularization training************************************')
         estimator_l2.fit()
 
         # Converting Pytorch weights to numpy
         torch_wt = []
         for _, param in pytorch_l2.named_parameters():
             if param.requires_grad:
@@ -216,36 +213,33 @@
                                batch_size=128,
                                ops=[ExpandDims(inputs="x", outputs="x"), Minmax(inputs="x", outputs="x")])
         # step 2
         model_tf = fe.build(model_fn=MyNet_tf, optimizer_fn=lambda: tf.optimizers.SGD(learning_rate=0.01))
         network = fe.Network(ops=[
             ModelOp(model=model_tf, inputs="x", outputs="y_pred"),
             CrossEntropy(inputs=("y_pred", "y"), outputs="ce"),
-            L2Regularizaton(inputs="ce",outputs="l2",model=model_tf,beta = self.beta),
+            L2Regularizaton(inputs="ce", outputs="l2", model=model_tf, beta=self.beta),
             UpdateOp(model=model_tf, loss_name="l2")
         ])
         # step 3
-        traces = [
-            Accuracy(true_key="y", pred_key="y_pred")
-        ]
+        traces = [Accuracy(true_key="y", pred_key="y_pred")]
         estimator = fe.Estimator(pipeline=pipeline,
-                                network=network,
-                                epochs=1,
-                                traces=traces,
-                                train_steps_per_epoch=1,
-                                monitor_names=["ce","l2"])
+                                 network=network,
+                                 epochs=1,
+                                 traces=traces,
+                                 train_steps_per_epoch=1,
+                                 monitor_names=["ce", "l2"])
         print('*******************************Tensorflow L2 Regularization training***********************************')
         estimator.fit()
 
-
         # Converting TF weights to numpy
         tf_wt = []
         for layer in model_tf.layers:
             for w in layer.trainable_variables:
                 tf_wt.append(w.numpy())
 
         # testing weights
         count = 0
-        for tf_t,tr in zip(tf_wt,torch_wt):
-            if np.sum(np.abs(tf_t-np.transpose(tr))) < (10**-5):
+        for tf_t, tr in zip(tf_wt, torch_wt):
+            if np.sum(np.abs(tf_t - np.transpose(tr))) < (10**-5):
                 count += 1
         self.assertTrue(count == 6)
```

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/test_mean_squared_error.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/test_mean_squared_error.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/loss/test_super_loss.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/loss/test_super_loss.py`

 * *Files 6% similar despite different names*

```diff
@@ -19,30 +19,29 @@
 import tensorflow as tf
 import torch
 
 import fastestimator as fe
 from fastestimator.op.tensorop.loss import CrossEntropy, Hinge, SuperLoss
 from fastestimator.op.tensorop.model import ModelOp
 from fastestimator.test.unittest_util import sample_system_object
+from fastestimator.util.util import get_device
 
 
 class TestSuperLoss(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
+        device = get_device()
         # torch binary ce
-        cls.torch_true_binary = torch.tensor([[1], [0], [1], [0]]).to("cuda:0" if torch.cuda.is_available() else "cpu")
-        cls.torch_pred_binary = torch.tensor([[0.9], [0.3], [0.8],
-                                              [0.1]]).to("cuda:0" if torch.cuda.is_available() else "cpu")
+        cls.torch_true_binary = torch.tensor([[1], [0], [1], [0]]).to(device)
+        cls.torch_pred_binary = torch.tensor([[0.9], [0.3], [0.8], [0.1]]).to(device)
         # categorical ce
         cls.tf_true_cat = tf.constant([[0, 1, 0], [1, 0, 0], [0, 0, 1]])
         cls.tf_pred_cat = tf.constant([[0.1, 0.8, 0.1], [0.9, 0.05, 0.05], [0.1, 0.2, 0.7]])
-        cls.torch_true_cat = torch.tensor([[0, 1, 0], [1, 0, 0],
-                                           [0, 0, 1]]).to("cuda:0" if torch.cuda.is_available() else "cpu")
-        cls.torch_pred_cat = torch.tensor([[0.1, 0.8, 0.1], [0.9, 0.05, 0.05],
-                                           [0.1, 0.2, 0.7]]).to("cuda:0" if torch.cuda.is_available() else "cpu")
+        cls.torch_true_cat = torch.tensor([[0, 1, 0], [1, 0, 0], [0, 0, 1]]).to(device)
+        cls.torch_pred_cat = torch.tensor([[0.1, 0.8, 0.1], [0.9, 0.05, 0.05], [0.1, 0.2, 0.7]]).to(device)
         # sparse categorical ce
         cls.tf_true_sparse = tf.constant([[0], [1], [0]])
         cls.tf_pred_sparse = tf.constant([[0.1, 0.8, 0.1], [0.9, 0.05, 0.05], [0.1, 0.2, 0.7]])
         cls.state = {'warmup': False, 'epoch': 1, 'mode': 'train'}
 
     @staticmethod
     @tf.function
```

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/meta/test_fuse.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/meta/test_fuse.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/meta/test_one_of.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/meta/test_one_of.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/meta/test_repeat.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/meta/test_repeat.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/meta/test_sometimes.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/meta/test_sometimes.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/model/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/model/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/model/test_modelop.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/model/test_modelop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/model/test_updateop.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/model/test_updateop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/test_argmax.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/test_argmax.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/test_average.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/test_average.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/test_reshape.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/test_reshape.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/tensorop/test_un_hadamard.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/tensorop/test_un_hadamard.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/op/test_op.py` & `fastestimator-1.6.0/test/PR_test/integration_test/op/test_op.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/schedule/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/schedule/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/schedule/test_arc.py` & `fastestimator-1.6.0/test/PR_test/integration_test/schedule/test_arc.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/schedule/test_epoch_scheduler.py` & `fastestimator-1.6.0/test/PR_test/integration_test/schedule/test_epoch_scheduler.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/schedule/test_repeat_scheduler.py` & `fastestimator-1.6.0/test/PR_test/integration_test/schedule/test_repeat_scheduler.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/schedule/test_schedule.py` & `fastestimator-1.6.0/test/PR_test/integration_test/schedule/test_schedule.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/search/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/search/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/search/visualize/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/search/visualize/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/search/visualize/test_visualize.py` & `fastestimator-1.6.0/test/PR_test/integration_test/search/visualize/test_visualize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/summary/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/summary/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/summary/test_history.py` & `fastestimator-1.6.0/test/PR_test/integration_test/summary/test_history.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/summary/test_system.py` & `fastestimator-1.6.0/test/PR_test/integration_test/summary/test_system.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/test_estimator.py` & `fastestimator-1.6.0/test/PR_test/integration_test/test_estimator.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/test_network.py` & `fastestimator-1.6.0/test/PR_test/integration_test/test_network.py`

 * *Files 1% similar despite different names*

```diff
@@ -193,15 +193,15 @@
         str_list = ['adadelta', 'adagrad', 'adam', 'adamax', 'rmsprop', 'sgd']
         for opt_name in str_list:
             with self.subTest(optimizer_fn=opt_name):
                 optimizer = fe.network._build_optimizer(optimizer_fn=opt_name,
                                                         model=self.tf_model,
                                                         framework="tf",
                                                         mixed_precision=False)
-                self.assertIsInstance(optimizer, tf.optimizers.Optimizer)
+                self.assertIsInstance(optimizer, tf.optimizers.legacy.Optimizer)
 
     def test_network_build_optimizer_torch_model_optimizer_str(self):
         str_list = ['adadelta', 'adagrad', 'adam', 'adamax', 'rmsprop', 'sgd']
         for opt_name in str_list:
             with self.subTest(optimizer_fn=opt_name):
                 optimizer = fe.network._build_optimizer(optimizer_fn=opt_name,
                                                         model=self.torch_model,
@@ -257,18 +257,18 @@
                                        optimizer_fn=optimizer,
                                        weight=None,
                                        name="test",
                                        mixed_precision=False)
 
         with self.subTest("check optimizer instantiation"):
             for optimizer in model.optimizer.get_all_values():
-                self.assertIsInstance(optimizer, tf.optimizers.Optimizer)
+                self.assertIsInstance(optimizer, tf.optimizers.legacy.Optimizer)
 
         with self.subTest("check current_optimizer"):
-            self.assertIsInstance(model.current_optimizer, tf.optimizers.Adam)
+            self.assertIsInstance(model.current_optimizer, tf.optimizers.legacy.Adam)
 
         with self.subTest("check model_name"):
             self.assertEqual(model.model_name, "test")
 
         with self.subTest("check fe_compiled"):
             self.assertEqual(model.fe_compiled, True)
 
@@ -278,28 +278,28 @@
                                        optimizer_fn=optimizer,
                                        weight=None,
                                        name=None,
                                        mixed_precision=False)
 
         with self.subTest("check optimizer instantiation"):
             for optimizer in model.optimizer.get_all_values():
-                self.assertIsInstance(optimizer, tf.optimizers.Optimizer)
+                self.assertIsInstance(optimizer, tf.optimizers.legacy.Optimizer)
 
         with self.subTest("check current optimizer"):
-            self.assertIsInstance(model.current_optimizer, tf.optimizers.Adam)
+            self.assertIsInstance(model.current_optimizer, tf.optimizers.legacy.Adam)
 
     def test_network_fe_compile_optimizer_no_scheduler_tf_check_optimizer(self):
         optimizer = "adam"
         model = fe.network._fe_compile(model=self.tf_model,
                                        optimizer_fn=optimizer,
                                        weight=None,
                                        name=None,
                                        mixed_precision=False)
         with self.subTest("check optimizer instantiation"):
-            self.assertIsInstance(model.optimizer, tf.optimizers.Optimizer)
+            self.assertIsInstance(model.optimizer, tf.optimizers.legacy.Optimizer)
 
         with self.subTest("check current optimizer"):
             self.assertEqual(model.current_optimizer, model.optimizer)
 
     def test_network_fe_compile_optimizer_epochscheduler_torch_check_optimizer(self):
         optimizer = EpochScheduler(epoch_dict={1: "adam", 10: "sgd"})
         model = fe.network._fe_compile(model=self.torch_model,
@@ -383,17 +383,21 @@
 
     def test_network_build_tf_model_torch_optimizer_check_assertion_error(self):
         with self.assertRaises(AssertionError):
             model = fe.build(model_fn=one_layer_tf_model, optimizer_fn=lambda x: torch.optim.SGD(params=x, lr=0.01))
 
     def test_network_build_torch_model_tf_optimizer_check_assertion_error(self):
         with self.subTest("optimizer_fn directly uses tf optimizer "):
-            with self.assertRaises(AssertionError):
+            with self.assertRaises(ValueError):
                 model = fe.build(model_fn=OneLayerTorchModel, optimizer_fn=tf.optimizers.Adadelta)
 
+        with self.subTest("optimizer_fn directly uses legacy tf optimizer "):
+            with self.assertRaises(AssertionError):
+                model = fe.build(model_fn=OneLayerTorchModel, optimizer_fn=tf.optimizers.legacy.Adadelta)
+
         with self.subTest("optimizer_fn use lambda function"):
             with self.assertRaises(ValueError):
                 model = fe.build(model_fn=OneLayerTorchModel, optimizer_fn=lambda: tf.optimizers.Adadelta())
 
     def test_network_build_unknown_model_check_assertion_error(self):
         with self.assertRaises(ValueError):
             model = fe.build(model_fn=lambda: "string", optimizer_fn=tf.optimizers.Adadelta)
@@ -420,15 +424,15 @@
         network = fe.Network(
             ops=[
                 ModelOp(model=model, inputs="x", outputs="y_pred"),
                 MeanSquaredError(inputs=("y_pred", "y"), outputs="ce"),
                 UpdateOp(model=model, loss_name="ce")
             ],
             pops=PlusOneNumpyOp(inputs="y_pred", outputs="y_pred_processed"))
-        batch = {"x": np.array([[1, 1, 1]]), "y": np.array([[1]])}
+        batch = {"x": np.array([[1, 1, 1]]), "y": np.array([1])}
         batch = network.transform(data=batch, mode="train")
 
         with self.subTest("output y_pred check"):
             ans = np.array([[6]], dtype=np.float32)  # 1*1 + 1*2 + 1*3
             self.assertTrue(np.array_equal(batch["y_pred"].numpy(), ans))
 
         with self.subTest("postprocessing y_pred check"):
@@ -453,15 +457,15 @@
             ],
             pops=PlusOneNumpyOp(inputs="y_pred", outputs="y_pred_processed"))
         batch = {
             "x": np.array([[
                 1,
                 1,
                 1,
-            ]], dtype=np.float32), "y": np.array([[1]], dtype=np.float32)
+            ]], dtype=np.float32), "y": np.array([1], dtype=np.float32)
         }
         batch = network.transform(data=batch, mode="train")
 
         with self.subTest("output y_pred check"):
             ans = np.array([[6]], dtype=np.float32)  # 1*1 + 1*2 + 1*3
             self.assertTrue(np.array_equal(batch["y_pred"].numpy(), ans))
 
@@ -481,15 +485,15 @@
         weight = get_tf_model_weight(model)
         network = fe.Network(ops=[
             ModelOp(model=model, inputs="x", outputs="y_pred"),
             CrossEntropy(inputs=("y_pred", "y"), outputs="ce"),
             UpdateOp(model=model, loss_name="ce")
         ])
 
-        batch = {"x": np.ones((1, 28, 28, 1)), "y": np.array([[1]])}
+        batch = {"x": np.ones((1, 28, 28, 1)), "y": np.array([1])}
         batch = network.transform(data=batch, mode="train")
         with self.subTest("output y_pred check"):
             self.assertTrue("y_pred" in batch.keys())
             self.assertIsNotNone(batch["y_pred"])
 
         with self.subTest("output ce check"):
             self.assertTrue("ce" in batch.keys())
@@ -503,15 +507,15 @@
         model = fe.build(model_fn=LeNetTorch, optimizer_fn=lambda x: torch.optim.Adam(params=x, lr=1.0))
         weight = get_torch_lenet_model_weight(model)
         network = fe.Network(ops=[
             ModelOp(model=model, inputs="x", outputs="y_pred"),
             CrossEntropy(inputs=("y_pred", "y"), outputs="ce"),
             UpdateOp(model=model, loss_name="ce")
         ])
-        batch = {"x": np.ones((1, 1, 28, 28), dtype=np.float32), "y": np.array([[1]], dtype=np.float32)}
+        batch = {"x": np.ones((1, 1, 28, 28), dtype=np.float32), "y": np.array([1], dtype=np.float32)}
         batch = network.transform(data=batch, mode="train")
 
         with self.subTest("output y_pred check"):
             self.assertTrue("y_pred" in batch.keys())
             self.assertIsNotNone(batch["y_pred"])
 
         with self.subTest("output ce check"):
```

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/test_pipeline.py` & `fastestimator-1.6.0/test/PR_test/integration_test/test_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -19,14 +19,15 @@
 import tensorflow as tf
 import torch
 from torch.utils.data import DataLoader, Dataset
 
 import fastestimator as fe
 from fastestimator.dataset.batch_dataset import BatchDataset
 from fastestimator.dataset.extend_dataset import ExtendDataset
+from fastestimator.dataset.interleave_dataset import InterleaveDataset
 from fastestimator.dataset.numpy_dataset import NumpyDataset
 from fastestimator.op.numpyop import NumpyOp, RemoveIf
 from fastestimator.op.numpyop.numpyop import Batch
 from fastestimator.op.numpyop.univariate import Minmax
 from fastestimator.op.tensorop import TensorOp
 from fastestimator.schedule import EpochScheduler, RepeatScheduler
 from fastestimator.test.unittest_util import is_equal
@@ -232,24 +233,27 @@
             with self.assertRaises(AssertionError):
                 fe.Pipeline(train_data=data, ops=[Batch(mode='train'), Batch(mode='train')])
         with self.subTest("Simple DS Conflict"):
             with self.assertRaises(AssertionError):
                 fe.Pipeline(train_data={'ds1': data}, ops=[Batch(ds_id='ds1'), Batch(ds_id='ds1')])
         with self.subTest("Scheduler Conflict"):
             with self.assertRaises(AssertionError):
-                fe.Pipeline(train_data=data,
-                            eval_data={'ds1': data, 'ds2': data, 'ds3': data, 'ds4': data},
-                            test_data=data,
-                            ops=[EpochScheduler({1: Batch(mode='train'),
-                                                 50: Batch(mode='eval', ds_id='ds4'),
-                                                 10000: Batch(mode='test')}),
-                                 RepeatScheduler([Batch(ds_id='ds1'),
-                                                  Batch(ds_id='ds2'),
-                                                  Batch(ds_id='ds3'),
-                                                  Batch(ds_id='ds4')])])
+                fe.Pipeline(
+                    train_data=data,
+                    eval_data={
+                        'ds1': data, 'ds2': data, 'ds3': data, 'ds4': data
+                    },
+                    test_data=data,
+                    ops=[
+                        EpochScheduler({
+                            1: Batch(mode='train'), 50: Batch(mode='eval', ds_id='ds4'), 10000: Batch(mode='test')
+                        }),
+                        RepeatScheduler(
+                            [Batch(ds_id='ds1'), Batch(ds_id='ds2'), Batch(ds_id='ds3'), Batch(ds_id='ds4')])
+                    ])
 
     def test_init_with_permissible_batch_ops(self):
         data = self.sample_torch_dataset
         with self.subTest("Simple Mode Non-Conflict"):
             try:
                 fe.Pipeline(train_data=data, ops=[Batch(mode='train'), Batch(mode='eval')])
             except (AssertionError, ValueError):
@@ -262,53 +266,71 @@
         with self.subTest("Simple DS Non-Conflict (2)"):
             try:
                 fe.Pipeline(train_data={'ds1': data, 'ds2': data}, ops=[Batch(ds_id="ds1"), Batch(ds_id="ds2")])
             except (AssertionError, ValueError):
                 self.fail("Exception Occurred")
         with self.subTest("Mode/DS Non Conflict (1)"):
             try:
-                fe.Pipeline(train_data={'ds1': data, 'ds2': data},
-                            eval_data={'ds1': data, 'ds2': data},
-                            ops=[Batch(mode="train", ds_id="ds1"),
-                                 Batch(mode="eval", ds_id="ds1")])
+                fe.Pipeline(train_data={
+                    'ds1': data, 'ds2': data
+                },
+                            eval_data={
+                                'ds1': data, 'ds2': data
+                            },
+                            ops=[Batch(mode="train", ds_id="ds1"), Batch(mode="eval", ds_id="ds1")])
             except (AssertionError, ValueError):
                 self.fail("Exception Occurred")
         with self.subTest("Mode/DS Non Conflict (2)"):
             try:
-                fe.Pipeline(train_data={'ds1': data, 'ds2': data},
-                            eval_data={'ds1': data, 'ds2': data},
-                            ops=[Batch(mode="train", ds_id="ds1"),
-                                 Batch(mode="train", ds_id="ds2")])
+                fe.Pipeline(train_data={
+                    'ds1': data, 'ds2': data
+                },
+                            eval_data={
+                                'ds1': data, 'ds2': data
+                            },
+                            ops=[Batch(mode="train", ds_id="ds1"), Batch(mode="train", ds_id="ds2")])
             except (AssertionError, ValueError):
                 self.fail("Exception Occurred")
         with self.subTest("Scheduler Non Conflict"):
             try:
-                fe.Pipeline(train_data={'ds1': data, 'ds2': data},
-                            eval_data={'ds1': data, 'ds2': data},
-                            ops=[EpochScheduler({1: Batch(mode="train", ds_id="ds1"),
-                                                 5: Batch(mode="eval")}),
-                                 EpochScheduler({1: Batch(mode="eval"),
-                                                 5: Batch(mode="train", ds_id="ds1")})])
+                fe.Pipeline(
+                    train_data={
+                        'ds1': data, 'ds2': data
+                    },
+                    eval_data={
+                        'ds1': data, 'ds2': data
+                    },
+                    ops=[
+                        EpochScheduler({
+                            1: Batch(mode="train", ds_id="ds1"), 5: Batch(mode="eval")
+                        }),
+                        EpochScheduler({
+                            1: Batch(mode="eval"), 5: Batch(mode="train", ds_id="ds1")
+                        })
+                    ])
             except (AssertionError, ValueError):
                 self.fail("Exception Occurred")
         with self.subTest("Scheduler Non Conflict (2)"):
             try:
-                fe.Pipeline(train_data=data,
-                            eval_data={'ds1': data, 'ds2': data, 'ds3': data, 'ds4': data},
-                            test_data=data,
-                            ops=[EpochScheduler({1: Batch(mode='train'),
-                                                 50: Batch(mode='eval', ds_id='ds4'),
-                                                 100: Batch(mode='test')}),
-                                 RepeatScheduler([Batch(ds_id='ds1'),
-                                                  Batch(ds_id='ds2'),
-                                                  Batch(ds_id='ds3')])
-                                 ])
+                fe.Pipeline(
+                    train_data=data,
+                    eval_data={
+                        'ds1': data, 'ds2': data, 'ds3': data, 'ds4': data
+                    },
+                    test_data=data,
+                    ops=[
+                        EpochScheduler({
+                            1: Batch(mode='train'), 50: Batch(mode='eval', ds_id='ds4'), 100: Batch(mode='test')
+                        }),
+                        RepeatScheduler([Batch(ds_id='ds1'), Batch(ds_id='ds2'), Batch(ds_id='ds3')])
+                    ])
             except (AssertionError, ValueError):
                 self.fail("Exception Occurred")
 
+
 class TestPipelineGetModes(unittest.TestCase):
     """This test include:
     * fe.pipeline.Pipeline.get_modes
     * fe.schedule.schedule.EpochScheduler
     """
     def setUp(self):
         self.sample_torch_dataset = get_sample_torch_dataset()
@@ -427,16 +449,15 @@
         data = pipeline.transform(data=self.sample_data, mode="train")
         ans = {"x": np.array([[1, 2, 3]], dtype=np.float32)}
         self.assertTrue(is_equal(data, ans))
 
     def test_pipeline_transform_with_ops(self):
         pipeline = fe.Pipeline(train_data=self.sample_dataset, ops=[NumpyOpAdd1(inputs="x", outputs="y")])
         data = pipeline.transform(data=self.sample_data, mode="train")
-        ans = {"x": np.array([[1, 2, 3]], dtype=np.float32),
-               "y": np.array([[2, 3, 4]], dtype=np.float32)}
+        ans = {"x": np.array([[1, 2, 3]], dtype=np.float32), "y": np.array([[2, 3, 4]], dtype=np.float32)}
         self.assertTrue(is_equal(data, ans))
 
     def test_multi_train(self):
         pipeline = fe.Pipeline(train_data=self.sample_dataset,
                                ops=Minmax(inputs="x", outputs="x", ds_id=("ds_1", "ds_2")))
         sample_data = {"x": np.array([0, 255], dtype=np.float32)}
         data1 = pipeline.transform(data=sample_data, mode="train", ds_id="ds_1")
@@ -522,29 +543,32 @@
         data = pipeline.get_results(mode="train", epoch=1)
         data["x"] = data["x"].numpy()
         data["y"] = data["y"].numpy()
         ans = {"x": np.array([[0]], dtype=np.float32), "y": np.array([[1]], dtype=np.float32)}
         self.assertTrue(is_equal(data, ans))
 
     def test_pipeline_get_result_dict_batch_size_scheduler(self):
-        pipeline = fe.Pipeline(train_data=self.sample_torch_dataset,
-                               ops=[NumpyOpAdd1(inputs="x", outputs="y"),
-                                    EpochScheduler({1: Batch(batch_size=1, mode='train')})])
+        pipeline = fe.Pipeline(
+            train_data=self.sample_torch_dataset,
+            ops=[NumpyOpAdd1(inputs="x", outputs="y"), EpochScheduler({1: Batch(batch_size=1, mode='train')})])
         data = pipeline.get_results(mode="train", epoch=1)
         data["x"] = data["x"].numpy()
         data["y"] = data["y"].numpy()
         ans = {"x": np.array([[0]], dtype=np.float32), "y": np.array([[1]], dtype=np.float32)}
         self.assertTrue(is_equal(data, ans))
 
     def test_pipeline_get_result_dict_batch_size_train_eval(self):
-        pipeline = fe.Pipeline(train_data=self.sample_torch_dataset,
-                               eval_data=self.sample_torch_dataset,
-                               ops=[NumpyOpAdd1(inputs="x", outputs="y"),
-                                    Batch(batch_size=2, mode='train'),
-                                    Batch(batch_size=1, mode='eval')])
+        pipeline = fe.Pipeline(
+            train_data=self.sample_torch_dataset,
+            eval_data=self.sample_torch_dataset,
+            ops=[
+                NumpyOpAdd1(inputs="x", outputs="y"),
+                Batch(batch_size=2, mode='train'),
+                Batch(batch_size=1, mode='eval')
+            ])
         data_train = pipeline.get_results(mode="train", epoch=1)
         data_eval = pipeline.get_results(mode="eval", epoch=1)
         data_train["x"] = data_train["x"].numpy()
         data_train["y"] = data_train["y"].numpy()
         data_eval["x"] = data_eval["x"].numpy()
         data_eval["y"] = data_eval["y"].numpy()
         ans_train = {"x": np.array([[0], [1]], dtype=np.float32), "y": np.array([[1], [2]], dtype=np.float32)}
@@ -810,24 +834,26 @@
         data = NumpyDataset({"x": np.array([[0, 255], [255, 0]])})
         train_ds = {"ds|ds1": data}
         with self.assertRaises(AssertionError):
             fe.Pipeline(train_data=train_ds)
 
 
 class TestPipelineFilter(unittest.TestCase):
-
     def test_unbatched_no_drop_multi_filter(self):
         data = NumpyDataset({"idx": np.array([i for i in range(10)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       num_process=n_process,
-                                       ops=[RemoveIf(inputs="idx", replacement=False, fn=lambda x: x in [6, 7]),
-                                            Batch(batch_size=4),
-                                            RemoveIf(inputs="idx", replacement=False, fn=lambda x: 0 in x)])
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    num_process=n_process,
+                    ops=[
+                        RemoveIf(inputs="idx", replacement=False, fn=lambda x: x in [6, 7]),
+                        Batch(batch_size=4),
+                        RemoveIf(inputs="idx", replacement=False, fn=lambda x: 0 in x)
+                    ])
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -843,31 +869,29 @@
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
-                    self.assertListEqual([i+1 for i in range(39)], composite_list)
+                    self.assertListEqual([i + 1 for i in range(39)], composite_list)
                 with self.subTest("shuffle True"):
                     with pipeline(mode="train", shuffle=True) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
-                    self.assertSetEqual(set([i+1 for i in range(39)]), set(composite_list))
+                    self.assertSetEqual(set([i + 1 for i in range(39)]), set(composite_list))
 
     def test_unbatched_nodrop_nofilter(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process)
+                pipeline = fe.Pipeline(train_data=data, batch_size=5, num_process=n_process)
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -908,20 +932,19 @@
                     self.assertEqual(23, len(composite_list))
                     self.assertSetEqual(set(target), set(composite_list))  # Should visit all the data at least once
 
     def test_unbatched_nodrop_cutfilter(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process,
-                                       ops=RemoveIf(fn=lambda x: x in [2, 6, 9, 10, 11],
-                                                    inputs="idx",
-                                                    replacement=False))
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=RemoveIf(fn=lambda x: x in [2, 6, 9, 10, 11], inputs="idx", replacement=False))
                 target = [0, 1, 3, 4, 5, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
@@ -938,18 +961,15 @@
                     self.assertEqual(18, len(composite_list))
                     self.assertSetEqual(set(target), set(composite_list))  # Should visit all the data at least once
 
     def test_unbatched_drop_nofilter(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process,
-                                       ops=Batch(drop_last=True))
+                pipeline = fe.Pipeline(train_data=data, batch_size=5, num_process=n_process, ops=Batch(drop_last=True))
                 with self.subTest("shuffle false"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -963,19 +983,19 @@
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
                     self.assertEqual(20, len(composite_list))  # Since shuffling don't know which will be kept
 
     def test_unbatched_drop_replacementfilter(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process,
-                                       ops=[RemoveIf(inputs="idx", fn=lambda x: x in [2, 6, 9, 10, 11]),
-                                            Batch(drop_last=True)])
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=[RemoveIf(inputs="idx", fn=lambda x: x in [2, 6, 9, 10, 11]), Batch(drop_last=True)])
                 target = [0, 1, 3, 4, 5, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1]
                 with self.subTest("shuffle false"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
@@ -991,21 +1011,22 @@
                     self.assertEqual(20, len(composite_list))  # Since shuffling don't know which will be kept
                     self.assertSetEqual(set(target), set(composite_list))  # Everything should be visited at least once
 
     def test_unbatched_drop_cutfilter(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process,
-                                       ops=[RemoveIf(fn=lambda x: x in [2, 6, 9, 10, 11],
-                                                    inputs="idx",
-                                                    replacement=False),
-                                            Batch(drop_last=True)])
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=[
+                        RemoveIf(fn=lambda x: x in [2, 6, 9, 10, 11], inputs="idx", replacement=False),
+                        Batch(drop_last=True)
+                    ])
                 target = [0, 1, 3, 4, 5, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19]
                 with self.subTest("shuffle false"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
@@ -1022,25 +1043,23 @@
                     # Don't know which ones, but should be no repeats at least
                     self.assertEqual(15, len(set(composite_list)))
 
     def test_unbatched_nofilter_expand(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process)
+                pipeline = fe.Pipeline(train_data=data, batch_size=5, num_process=n_process)
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False, steps_per_epoch=11) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
-                    self.assertListEqual([i for i in range(23)]*2+[i for i in range(9)], composite_list)
+                    self.assertListEqual([i for i in range(23)] * 2 + [i for i in range(9)], composite_list)
                 with self.subTest("shuffle True"):
                     with pipeline(mode="train", shuffle=True, steps_per_epoch=11) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1048,17 +1067,15 @@
                     for i in range(23):
                         self.assertGreaterEqual(composite_list.count(i), 2)
 
     def test_unbatched_nofilter_contract(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process)
+                pipeline = fe.Pipeline(train_data=data, batch_size=5, num_process=n_process)
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False, steps_per_epoch=2) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1083,35 +1100,35 @@
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False, steps_per_epoch=11) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
-                    self.assertListEqual(([0, 1, 3, 4, 5, 7, 8]+list(range(12, 23)))*3+[0], composite_list)
+                    self.assertListEqual(([0, 1, 3, 4, 5, 7, 8] + list(range(12, 23))) * 3 + [0], composite_list)
                 with self.subTest("shuffle True"):
                     with pipeline(mode="train", shuffle=True, steps_per_epoch=11) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
                     self.assertEqual(55, len(composite_list))
-                    for i in [0, 1, 3, 4, 5, 7, 8]+list(range(12, 23)):
+                    for i in [0, 1, 3, 4, 5, 7, 8] + list(range(12, 23)):
                         self.assertGreaterEqual(composite_list.count(i), 3)
 
     def test_unbatched_replacementfilter_contract(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process,
-                                       ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13],
-                                                    inputs="idx"))
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13], inputs="idx"))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False, steps_per_epoch=2) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1126,50 +1143,48 @@
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
                     self.assertEqual(10, len(set(composite_list)))  # All the elements should be unique
 
     def test_unbatched_cutfilter_expand(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process,
-                                       ops=RemoveIf(inputs="idx",
-                                                    replacement=False,
-                                                    fn=lambda x: x in [2, 6, 9, 10, 11]))
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=RemoveIf(inputs="idx", replacement=False, fn=lambda x: x in [2, 6, 9, 10, 11]))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False, steps_per_epoch=11) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
-                    self.assertListEqual((([0, 1, 3, 4, 5, 7, 8]+list(range(12, 23)))*3)[:43], composite_list)
+                    self.assertListEqual((([0, 1, 3, 4, 5, 7, 8] + list(range(12, 23))) * 3)[:43], composite_list)
                 with self.subTest("shuffle True"):
                     with pipeline(mode="train", shuffle=True, steps_per_epoch=11) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
                     self.assertGreaterEqual(len(composite_list), 40)
                     self.assertLessEqual(len(composite_list), 45)
-                    for i in [0, 1, 3, 4, 5, 7, 8]+list(range(12, 23)):
+                    for i in [0, 1, 3, 4, 5, 7, 8] + list(range(12, 23)):
                         self.assertGreaterEqual(composite_list.count(i), 2)
 
     def test_unbatched_cutfilter_contract(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process,
-                                       ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10],
-                                                    replacement=False,
-                                                    inputs="idx"))
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10], replacement=False, inputs="idx"))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False, steps_per_epoch=2) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1184,17 +1199,15 @@
                     self.assertGreaterEqual(len(set(composite_list)), 2)
 
     def test_unbatched_nofilter_expandds(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         data = ExtendDataset(data, spoof_length=55)
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process)
+                pipeline = fe.Pipeline(train_data=data, batch_size=5, num_process=n_process)
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1211,17 +1224,15 @@
                         self.assertGreaterEqual(composite_list.count(i), 2)
 
     def test_unbatched_nofilter_contractds(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         data = ExtendDataset(data, spoof_length=10)
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process)
+                pipeline = fe.Pipeline(train_data=data, batch_size=5, num_process=n_process)
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1264,19 +1275,19 @@
                         self.assertGreaterEqual(composite_list.count(i), 3)
 
     def test_unbatched_replacementfilter_contractds(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         data = ExtendDataset(data, spoof_length=10)
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process,
-                                       ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13],
-                                                    inputs="idx"))
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13], inputs="idx"))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1292,20 +1303,19 @@
                     self.assertEqual(10, len(set(composite_list)))  # All the elements should be unique
 
     def test_unbatched_cutfilter_expandds(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         data = ExtendDataset(data, spoof_length=55)
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process,
-                                       ops=RemoveIf(inputs="idx",
-                                                    replacement=False,
-                                                    fn=lambda x: x in [2, 6, 9, 10, 11]))
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=RemoveIf(inputs="idx", replacement=False, fn=lambda x: x in [2, 6, 9, 10, 11]))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1323,20 +1333,19 @@
                         self.assertGreaterEqual(composite_list.count(i), 2)
 
     def test_unbatched_cutfilter_contractds(self):
         data = NumpyDataset({"idx": np.array([i for i in range(23)])})
         data = ExtendDataset(data, spoof_length=10)
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process,
-                                       ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10],
-                                                    replacement=False,
-                                                    inputs="idx"))
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10], replacement=False, inputs="idx"))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1357,33 +1366,28 @@
     def test_batched_nofilter(self):
         data_a = NumpyDataset({"a": np.array([i for i in range(23)])})
         data_b = NumpyDataset({"b": np.array([i for i in range(23)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
                 with self.subTest("shuffle False"):
                     data = BatchDataset(datasets=[data_a, data_b], num_samples=[3, 3])
-                    pipeline = fe.Pipeline(train_data=data,
-                                           batch_size=5,
-                                           num_process=n_process)
+                    pipeline = fe.Pipeline(train_data=data, batch_size=5, num_process=n_process)
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_a = list(np.concatenate([batch['a'] for batch in batches]))
                     composite_b = list(np.concatenate([batch['b'] for batch in batches]))
                     self.assertEqual(24, len(composite_a))  # batch dataset will fill up the final batch
-                    self.assertListEqual(composite_a, composite_b)  # make sure that the index orders are consistent
                     self.assertEqual(23, len(set(composite_a)))  # make sure all the elements got visited
                 with self.subTest("shuffle True"):
                     # have to re-create the dataset since shuffle pollutes the state of the index maps
                     data = BatchDataset(datasets=[data_a, data_b], num_samples=[3, 3])
-                    pipeline = fe.Pipeline(train_data=data,
-                                           batch_size=5,
-                                           num_process=n_process)
+                    pipeline = fe.Pipeline(train_data=data, batch_size=5, num_process=n_process)
                     with pipeline(mode="train", shuffle=True) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_a = list(np.concatenate([batch['a'] for batch in batches]))
                     composite_b = list(np.concatenate([batch['b'] for batch in batches]))
@@ -1408,15 +1412,14 @@
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_a = list(np.concatenate([batch['a'] for batch in batches]))
                     composite_b = list(np.concatenate([batch['b'] for batch in batches]))
                     self.assertEqual(30, len(composite_a))  # batch dataset will fill up the final batch
-                    self.assertListEqual(composite_a, composite_b)  # make sure that the index orders are consistent
                     self.assertGreaterEqual(len(set(composite_a)), 12)  # There should be at least 4 unique batches
                 with self.subTest("shuffle True"):
                     # have to re-create the dataset since shuffle pollutes the state of the index maps
                     data = BatchDataset(datasets=[data_a, data_b], num_samples=[5, 5])
                     pipeline = fe.Pipeline(train_data=data,
                                            batch_size=5,
                                            num_process=n_process,
@@ -1445,37 +1448,32 @@
         data_b = NumpyDataset({"b": np.array([i for i in range(29)])})
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
                 data = BatchDataset(datasets=[data_a, data_b], num_samples=[3, 3])
                 pipeline = fe.Pipeline(train_data=data,
                                        batch_size=5,
                                        num_process=n_process,
-                                       ops=RemoveIf(inputs="a",
-                                                    replacement=False,
-                                                    fn=lambda x: x in [2, 6, 9, 10, 11]))
+                                       ops=RemoveIf(inputs="a", replacement=False, fn=lambda x: x in [2, 6, 9, 10, 11]))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_a = list(np.concatenate([batch['a'] for batch in batches]))
                     composite_b = list(np.concatenate([batch['b'] for batch in batches]))
-                    self.assertListEqual(composite_a, composite_b)  # make sure that the index orders are consistent
                     self.assertGreaterEqual(len(set(composite_a)), 12)  # There should be at least 4 unique batches
                     self.assertGreaterEqual(len(composite_a), 15)  # There should be at least 5 batches
                 with self.subTest("shuffle True"):
                     # have to re-create the dataset since shuffle pollutes the state of the index maps
                     data = BatchDataset(datasets=[data_a, data_b], num_samples=[5, 5])
                     pipeline = fe.Pipeline(train_data=data,
                                            batch_size=5,
                                            num_process=n_process,
-                                           ops=RemoveIf(inputs="a",
-                                                        replacement=False,
-                                                        fn=lambda x: x in [2, 6, 9]))
+                                           ops=RemoveIf(inputs="a", replacement=False, fn=lambda x: x in [2, 6, 9]))
                     with pipeline(mode="train", shuffle=True) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_a = list(np.concatenate([batch['a'] for batch in batches]))
                     composite_b = list(np.concatenate([batch['b'] for batch in batches]))
@@ -1492,16 +1490,15 @@
 
     def test_batched_nofilter_expand(self):
         data_x = NumpyDataset({"idx": np.array([i for i in range(23)])})
         data_y = NumpyDataset({"y": np.array([i for i in range(23)])})
         data = BatchDataset(datasets=[data_x, data_y], num_samples=[5, 5])
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       num_process=n_process)
+                pipeline = fe.Pipeline(train_data=data, num_process=n_process)
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False, steps_per_epoch=11) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1521,17 +1518,15 @@
 
     def test_batched_nofilter_contract(self):
         data_x = NumpyDataset({"idx": np.array([i for i in range(25)])})
         data_y = NumpyDataset({"y": np.array([i for i in range(25)])})
         data = BatchDataset(datasets=[data_x, data_y], num_samples=[5, 5])
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process)
+                pipeline = fe.Pipeline(train_data=data, batch_size=5, num_process=n_process)
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False, steps_per_epoch=2) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1574,18 +1569,18 @@
 
     def test_batched_replacementfilter_contract(self):
         data_x = NumpyDataset({"idx": np.array([i for i in range(23)])})
         data_y = NumpyDataset({"y": np.array([i for i in range(23)])})
         data = BatchDataset(datasets=[data_x, data_y], num_samples=[5, 5])
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       num_process=n_process,
-                                       ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13],
-                                                    inputs="idx"))
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    num_process=n_process,
+                    ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13], inputs="idx"))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False, steps_per_epoch=2) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1604,17 +1599,15 @@
         data_y = NumpyDataset({"y": np.array([i for i in range(23)])})
         data = BatchDataset(datasets=[data_x, data_y], num_samples=[5, 5])
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
                 pipeline = fe.Pipeline(train_data=data,
                                        batch_size=5,
                                        num_process=n_process,
-                                       ops=RemoveIf(inputs="idx",
-                                                    replacement=False,
-                                                    fn=lambda x: x in [2, 6, 9]))
+                                       ops=RemoveIf(inputs="idx", replacement=False, fn=lambda x: x in [2, 6, 9]))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False, steps_per_epoch=11) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1634,17 +1627,15 @@
         data_x = NumpyDataset({"idx": np.array([i for i in range(23)])})
         data_y = NumpyDataset({"y": np.array([i for i in range(23)])})
         data = BatchDataset(datasets=[data_x, data_y], num_samples=[5, 5])
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
                 pipeline = fe.Pipeline(train_data=data,
                                        num_process=n_process,
-                                       ops=RemoveIf(fn=lambda x: x in list(range(18)),
-                                                    replacement=False,
-                                                    inputs="idx"))
+                                       ops=RemoveIf(fn=lambda x: x in list(range(19)), replacement=False, inputs="idx"))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False, steps_per_epoch=2) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     self.assertEqual(0, len(batches))
@@ -1659,17 +1650,15 @@
     def test_batched_nofilter_expandds(self):
         data_x = NumpyDataset({"idx": np.array([i for i in range(23)])})
         data_y = NumpyDataset({"y": np.array([i for i in range(23)])})
         data = BatchDataset(datasets=[data_x, data_y], num_samples=[5, 5])
         data = ExtendDataset(data, spoof_length=11)
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process)
+                pipeline = fe.Pipeline(train_data=data, batch_size=5, num_process=n_process)
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1690,17 +1679,15 @@
     def test_batched_nofilter_contractds(self):
         data_x = NumpyDataset({"idx": np.array([i for i in range(25)])})
         data_y = NumpyDataset({"y": np.array([i for i in range(25)])})
         data = BatchDataset(datasets=[data_x, data_y], num_samples=[5, 5])
         data = ExtendDataset(data, spoof_length=2)
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process)
+                pipeline = fe.Pipeline(train_data=data, batch_size=5, num_process=n_process)
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1745,19 +1732,19 @@
     def test_batched_replacementfilter_contractds(self):
         data_x = NumpyDataset({"idx": np.array([i for i in range(23)])})
         data_y = NumpyDataset({"y": np.array([i for i in range(23)])})
         data = BatchDataset(datasets=[data_x, data_y], num_samples=[5, 5])
         data = ExtendDataset(data, spoof_length=2)
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
-                pipeline = fe.Pipeline(train_data=data,
-                                       batch_size=5,
-                                       num_process=n_process,
-                                       ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13],
-                                                    inputs="idx"))
+                pipeline = fe.Pipeline(
+                    train_data=data,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=RemoveIf(fn=lambda x: x in [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13], inputs="idx"))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1777,17 +1764,15 @@
         data = BatchDataset(datasets=[data_x, data_y], num_samples=[5, 5])
         data = ExtendDataset(data, spoof_length=11)
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
                 pipeline = fe.Pipeline(train_data=data,
                                        batch_size=5,
                                        num_process=n_process,
-                                       ops=RemoveIf(inputs="idx",
-                                                    replacement=False,
-                                                    fn=lambda x: x in [2, 6, 9]))
+                                       ops=RemoveIf(inputs="idx", replacement=False, fn=lambda x: x in [2, 6, 9]))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     composite_list = list(np.concatenate([batch['idx'] for batch in batches]))
@@ -1809,24 +1794,123 @@
         data = BatchDataset(datasets=[data_x, data_y], num_samples=[5, 5])
         data = ExtendDataset(data, spoof_length=2)
         for n_process in [0, 7]:
             with self.subTest("proc status", workers=n_process):
                 pipeline = fe.Pipeline(train_data=data,
                                        batch_size=5,
                                        num_process=n_process,
-                                       ops=RemoveIf(fn=lambda x: x in list(range(18)),
-                                                    replacement=False,
-                                                    inputs="idx"))
+                                       ops=RemoveIf(fn=lambda x: x in list(range(18)), replacement=False, inputs="idx"))
                 with self.subTest("shuffle False"):
                     with pipeline(mode="train", shuffle=False) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     self.assertEqual(0, len(batches))
                 with self.subTest("shuffle True"):
                     with pipeline(mode="train", shuffle=True) as loader:
                         itr = iter(loader)
                         batches = []
                         for elem in itr:
                             batches.append(elem)
                     self.assertEqual(0, len(batches))
+
+    # ### Interleaved Tests ### #
+    # For now we are wasting a ton of data due to implementation of InterleaveDataset. If Torch ever resolves
+    # https://github.com/pytorch/pytorch/issues/104761 then we should switch to a data-loader based implementation and
+    # update these tests accordingly.
+    # ###               ### #
+
+    def test_interleave_drop_replacementfilter(self):
+        data1 = NumpyDataset({"idx": [f'ds1_{idx}' for idx in range(50)]})
+        data2 = NumpyDataset({"idx": [f'ds2_{idx}' for idx in range(50)]})
+        data3 = NumpyDataset({"idx": [f'ds3_{idx}' for idx in range(50)]})
+
+        interleaved = InterleaveDataset(datasets=[data1, data2, data3], pattern=[1, 0, 2, 2])
+        self.assertEqual(len(interleaved), 100)  # 25 + 25 + 50
+        for n_process in [0, 7]:
+            with self.subTest("proc status", workers=n_process):
+                pipeline = fe.Pipeline(
+                    train_data=interleaved,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=[
+                        RemoveIf(inputs="idx", fn=lambda x: x in ['ds2_5', 'ds1_10', 'ds2_20']), Batch(drop_last=True)
+                    ])
+                target = [
+                    ['ds2_0', 'ds2_1', 'ds2_2', 'ds2_3', 'ds2_4'],
+                    ['ds1_0', 'ds1_1', 'ds1_2', 'ds1_3', 'ds1_4'],
+                    ['ds3_0', 'ds3_1', 'ds3_2', 'ds3_3', 'ds3_4'],
+                    ['ds3_5', 'ds3_6', 'ds3_7', 'ds3_8', 'ds3_9'],
+                    ['ds2_10', 'ds2_11', 'ds2_12', 'ds2_13', 'ds2_14'],
+                    ['ds1_15', 'ds1_16', 'ds1_17', 'ds1_18', 'ds1_19'],
+                    ['ds3_30', 'ds3_31', 'ds3_32', 'ds3_33', 'ds3_34'],
+                    ['ds3_35', 'ds3_36', 'ds3_37', 'ds3_38', 'ds3_39'],
+                ]
+                target = target * 3
+                target = target[:20]
+                with self.subTest("shuffle false"):
+                    with pipeline(mode="train", shuffle=False) as loader:
+                        itr = iter(loader)
+                        batches = []
+                        for elem in itr:
+                            batches.append(elem)
+                    batches = [batch['idx'] for batch in batches]
+                    self.assertEqual(len(target), len(batches))
+                    for ti, bi in zip(target, batches):
+                        self.assertListEqual(ti, bi)
+                with self.subTest("shuffle true"):
+                    with pipeline(mode="train", shuffle=True) as loader:
+                        itr = iter(loader)
+                        batches = []
+                        for elem in itr:
+                            batches.append(elem)
+                    batches = [batch['idx'] for batch in batches]
+                    self.assertEqual(20, len(batches))  # Since shuffling don't know which will be kept
+
+    def test_interleave_drop_cutfilter(self):
+        data1 = NumpyDataset({"idx": [f'ds1_{idx}' for idx in range(50)]})
+        data2 = NumpyDataset({"idx": [f'ds2_{idx}' for idx in range(50)]})
+        data3 = NumpyDataset({"idx": [f'ds3_{idx}' for idx in range(50)]})
+
+        interleaved = InterleaveDataset(datasets=[data1, data2, data3], pattern=[1, 0, 2, 2])
+        self.assertEqual(len(interleaved), 100)  # 25 + 25 + 50
+        for n_process in [0, 7]:
+            with self.subTest("proc status", workers=n_process):
+                pipeline = fe.Pipeline(
+                    train_data=interleaved,
+                    batch_size=5,
+                    num_process=n_process,
+                    ops=[
+                        RemoveIf(inputs="idx",
+                                 fn=lambda x: x in ['ds2_5', 'ds1_10', 'ds2_20', 'ds3_49'],
+                                 replacement=False),
+                        Batch(drop_last=True)
+                    ])
+                target = [
+                    ['ds2_0', 'ds2_1', 'ds2_2', 'ds2_3', 'ds2_4'],
+                    ['ds1_0', 'ds1_1', 'ds1_2', 'ds1_3', 'ds1_4'],
+                    ['ds3_0', 'ds3_1', 'ds3_2', 'ds3_3', 'ds3_4'],
+                    ['ds3_5', 'ds3_6', 'ds3_7', 'ds3_8', 'ds3_9'],
+                    ['ds2_10', 'ds2_11', 'ds2_12', 'ds2_13', 'ds2_14'],
+                    ['ds1_15', 'ds1_16', 'ds1_17', 'ds1_18', 'ds1_19'],
+                    ['ds3_30', 'ds3_31', 'ds3_32', 'ds3_33', 'ds3_34'],
+                    ['ds3_35', 'ds3_36', 'ds3_37', 'ds3_38', 'ds3_39'],
+                ]
+                with self.subTest("shuffle false"):
+                    with pipeline(mode="train", shuffle=False) as loader:
+                        itr = iter(loader)
+                        batches = []
+                        for elem in itr:
+                            batches.append(elem)
+                    batches = [batch['idx'] for batch in batches]
+                    self.assertEqual(len(target), len(batches))
+                    for ti, bi in zip(target, batches):
+                        self.assertListEqual(ti, bi)
+                with self.subTest("shuffle true"):
+                    with pipeline(mode="train", shuffle=True) as loader:
+                        itr = iter(loader)
+                        batches = []
+                        for elem in itr:
+                            batches.append(elem)
+                    batches = [batch['idx'] for batch in batches]
+                    self.assertLess(len(batches), 20)  # Since shuffling don't know which will be kept
```

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/test_early_stopping.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/test_early_stopping.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/test_lr_scheduler.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/test_lr_scheduler.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/test_pbm_calibrator.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/test_pbm_calibrator.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/test_reduce_lr_on_plateau.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/test_reduce_lr_on_plateau.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/adapt/test_terminate_on_nan.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/adapt/test_terminate_on_nan.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/io/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/io/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_image_saver.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_image_saver.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_image_viewer.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_image_viewer.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_model_saver.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_model_saver.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_restore_wizard.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_restore_wizard.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_saliency.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_saliency.py`

 * *Files 11% similar despite different names*

```diff
@@ -14,67 +14,67 @@
 # ==============================================================================
 import os
 import tempfile
 import unittest
 
 import fastestimator as fe
 from fastestimator.architecture.tensorflow import LeNet
-from fastestimator.dataset.data import cifair10
-from fastestimator.op.numpyop.univariate import Normalize
+from fastestimator.dataset.data import mnist
+from fastestimator.op.numpyop.univariate import ExpandDims, Minmax
 from fastestimator.op.tensorop.model import ModelOp
-from fastestimator.test.unittest_util import img_to_rgb_array, check_img_similar
+from fastestimator.test.unittest_util import check_img_similar, img_to_rgb_array
 from fastestimator.trace.io import ImageSaver
 from fastestimator.trace.xai import Saliency
 
 
 class TestSaliency(unittest.TestCase):
     """ This test has dependency on:
     * fe.trace.ImageSaver
-    * fe.estimator.enable_deterministic
     """
     def test_saliency(self):
-        fe.enable_deterministic(200)
         label_mapping = {
-            'airplane': 0,
-            'automobile': 1,
-            'bird': 2,
-            'cat': 3,
-            'deer': 4,
-            'dog': 5,
-            'frog': 6,
-            'horse': 7,
-            'ship': 8,
-            'truck': 9
+            'zero': 0,
+            'one': 1,
+            'two': 2,
+            'three': 3,
+            'four': 4,
+            'five': 5,
+            'six': 6,
+            'seven': 7,
+            'eight': 8,
+            'nine': 9
         }
 
         batch_size = 32
 
-        train_data, eval_data = cifair10.load_data()
-        pipeline = fe.Pipeline(test_data=train_data,
+        train_data, _ = mnist.load_data()
+        test_data = train_data.split([i for i in range(10)])
+        pipeline = fe.Pipeline(test_data=test_data,
                                batch_size=batch_size,
-                               ops=[Normalize(inputs="x", outputs="x")],
-                               num_process=0)
+                               ops=[ExpandDims(inputs="x", outputs="x", axis=-1), Minmax(inputs="x", outputs="x")])
 
-        weight_path = os.path.abspath(os.path.join(__file__, "..", "resources", "lenet_cifar10_tf.h5"))
+        weight_path = os.path.abspath(os.path.join(__file__, "..", "resources", "lenet_mnist_tf.h5"))
 
-        model = fe.build(model_fn=lambda: LeNet(input_shape=(32, 32, 3)), optimizer_fn="adam", weights_path=weight_path)
+        model = fe.build(model_fn=lambda: LeNet(input_shape=(28, 28, 1)), optimizer_fn="adam", weights_path=weight_path)
         network = fe.Network(ops=[ModelOp(model=model, inputs="x", outputs="y_pred")])
 
         save_dir = tempfile.mkdtemp()
         traces = [
             Saliency(model=model,
                      model_inputs="x",
                      class_key="y",
                      model_outputs="y_pred",
                      samples=5,
-                     label_mapping=label_mapping),
+                     label_mapping=label_mapping,
+                     smoothing=0,
+                     integrating=0),
             ImageSaver(inputs="saliency", save_dir=save_dir)
         ]
 
         estimator = fe.Estimator(pipeline=pipeline, network=network, epochs=5, traces=traces, log_steps=1000)
         estimator.test()
 
         ans_img_path = os.path.abspath(os.path.join(__file__, "..", "resources", "saliency_figure.png"))
         ans_img = img_to_rgb_array(ans_img_path)
         output_img_path = os.path.join(save_dir, "saliency_test_epoch_5.png")
         output_img = img_to_rgb_array(output_img_path)
-        self.assertTrue(check_img_similar(output_img, ans_img))
+        self.assertTrue(check_img_similar(output_img, ans_img))
```

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_tensorboard.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_tensorboard.py`

 * *Files 2% similar despite different names*

```diff
@@ -115,15 +115,15 @@
         with self.subTest('Check if tensors.tsv was generated'):
             self.assertTrue(os.path.exists(tsv_path))
         with self.subTest('Check if embed image was generated'):
             self.assertTrue(os.path.exists(embed_img_path))
         with self.subTest('Check content of tensors.tsv'):
             self.assertEqual(tsv_data, 27 * ['1.0'])
         with self.subTest('Check embed image content'):
-            self.assertTrue(is_equal(output_img, 255 * np.ones(shape=(3, 3, 3), dtype=np.int)))
+            self.assertTrue(is_equal(output_img, 255 * np.ones(shape=(3, 3, 3), dtype=np.int32)))
 
     def test_torch_on_begin(self):
         tensorboard = TensorBoard(log_dir=self.log_dir)
         tensorboard.system = sample_system_object_torch()
         tensorboard.system.global_step = 1
         with patch('sys.stdout', new=StringIO()) as fake_stdout:
             tensorboard.on_begin(data=self.torch_data)
@@ -137,14 +137,15 @@
         tensorboard.writer = _TorchWriter(self.log_dir, '', tensorboard.system.network)
         model = fe.build(model_fn=fe.architecture.pytorch.LeNet, optimizer_fn='adam', model_name='torch')
         model.fe_input_spec = FeInputSpec(self.torch_data['x'], model)
         tensorboard.system.network.epoch_models = {model}
         if os.path.exists(self.train_path):
             shutil.rmtree(self.train_path)
         tensorboard.on_batch_end(data=self.torch_data)
+        tensorboard.writer.flush()
         filepath = getfilepath()
         for e in tf.compat.v1.train.summary_iterator(filepath):
             for v in e.summary.value:
                 if v.tag == "torch_fc1/bias":
                     output = v.histo.num
                     self.assertEqual(output, 64.0)
 
@@ -176,8 +177,8 @@
         with self.subTest('Check if tensors.tsv was generated'):
             self.assertTrue(os.path.exists(tsv_path))
         with self.subTest('Check if embed image was generated'):
             self.assertTrue(os.path.exists(embed_img_path))
         with self.subTest('Check content of tensors.tsv'):
             self.assertEqual(tsv_data, 27 * ['1.0'])
         with self.subTest('Check embed image content'):
-            self.assertTrue(is_equal(output_img, 255 * np.ones(shape=(3, 3, 3), dtype=np.int)))
+            self.assertTrue(is_equal(output_img, 255 * np.ones(shape=(3, 3, 3), dtype=np.int32)))
```

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_test_report.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_test_report.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/io/test_traceability.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/io/test_traceability.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_accuracy.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_accuracy.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_calibration_error.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_calibration_error.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_confusion_matrix.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_confusion_matrix.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_dice.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_dice.py`

 * *Files 11% similar despite different names*

```diff
@@ -20,35 +20,30 @@
 from fastestimator.trace.metric import Dice
 from fastestimator.util import Data
 
 
 class TestDice(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        x = np.array([[[[0, 1, 1], [1, 0, 1], [1, 0, 1]],
-                       [[0, 0, 1], [1, 1, 1], [1, 0, 1]],
-                       [[0, 1, 1], [1, 0, 1], [1, 0, 1]]]], dtype=np.float32)
-
-        x_pred = np.array([[[[0, 1, 0], [1, 0, 0], [1, 0, 1]],
-                            [[1, 0, 1], [1, 0, 1], [0, 1, 0]],
-                            [[0, 0, 1], [1, 0, 1], [1, 0, 1]]]], dtype=np.float32)
-        cls.data = Data({'x': x, 'x_pred': x_pred})
-        cls.dice_output = [0.750]
+        cls.x = np.array([[[[0, 1, 1], [1, 0, 1], [1, 0, 1]],
+                           [[0, 0, 1], [1, 1, 1], [1, 0, 1]],
+                           [[0, 1, 1], [1, 0, 1], [1, 0, 1]]]], dtype=np.float32)
+
+        cls.x_pred = np.array([[[[0, 1, 0], [1, 0, 0], [1, 0, 1]],
+                                [[1, 0, 1], [1, 0, 1], [0, 1, 0]],
+                                [[0, 0, 1], [1, 0, 1], [1, 0, 1]]]], dtype=np.float32)
+        cls.dice_output = 0.67777777
         cls.dice = Dice(true_key='x', pred_key='x_pred')
         cls.dice.system = sample_system_object()
 
-    def test_on_epoch_begin(self):
-        self.dice.on_epoch_begin(data=self.data)
-        self.assertEqual(self.dice.dice, [])
-
-    def test_on_batch_end(self):
-        self.dice.dice = []
-        self.dice.on_batch_end(data=self.data)
-        self.assertEqual(self.dice.dice, self.dice_output)
-
-    def test_on_epoch_end(self):
-        self.dice.dice = [0.750]
-        self.dice.on_epoch_end(data=self.data)
+    def test_sanity(self):
+        data = Data()
+        self.dice.on_epoch_begin(data=data)
+        self.assertTrue(len(data) == 0)
+        data = Data({'x': self.x, 'x_pred': self.x_pred})
+        self.dice.on_batch_end(data=data)
+        data = Data()
+        self.dice.on_epoch_end(data=data)
         with self.subTest('Check if dice exists'):
-            self.assertIn('Dice', self.data)
+            self.assertIn('Dice', data)
         with self.subTest('Check the value of dice'):
-            self.assertEqual(self.data['Dice'], 0.750)
+            self.assertAlmostEqual(data['Dice'], self.dice_output, places=4)
```

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_f1_score.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_f1_score.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_mcc.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_mcc.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_mean_average_precision.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_mean_average_precision.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_precision.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_precision.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/metric/test_recall.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/metric/test_recall.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/test_eval_essential.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/test_eval_essential.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/test_logger.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/test_logger.py`

 * *Files 1% similar despite different names*

```diff
@@ -59,15 +59,15 @@
         self._test_print_msg(func=logger.on_batch_end, data=self.data, msg=self.on_batch_end_msg)
 
     def test_on_batch_end_mode_eval(self):
         logger = Logger()
         logger.system = sample_system_object()
         logger.system.mode = 'eval'
         logger.system.global_step = 2
-        logger.system.eval_log_steps = [1, 2, 3]
+        logger.system.eval_log_steps = ([1, 2, 3], 3)
         logger.system.log_steps = 3
         logger.on_epoch_begin(self.data)
         self._test_print_msg(func=logger.on_batch_end, data=self.data, msg=self.on_batch_end_eval_msg)
 
     def test_on_epoch_end_mode_train(self):
         logger = Logger()
         logger.system = sample_system_object()
```

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/test_test_essential.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/test_test_essential.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/test_trace.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/test_trace.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/test_train_essential.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/test_train_essential.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,19 +12,18 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import math
 import time
 import unittest
 
-import torch
-
 from fastestimator.test.unittest_util import sample_system_object
 from fastestimator.trace import TrainEssential
 from fastestimator.util.data import Data
+from fastestimator.util.util import get_num_gpus
 
 
 class TestTrainEssential(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
         cls.data = Data({'loss': 10})
         cls.train_essential = TrainEssential(monitor_names='loss')
@@ -33,15 +32,15 @@
         cls.train_essential.system.global_step = 10
         cls.train_essential.epoch_start = time.perf_counter() - 500
         cls.train_essential.step_start = time.perf_counter() - 300
 
     def test_on_begin(self):
         self.train_essential.on_begin(data=self.data)
         with self.subTest('Check number of devices'):
-            self.assertEqual(self.data['num_device'], torch.cuda.device_count())
+            self.assertEqual(self.data['num_device'], get_num_gpus())
         with self.subTest('Check logging interval'):
             self.assertEqual(self.data['logging_interval'], 5)
 
     def test_epoch_begin(self):
         self.train_essential.on_epoch_begin(data=self.data)
         with self.subTest('Epoch start time must not be none'):
             self.assertIsNotNone(self.train_essential.epoch_start)
@@ -53,16 +52,16 @@
         with self.subTest('Check steps/sec in data'):
             self.assertIsNotNone(self.data['steps/sec'])
         with self.subTest('Check elapse time list'):
             self.assertEqual(self.train_essential.elapse_times, [])
 
     def test_on_epoch_end(self):
         self.train_essential.on_epoch_end(data=self.data)
-        self.assertIsNotNone(self.data['epoch_time'])
+        self.assertIsNotNone(self.data['epoch_time(sec)'])
 
     def test_on_end(self):
         self.train_essential.on_end(data=self.data)
         model_name = self.train_essential.system.network.models[0].model_name
         with self.subTest('Check total time in data'):
-            self.assertIsNotNone(self.data['total_time'])
+            self.assertIsNotNone(self.data['total_time(sec)'])
         with self.subTest('Check model learning rate in data dictionary'):
             self.assertTrue(math.isclose(self.data[model_name + '_lr'], 0.001, rel_tol=1e-3))
```

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/xai/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/xai/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/xai/test_instance_tracker.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/xai/test_instance_tracker.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/trace/xai/test_label_tracker.py` & `fastestimator-1.6.0/test/PR_test/integration_test/trace/xai/test_label_tracker.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/util/__init__.py` & `fastestimator-1.6.0/test/PR_test/integration_test/util/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/util/test_img_data.py` & `fastestimator-1.6.0/test/PR_test/integration_test/util/test_img_data.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/util/test_traceability_util.py` & `fastestimator-1.6.0/test/PR_test/integration_test/util/test_traceability_util.py`

 * *Files 0% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 # limitations under the License.
 # ==============================================================================
 import unittest
 
 import numpy as np
 from pylatex.utils import NoEscape
 
-from fastestimator.schedule.lr_shedule import cosine_decay
+from fastestimator.schedule.lr_schedule import cosine_decay
 from fastestimator.util.latex_util import ContainerList, HrefFEID
 from fastestimator.util.traceability_util import _parse_lambda, _parse_lambda_fallback, _trace_value, traceable
 from fastestimator.util.base_util import Flag
 
 
 class NonTraceableObject:
     def __init__(self, a, b):
@@ -104,15 +104,15 @@
         self.assertIsInstance(resp, dict, "_parse_lambda_fallback should return a dictionary")
         self.assertEqual({}, tables, "_parse_lambda_fallback should not have generated any tables for this lambda")
         self.assertIn('function', resp, "response should contain a function summary")
         self.assertEqual(r"cosine\_decay(step, cycle\_length=3750, init\_lr=1e{-}3 + 1 if epochs > 2 else 1e{-}4)",
                          resp['function'])
         self.assertIn('kwargs', resp, "response should contain kwargs")
         self.assertIsInstance(resp['kwargs'], dict, "kwargs should be a dictionary")
-        self.assertDictEqual({NoEscape('epochs'): NoEscape(r'\seqsplit{8}')}, resp['kwargs'])
+        self.assertDictEqual({NoEscape('epochs'): NoEscape(r'\seqsplit{\thinspace 8}')}, resp['kwargs'])
 
     def test_lambda_inlining(self):
         tables = {}
         ret_ref = Flag()
         resp = _parse_lambda_fallback(
             lambda a, b=[0, 1, 2, 3], c={'x': "it's"}: b[0] + a * c['x'] - {0
                                                                             for j in range(5)}, tables, ret_ref)
```

### Comparing `fastestimator-1.5.2/test/PR_test/integration_test/util/test_util.py` & `fastestimator-1.6.0/test/PR_test/integration_test/util/test_util.py`

 * *Files 11% similar despite different names*

```diff
@@ -53,14 +53,20 @@
         img[:, 30:60, :] = np.array([0, 255, 0])
         img[:, 60:90, :] = np.array([0, 0, 255])
 
         fig = fe.util.ImageDisplay(image=img)
 
         # Now we can save it to a numpy array.
         obj1 = fig_to_rgb_array(fig.prepare())
+
+        # If the target output image has changed, you can regenerate it with:
+        # from PIL import Image
+        # im = Image.fromarray(obj1)
+        # im.save("../resources/test.png")
+
         obj2 = self.color_img_ans
         self.assertTrue(check_img_similar(obj1, obj2))
 
     def test_show_image_color_torch(self):
         img = np.zeros((90, 90, 3), dtype=np.uint8)
         img[:, 0:30, :] = np.array([255, 0, 0])
         img[:, 30:60, :] = np.array([0, 255, 0])
@@ -133,17 +139,17 @@
         fig = fe.util.ImageDisplay(text=text).prepare()
         obj1 = fig_to_rgb_array(fig)
         obj2 = self.text_img_ans
         self.assertTrue(check_img_similar(obj1, obj2))
 
     def test_show_image_bounding_box_np(self):
         bg_img = np.zeros((150, 150))
-        boxes = np.array([[0, 0, 10, 20, "apple"], [10, 20, 30, 50, "dog"], [40, 70, 200, 200, "cat"],
-                          [0, 0, 0, 0, "shouldn't shown"], [0, 0, -50, -30, "shouldn't shown2"]])
-        fig = fe.util.ImageDisplay(image=bg_img, bboxes=boxes).prepare()
+        boxes = np.array([[0, 0, 10, 20], [10, 20, 30, 50], [40, 70, 200, 200],
+                          [0, 0, 0, 0], [0, 0, -50, -30]])
+        fig = fe.util.ImageDisplay(image=bg_img, color_map='gray', bboxes=boxes).prepare()
         obj1 = fig_to_rgb_array(fig)
         obj2 = self.bb_img_ans
         self.assertTrue(check_img_similar(obj1, obj2))
 
     def test_show_image_mixed_figure_layer_np(self):
         bg_img = np.ones((150, 150, 3), dtype=np.uint8) * 255
         boxes = np.array([[0, 0, 10, 20], [10, 20, 30, 50], [40, 70, 200, 200]])
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/test_attention_unet.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/test_attention_unet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/test_lenet.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/test_lenet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/test_resnet9.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/test_resnet9.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/test_unet.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/test_unet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/pytorch/test_wideresnet.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/pytorch/test_wideresnet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/test_attention_unet.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/test_attention_unet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/test_lenet.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/test_lenet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/test_resnet9.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/test_resnet9.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/test_unet.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/test_unet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/architecture/tensorflow/test_wideresnet.py` & `fastestimator-1.6.0/test/PR_test/unit_test/architecture/tensorflow/test_wideresnet.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_abs.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_abs.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_argmax.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_argmax.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_binary_crossentropy.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_binary_crossentropy.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_cast.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_cast.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_categorical_crossentropy.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_categorical_crossentropy.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_check_nan.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_check_nan.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_clip_by_value.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_clip_by_value.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_concat.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_concat.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_exp.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_exp.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_expand_dims.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_expand_dims.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_feed_forward.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_feed_forward.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_gather.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_gather.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_gather_from_batch.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_gather_from_batch.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_get_gradient.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_get_gradient.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_get_image_dims.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_get_image_dims.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_hinge.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_hinge.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_iwd.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_iwd.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_lambertw.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_lambertw.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_matmul.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_matmul.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_maximum.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_maximum.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_mean_squared_error.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_mean_squared_error.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_ones_like.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_ones_like.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_percentile.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_percentile.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_permute.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_permute.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_pow.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_pow.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_random_normal_like.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_random_normal_like.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_random_uniform_like.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_random_uniform_like.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reduce_max.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reduce_max.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reduce_mean.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reduce_mean.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reduce_min.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reduce_min.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reduce_std.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reduce_std.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reduce_sum.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reduce_sum.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_reshape.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_reshape.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_resize3d.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_resize3d.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_roll.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_roll.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_sign.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_sign.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_sparse_categorical_crossentropy.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_sparse_categorical_crossentropy.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,19 +20,19 @@
 
 from fastestimator.backend import sparse_categorical_crossentropy
 
 
 class TestSparseCategoricalCrossEntropy(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        cls.tf_true = tf.constant([[0], [1], [0]])
+        cls.tf_true = tf.constant([0, 1, 0])
         cls.tf_pred = tf.constant([[0.1, 0.8, 0.1], [0.9, 0.05, 0.05], [0.1, 0.2, 0.7]])
         cls.tf_weights = tf.lookup.StaticHashTable(
             tf.lookup.KeyValueTensorInitializer(tf.constant([1]), tf.constant([2.0])), default_value=1.0)
-        cls.torch_true = torch.Tensor([[0], [1], [0]])
+        cls.torch_true = torch.Tensor([0, 1, 0])
         cls.torch_pred = torch.Tensor([[0.1, 0.8, 0.1], [0.9, 0.05, 0.05], [0.1, 0.2, 0.7]])
         cls.torch_weights = {1: 2.0}
 
     def test_sparse_categorical_crossentropy_average_loss_true_tf(self):
         obj1 = sparse_categorical_crossentropy(y_pred=self.tf_pred, y_true=self.tf_true).numpy()
         obj2 = 2.5336342
         self.assertTrue(np.allclose(obj1, obj2))
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_squeeze.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_squeeze.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_tensor_normalize.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_tensor_normalize.py`

 * *Files 20% similar despite different names*

```diff
@@ -25,14 +25,18 @@
     def setUpClass(self):
         self.numpy_array = np.arange(0.0, 12.0, 1.0, dtype=np.float32).reshape((1, 2, 2, 3))
         self.numpy_array_int = np.arange(0.0, 12.0, 1.0, dtype=int).reshape((1, 2, 2, 3))
         self.expected_result = np.array([[[[-1.593255, -1.3035723, -1.0138896], [-0.7242068, -0.4345241, -0.14484136]],
                                           [[0.14484136, 0.4345241, 0.7242068], [1.0138896, 1.3035723, 1.593255]]]],
                                         dtype=np.float32)
 
+        self.numpy_array_float = np.moveaxis(self.numpy_array, -1, 1)
+        self.numpy_array_int_float = np.moveaxis(self.numpy_array_int, -1, 1)
+        self.expected_result_torch = np.moveaxis(self.expected_result, -1, 1)
+
     def test_normalize_np_value(self):
         np.testing.assert_array_almost_equal(normalize(self.numpy_array, 0.5, 0.31382295, 11.0), self.expected_result)
 
     def test_normalize_np_value_int(self):
         np.testing.assert_array_almost_equal(normalize(self.numpy_array_int, 0.5, 0.31382295, 11), self.expected_result)
 
     def test_normalize_tf_value(self):
@@ -41,12 +45,13 @@
 
     def test_normalize_tf_value_int(self):
         np.testing.assert_array_almost_equal(
             normalize(tf.convert_to_tensor(self.numpy_array_int), 0.5, 0.31382295, 11.0).numpy(), self.expected_result)
 
     def test_normalize_torch_value(self):
         np.testing.assert_array_almost_equal(
-            normalize(to_tensor(self.numpy_array, 'torch'), 0.5, 0.31382295, 11.0).numpy(), self.expected_result)
+            normalize(to_tensor(self.numpy_array_float, 'torch'), 0.5, 0.31382295, 11.0).numpy(), self.expected_result_torch)
 
     def test_normalize_torch_value_int(self):
         np.testing.assert_array_almost_equal(
-            normalize(to_tensor(self.numpy_array_int, 'torch'), 0.5, 0.31382295, 11.0).numpy(), self.expected_result)
+            normalize(to_tensor(self.numpy_array_int_float, 'torch'), 0.5, 0.31382295, 11.0).numpy(),
+            self.expected_result_torch)
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_tensor_pow.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_tensor_pow.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_tensor_round.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_tensor_round.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_tensor_sqrt.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_tensor_sqrt.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_to_shape.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_to_shape.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_to_tensor.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_to_tensor.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_to_type.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_to_type.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_transpose.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_transpose.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_watch.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_watch.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_zeros_like.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_zeros_like.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/backend/test_zscore.py` & `fastestimator-1.6.0/test/PR_test/unit_test/backend/test_zscore.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/cli/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/cli/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/cli/test_cli_util.py` & `fastestimator-1.6.0/test/PR_test/unit_test/cli/test_cli_util.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/dataset/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/dataset/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_csv_dataset.py` & `fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_generator_dataset.py`

 * *Files 18% similar despite different names*

```diff
@@ -8,27 +8,24 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-import os
-import tempfile
 import unittest
 
-import pandas as pd
+import numpy as np
 
-import fastestimator as fe
+from fastestimator.dataset import GeneratorDataset
 
 
-class TestCSVDataset(unittest.TestCase):
-    def test_dataset(self):
-        tmpdirname = tempfile.mkdtemp()
+def inputs():
+    while True:
+        yield {'x': np.random.rand(4), 'y': np.random.randint(2)}
 
-        data = {'x': ['a1.txt', 'a2.txt', 'b1.txt', 'b2.txt'], 'y': [0, 0, 1, 1]}
-        df = pd.DataFrame(data=data)
-        df.to_csv(os.path.join(tmpdirname, 'data.csv'), index=False)
 
-        dataset = fe.dataset.CSVDataset(file_path=os.path.join(tmpdirname, 'data.csv'))
+class TestGeneratorDataset(unittest.TestCase):
+    def test_dataset(self):
+        dataset = GeneratorDataset(generator=inputs(), samples_per_epoch=10)
 
-        self.assertEqual(len(dataset), 4)
+        self.assertEqual(len(dataset), 10)
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_data.py` & `fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_data.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_dir_dataset.py` & `fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_dir_dataset.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_extend_dataset.py` & `fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_extend_dataset.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_generator_dataset.py` & `fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_pickle_dataset.py`

 * *Files 22% similar despite different names*

```diff
@@ -8,24 +8,18 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
+import os
 import unittest
 
-import numpy as np
+import fastestimator as fe
 
-from fastestimator.dataset import GeneratorDataset
 
-
-def inputs():
-    while True:
-        yield {'x': np.random.rand(4), 'y': np.random.randint(2)}
-
-
-class TestGeneratorDataset(unittest.TestCase):
+class TestPickleDataset(unittest.TestCase):
     def test_dataset(self):
-        dataset = GeneratorDataset(generator=inputs(), samples_per_epoch=10)
+        test_data = fe.dataset.PickleDataset(os.path.abspath(os.path.join(__file__, "..", "resources", "dummy.pkl")))
 
-        self.assertEqual(len(dataset), 10)
+        self.assertEqual(len(test_data), 5)
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_labeled_dir_dataset.py` & `fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_labeled_dir_dataset.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_numpy_dataset.py` & `fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_numpy_dataset.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/dataset/test_siamese_dir_dataset.py` & `fastestimator-1.6.0/test/PR_test/unit_test/dataset/test_siamese_dir_dataset.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/layers/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/layers/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/layers/pytorch/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/layers/pytorch/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/layers/pytorch/test_cropping_2d.py` & `fastestimator-1.6.0/test/PR_test/unit_test/layers/pytorch/test_cropping_2d.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/layers/pytorch/test_hadamard.py` & `fastestimator-1.6.0/test/PR_test/unit_test/layers/pytorch/test_hadamard.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/layers/tensorflow/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/layers/tensorflow/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/layers/tensorflow/test_hadamard.py` & `fastestimator-1.6.0/test/PR_test/unit_test/layers/tensorflow/test_hadamard.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/layers/tensorflow/test_instance_norm.py` & `fastestimator-1.6.0/test/PR_test/unit_test/layers/tensorflow/test_instance_norm.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/layers/tensorflow/test_reflection_padding_2d.py` & `fastestimator-1.6.0/test/PR_test/unit_test/layers/tensorflow/test_reflection_padding_2d.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/loss/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/loss/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/loss/test_focal_loss.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/loss/test_focal_loss.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/meta/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/meta/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/meta/test_fuse.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/meta/test_fuse.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/meta/test_one_of.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/meta/test_one_of.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/meta/test_repeat.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/meta/test_repeat.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/meta/test_sometimes.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/meta/test_sometimes.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_affine.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_affine.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_center_crop.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_center_crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_crop.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_crop_non_empy_mask_if_exists.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_crop_non_empy_mask_if_exists.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_elastic_transform.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_elastic_transform.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_flip.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_flip.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_grid_distortion.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_grid_distortion.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_horizontal_flip.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_horizontal_flip.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_iaa_crop_and_pad.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_iaa_crop_and_pad.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_longest_max_size.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_longest_max_size.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_mask_dropout.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_mask_dropout.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_optical_distortion.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_optical_distortion.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_pad_if_needed.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_pad_if_needed.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_crop.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_crop_near_bbox.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_crop_near_bbox.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_grid_shuffle.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_grid_shuffle.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_resized_crop.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_resized_crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_rotate_90.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_rotate_90.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_scale.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_scale.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_sized_bbox_safe_crop.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_sized_bbox_safe_crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_random_sized_crop.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_random_sized_crop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_resize.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_resize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_rotate.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_rotate.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_shift_scale_rotate.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_shift_scale_rotate.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_smallest_max_size.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_smallest_max_size.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_transpose.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_transpose.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/multivariate/test_vertical_flip.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/multivariate/test_vertical_flip.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/test_numpyop.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/test_numpyop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_autocontrast.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_autocontrast.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_binarize.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_binarize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_blur.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_blur.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_brightness.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_brightness.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_calibrate.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_calibrate.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_channel_dropout.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_channel_dropout.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_channel_shuffle.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_channel_shuffle.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_channel_transpose.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_channel_transpose.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_clahe.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_clahe.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_coarse_dropout.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_coarse_dropout.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_color.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_color.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_color_jitter.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_color_jitter.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_contrast.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_contrast.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_downscale.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_downscale.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_equalize.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_equalize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_expand_dims.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_expand_dims.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_fromfloat.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_fromfloat.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_gaussian_blur.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_gaussian_blur.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_gaussian_noise.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_gaussian_noise.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_hue_saturation_value.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_hue_saturation_value.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_iaa_additive_gaussian_noise.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_iaa_additive_gaussian_noise.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_image_compression.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_image_compression.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_invert_img.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_invert_img.py`

 * *Files 6% similar despite different names*

```diff
@@ -18,17 +18,17 @@
 
 from fastestimator.op.numpyop.univariate import InvertImg
 
 
 class TestInvertImg(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        cls.single_input = [np.random.rand(28, 28, 3)]
+        cls.single_input = [np.random.rand(28, 28, 3).astype('float32')]
         cls.single_output_shape = (28, 28, 3)
-        cls.multi_input = [np.random.rand(28, 28, 3), np.random.rand(28, 28, 3)]
+        cls.multi_input = [np.random.rand(28, 28, 3).astype('float32'), np.random.rand(28, 28, 3).astype('float32')]
         cls.multi_output_shape = (28, 28, 3)
 
     def test_single_input(self):
         invert_img = InvertImg(inputs='x', outputs='x')
         output = invert_img.forward(data=self.single_input, state={})
         with self.subTest('Check output type'):
             self.assertEqual(type(output), list)
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_iso_noise.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_iso_noise.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_median_blur.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_median_blur.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_minmax.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_minmax.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_motion_blur.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_motion_blur.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_multiplicative_noise.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_multiplicative_noise.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_normalize.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_normalize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_onehot.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_to_array.py`

 * *Files 16% similar despite different names*

```diff
@@ -12,26 +12,21 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import unittest
 
 import numpy as np
 
-from fastestimator.op.numpyop.univariate import Onehot
+from fastestimator.op.numpyop.univariate import ToArray
 from fastestimator.test.unittest_util import is_equal
 
 
-class TestOnehot(unittest.TestCase):
+class TestToArray(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        cls.single_input = [[1], [2], [3], [3]]
-        cls.single_output = [
-            np.array([0., 1., 0., 0.]),
-            np.array([0., 0., 1., 0.]),
-            np.array([0., 0., 0., 1.]),
-            np.array([0., 0., 0., 1.])
-        ]
+        cls.input = [1, 2, 3]
+        cls.output = [np.array(1), np.array(2), np.array(3)]
 
-    def test_input_labels(self):
-        op = Onehot(inputs='x', outputs='x', num_classes=4)
-        data = op.forward(data=self.single_input, state={})
-        self.assertTrue(is_equal(data, self.single_output))
+    def test_output_values(self):
+        op = ToArray(inputs='x', outputs='x')
+        data = op.forward(data=self.input, state={})
+        self.assertTrue(is_equal(data, self.output))
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_pad_sequence.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_pad_sequence.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_posterize.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_posterize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_brightness_contrast.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_brightness_contrast.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_fog.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_fog.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_gamma.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_gamma.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_rain.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_rain.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_shadow.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_shadow.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_shapes.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_shapes.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_snow.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_snow.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_random_sun_flare.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_random_sun_flare.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_reshape.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_reshape.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_rgb_shift.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_rgb_shift.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_rua.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_rua.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_sharpness.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_sharpness.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_shear_x.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_shear_x.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_shear_y.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_shear_y.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_solarize.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_solarize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_to_array.py` & `fastestimator-1.6.0/test/PR_test/unit_test/slicer/test_mean_slicer.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2020 The FastEstimator Authors. All Rights Reserved.
+# Copyright 2023 The FastEstimator Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,22 +11,29 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import unittest
 
 import numpy as np
+import tensorflow as tf
+import torch
 
-from fastestimator.op.numpyop.univariate import ToArray
-from fastestimator.test.unittest_util import is_equal
+from fastestimator.slicer import MeanUnslicer
 
 
-class TestToArray(unittest.TestCase):
+class TestMeanUnslicer(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        cls.input = [1, 2, 3]
-        cls.output = [np.array(1), np.array(2), np.array(3)]
+        cls.minibatches = [np.array([0.3, 0.6, 0.9]), np.array([1.0, 1.0, 1.0]), np.array([2.0, 2.0, 2.0])]
+        cls.target = np.array([1.1, 1.2, 1.3])
 
-    def test_output_values(self):
-        op = ToArray(inputs='x', outputs='x')
-        data = op.forward(data=self.input, state={})
-        self.assertTrue(is_equal(data, self.output))
+    def test_unslice(self):
+        slicer = MeanUnslicer(unslice="x")
+        with self.subTest("TF"):
+            minibatches = [tf.convert_to_tensor(elem) for elem in self.minibatches]
+            batch = slicer._unslice_batch(minibatches, key='x')
+            np.testing.assert_array_almost_equal(batch, self.target)
+        with self.subTest("Torch"):
+            minibatches = [torch.tensor(elem) for elem in self.minibatches]
+            batch = slicer._unslice_batch(minibatches, key='x')
+            np.testing.assert_array_almost_equal(batch, self.target)
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_to_float.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_to_float.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_to_gray.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_to_gray.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_to_sepia.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_to_sepia.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_tokenize.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_tokenize.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_translate_x.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_translate_x.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_translate_y.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_translate_y.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/numpyop/univariate/test_word_to_id.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/numpyop/univariate/test_word_to_id.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/augmentation/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/augmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/augmentation/test_mixup_batch.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/augmentation/test_mixup_batch.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/meta/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/meta/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/meta/test_fuse.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/meta/test_fuse.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/meta/test_one_of.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/meta/test_one_of.py`

 * *Files 0% similar despite different names*

```diff
@@ -106,14 +106,15 @@
             self.assertEqual(type(output), list)
         with self.subTest('Check output list length'):
             self.assertEqual(len(output), 2)
         for img_output in output:
             with self.subTest('Check output image shape'):
                 self.assertEqual(img_output.shape, self.output_shape)
 
+
     def test_probability_left_tf(self):
         op1 = LambdaOp(fn=lambda x: tf.convert_to_tensor(1.0), inputs="x", outputs="x")
         op2 = LambdaOp(fn=lambda x: tf.convert_to_tensor(2.0), inputs="x", outputs="x")
         oneof = OneOf(op1, op2, probs=[1.0, 0])
         oneof.build('tf')
         outputs = set(oneof.forward(data=self.single_input_tf, state={}).numpy() for _ in range(10))
         self.assertEqual(len(outputs), 1)
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/meta/test_repeat.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/meta/test_repeat.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/meta/test_sometimes.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/meta/test_sometimes.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/test_normalize.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/test_normalize.py`

 * *Files 16% similar despite different names*

```diff
@@ -12,15 +12,14 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import unittest
 
 import numpy as np
 import tensorflow as tf
-import torch
 
 from fastestimator.backend import to_tensor
 from fastestimator.op.tensorop.normalize import Normalize
 
 
 class TestNormalize(unittest.TestCase):
     @classmethod
@@ -38,63 +37,68 @@
             [[[[-1.5331011, -1.543425, -1.5537487], [-1.1459544, -1.1562783, -1.166602],
                [-0.7588076, -0.7691315, -0.7794553]],
               [[-0.37166086, -0.38198477, -0.39230856], [0.01548585, 0.00516195, -0.00516183], [
                   0.4026326, 0.39230868, 0.3819849
               ]], [[0.7897793, 0.7794554, 0.7691316], [1.176926, 1.1666021, 1.1562784],
                    [1.5640727, 1.5537488, 1.5434251]]]],
             dtype=np.float32)
+        self.numpy_array_torch = np.moveaxis(self.numpy_array, -1, 1)
+        self.numpy_array_int_torch = np.moveaxis(self.numpy_array_int, -1, 1)
+        self.expected_result_torch = np.moveaxis(self.expected_result, -1, 1)
+        self.expected_result_multi_torch = np.moveaxis(self.expected_result_multi, -1, 1)
+
 
     def test_normalize_tf_int(self):
         op = Normalize(inputs="image", outputs="image", mean=0.482, std=0.289, max_pixel_value=27)
-        data = op.forward(data=tf.convert_to_tensor(self.numpy_array), state={})
-        np.testing.assert_array_almost_equal(data.numpy(), self.expected_result, 2)
+        data = op.forward(data=[tf.convert_to_tensor(self.numpy_array)], state={})
+        np.testing.assert_array_almost_equal(data[0].numpy(), self.expected_result, 2)
 
     def test_normalize_tf_multi_int(self):
         op = Normalize(inputs="image",
                        outputs="image",
                        mean=(0.44, 0.48, 0.52),
                        std=(0.287, 0.287, 0.287),
                        max_pixel_value=27)
-        data = op.forward(data=tf.convert_to_tensor(self.numpy_array), state={})
-        np.testing.assert_array_almost_equal(data.numpy(), self.expected_result_multi, 2)
+        data = op.forward(data=[tf.convert_to_tensor(self.numpy_array)], state={})
+        np.testing.assert_array_almost_equal(data[0].numpy(), self.expected_result_multi, 2)
 
     def test_normalize_torch(self):
         op = Normalize(inputs="image", outputs="image", mean=0.482, std=0.289, max_pixel_value=27.0)
-        data = op.forward(data=to_tensor(self.numpy_array, "torch"), state={})
-        np.testing.assert_array_almost_equal(data.numpy(), self.expected_result, 2)
+        data = op.forward(data=[to_tensor(self.numpy_array_int_torch, "torch")], state={})
+        np.testing.assert_array_almost_equal(data[0].numpy(), self.expected_result_torch, 2)
 
     def test_normalize_torch_multi(self):
         op = Normalize(inputs="image",
                        outputs="image",
                        mean=(0.44, 0.48, 0.52),
                        std=(0.287, 0.287, 0.287),
                        max_pixel_value=27)
-        data = op.forward(data=to_tensor(self.numpy_array, "torch"), state={})
-        np.testing.assert_array_almost_equal(data.numpy(), self.expected_result_multi, 2)
+        data = op.forward(data=[to_tensor(self.numpy_array_int_torch, "torch")], state={})
+        np.testing.assert_array_almost_equal(data[0].numpy(), self.expected_result_multi_torch, 2)
 
     def test_normalize_torch_float(self):
         op = Normalize(inputs="image", outputs="image", mean=0.482, std=0.289, max_pixel_value=27.0)
-        data = op.forward(data=to_tensor(self.numpy_array, "torch"), state={})
-        np.testing.assert_array_almost_equal(data.numpy(), self.expected_result, 2)
+        data = op.forward(data=[to_tensor(self.numpy_array_torch, "torch")], state={})
+        np.testing.assert_array_almost_equal(data[0].numpy(), self.expected_result_torch, 2)
 
     def test_normalize_torch_multi_float(self):
         op = Normalize(inputs="image",
                        outputs="image",
                        mean=(0.44, 0.48, 0.52),
                        std=(0.287, 0.287, 0.287),
                        max_pixel_value=27)
-        data = op.forward(data=to_tensor(self.numpy_array, "torch"), state={})
-        np.testing.assert_array_almost_equal(data.numpy(), self.expected_result_multi, 2)
+        data = op.forward(data=[to_tensor(self.numpy_array_torch, "torch")], state={})
+        np.testing.assert_array_almost_equal(data[0].numpy(), self.expected_result_multi_torch, 2)
 
     def test_normalize_numpy_float(self):
         op = Normalize(inputs="image", outputs="image", mean=0.482, std=0.289, max_pixel_value=27.0)
-        data = op.forward(data=self.numpy_array, state={})
-        np.testing.assert_array_almost_equal(data, self.expected_result, 2)
+        data = op.forward(data=[self.numpy_array], state={})
+        np.testing.assert_array_almost_equal(data[0], self.expected_result, 2)
 
     def test_normalize_numpy_multi_float(self):
         op = Normalize(inputs="image",
                        outputs="image",
                        mean=(0.44, 0.48, 0.52),
                        std=(0.287, 0.287, 0.287),
                        max_pixel_value=27)
-        data = op.forward(data=self.numpy_array, state={})
-        np.testing.assert_array_almost_equal(data, self.expected_result_multi, 2)
+        data = op.forward(data=[self.numpy_array], state={})
+        np.testing.assert_array_almost_equal(data[0], self.expected_result_multi, 2)
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/tensorop/test_tensorop.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/tensorop/test_tensorop.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/op/test_op.py` & `fastestimator-1.6.0/test/PR_test/unit_test/op/test_op.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/schedule/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/schedule/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/schedule/test_epoch_scheduler.py` & `fastestimator-1.6.0/test/PR_test/unit_test/schedule/test_epoch_scheduler.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/schedule/test_lr_schedule.py` & `fastestimator-1.6.0/test/PR_test/unit_test/schedule/test_lr_schedule.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import math
 import unittest
 
-from fastestimator.schedule.lr_shedule import cosine_decay
+from fastestimator.schedule.lr_schedule import cosine_decay
 
 
 class TestLRSchedule(unittest.TestCase):
     def test_cosine_decay(self):
         learning_rate = cosine_decay(time=5, cycle_length=10, init_lr=0.01, min_lr=0.0)
         self.assertEqual(learning_rate, 0.005)
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/schedule/test_repeat_scheduler.py` & `fastestimator-1.6.0/test/PR_test/unit_test/schedule/test_repeat_scheduler.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/search/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/search/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/search/test_golden_section_search.py` & `fastestimator-1.6.0/test/PR_test/unit_test/search/test_golden_section_search.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/search/test_grid_search.py` & `fastestimator-1.6.0/test/PR_test/unit_test/search/test_grid_search.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/search/test_search.py` & `fastestimator-1.6.0/test/PR_test/unit_test/search/test_search.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/summary/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/summary/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/summary/logs/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/summary/logs/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/summary/logs/test_metrics.py` & `fastestimator-1.6.0/test/PR_test/unit_test/summary/logs/test_metrics.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/summary/test_history.py` & `fastestimator-1.6.0/test/PR_test/unit_test/summary/test_history.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/summary/test_summary.py` & `fastestimator-1.6.0/test/PR_test/unit_test/summary/test_summary.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/test/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/test/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/test/test_unittest_util.py` & `fastestimator-1.6.0/test/PR_test/unit_test/test/test_unittest_util.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/trace/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/trace/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/trace/metric/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/trace/metric/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/trace/metric/test_bleu_score.py` & `fastestimator-1.6.0/test/PR_test/unit_test/trace/metric/test_bleu_score.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/util/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/util/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/util/test_data.py` & `fastestimator-1.6.0/test/PR_test/unit_test/util/test_data.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/util/test_traceability_util.py` & `fastestimator-1.6.0/test/PR_test/unit_test/util/test_traceability_util.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/util/test_util.py` & `fastestimator-1.6.0/test/PR_test/unit_test/util/test_util.py`

 * *Files 2% similar despite different names*

```diff
@@ -104,14 +104,36 @@
         self.assertEqual(x, {None, "2", (3, 4)})
 
     def test_to_set_input_set(self):
         x = fe.util.to_set({3, 4})
         self.assertEqual(x, {3, 4})
 
 
+class TestFilterNones(unittest.TestCase):
+    def test_with_list(self):
+        x = fe.util.filter_nones([1, None, "A", None, 0.9])
+        self.assertTrue(isinstance(x, list))
+        self.assertListEqual(x, [1, "A", 0.9])
+
+    def test_with_tuple(self):
+        x = fe.util.filter_nones((1, None, "A", None, 0.9))
+        self.assertTrue(isinstance(x, tuple))
+        self.assertTupleEqual(x, (1, "A", 0.9))
+
+    def test_with_set(self):
+        x = fe.util.filter_nones({1, None, "A", None, 0.9})
+        self.assertTrue(isinstance(x, set))
+        self.assertSetEqual(x, {1, "A", 0.9})
+
+    def test_with_dict(self):
+        x = fe.util.filter_nones({'a': 1, 'b': None, 'c': "A", 'd': None, 'e': 0.9})
+        self.assertTrue(isinstance(x, dict))
+        self.assertDictEqual(x, {'a': 1, 'c': "A", 'e': 0.9})
+
+
 class TestParamToRange(unittest.TestCase):
     def test_param_to_range_int(self):
         x = fe.util.param_to_range(3)
         self.assertEqual(x, (-3, 3))
 
     def test_param_to_range_float(self):
         x = fe.util.param_to_range(2.3)
```

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/xai/__init__.py` & `fastestimator-1.6.0/test/PR_test/unit_test/xai/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/PR_test/unit_test/xai/test_saliency.py` & `fastestimator-1.6.0/test/PR_test/unit_test/xai/test_saliency.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/__init__.py` & `fastestimator-1.6.0/test/__init__.py`

 * *Files identical despite different names*

### Comparing `fastestimator-1.5.2/test/run_pr_test.py` & `fastestimator-1.6.0/test/run_pr_test.py`

 * *Files identical despite different names*

