# Comparing `tmp/brainpy-2.4.3.2-py3-none-any.whl.zip` & `tmp/brainpy-2.4.3.post3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,9 +1,9 @@
-Zip file size: 658173 bytes, number of entries: 333
--rw-rw-rw-  2.0 fat     4723 b- defN 23-Jul-24 02:46 brainpy/__init__.py
+Zip file size: 658261 bytes, number of entries: 333
+-rw-rw-rw-  2.0 fat     4727 b- defN 23-Jul-25 05:20 brainpy/__init__.py
 -rw-rw-rw-  2.0 fat     6082 b- defN 23-Jul-23 10:10 brainpy/_add_deprecations.py
 -rw-rw-rw-  2.0 fat      686 b- defN 23-Jun-22 06:44 brainpy/analysis.py
 -rw-rw-rw-  2.0 fat       81 b- defN 23-Jul-23 10:10 brainpy/channels.py
 -rw-rw-rw-  2.0 fat    19618 b- defN 23-Jul-23 10:10 brainpy/check.py
 -rw-rw-rw-  2.0 fat      429 b- defN 23-Jul-21 14:18 brainpy/checkpoints.py
 -rw-rw-rw-  2.0 fat     1332 b- defN 23-Jul-21 14:18 brainpy/connect.py
 -rw-rw-rw-  2.0 fat      338 b- defN 23-Jun-22 06:44 brainpy/encoding.py
@@ -24,18 +24,18 @@
 -rw-rw-rw-  2.0 fat      126 b- defN 23-Jul-23 10:10 brainpy/synplast.py
 -rw-rw-rw-  2.0 fat     1094 b- defN 23-Jul-21 14:18 brainpy/tools.py
 -rw-rw-rw-  2.0 fat      279 b- defN 23-Jul-21 14:18 brainpy/types.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-23 10:10 brainpy/_src/__init__.py
 -rw-rw-rw-  2.0 fat    10243 b- defN 23-Jul-23 10:10 brainpy/_src/_delay.py
 -rw-rw-rw-  2.0 fat     2509 b- defN 23-Jul-21 14:18 brainpy/_src/checking.py
 -rw-rw-rw-  2.0 fat     2714 b- defN 23-Jul-23 10:10 brainpy/_src/context.py
--rw-rw-rw-  2.0 fat    23805 b- defN 23-Jul-24 02:42 brainpy/_src/delay.py
--rw-rw-rw-  2.0 fat     2121 b- defN 23-Jul-23 10:10 brainpy/_src/deprecations.py
--rw-rw-rw-  2.0 fat    25795 b- defN 23-Jul-23 13:29 brainpy/_src/dynsys.py
--rw-rw-rw-  2.0 fat    21257 b- defN 23-Jul-23 13:30 brainpy/_src/mixin.py
+-rw-rw-rw-  2.0 fat    14197 b- defN 23-Jul-24 06:06 brainpy/_src/delay.py
+-rw-rw-rw-  2.0 fat     2161 b- defN 23-Jul-24 02:50 brainpy/_src/deprecations.py
+-rw-rw-rw-  2.0 fat    27134 b- defN 23-Jul-24 12:13 brainpy/_src/dynsys.py
+-rw-rw-rw-  2.0 fat    21211 b- defN 23-Jul-24 10:56 brainpy/_src/mixin.py
 -rw-rw-rw-  2.0 fat     1128 b- defN 23-Jul-21 14:18 brainpy/_src/modes.py
 -rw-rw-rw-  2.0 fat    24011 b- defN 23-Jul-23 10:10 brainpy/_src/runners.py
 -rw-rw-rw-  2.0 fat    10537 b- defN 23-Jul-23 10:10 brainpy/_src/transform.py
 -rw-rw-rw-  2.0 fat     1102 b- defN 23-Jul-21 14:18 brainpy/_src/types.py
 -rw-rw-rw-  2.0 fat      871 b- defN 23-Jun-28 12:42 brainpy/_src/analysis/__init__.py
 -rw-rw-rw-  2.0 fat      168 b- defN 23-Jun-28 12:42 brainpy/_src/analysis/base.py
 -rw-rw-rw-  2.0 fat     1807 b- defN 23-Jun-28 12:42 brainpy/_src/analysis/constants.py
@@ -106,47 +106,47 @@
 -rw-rw-rw-  2.0 fat    49933 b- defN 23-Jul-23 13:07 brainpy/_src/dyn/neurons/hh.py
 -rw-rw-rw-  2.0 fat    88145 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/neurons/lif.py
 -rw-rw-rw-  2.0 fat       29 b- defN 23-Jul-21 14:18 brainpy/_src/dyn/others/__init__.py
 -rw-rw-rw-  2.0 fat     4293 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/others/common.py
 -rw-rw-rw-  2.0 fat     6984 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/others/input.py
 -rw-rw-rw-  2.0 fat     2278 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/others/noise.py
 -rw-rw-rw-  2.0 fat       45 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/outs/__init__.py
--rw-rw-rw-  2.0 fat      779 b- defN 23-Jul-23 13:03 brainpy/_src/dyn/outs/base.py
--rw-rw-rw-  2.0 fat     3314 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/outs/outputs.py
+-rw-rw-rw-  2.0 fat      864 b- defN 23-Jul-24 14:33 brainpy/_src/dyn/outs/base.py
+-rw-rw-rw-  2.0 fat     3313 b- defN 23-Jul-25 01:43 brainpy/_src/dyn/outs/outputs.py
 -rw-rw-rw-  2.0 fat       69 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/projections/__init__.py
--rw-rw-rw-  2.0 fat    30740 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/projections/aligns.py
+-rw-rw-rw-  2.0 fat    40643 b- defN 23-Jul-25 05:20 brainpy/_src/dyn/projections/aligns.py
 -rw-rw-rw-  2.0 fat     3872 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/projections/conn.py
 -rw-rw-rw-  2.0 fat     2772 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/projections/others.py
 -rw-rw-rw-  2.0 fat       55 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/rates/__init__.py
 -rw-rw-rw-  2.0 fat    42276 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/rates/populations.py
 -rw-rw-rw-  2.0 fat       61 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/synapses/__init__.py
--rw-rw-rw-  2.0 fat    22572 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/synapses/abstract_models.py
+-rw-rw-rw-  2.0 fat    22788 b- defN 23-Jul-24 10:25 brainpy/_src/dyn/synapses/abstract_models.py
 -rw-rw-rw-  2.0 fat    12152 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/synapses/bio_models.py
 -rw-rw-rw-  2.0 fat    11132 b- defN 23-Jul-23 10:10 brainpy/_src/dyn/synapses/delay_couplings.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/experimental/__init__.py
 -rw-rw-rw-  2.0 fat    13965 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/experimental/abstract_synapses.py
 -rw-rw-rw-  2.0 fat     4774 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/experimental/base.py
 -rw-rw-rw-  2.0 fat     2632 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/experimental/others.py
 -rw-rw-rw-  2.0 fat     2775 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/experimental/syn_outs.py
 -rw-rw-rw-  2.0 fat     4898 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/experimental/syn_plasticity.py
 -rw-rw-rw-  2.0 fat      126 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/neurons/__init__.py
 -rw-rw-rw-  2.0 fat    37874 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/neurons/biological_models.py
 -rw-rw-rw-  2.0 fat    13424 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/neurons/fractional_models.py
 -rw-rw-rw-  2.0 fat    62971 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/neurons/reduced_models.py
 -rw-rw-rw-  2.0 fat      170 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synapses/__init__.py
--rw-rw-rw-  2.0 fat    29549 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synapses/abstract_models.py
--rw-rw-rw-  2.0 fat    10819 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synapses/base.py
+-rw-rw-rw-  2.0 fat    29549 b- defN 23-Jul-25 02:03 brainpy/_src/dynold/synapses/abstract_models.py
+-rw-rw-rw-  2.0 fat    10819 b- defN 23-Jul-25 02:03 brainpy/_src/dynold/synapses/base.py
 -rw-rw-rw-  2.0 fat    13792 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synapses/biological_models.py
 -rw-rw-rw-  2.0 fat     7826 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synapses/compat.py
 -rw-rw-rw-  2.0 fat     2116 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synapses/gap_junction.py
 -rw-rw-rw-  2.0 fat     8796 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synapses/learning_rules.py
 -rw-rw-rw-  2.0 fat       77 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synouts/__init__.py
--rw-rw-rw-  2.0 fat     2727 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synouts/conductances.py
--rw-rw-rw-  2.0 fat     3363 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synouts/ions.py
+-rw-rw-rw-  2.0 fat     2727 b- defN 23-Jul-25 02:05 brainpy/_src/dynold/synouts/conductances.py
+-rw-rw-rw-  2.0 fat     3363 b- defN 23-Jul-25 02:05 brainpy/_src/dynold/synouts/ions.py
 -rw-rw-rw-  2.0 fat       65 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synplast/__init__.py
 -rw-rw-rw-  2.0 fat     5782 b- defN 23-Jul-23 10:10 brainpy/_src/dynold/synplast/short_term_plasticity.py
 -rw-rw-rw-  2.0 fat      121 b- defN 23-Jun-28 12:42 brainpy/_src/encoding/__init__.py
 -rw-rw-rw-  2.0 fat      381 b- defN 23-Jun-28 12:42 brainpy/_src/encoding/base.py
 -rw-rw-rw-  2.0 fat     4930 b- defN 23-Jul-21 14:18 brainpy/_src/encoding/stateful_encoding.py
 -rw-rw-rw-  2.0 fat     2224 b- defN 23-Jul-21 14:18 brainpy/_src/encoding/stateless_encoding.py
 -rw-rw-rw-  2.0 fat      163 b- defN 23-Jun-28 12:42 brainpy/_src/initialize/__init__.py
@@ -292,15 +292,15 @@
 -rw-rw-rw-  2.0 fat       78 b- defN 23-Jul-23 10:10 brainpy/dyn/base.py
 -rw-rw-rw-  2.0 fat     1593 b- defN 23-Jul-23 10:10 brainpy/dyn/channels.py
 -rw-rw-rw-  2.0 fat      102 b- defN 23-Jul-23 10:10 brainpy/dyn/compat.py
 -rw-rw-rw-  2.0 fat      592 b- defN 23-Jul-23 10:10 brainpy/dyn/ions.py
 -rw-rw-rw-  2.0 fat      632 b- defN 23-Jul-23 10:10 brainpy/dyn/neurons.py
 -rw-rw-rw-  2.0 fat      358 b- defN 23-Jul-23 10:10 brainpy/dyn/others.py
 -rw-rw-rw-  2.0 fat      134 b- defN 23-Jul-23 10:10 brainpy/dyn/outs.py
--rw-rw-rw-  2.0 fat      362 b- defN 23-Jul-23 10:10 brainpy/dyn/projections.py
+-rw-rw-rw-  2.0 fat      398 b- defN 23-Jul-25 05:20 brainpy/dyn/projections.py
 -rw-rw-rw-  2.0 fat      146 b- defN 23-Jul-23 10:10 brainpy/dyn/rates.py
 -rw-rw-rw-  2.0 fat      332 b- defN 23-Jul-23 10:10 brainpy/dyn/synapses.py
 -rw-rw-rw-  2.0 fat      134 b- defN 23-Jun-22 06:44 brainpy/integrators/__init__.py
 -rw-rw-rw-  2.0 fat      597 b- defN 23-Jun-22 06:44 brainpy/integrators/fde.py
 -rw-rw-rw-  2.0 fat     1103 b- defN 23-Jun-22 06:44 brainpy/integrators/ode.py
 -rw-rw-rw-  2.0 fat      706 b- defN 23-Jun-22 06:44 brainpy/integrators/sde.py
 -rw-rw-rw-  2.0 fat     4883 b- defN 23-Jul-21 14:18 brainpy/math/__init__.py
@@ -323,13 +323,13 @@
 -rw-rw-rw-  2.0 fat      137 b- defN 23-Jul-21 14:18 brainpy/math/op_register.py
 -rw-rw-rw-  2.0 fat      268 b- defN 23-Jul-21 14:18 brainpy/math/others.py
 -rw-rw-rw-  2.0 fat      352 b- defN 23-Jul-21 14:18 brainpy/math/pre_syn_post.py
 -rw-rw-rw-  2.0 fat     1843 b- defN 23-Jun-22 06:44 brainpy/math/random.py
 -rw-rw-rw-  2.0 fat      228 b- defN 23-Jul-21 14:18 brainpy/math/sharding.py
 -rw-rw-rw-  2.0 fat      175 b- defN 23-Jul-21 14:18 brainpy/math/sparse.py
 -rw-rw-rw-  2.0 fat     1320 b- defN 23-Jul-21 14:18 brainpy/math/surrogate.py
--rw-rw-rw-  2.0 fat    35773 b- defN 23-Jul-24 02:47 brainpy-2.4.3.2.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     4351 b- defN 23-Jul-24 02:47 brainpy-2.4.3.2.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Jul-24 02:47 brainpy-2.4.3.2.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 23-Jul-24 02:47 brainpy-2.4.3.2.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat    29719 b- defN 23-Jul-24 02:47 brainpy-2.4.3.2.dist-info/RECORD
-333 files, 2741265 bytes uncompressed, 611099 bytes compressed:  77.7%
+-rw-rw-rw-  2.0 fat    35773 b- defN 23-Jul-25 06:00 brainpy-2.4.3.post3.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     4355 b- defN 23-Jul-25 06:00 brainpy-2.4.3.post3.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Jul-25 06:00 brainpy-2.4.3.post3.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        8 b- defN 23-Jul-25 06:00 brainpy-2.4.3.post3.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat    29739 b- defN 23-Jul-25 06:00 brainpy-2.4.3.post3.dist-info/RECORD
+333 files, 2743257 bytes uncompressed, 611147 bytes compressed:  77.7%
```

## zipnote {}

```diff
@@ -978,23 +978,23 @@
 
 Filename: brainpy/math/sparse.py
 Comment: 
 
 Filename: brainpy/math/surrogate.py
 Comment: 
 
-Filename: brainpy-2.4.3.2.dist-info/LICENSE
+Filename: brainpy-2.4.3.post3.dist-info/LICENSE
 Comment: 
 
-Filename: brainpy-2.4.3.2.dist-info/METADATA
+Filename: brainpy-2.4.3.post3.dist-info/METADATA
 Comment: 
 
-Filename: brainpy-2.4.3.2.dist-info/WHEEL
+Filename: brainpy-2.4.3.post3.dist-info/WHEEL
 Comment: 
 
-Filename: brainpy-2.4.3.2.dist-info/top_level.txt
+Filename: brainpy-2.4.3.post3.dist-info/top_level.txt
 Comment: 
 
-Filename: brainpy-2.4.3.2.dist-info/RECORD
+Filename: brainpy-2.4.3.post3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## brainpy/__init__.py

```diff
@@ -1,10 +1,10 @@
 # -*- coding: utf-8 -*-
 
-__version__ = "2.4.3.2"
+__version__ = "2.4.3.post3"
 
 # fundamental supporting modules
 from brainpy import errors, check, tools
 
 try:
   import jaxlib
   del jaxlib
```

## brainpy/_src/delay.py

```diff
@@ -15,14 +15,15 @@
 from brainpy._src.context import share
 from brainpy._src.dynsys import DynamicalSystem
 from brainpy._src.initialize import variable_
 from brainpy._src.math.delayvars import ROTATE_UPDATE, CONCAT_UPDATE
 from brainpy._src.mixin import ParamDesc
 from brainpy.check import jit_error
 
+
 __all__ = [
   'Delay',
   'VarDelay',
   'DataDelay',
   'DelayAccess',
 ]
 
@@ -125,305 +126,14 @@
     ----------
     delay_step: int, ArrayType
       The delay length used to retrieve the data.
     """
     raise NotImplementedError()
 
 
-class VariableDelay2(Delay):
-  """Delay variable which has a fixed delay length.
-
-  The data in this delay variable is arranged as::
-
-       delay = 0             [ data
-       delay = 1               data
-       delay = 2               data
-       ...                     ....
-       ...                     ....
-       delay = length-1        data
-       delay = length          data ]
-
-  Args:
-    target: Variable. The delay target.
-    sharding: sequence of str. The name for each axis.
-    time: int, float. The delay time.
-    init: Any. The delay data. It can be a Python number, like float, int, boolean values.
-      It can also be arrays. Or a callable function or instance of ``Connector``.
-      Note that ``initial_delay_data`` should be arranged as the following way::
-
-         delay = 1             [ data
-         delay = 2               data
-         ...                     ....
-         ...                     ....
-         delay = length-1        data
-         delay = length          data ]
-    entries: optional, dict. The delay access entries.
-    name: str. The delay name.
-    method: str. The method used for updating delay. Default None.
-    mode: Mode. The computing mode. Default None.
-
-  """
-
-  not_desc_params = ('time', 'entries')
-
-  def __init__(
-      self,
-
-      # delay target
-      target: bm.Variable,
-
-      # delay time
-      time: Optional[Union[int, float]] = None,
-
-      # delay init
-      init: Optional[Union[numbers.Number, bm.Array, jax.Array, Callable]] = None,
-
-      # delay access entry
-      entries: Optional[Dict] = None,
-
-      # delay method
-      method: Optional[str] = None,
-
-      # others
-      name: Optional[str] = None,
-      mode: Optional[bm.Mode] = None,
-  ):
-    super().__init__(time=time, init=init, method=method, name=name, mode=mode)
-
-    # check
-    if not isinstance(target, bm.Variable):
-      raise ValueError(f'Must be an instance of brainpy.math.Variable. But we got {type(target)}')
-
-    if self.mode.is_child_of(bm.BatchingMode):
-      assert target.batch_axis is not None
-
-    # sharding
-    sharding = None
-    if target.axis_names is not None:
-      sharding = list(target.axis_names)
-      sharding.insert(0, bm.sharding.TIME_AXIS)
-      sharding = tuple(sharding)
-    self.axis_names = sharding
-
-    # target
-    self.target = target
-
-    # delay data
-    self._init = init
-    if self.max_length > 0:
-      self._init_data(self.max_length)
-    else:
-      self.data = None
-
-    # other info
-    if entries is not None:
-      for entry, value in entries.items():
-        self.register_entry(entry, value)
-
-  def register_entry(
-      self,
-      entry: str,
-      delay_time: Optional[Union[float, bm.Array, Callable]],
-  ) -> 'Delay':
-    """Register an entry to access the data.
-
-    Args:
-      entry: str. The entry to access the delay data.
-      delay_time: The delay time of the entry (can be a float).
-
-    Returns:
-      Return the self.
-    """
-    if entry in self._registered_entries:
-      raise KeyError(f'Entry {entry} has been registered.')
-
-    if delay_time is None:
-      delay_step = None
-      delay_time = 0.
-    elif callable(delay_time):
-      delay_time = bm.as_jax(delay_time(self.delay_target_shape))
-      delay_step = jnp.asarray(delay_time / bm.get_dt(), dtype=bm.get_int())
-    elif isinstance(delay_time, float):
-      delay_step = int(delay_time / bm.get_dt())
-    else:
-      delay_step = jnp.asarray(bm.as_jax(delay_time) / bm.get_dt(), dtype=bm.get_int())
-
-    # delay steps
-    if delay_step is None:
-      delay_type = 'none'
-    elif isinstance(delay_step, int):
-      delay_type = 'homo'
-    elif isinstance(delay_step, (bm.Array, jax.Array, np.ndarray)):
-      if delay_step.size == 1 and delay_step.ndim == 0:
-        delay_type = 'homo'
-      else:
-        delay_type = 'heter'
-        delay_step = bm.Array(delay_step)
-    elif callable(delay_step):
-      delay_step = delay_step(self.delay_target_shape)
-      delay_type = 'heter'
-    else:
-      raise ValueError(f'Unknown "delay_steps" type {type(delay_step)}, only support '
-                       f'integer, array of integers, callable function, brainpy.init.Initializer.')
-    if delay_type == 'heter':
-      if delay_step.dtype not in [jnp.int32, jnp.int64]:
-        raise ValueError('Only support delay steps of int32, int64. If your '
-                         'provide delay time length, please divide the "dt" '
-                         'then provide us the number of delay steps.')
-      if self.delay_target_shape[0] != delay_step.shape[0]:
-        raise ValueError(f'Shape is mismatched: {self.delay_target_shape[0]} != {delay_step.shape[0]}')
-    if delay_type == 'heter':
-      max_delay_step = int(max(delay_step))
-    elif delay_type == 'homo':
-      max_delay_step = delay_step
-    else:
-      max_delay_step = None
-
-    # delay variable
-    if max_delay_step is not None:
-      if self.max_length < max_delay_step:
-        self._init_data(max_delay_step)
-        self.max_length = max_delay_step
-        self.max_time = delay_time
-    self._registered_entries[entry] = delay_step
-    return self
-
-  def at(self, entry: str, *indices) -> bm.Array:
-    """Get the data at the given entry.
-
-    Args:
-      entry: str. The entry to access the data.
-      *indices: The slicing indices.
-
-    Returns:
-      The data.
-    """
-    assert isinstance(entry, str), 'entry should be a string for describing the '
-    if entry not in self._registered_entries:
-      raise KeyError(f'Does not find delay entry "{entry}".')
-    delay_step = self._registered_entries[entry]
-    if delay_step is None:
-      return self.target.value
-    else:
-      if self.data is None:
-        return self.target.value
-      else:
-        if isinstance(delay_step, slice):
-          return self.retrieve(delay_step, *indices)
-        elif np.ndim(delay_step) == 0:
-          return self.retrieve(delay_step, *indices)
-        else:
-          if len(indices) == 0 and len(delay_step) == self.target.shape[0]:
-            indices = (jnp.arange(delay_step.size),)
-          return self.retrieve(delay_step, *indices)
-
-  @property
-  def delay_target_shape(self):
-    """The data shape of the delay target."""
-    return self.target.shape
-
-  def __repr__(self):
-    name = self.__class__.__name__
-    return f'{name}(step={self.max_length}, shape={self.delay_target_shape}, method={self.method})'
-
-  def _check_delay(self, delay_len):
-    raise ValueError(f'The request delay length should be less than the '
-                     f'maximum delay {self.max_length}. '
-                     f'But we got {delay_len}')
-
-  def retrieve(self, delay_step, *indices):
-    """Retrieve the delay data according to the delay length.
-
-    Parameters
-    ----------
-    delay_step: int, ArrayType
-      The delay length used to retrieve the data.
-    """
-    assert delay_step is not None
-    if check.is_checking():
-      jit_error(bm.any(delay_step > self.max_length), self._check_delay, delay_step)
-
-    if self.method == ROTATE_UPDATE:
-      i = share.load('i')
-      delay_idx = (i + delay_step) % (self.max_length + 1)
-      delay_idx = jax.lax.stop_gradient(delay_idx)
-
-    elif self.method == CONCAT_UPDATE:
-      delay_idx = delay_step
-
-    else:
-      raise ValueError(f'Unknown updating method "{self.method}"')
-
-    # the delay index
-    if hasattr(delay_idx, 'dtype') and not jnp.issubdtype(delay_idx.dtype, jnp.integer):
-      raise ValueError(f'"delay_len" must be integer, but we got {delay_idx}')
-    indices = (delay_idx,) + tuple(indices)
-
-    # the delay data
-    return self.data[indices]
-
-  def update(
-      self,
-      latest_value: Optional[Union[bm.Array, jax.Array]] = None
-  ) -> None:
-    """Update delay variable with the new data.
-    """
-    if self.data is not None:
-      # get the latest target value
-      if latest_value is None:
-        latest_value = self.target.value
-
-      # update the delay data at the rotation index
-      if self.method == ROTATE_UPDATE:
-        i = share.load('i')
-        idx = bm.as_jax((i - 1) % (self.max_length + 1))
-        self.data[idx] = latest_value
-
-      # update the delay data at the first position
-      elif self.method == CONCAT_UPDATE:
-        if self.max_length >= 2:
-          self.data.value = bm.vstack([latest_value, self.data[1:]])
-        else:
-          self.data[0] = latest_value
-
-  def reset_state(self, batch_size: int = None):
-    """Reset the delay data.
-    """
-    # initialize delay data
-    if self.data is not None:
-      self._init_data(self.max_length, batch_size)
-
-  def _init_data(self, length: int, batch_size: int = None):
-    if batch_size is not None:
-      if self.target.batch_size != batch_size:
-        raise ValueError(f'The batch sizes of delay variable and target variable differ '
-                         f'({self.target.batch_size} != {batch_size}). '
-                         'Please reset the target variable first, because delay data '
-                         'depends on the target variable. ')
-
-    if self.target.batch_axis is None:
-      batch_axis = None
-    else:
-      batch_axis = self.target.batch_axis + 1
-
-    f = jax.jit(jnp.zeros,
-                static_argnums=0,
-                static_argnames='dtype',
-                out_shardings=bm.sharding.get_sharding(self._data_sharding))
-    data = f((length + 1,) + self.target.shape, dtype=self.target.dtype)
-    self.data = bm.Variable(data, batch_axis=batch_axis)
-    # update delay data
-    self.data[0] = self.target.value
-    if isinstance(self._init, (bm.Array, jax.Array, numbers.Number)):
-      self.data[1:] = self._init
-    elif callable(self._init):
-      self.data[1:] = self._init((length,) + self.target.shape,
-                                 dtype=self.target.dtype)
-
-
 def _check_target_sharding(sharding, ndim, mode: bm.Mode):
   if sharding is not None:
     if len(sharding) == ndim:
       sharding = list(sharding)
     elif len(sharding) + 1 == ndim and mode.is_child_of(bm.BatchingMode):
       sharding = list(sharding)
       sharding.insert(0, bm.sharding.BATCH_AXIS)
@@ -461,15 +171,15 @@
     entries: optional, dict. The delay access entries.
     name: str. The delay name.
     method: str. The method used for updating delay. Default None.
     mode: Mode. The computing mode. Default None.
 
   """
 
-  not_desc_params = ('time', 'entries')
+  not_desc_params = ('time', 'entries', 'name')
 
   def __init__(
       self,
 
       # delay target
       target: bm.Variable,
 
@@ -500,15 +210,15 @@
 
     # sharding
     sharding = None
     if target.axis_names is not None:
       sharding = list(target.axis_names)
       sharding.insert(0, bm.sharding.TIME_AXIS)
       sharding = tuple(sharding)
-    self.axis_names = sharding
+    self.sharding = bm.sharding.get_sharding(sharding)
 
     # target
     self.target = target
 
     # delay data
     self._init = init
     if self.max_length > 0:
@@ -532,15 +242,15 @@
       entry: str. The entry to access the delay data.
       delay_time: The delay time of the entry (can be a float).
 
     Returns:
       Return the self.
     """
     if entry in self._registered_entries:
-      raise KeyError(f'Entry {entry} has been registered.')
+      raise KeyError(f'Entry {entry} has been registered. You can use another key, or reuse the existing key. ')
 
     if isinstance(delay_time, (np.ndarray, jax.Array)):
       assert delay_time.size == 1 and delay_time.ndim == 0
       delay_time = delay_time.item()
 
     if delay_time is None:
       delay_step = None
@@ -559,36 +269,34 @@
     return self
 
   def at(self, entry: str, *indices) -> bm.Array:
     """Get the data at the given entry.
 
     Args:
       entry: str. The entry to access the data.
-      *indices: The slicing indices.
+      *indices: The slicing indices. Not include the slice at the batch dimension.
 
     Returns:
       The data.
     """
     assert isinstance(entry, str), 'entry should be a string for describing the '
     if entry not in self._registered_entries:
       raise KeyError(f'Does not find delay entry "{entry}".')
     delay_step = self._registered_entries[entry]
+    if isinstance(self.mode, bm.BatchingMode) and len(indices) > self.target.batch_axis:
+      indices = list(indices)
+      indices.insert(self.target.batch_axis, slice(None, None, None))
+      indices = tuple(indices)
+
     if delay_step is None or delay_step == 0.:
       if len(indices):
         return self.target[indices]
       else:
         return self.target.value
     else:
-      assert self.data is not None
-      if delay_step == 0:
-        if len(indices):
-          return self.target[indices]
-        else:
-          return self.target.value
-      else:
         return self.retrieve(delay_step, *indices)
 
   @property
   def delay_target_shape(self):
     """The data shape of the delay target."""
     return self.target.shape
 
@@ -602,36 +310,37 @@
                      f'But we got {delay_len}')
 
   def retrieve(self, delay_step, *indices):
     """Retrieve the delay data according to the delay length.
 
     Parameters
     ----------
-    delay_step: int, ArrayType
+    delay_step: int, Array
       The delay length used to retrieve the data.
     """
+    assert self.data is not None
     assert delay_step is not None
     if check.is_checking():
       jit_error(delay_step > self.max_length, self._check_delay, delay_step)
 
     if self.method == ROTATE_UPDATE:
       i = share.load('i')
-      delay_idx = (i + delay_step - 1) % self.max_length
+      delay_idx = bm.as_jax((delay_step - i - 1) % self.max_length)
       delay_idx = jax.lax.stop_gradient(delay_idx)
 
     elif self.method == CONCAT_UPDATE:
-      delay_idx = delay_step
+      delay_idx = delay_step - 1
 
     else:
       raise ValueError(f'Unknown updating method "{self.method}"')
 
     # the delay index
     if hasattr(delay_idx, 'dtype') and not jnp.issubdtype(delay_idx.dtype, jnp.integer):
       raise ValueError(f'"delay_len" must be integer, but we got {delay_idx}')
-    indices = (delay_idx,) + tuple(indices)
+    indices = (delay_idx,) + indices
 
     # the delay data
     return self.data[indices]
 
   def update(
       self,
       latest_value: Optional[Union[bm.Array, jax.Array]] = None
@@ -642,15 +351,15 @@
       # get the latest target value
       if latest_value is None:
         latest_value = self.target.value
 
       # update the delay data at the rotation index
       if self.method == ROTATE_UPDATE:
         i = share.load('i')
-        idx = bm.as_jax((i - 1) % self.max_length)
+        idx = bm.as_jax((-i - 1) % self.max_length)
         self.data[idx] = latest_value
 
       # update the delay data at the first position
       elif self.method == CONCAT_UPDATE:
         if self.max_length > 1:
           latest_value = bm.expand_dims(latest_value, 0)
           self.data.value = bm.concat([latest_value, self.data[1:]], axis=0)
@@ -659,46 +368,49 @@
 
   def reset_state(self, batch_size: int = None):
     """Reset the delay data.
     """
     # initialize delay data
     if self.data is not None:
       self._init_data(self.max_length, batch_size)
+    for cls in self.before_updates.values():
+      cls.reset_state(batch_size)
+    for cls in self.after_updates.values():
+      cls.reset_state(batch_size)
 
   def _init_data(self, length: int, batch_size: int = None):
     if batch_size is not None:
       if self.target.batch_size != batch_size:
         raise ValueError(f'The batch sizes of delay variable and target variable differ '
                          f'({self.target.batch_size} != {batch_size}). '
                          'Please reset the target variable first, because delay data '
                          'depends on the target variable. ')
 
     if self.target.batch_axis is None:
       batch_axis = None
     else:
       batch_axis = self.target.batch_axis + 1
 
-    f = jax.jit(jnp.zeros,
-                static_argnums=0,
-                static_argnames='dtype',
-                out_shardings=bm.sharding.get_sharding(self.axis_names))
+    f = jax.jit(jnp.zeros, static_argnums=0, static_argnames='dtype', out_shardings=self.sharding)
     data = f((length,) + self.target.shape, dtype=self.target.dtype)
     if self.data is None:
       self.data = bm.Variable(data, batch_axis=batch_axis)
     else:
       self.data._value = data
     # update delay data
     if isinstance(self._init, (bm.Array, jax.Array, numbers.Number)):
       self.data[:] = self._init
     elif callable(self._init):
       self.data[:] = self._init((length,) + self.target.shape, dtype=self.target.dtype)
+    else:
+      assert self._init is None, f'init should be Array, Callable, or None. but got {self._init}'
 
 
 class DataDelay(VarDelay):
-  not_desc_params = ('time', 'entries')
+  not_desc_params = ('time', 'entries', 'name')
 
   def __init__(
       self,
 
       # delay target
       data: bm.Variable,
       data_init: Union[Callable, bm.Array, jax.Array],
```

## brainpy/_src/deprecations.py

```diff
@@ -22,24 +22,24 @@
   def update(self, *args, **kwagrs):
      t = bp.share['t']
      ...
 '''
 
 
 _input_deprecate_msg = '''
-From brainpy>=2.4.3, input() function no longer needs to receive a global shared argument.
+From brainpy>=2.4.3, input() and monitor() function no longer needs to receive a global shared argument.
 
 Instead of using:
 
-  def input(tdi):
+  def f_input_or_monitor(tdi):
      ...
 
 Please use:
 
-  def input():
+  def f_input_or_monitor():
      t = bp.share['t']
      ...
 '''
 
 
 
 def _deprecate(msg):
```

## brainpy/_src/dynsys.py

```diff
@@ -129,14 +129,48 @@
     # added after the version of 2.4.3
     self.before_updates: Dict[str, Callable] = bm.node_dict()
     self.after_updates: Dict[str, Callable] = bm.node_dict()
 
     # super initialization
     super().__init__(name=name)
 
+  def add_bef_update(self, key: Any, fun: Callable):
+    if key in self.before_updates:
+      raise KeyError(f'{key} has been registered in before_updates of {self}')
+    self.before_updates[key] = fun
+
+  def add_aft_update(self, key: Any, fun: Callable):
+    if key in self.after_updates:
+      raise KeyError(f'{key} has been registered in after_updates of {self}')
+    self.after_updates[key] = fun
+
+  def get_bef_update(self, key: Any):
+    if key not in self.before_updates:
+      raise KeyError(f'{key} is not registered in before_updates of {self}')
+    return self.before_updates.get(key)
+
+  def get_aft_update(self, key: Any):
+    if key not in self.after_updates:
+      raise KeyError(f'{key} is not registered in after_updates of {self}')
+    return self.after_updates.get(key)
+
+  def has_bef_update(self, key: Any):
+    return key in self.before_updates
+
+  def has_aft_update(self, key: Any):
+    return key in self.after_updates
+
+  def reset_bef_updates(self, batch_size=None):
+    for node in self.before_updates.values():
+      node.reset_state(batch_size)
+
+  def reset_aft_updates(self, batch_size=None):
+    for node in self.after_updates.values():
+      node.reset_state(batch_size)
+
   def update(self, *args, **kwargs):
     """The function to specify the updating rule.
 
     Assume any dynamical system depends on the shared variables (`sha`),
     like time variable ``t``, the step precision ``dt``, and the time step `i`.
     """
     raise NotImplementedError('Must implement "update" function by subclass self.')
@@ -402,15 +436,19 @@
     # reset dynamics
     for node in nodes.subset(Dynamic).values():
       node.reset_state(batch_size)
 
     # reset other types of nodes, including delays, ...
     for node in nodes.not_subset(Dynamic).not_subset(Projection).values():
       node.reset_state(batch_size)
-
+    
+    # reset
+    self.reset_aft_updates(batch_size)
+    self.reset_bef_updates(batch_size)
+    
     # reset delays
     # TODO: will be removed in the future
     self.reset_local_delays(nodes)
 
   def clear_input(self):
     """Clear inputs in the children classes."""
     nodes = self.nodes(level=1, include_self=False).subset(DynamicalSystem).unique().not_subset(DynView)
```

## brainpy/_src/mixin.py

```diff
@@ -500,17 +500,15 @@
   def get_delay_var(self, name):
     return global_delay_data[name]
 
 
 class BindCondData(MixIn):
   """Bind temporary conductance data.
   """
-
-  def __init__(self, *args, **kwargs):
-    self._conductance = None
+  _conductance: Optional
 
   def bind_cond(self, conductance):
     self._conductance = conductance
 
   def unbind_cond(self):
     self._conductance = None
```

## brainpy/_src/dyn/outs/base.py

```diff
@@ -11,14 +11,18 @@
 class SynOut(DynamicalSystem, ParamDesc, BindCondData):
   """Base class for synaptic outputs.
 
   :py:class:`~.SynOut` is also subclass of :py:class:`~.ParamDesc` and :pu:class:`~.BindCondData`.
   """
   def __init__(self, name: Optional[str] = None):
     super().__init__(name=name)
+    self._conductance = None
 
   def __call__(self, *args, **kwargs):
     if self._conductance is None:
       raise ValueError(f'Please first pack conductance data at the current step using '
                        f'".{BindCondData.bind_cond.__name__}(data)". {self}')
     ret = self.update(self._conductance, *args, **kwargs)
     return ret
+
+  def reset_state(self, *args, **kwargs):
+    pass
```

## brainpy/_src/dyn/outs/outputs.py

```diff
@@ -116,14 +116,14 @@
   ):
     super().__init__(name=name)
 
     self.sharding = sharding
     self.E = init.parameter(E, np.shape(E), sharding=sharding)
     self.cc_Mg = init.parameter(cc_Mg, np.shape(cc_Mg), sharding=sharding)
     self.alpha = init.parameter(alpha, np.shape(alpha), sharding=sharding)
-    self.beta = init.parameter(alpha, np.shape(beta), sharding=sharding)
+    self.beta = init.parameter(beta, np.shape(beta), sharding=sharding)
 
   def update(self, conductance, potential):
     return conductance * (self.E - potential) / (1 + self.cc_Mg / self.beta * bm.exp(-self.alpha * potential))
```

## brainpy/_src/dyn/projections/aligns.py

```diff
@@ -1,23 +1,24 @@
 from typing import Optional, Callable, Union
 
 import jax
 
 from brainpy import math as bm, check
 from brainpy._src.delay import Delay, VarDelay, DataDelay, DelayAccess
-from brainpy._src.dynsys import DynamicalSystem, Projection, Dynamic
+from brainpy._src.dynsys import DynamicalSystem, Projection
 from brainpy._src.mixin import (JointType, ParamDescInit, ReturnInfo,
                                 AutoDelaySupp, BindCondData, AlignPost,
                                 ReceiveInputProj)
 
 __all__ = [
   'VanillaProj',
   'ProjAlignPostMg1', 'ProjAlignPostMg2',
   'ProjAlignPost1', 'ProjAlignPost2',
   'ProjAlignPreMg1', 'ProjAlignPreMg2',
+  'ProjAlignPre1', 'ProjAlignPre2',
 ]
 
 _pre_delay_repr = '_*_align_pre_spk_delay_*_'
 
 
 class _AlignPre(DynamicalSystem):
   def __init__(self, syn, delay=None):
@@ -46,15 +47,15 @@
 
 class _AlignPreMg(DynamicalSystem):
   def __init__(self, access, syn):
     super().__init__()
     self.access = access
     self.syn = syn
 
-  def update(self):
+  def update(self, *args, **kwargs):
     return self.syn(self.access())
 
 
 def _init_delay(info: Union[bm.Variable, ReturnInfo]) -> Delay:
   if isinstance(info, bm.Variable):
     return VarDelay(info)
   elif isinstance(info, ReturnInfo):
@@ -149,23 +150,25 @@
   ):
     super().__init__(name=name, mode=mode)
 
     # synaptic models
     check.is_instance(comm, DynamicalSystem)
     check.is_instance(out, JointType[DynamicalSystem, BindCondData])
     check.is_instance(post, JointType[DynamicalSystem, ReceiveInputProj])
-    self.post = post
     self.comm = comm
 
     # output initialization
     post.add_inp_fun(self.name, out)
 
+    # references
+    self.refs = dict(post=post, out=out)  # invisible to ``self.nodes()``
+
   def update(self, x):
     current = self.comm(x)
-    self.post.get_inp_fun(self.name).bind_cond(current)
+    self.refs['out'].bind_cond(current)
     return current
 
 
 class ProjAlignPostMg1(Projection):
   r"""Synaptic projection which defines the synaptic computation with the dimension of postsynaptic neuron group.
 
   **Code Examples**
@@ -225,29 +228,32 @@
     super().__init__(name=name, mode=mode)
 
     # synaptic models
     check.is_instance(comm, DynamicalSystem)
     check.is_instance(syn, ParamDescInit[JointType[DynamicalSystem, AlignPost]])
     check.is_instance(out, ParamDescInit[JointType[DynamicalSystem, BindCondData]])
     check.is_instance(post, JointType[DynamicalSystem, ReceiveInputProj])
-    self.post = post
     self.comm = comm
 
     # synapse and output initialization
-    self._post_repr = f'{syn._identifier} // {out._identifier}'
-    if self._post_repr not in self.post.before_updates:
+    self._post_repr = f'{syn.identifier} // {out.identifier}'
+    if not post.has_bef_update(self._post_repr):
       syn_cls = syn()
       out_cls = out()
-      self.post.add_inp_fun(self.name, out_cls)
-      self.post.before_updates[self._post_repr] = _AlignPost(syn_cls, out_cls)
+      post.add_inp_fun(self.name, out_cls)
+      post.add_bef_update(self._post_repr, _AlignPost(syn_cls, out_cls))
+
+    # references
+    self.refs = dict(post=post)  # invisible to ``self.nodes()``
+    self.refs['syn'] = post.get_bef_update(self._post_repr).syn
+    self.refs['out'] = post.get_bef_update(self._post_repr).out
 
   def update(self, x):
     current = self.comm(x)
-    syn: _AlignPost = self.post.before_updates[self._post_repr].syn
-    syn.add_current(current)  # synapse post current
+    self.refs['syn'].add_current(current)  # synapse post current
     return current
 
 
 class ProjAlignPostMg2(Projection):
   """Synaptic projection which defines the synaptic computation with the dimension of postsynaptic neuron group.
 
   **Code Examples**
@@ -332,39 +338,42 @@
 
     # synaptic models
     check.is_instance(pre, JointType[DynamicalSystem, AutoDelaySupp])
     check.is_instance(comm, DynamicalSystem)
     check.is_instance(syn, ParamDescInit[JointType[DynamicalSystem, AlignPost]])
     check.is_instance(out, ParamDescInit[JointType[DynamicalSystem, BindCondData]])
     check.is_instance(post, JointType[DynamicalSystem, ReceiveInputProj])
-    self.pre = pre
-    self.post = post
     self.comm = comm
 
     # delay initialization
-    if _pre_delay_repr not in self.pre.after_updates:
+    if not pre.has_aft_update(_pre_delay_repr):
       # pre should support "ProjAutoDelay"
       delay_cls = _init_delay(pre.return_info())
       # add to "after_updates"
-      self.pre.after_updates[_pre_delay_repr] = delay_cls
-    delay_cls: Delay = pre.after_updates[_pre_delay_repr]
+      pre.add_aft_update(_pre_delay_repr, delay_cls)
+    delay_cls: Delay = pre.get_aft_update(_pre_delay_repr)
     delay_cls.register_entry(self.name, delay)
 
     # synapse and output initialization
-    self._post_repr = f'{syn._identifier} // {out._identifier}'
-    if self._post_repr not in self.post.before_updates:
+    self._post_repr = f'{syn.identifier} // {out.identifier}'
+    if not post.has_bef_update(self._post_repr):
       syn_cls = syn()
       out_cls = out()
-      self.post.add_inp_fun(self.name, out_cls)
-      self.post.before_updates[self._post_repr] = _AlignPost(syn_cls, out_cls)
+      post.add_inp_fun(self.name, out_cls)
+      post.add_bef_update(self._post_repr, _AlignPost(syn_cls, out_cls))
+
+    # references
+    self.refs = dict(pre=pre, post=post)   # invisible to ``self.nodes()``
+    self.refs['syn'] = post.get_bef_update(self._post_repr).syn  # invisible to ``self.node()``
+    self.refs['out'] = post.get_bef_update(self._post_repr).out  # invisible to ``self.node()``
 
   def update(self):
-    x = self.pre.after_updates[_pre_delay_repr].at(self.name)
+    x = self.refs['pre'].get_aft_update(_pre_delay_repr).at(self.name)
     current = self.comm(x)
-    self.post.before_updates[self._post_repr].syn.add_current(current)  # synapse post current
+    self.refs['syn'].add_current(current)  # synapse post current
     return current
 
 
 class ProjAlignPost1(Projection):
   """Synaptic projection which defines the synaptic computation with the dimension of postsynaptic neuron group.
 
   To simulate an E/I balanced network:
@@ -420,25 +429,28 @@
     super().__init__(name=name, mode=mode)
 
     # synaptic models
     check.is_instance(comm, DynamicalSystem)
     check.is_instance(syn, JointType[DynamicalSystem, AlignPost])
     check.is_instance(out, JointType[DynamicalSystem, BindCondData])
     check.is_instance(post, JointType[DynamicalSystem, ReceiveInputProj])
-    self.post = post
     self.comm = comm
 
     # synapse and output initialization
-    self.post.add_inp_fun(self.name, out)
-    self.post.before_updates[self.name] = _AlignPost(syn, out)
+    post.add_inp_fun(self.name, out)
+    post.add_bef_update(self.name, _AlignPost(syn, out))
+
+    # reference
+    self.refs = dict(post=post)  # invisible to ``self.nodes()``
+    self.refs['syn'] = post.get_bef_update(self.name).syn
+    self.refs['out'] = post.get_bef_update(self.name).out
 
   def update(self, x):
     current = self.comm(x)
-    syn: _AlignPost = self.post.before_updates[self.name].syn
-    syn.add_current(current)  # synapse post current
+    self.refs['syn'].add_current(current)
     return current
 
 
 class ProjAlignPost2(Projection):
   """Synaptic projection which defines the synaptic computation with the dimension of postsynaptic neuron group.
 
   To simulate and define an E/I balanced network model:
@@ -519,36 +531,38 @@
 
     # synaptic models
     check.is_instance(pre, JointType[DynamicalSystem, AutoDelaySupp])
     check.is_instance(comm, DynamicalSystem)
     check.is_instance(syn, JointType[DynamicalSystem, AlignPost])
     check.is_instance(out, JointType[DynamicalSystem, BindCondData])
     check.is_instance(post, JointType[DynamicalSystem, ReceiveInputProj])
-    self.pre = pre
-    self.post = post
     self.comm = comm
+    self.syn = syn
 
     # delay initialization
-    if _pre_delay_repr not in self.pre.after_updates:
+    if not pre.has_aft_update(_pre_delay_repr):
       # pre should support "ProjAutoDelay"
       delay_cls = _init_delay(pre.return_info())
       # add to "after_updates"
-      self.pre.after_updates[_pre_delay_repr] = delay_cls
-    delay_cls: Delay = pre.after_updates[_pre_delay_repr]
+      pre.add_aft_update(_pre_delay_repr, delay_cls)
+    delay_cls: Delay = pre.get_aft_update(_pre_delay_repr)
     delay_cls.register_entry(self.name, delay)
 
     # synapse and output initialization
-    self.post.add_inp_fun(self.name, out)
-    self.post.before_updates[self.name] = _AlignPost(syn, out)
+    post.add_inp_fun(self.name, out)
+
+    # references
+    self.refs = dict(pre=pre, post=post)  # invisible to ``self.nodes()``
+    self.refs['out'] = out
 
   def update(self):
-    x = self.pre.after_updates[_pre_delay_repr].at(self.name)
-    current = self.comm(x)
-    self.post.before_updates[self.name].syn.add_current(current)  # synapse post current
-    return current
+    x = self.refs['pre'].get_aft_update(_pre_delay_repr).at(self.name)
+    g = self.syn(self.comm(x))
+    self.refs['out'].bind_cond(g)  # synapse post current
+    return g
 
 
 class ProjAlignPreMg1(Projection):
   """Synaptic projection which defines the synaptic computation with the dimension of presynaptic neuron group.
 
   To simulate an E/I balanced network model:
 
@@ -614,51 +628,53 @@
   """
 
   def __init__(
       self,
       pre: DynamicalSystem,
       syn: ParamDescInit[JointType[DynamicalSystem, AutoDelaySupp]],
       delay: Union[None, int, float],
-      comm: Callable,
+      comm: DynamicalSystem,
       out: JointType[DynamicalSystem, BindCondData],
       post: JointType[DynamicalSystem, ReceiveInputProj],
       name: Optional[str] = None,
       mode: Optional[bm.Mode] = None,
   ):
     super().__init__(name=name, mode=mode)
 
     # synaptic models
     check.is_instance(pre, DynamicalSystem)
     check.is_instance(syn, ParamDescInit[JointType[DynamicalSystem, AutoDelaySupp]])
-    check.is_instance(comm, Callable)
+    check.is_instance(comm, DynamicalSystem)
     check.is_instance(out, JointType[DynamicalSystem, BindCondData])
     check.is_instance(post, JointType[DynamicalSystem, ReceiveInputProj])
-    self.pre = pre
-    self.post = post
     self.comm = comm
 
     # synapse and delay initialization
-    self._syn_id = syn.identifier
-    if self._syn_id not in pre.after_updates:
+    self._syn_id = f'{syn.identifier} // Delay'
+    if not pre.has_aft_update(self._syn_id):
       # "syn_cls" needs an instance of "ProjAutoDelay"
       syn_cls: AutoDelaySupp = syn()
       delay_cls = _init_delay(syn_cls.return_info())
       # add to "after_updates"
-      pre.after_updates[self._syn_id] = _AlignPre(syn_cls, delay_cls)
-    delay_cls: Delay = pre.after_updates[self._syn_id].delay
+      pre.add_aft_update(self._syn_id, _AlignPre(syn_cls, delay_cls))
+    delay_cls: Delay = pre.get_aft_update(self._syn_id).delay
     delay_cls.register_entry(self.name, delay)
 
     # output initialization
     post.add_inp_fun(self.name, out)
 
+    # references
+    self.refs = dict(pre=pre, post=post, out=out, delay=delay_cls)  # invisible to ``self.nodes()``
+    self.refs['syn'] = pre.get_aft_update(self._syn_id).syn
+
   def update(self, x=None):
     if x is None:
-      x = self.pre.after_updates[self._syn_id].delay.at(self.name)
+      x = self.refs['delay'].at(self.name)
     current = self.comm(x)
-    self.post.cur_inputs[self.name].bind_cond(current)
+    self.refs['out'].bind_cond(current)
     return current
 
 
 class ProjAlignPreMg2(Projection):
   """Synaptic projection which defines the synaptic computation with the dimension of presynaptic neuron group.
 
   To simulate an E/I balanced network model:
@@ -725,49 +741,270 @@
   """
 
   def __init__(
       self,
       pre: JointType[DynamicalSystem, AutoDelaySupp],
       delay: Union[None, int, float],
       syn: ParamDescInit[JointType[DynamicalSystem, AutoDelaySupp]],
-      comm: Callable,
+      comm: DynamicalSystem,
       out: JointType[DynamicalSystem, BindCondData],
       post: JointType[DynamicalSystem, ReceiveInputProj],
       name: Optional[str] = None,
       mode: Optional[bm.Mode] = None,
   ):
     super().__init__(name=name, mode=mode)
 
     # synaptic models
     check.is_instance(pre, JointType[DynamicalSystem, AutoDelaySupp])
     check.is_instance(syn, ParamDescInit[JointType[DynamicalSystem, AutoDelaySupp]])
-    check.is_instance(comm, Callable)
+    check.is_instance(comm, DynamicalSystem)
     check.is_instance(out, JointType[DynamicalSystem, BindCondData])
     check.is_instance(post, JointType[DynamicalSystem, ReceiveInputProj])
-    self.pre = pre
-    self.post = post
     self.comm = comm
 
-    # synapse and delay initialization
-    if _pre_delay_repr not in self.pre.after_updates:
+    # delay initialization
+    if not pre.has_aft_update(_pre_delay_repr):
       delay_ins = _init_delay(pre.return_info())
-      self.pre.after_updates[_pre_delay_repr] = delay_ins
+      pre.add_aft_update(_pre_delay_repr, delay_ins)
+    delay_cls = pre.get_aft_update(_pre_delay_repr)
 
-    # synapse
-    self._syn_id = f'{str(delay)} / {syn.identifier}'
-    if self._syn_id not in post.before_updates:
+    # synapse initialization
+    self._syn_id = f'Delay({str(delay)}) // {syn.identifier}'
+    if not delay_cls.has_bef_update(self._syn_id):
       # delay
-      delay_ins: Delay = pre.after_updates[_pre_delay_repr]
-      delay_access = DelayAccess(delay_ins, delay)
+      delay_access = DelayAccess(delay_cls, delay)
       # synapse
       syn_cls = syn()
       # add to "after_updates"
-      post.before_updates[self._syn_id] = _AlignPreMg(delay_access, syn_cls)
+      delay_cls.add_bef_update(self._syn_id, _AlignPreMg(delay_access, syn_cls))
 
     # output initialization
     post.add_inp_fun(self.name, out)
 
+    # references
+    self.refs = dict(pre=pre, post=post)  # invisible to `self.nodes()`
+    self.refs['syn'] = delay_cls.get_bef_update(self._syn_id).syn
+    self.refs['out'] = out
+
   def update(self):
-    x = _get_return(self.post.before_updates[self._syn_id].syn.return_info())
+    x = _get_return(self.refs['syn'].return_info())
+    current = self.comm(x)
+    self.refs['out'].bind_cond(current)
+    return current
+
+
+class ProjAlignPre1(Projection):
+  """Synaptic projection which defines the synaptic computation with the dimension of presynaptic neuron group.
+
+  To simulate an E/I balanced network model:
+
+  .. code-block:: python
+
+      class EINet(bp.DynSysGroup):
+        def __init__(self):
+          super().__init__()
+          ne, ni = 3200, 800
+          self.E = bp.dyn.LifRef(ne, V_rest=-60., V_th=-50., V_reset=-60., tau=20., tau_ref=5.,
+                                 V_initializer=bp.init.Normal(-55., 2.))
+          self.I = bp.dyn.LifRef(ni, V_rest=-60., V_th=-50., V_reset=-60., tau=20., tau_ref=5.,
+                                 V_initializer=bp.init.Normal(-55., 2.))
+          self.E2E = bp.dyn.ProjAlignPreMg1(pre=self.E,
+                                            syn=bp.dyn.Expon.desc(size=ne, tau=5.),
+                                            delay=0.1,
+                                            comm=bp.dnn.JitFPHomoLinear(ne, ne, prob=0.02, weight=0.6),
+                                            out=bp.dyn.COBA(E=0.),
+                                            post=self.E)
+          self.E2I = bp.dyn.ProjAlignPreMg1(pre=self.E,
+                                            syn=bp.dyn.Expon.desc(size=ne, tau=5.),
+                                            delay=0.1,
+                                            comm=bp.dnn.JitFPHomoLinear(ne, ni, prob=0.02, weight=0.6),
+                                            out=bp.dyn.COBA(E=0.),
+                                            post=self.I)
+          self.I2E = bp.dyn.ProjAlignPreMg1(pre=self.I,
+                                            syn=bp.dyn.Expon.desc(size=ni, tau=10.),
+                                            delay=0.1,
+                                            comm=bp.dnn.JitFPHomoLinear(ni, ne, prob=0.02, weight=6.7),
+                                            out=bp.dyn.COBA(E=-80.),
+                                            post=self.E)
+          self.I2I = bp.dyn.ProjAlignPreMg1(pre=self.I,
+                                            syn=bp.dyn.Expon.desc(size=ni, tau=10.),
+                                            delay=0.1,
+                                            comm=bp.dnn.JitFPHomoLinear(ni, ni, prob=0.02, weight=6.7),
+                                            out=bp.dyn.COBA(E=-80.),
+                                            post=self.I)
+
+        def update(self, inp):
+          self.E2E()
+          self.E2I()
+          self.I2E()
+          self.I2I()
+          self.E(inp)
+          self.I(inp)
+          return self.E.spike
+
+      model = EINet()
+      indices = bm.arange(1000)
+      spks = bm.for_loop(lambda i: model.step_run(i, 20.), indices)
+      bp.visualize.raster_plot(indices, spks, show=True)
+
+
+  Args:
+    pre: The pre-synaptic neuron group.
+    syn: The synaptic dynamics.
+    delay: The synaptic delay.
+    comm: The synaptic communication.
+    out: The synaptic output.
+    post: The post-synaptic neuron group.
+    name: str. The projection name.
+    mode: Mode. The computing mode.
+  """
+
+  def __init__(
+      self,
+      pre: DynamicalSystem,
+      syn: JointType[DynamicalSystem, AutoDelaySupp],
+      delay: Union[None, int, float],
+      comm: DynamicalSystem,
+      out: JointType[DynamicalSystem, BindCondData],
+      post: JointType[DynamicalSystem, ReceiveInputProj],
+      name: Optional[str] = None,
+      mode: Optional[bm.Mode] = None,
+  ):
+    super().__init__(name=name, mode=mode)
+
+    # synaptic models
+    check.is_instance(pre, DynamicalSystem)
+    check.is_instance(syn, JointType[DynamicalSystem, AutoDelaySupp])
+    check.is_instance(comm, DynamicalSystem)
+    check.is_instance(out, JointType[DynamicalSystem, BindCondData])
+    check.is_instance(post, JointType[DynamicalSystem, ReceiveInputProj])
+    self.comm = comm
+
+    # synapse and delay initialization
+    delay_cls = _init_delay(syn.return_info())
+    delay_cls.register_entry(self.name, delay)
+    pre.add_aft_update(self.name, _AlignPre(syn, delay_cls))
+
+    # output initialization
+    post.add_inp_fun(self.name, out)
+
+    # references
+    self.refs = dict(pre=pre, post=post, out=out)  # invisible to ``self.nodes()``
+    self.refs['delay'] = delay_cls
+    self.refs['syn'] = syn
+
+  def update(self, x=None):
+    if x is None:
+      x = self.refs['delay'].at(self.name)
     current = self.comm(x)
-    self.post.get_inp_fun(self.name).bind_cond(current)
+    self.refs['out'].bind_cond(current)
     return current
+
+
+class ProjAlignPre2(Projection):
+  """Synaptic projection which defines the synaptic computation with the dimension of presynaptic neuron group.
+
+  To simulate an E/I balanced network model:
+
+  .. code-block:: python
+
+      class EINet(bp.DynSysGroup):
+        def __init__(self):
+          super().__init__()
+          ne, ni = 3200, 800
+          self.E = bp.dyn.LifRef(ne, V_rest=-60., V_th=-50., V_reset=-60., tau=20., tau_ref=5.,
+                                 V_initializer=bp.init.Normal(-55., 2.))
+          self.I = bp.dyn.LifRef(ni, V_rest=-60., V_th=-50., V_reset=-60., tau=20., tau_ref=5.,
+                                 V_initializer=bp.init.Normal(-55., 2.))
+          self.E2E = bp.dyn.ProjAlignPreMg2(pre=self.E,
+                                            delay=0.1,
+                                            syn=bp.dyn.Expon.desc(size=ne, tau=5.),
+                                            comm=bp.dnn.JitFPHomoLinear(ne, ne, prob=0.02, weight=0.6),
+                                            out=bp.dyn.COBA(E=0.),
+                                            post=self.E)
+          self.E2I = bp.dyn.ProjAlignPreMg2(pre=self.E,
+                                            delay=0.1,
+                                            syn=bp.dyn.Expon.desc(size=ne, tau=5.),
+                                            comm=bp.dnn.JitFPHomoLinear(ne, ni, prob=0.02, weight=0.6),
+                                            out=bp.dyn.COBA(E=0.),
+                                            post=self.I)
+          self.I2E = bp.dyn.ProjAlignPreMg2(pre=self.I,
+                                            delay=0.1,
+                                            syn=bp.dyn.Expon.desc(size=ni, tau=10.),
+                                            comm=bp.dnn.JitFPHomoLinear(ni, ne, prob=0.02, weight=6.7),
+                                            out=bp.dyn.COBA(E=-80.),
+                                            post=self.E)
+          self.I2I = bp.dyn.ProjAlignPreMg2(pre=self.I,
+                                            delay=0.1,
+                                            syn=bp.dyn.Expon.desc(size=ni, tau=10.),
+                                            comm=bp.dnn.JitFPHomoLinear(ni, ni, prob=0.02, weight=6.7),
+                                            out=bp.dyn.COBA(E=-80.),
+                                            post=self.I)
+
+        def update(self, inp):
+          self.E2E()
+          self.E2I()
+          self.I2E()
+          self.I2I()
+          self.E(inp)
+          self.I(inp)
+          return self.E.spike
+
+      model = EINet()
+      indices = bm.arange(1000)
+      spks = bm.for_loop(lambda i: model.step_run(i, 20.), indices)
+      bp.visualize.raster_plot(indices, spks, show=True)
+
+
+  Args:
+    pre: The pre-synaptic neuron group.
+    delay: The synaptic delay.
+    syn: The synaptic dynamics.
+    comm: The synaptic communication.
+    out: The synaptic output.
+    post: The post-synaptic neuron group.
+    name: str. The projection name.
+    mode: Mode. The computing mode.
+  """
+
+  def __init__(
+      self,
+      pre: JointType[DynamicalSystem, AutoDelaySupp],
+      delay: Union[None, int, float],
+      syn: JointType[DynamicalSystem, AutoDelaySupp],
+      comm: DynamicalSystem,
+      out: JointType[DynamicalSystem, BindCondData],
+      post: JointType[DynamicalSystem, ReceiveInputProj],
+      name: Optional[str] = None,
+      mode: Optional[bm.Mode] = None,
+  ):
+    super().__init__(name=name, mode=mode)
+
+    # synaptic models
+    check.is_instance(pre, JointType[DynamicalSystem, AutoDelaySupp])
+    check.is_instance(syn, JointType[DynamicalSystem, AutoDelaySupp])
+    check.is_instance(comm, DynamicalSystem)
+    check.is_instance(out, JointType[DynamicalSystem, BindCondData])
+    check.is_instance(post, JointType[DynamicalSystem, ReceiveInputProj])
+    self.comm = comm
+    self.syn = syn
+
+    # delay initialization
+    if not pre.has_aft_update(_pre_delay_repr):
+      delay_ins = _init_delay(pre.return_info())
+      pre.add_aft_update(_pre_delay_repr, delay_ins)
+    delay_cls = pre.get_aft_update(_pre_delay_repr)
+    delay_cls.register_entry(self.name, delay)
+
+    # output initialization
+    post.add_inp_fun(self.name, out)
+
+    # references
+    self.refs = dict(pre=pre, post=post, out=out)  # invisible to ``self.nodes()``
+    self.refs['delay'] = pre.get_aft_update(_pre_delay_repr)
+
+  def update(self):
+    spk = self.refs['delay'].at(self.name)
+    g = self.comm(self.syn(spk))
+    self.refs['out'].bind_cond(g)
+    return g
+
```

## brainpy/_src/dyn/synapses/abstract_models.py

```diff
@@ -141,14 +141,15 @@
                      sharding=sharding)
 
     # parameters
     self.tau = self.init_param(tau)
 
     # function
     self.integral = odeint(self.derivative, method=method)
+    self._current = None
 
     self.reset_state(self.mode)
 
   def derivative(self, g, t):
     return -g / self.tau
 
   def reset_state(self, batch_size=None):
@@ -583,15 +584,21 @@
   def reset_state(self, batch_size=None):
     self.x = self.init_variable(bm.ones, batch_size)
 
   def update(self, pre_spike):
     t = share.load('t')
     dt = share.load('dt')
     x = self.integral(self.x.value, t, dt)
-    self.x.value = bm.where(pre_spike, x - self.U * self.x, x)
+
+    # --- original code:
+    # self.x.value = bm.where(pre_spike, x - self.U * self.x, x)
+
+    # --- simplified code:
+    self.x.value = x - pre_spike * self.U * self.x
+
     return self.x.value
 
   def return_info(self):
     return self.x
 
 
 STD.__doc__ = STD.__doc__ % (pneu_doc,)
@@ -674,22 +681,27 @@
     dx = lambda x, t: (1 - x) / self.tau_d
     return JointEq(du, dx)
 
   def update(self, pre_spike):
     t = share.load('t')
     dt = share.load('dt')
     u, x = self.integral(self.u.value, self.x.value, t, dt)
-    # if pre_spike.dtype == jax.numpy.bool_:
-    #   u = bm.where(pre_spike, u + self.U * (1 - self.u), u)
-    #   x = bm.where(pre_spike, x - u * self.x, x)
-    # else:
-    # u = pre_spike * (u + self.U * (1 - self.u)) + (1 - pre_spike) * u
-    # x = pre_spike * (x - u * self.x) + (1 - pre_spike) * x
+
+    # --- original code:
+    #   if pre_spike.dtype == jax.numpy.bool_:
+    #     u = bm.where(pre_spike, u + self.U * (1 - self.u), u)
+    #     x = bm.where(pre_spike, x - u * self.x, x)
+    #   else:
+    #     u = pre_spike * (u + self.U * (1 - self.u)) + (1 - pre_spike) * u
+    #     x = pre_spike * (x - u * self.x) + (1 - pre_spike) * x
+
+    # --- simplified code:
     u = pre_spike * self.U * (1 - self.u) + u
     x = pre_spike * -u * self.x + x
+
     self.x.value = x
     self.u.value = u
     return u * x
 
   def return_info(self):
     return ReturnInfo(self.varshape, self.sharding, self.mode,
                       lambda shape: self.u * self.x)
```

## brainpy/dyn/projections.py

```diff
@@ -4,14 +4,16 @@
   VanillaProj,
   ProjAlignPostMg1,
   ProjAlignPostMg2,
   ProjAlignPost1,
   ProjAlignPost2,
   ProjAlignPreMg1,
   ProjAlignPreMg2,
+  ProjAlignPre1,
+  ProjAlignPre2,
 )
 
 from brainpy._src.dyn.projections.conn import (
   SynConn as SynConn,
 )
 
 from brainpy._src.dyn.projections.others import (
```

## Comparing `brainpy-2.4.3.2.dist-info/LICENSE` & `brainpy-2.4.3.post3.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `brainpy-2.4.3.2.dist-info/METADATA` & `brainpy-2.4.3.post3.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: brainpy
-Version: 2.4.3.2
+Version: 2.4.3.post3
 Summary: BrainPy: Brain Dynamics Programming in Python
 Home-page: https://github.com/brainpy/BrainPy
 Author: BrainPy Team
 Author-email: chao.brain@qq.com
 License: GPL-3.0 license
 Project-URL: Bug Tracker, https://github.com/brainpy/BrainPy/issues
 Project-URL: Documentation, https://brainpy.readthedocs.io/
```

### html2text {}

```diff
@@ -1,27 +1,28 @@
-Metadata-Version: 2.1 Name: brainpy Version: 2.4.3.2 Summary: BrainPy: Brain
-Dynamics Programming in Python Home-page: https://github.com/brainpy/BrainPy
-Author: BrainPy Team Author-email: chao.brain@qq.com License: GPL-3.0 license
-Project-URL: Bug Tracker, https://github.com/brainpy/BrainPy/issues Project-
-URL: Documentation, https://brainpy.readthedocs.io/ Project-URL: Source Code,
-https://github.com/brainpy/BrainPy Keywords: computational neuroscience,brain-
-inspired computation,dynamical systems,differential equations,brain
-modeling,brain dynamics modeling,brain dynamics programming Classifier: Natural
-Language :: English Classifier: Operating System :: OS Independent Classifier:
-Programming Language :: Python Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.8 Classifier: Programming
-Language :: Python :: 3.9 Classifier: Programming Language :: Python :: 3.10
-Classifier: Programming Language :: Python :: 3.11 Classifier: Intended
-Audience :: Science/Research Classifier: License :: OSI Approved :: Apache
-Software License Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
-Classifier: Topic :: Scientific/Engineering :: Mathematics Classifier: Topic ::
-Scientific/Engineering :: Artificial Intelligence Classifier: Topic :: Software
-Development :: Libraries Requires-Python: >=3.8 Description-Content-Type: text/
-markdown License-File: LICENSE Requires-Dist: numpy (>=1.15) Requires-Dist: jax
-(>=0.4.1) Requires-Dist: tqdm Requires-Dist: msgpack
+Metadata-Version: 2.1 Name: brainpy Version: 2.4.3.post3 Summary: BrainPy:
+Brain Dynamics Programming in Python Home-page: https://github.com/brainpy/
+BrainPy Author: BrainPy Team Author-email: chao.brain@qq.com License: GPL-3.0
+license Project-URL: Bug Tracker, https://github.com/brainpy/BrainPy/issues
+Project-URL: Documentation, https://brainpy.readthedocs.io/ Project-URL: Source
+Code, https://github.com/brainpy/BrainPy Keywords: computational
+neuroscience,brain-inspired computation,dynamical systems,differential
+equations,brain modeling,brain dynamics modeling,brain dynamics programming
+Classifier: Natural Language :: English Classifier: Operating System :: OS
+Independent Classifier: Programming Language :: Python Classifier: Programming
+Language :: Python :: 3 Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9 Classifier: Programming
+Language :: Python :: 3.10 Classifier: Programming Language :: Python :: 3.11
+Classifier: Intended Audience :: Science/Research Classifier: License :: OSI
+Approved :: Apache Software License Classifier: Topic :: Scientific/Engineering
+:: Bio-Informatics Classifier: Topic :: Scientific/Engineering :: Mathematics
+Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
+Classifier: Topic :: Software Development :: Libraries Requires-Python: >=3.8
+Description-Content-Type: text/markdown License-File: LICENSE Requires-Dist:
+numpy (>=1.15) Requires-Dist: jax (>=0.4.1) Requires-Dist: tqdm Requires-Dist:
+msgpack
        [Header image of BrainPy - brain dynamics programming in Python.]
 [Supported_Python_Version] [LICENSE] [Documentation] [PyPI_version] [Continuous
                Integration] [Continuous_Integration_with_Models]
 BrainPy is a flexible, efficient, and extensible framework for computational
 neuroscience and brain-inspired computation based on the Just-In-Time (JIT)
 compilation (built on top of [JAX](https://github.com/google/jax), [Numba]
 (https://github.com/numba/numba), and other JIT compilers). It provides an
```

## Comparing `brainpy-2.4.3.2.dist-info/RECORD` & `brainpy-2.4.3.post3.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-brainpy/__init__.py,sha256=szf0LurYIC3wtQHyIjz87IeQULyu09_5bYDc5PBHeFY,4723
+brainpy/__init__.py,sha256=2EUmQ7rHy0qtgBqrTw6UOcHKM0YEP_kGktqZvOQEwt8,4727
 brainpy/_add_deprecations.py,sha256=VejwF-pk9I0AjruW-0TgtzTyZHlHFf_AUIz-MB1KMGw,6082
 brainpy/analysis.py,sha256=MqtAbIeuyjSI6obQesgrtuJX21hahCYOKIqh_P7o9F8,686
 brainpy/channels.py,sha256=HTexdVY_zeUWsEB09ZZ7SQQwFj7iD4NiKdjQWHKZ_N0,81
 brainpy/check.py,sha256=ZrpRXpLY2OJjUdNorSrQg3V0SjrpMBtYdj6eejE7j08,19618
 brainpy/checkpoints.py,sha256=2o7_DMDrE4iJ-IgKmDFMbON44ZCFk3Tx8UmLeFCJOQg,429
 brainpy/connect.py,sha256=tWKIDEsxqcdAbC2HzVClIAEbanFOymMi70KduMZyL1E,1332
 brainpy/encoding.py,sha256=2MhBAru8IpxhPt2B9OYTi1u3YxhT_GgTidNDAXese40,338
@@ -23,18 +23,18 @@
 brainpy/synplast.py,sha256=J3UlDw1Kkh3fZN8-A5a_qiX8aZ8Hd4L3cOWR_Cl04hI,126
 brainpy/tools.py,sha256=mn2LDO4JrTYc6gBvhXadYe1Ui5g6L80OBxjEmupBbVQ,1094
 brainpy/types.py,sha256=6BRhcrjF2c6lUaZAG7YU4e-bJ5o_vAleFPawIiXR-rs,279
 brainpy/_src/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 brainpy/_src/_delay.py,sha256=cAiPKloOodT-E5ED4b0BSIjxPD2YeIqpf-gyV9Q4YlI,10243
 brainpy/_src/checking.py,sha256=53gdS06Rwzkl9ckO5-CNhDuEOtbapZ7K9wdZOAQP67A,2509
 brainpy/_src/context.py,sha256=cqvAwG9Dzwv5alqiZlZ2NlJ8FIHqXx5T_lP0Zm-waWw,2714
-brainpy/_src/delay.py,sha256=hWILDCx3cqRV0ozk9ynJBm274PEK91P9Iih96FUPY20,23805
-brainpy/_src/deprecations.py,sha256=Jx2nSQuYtxt_CU1l01Q6fK0BQgajL9UIKx6c9lAFOnU,2121
-brainpy/_src/dynsys.py,sha256=8yrHOcAWNKf0uHsOgSPT6qs-hjZYwcfgJDVNnBJ9BPw,25795
-brainpy/_src/mixin.py,sha256=sVgNedHSjCYdoutCnIwToiINflYgfCE3Jx2nh4rFy6A,21257
+brainpy/_src/delay.py,sha256=G66vCGoVTjyG8zN85pUiuvC2Rk9x0_J3gO3w4LjYMrY,14197
+brainpy/_src/deprecations.py,sha256=DU7tKrxU0jWkhskrKu_O9AeHbC2cez7ERt8Tb6rFCmM,2161
+brainpy/_src/dynsys.py,sha256=SUVgus4s5vsv9XE1ZHKFaDlv7DsZvYPukvnKk70Gjyw,27134
+brainpy/_src/mixin.py,sha256=CO3tFKNynEmHc2szHAE6-K3V7pfdelpzaoMRt7-n-uw,21211
 brainpy/_src/modes.py,sha256=7OgTXtnTtc6qHIGfgHZ9w6KL1x9_XddT3h43bWP9Udc,1128
 brainpy/_src/runners.py,sha256=Iiqzh7GSwECRNks-70G1Q6Qscn7kRgSIYQaO_YnRdZg,24011
 brainpy/_src/transform.py,sha256=liJTR98hAL5rGt4FlUZC0vJmgkh8XOVtpHUf-CvxxJs,10537
 brainpy/_src/types.py,sha256=mEif18T9TyVNE9pQCKmpJZE2zlffvg1suxSthv14S8M,1102
 brainpy/_src/analysis/__init__.py,sha256=dTG4qtP8tahngjI4qaB88EITJ8uTBX7UwpqkH_cE9wM,871
 brainpy/_src/analysis/base.py,sha256=bb4CVPh8gky53nqFM73-ZIPOnJlAPIBKd5Zw1_1ZWs8,168
 brainpy/_src/analysis/constants.py,sha256=eTb1lRw0HquV3T_vPjySIvSwj3fpe-cMBAL-DqjCoYE,1807
@@ -105,24 +105,24 @@
 brainpy/_src/dyn/neurons/hh.py,sha256=4RDDhzFBdsJfnmOk-djvNbMXUaro0Wv38iuqoY7fskg,49933
 brainpy/_src/dyn/neurons/lif.py,sha256=uifBbmuhvS0sOcrLq0NRDE-nW037XpnZnoTWYnPs_zE,88145
 brainpy/_src/dyn/others/__init__.py,sha256=zIQjP_A1B2ttcZoiD_JHeNooMamlJFW9yTBI7iVl7Ro,29
 brainpy/_src/dyn/others/common.py,sha256=rxqpcPrOUozx2EXReKlIYWgu09iAwcRu2lusC97i52s,4293
 brainpy/_src/dyn/others/input.py,sha256=zUPhsVjJ8Cju4a9PIvTrRJ0djR_C0orlHMPEhKYSFm4,6984
 brainpy/_src/dyn/others/noise.py,sha256=cqSDvXJZCsoyDUedCLfKgiLqlpLCD71mbrvL8MEYk1g,2278
 brainpy/_src/dyn/outs/__init__.py,sha256=Mb8sKszo6mi6BAm1vTXQkOXwVExvXdT0vL7tg7gcsq4,45
-brainpy/_src/dyn/outs/base.py,sha256=64TBXavDemdJiNw5OQCBIcUJcCk8bDyNzFEqYEZLBwQ,779
-brainpy/_src/dyn/outs/outputs.py,sha256=Js5TAtshUzMenlN91Iia-eZFyWKDLJQZm4gCuDgIT4w,3314
+brainpy/_src/dyn/outs/base.py,sha256=Dg0lxLA_e38lCRpmU4HsAYWmy-rqjlvYZPbGb-v-fQw,864
+brainpy/_src/dyn/outs/outputs.py,sha256=7WaypAjAjVU8r_Y76Q1hooXgtvXawPZxUw4eekPcfDo,3313
 brainpy/_src/dyn/projections/__init__.py,sha256=OQRdV0uLWhIsL_c9mDZ1rr9Z-o4EqwcbpHsg2yfWe2w,69
-brainpy/_src/dyn/projections/aligns.py,sha256=kcqATUikCfJKXGxqkMDUt-Y3RrufiQAdSnvv6kgNpzs,30740
+brainpy/_src/dyn/projections/aligns.py,sha256=sEsQJFHyBa0424T-91i84gm0Pd9LhehLuWl3U_KQMcM,40643
 brainpy/_src/dyn/projections/conn.py,sha256=_dHCU0bNyMUSI89Xw3mbBz-sfA4RUWriOB6bx_D0s5c,3872
 brainpy/_src/dyn/projections/others.py,sha256=hN3elt7HGI6t78Nkcpy1G3UQYsjnnDz-iPDCjHSXvWI,2772
 brainpy/_src/dyn/rates/__init__.py,sha256=Iz02rqiBWUuifG87VY20P553MGapanBdHMmt48SN24A,55
 brainpy/_src/dyn/rates/populations.py,sha256=_-WLKjdeSIaghnRPdLaQPS3Hc2smh3y4c0l0eE96ny8,42276
 brainpy/_src/dyn/synapses/__init__.py,sha256=HovcuP8MxaZP1LrYVsRY00foNOO8W9wLIUdx-MbIXe0,61
-brainpy/_src/dyn/synapses/abstract_models.py,sha256=jHFZ5oZ2qKKaa-fLCs5TQyMSU0-9N_3CeloWw901VJk,22572
+brainpy/_src/dyn/synapses/abstract_models.py,sha256=ScJe4_2VUtw_5Hnd6v_mg7MNGgDmeRxcwpFFRsesTzA,22788
 brainpy/_src/dyn/synapses/bio_models.py,sha256=GsZPmZ0PE4_pwj2Xf_ZCp_409dJGvl3QyRdMUVEtzdc,12152
 brainpy/_src/dyn/synapses/delay_couplings.py,sha256=e8rkRhDchTTBEsG4je2CEysyq86XJsA0Q4QaBWt5p9U,11132
 brainpy/_src/dynold/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 brainpy/_src/dynold/experimental/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 brainpy/_src/dynold/experimental/abstract_synapses.py,sha256=hi-9998NyEsSatkj2UIjv0878BInydFbFj6y9fsQLsM,13965
 brainpy/_src/dynold/experimental/base.py,sha256=RFOzGOSEtiZ-PrCSucdYA1fGFYMGpmo6aBX87ooWKXU,4774
 brainpy/_src/dynold/experimental/others.py,sha256=FoYd3VwQetkSKAcGg9EQkHtkivgWk7oSafaqYD8QdMc,2632
@@ -291,15 +291,15 @@
 brainpy/dyn/base.py,sha256=LJ9Z2d2m1oEOLGNz6QnF9OINIOLltiJwPYygnzDegYQ,78
 brainpy/dyn/channels.py,sha256=wyPX5QOESmZD1ZT7WYYrSn09CFQghCJqiUltZVQ64Qo,1593
 brainpy/dyn/compat.py,sha256=dIW7y1kR5yneb28SQu3IKIrq3JNGGzm-lvcsFk2nvrk,102
 brainpy/dyn/ions.py,sha256=MtY_gFZ3BJJCchRcS-FRiSnYoZM-3duptFJqLT6v6ig,592
 brainpy/dyn/neurons.py,sha256=-hWE25gXSgjjbju96vi0All8VpHB4pK10tQ-0yPuHe8,632
 brainpy/dyn/others.py,sha256=msIhpmSBonxvAZxCRRiVeLe0j1hPSDDvo48qhrWTwwY,358
 brainpy/dyn/outs.py,sha256=bcHHPZtjQTiyHME2M9k39nNTSt9Y7Fyz8paBuH0rXP8,134
-brainpy/dyn/projections.py,sha256=_6dwkR9r7xL3MqbQN3TeQhpXAWgybHM_4ACu7FArRa4,362
+brainpy/dyn/projections.py,sha256=GTADn1od6AMYhB60NnpJbyiVZGyiagIBy_FrFFwPYaw,398
 brainpy/dyn/rates.py,sha256=ijzgpikZEPcSrmSOuok0oJ_OvMwf5faXa9-22ir7O_o,146
 brainpy/dyn/synapses.py,sha256=HBgpiKpw9jXYOMhG9T4N9RDWXX1hmvXgNrzcmGEGHP8,332
 brainpy/integrators/__init__.py,sha256=l4CciScjIQZNgKlggLMKVyg1hqg7CHrcQa3jU29eic0,134
 brainpy/integrators/fde.py,sha256=bKgEJtH5Bf8rmau1xUTT00ekYhhS3SjlxkRk6t4l4RU,597
 brainpy/integrators/ode.py,sha256=sVCzKfTOUDRf-nq8vB3FlSay2lZ8TRvBV1ovtnaSRU4,1103
 brainpy/integrators/sde.py,sha256=9DBedr1WENfq-RL7j0Ms3Le4rTbwOM_rEHqG2oALayo,706
 brainpy/math/__init__.py,sha256=McrMFl1o-n8Du7CwmE_2mN52GHjm41cxQoBqK3tnUyk,4883
@@ -322,12 +322,12 @@
 brainpy/math/op_register.py,sha256=DEn119RDRxYp3xxUg92PnG5h4Ups49wEnjLoitPd1gU,137
 brainpy/math/others.py,sha256=z97UhqDnrGWOde7ghntc6-PVOAmo8Vts4H10IxnDdgc,268
 brainpy/math/pre_syn_post.py,sha256=jITwBquVo0vKVRZXn9KMdq-2uRS-dRRVCjb8Mf7b9MI,352
 brainpy/math/random.py,sha256=6OpnjzSNsclFEfSEd5NhQKH5zZ62X8ch3Cb0NYJcNCw,1843
 brainpy/math/sharding.py,sha256=Sx3qYaTrW2hMIDVlnL7leiPm3bKar9emYjCbGR7DY-M,228
 brainpy/math/sparse.py,sha256=WVo-6ZRTZ-v8hsGhlOdo3-WakSvymY0mY6UIxP7CKlQ,175
 brainpy/math/surrogate.py,sha256=jcbXBdt4PuKNT70NskkLUu_WJMhxlAmlbQMy2mOLx9k,1320
-brainpy-2.4.3.2.dist-info/LICENSE,sha256=y_p8Hru855LwiNwIbkjJLmA0ZMwQQzHvJR5BVplHk1I,35773
-brainpy-2.4.3.2.dist-info/METADATA,sha256=mB40nl_MVrmtTSveY2RzFXPqfQXFbIK8E0L3TjgxIbY,4351
-brainpy-2.4.3.2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-brainpy-2.4.3.2.dist-info/top_level.txt,sha256=5oi55xrJaqccrIi7VVShKhvGx0MjnDl0efebGKr5Omc,8
-brainpy-2.4.3.2.dist-info/RECORD,,
+brainpy-2.4.3.post3.dist-info/LICENSE,sha256=y_p8Hru855LwiNwIbkjJLmA0ZMwQQzHvJR5BVplHk1I,35773
+brainpy-2.4.3.post3.dist-info/METADATA,sha256=T__aQv0VsptK6Nhcpkwk1-mV0FaojtWnZBrcuspNcgo,4355
+brainpy-2.4.3.post3.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+brainpy-2.4.3.post3.dist-info/top_level.txt,sha256=5oi55xrJaqccrIi7VVShKhvGx0MjnDl0efebGKr5Omc,8
+brainpy-2.4.3.post3.dist-info/RECORD,,
```

