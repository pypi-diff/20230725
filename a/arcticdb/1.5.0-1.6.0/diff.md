# Comparing `tmp/arcticdb-1.5.0-cp39-cp39-win_amd64.whl.zip` & `tmp/arcticdb-1.6.0-cp39-cp39-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,77 +1,77 @@
-Zip file size: 6480936 bytes, number of entries: 75
--rw-rw-rw-  2.0 fat 22087680 b- defN 23-Jul-10 21:53 arcticdb_ext.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat      302 b- defN 23-Jul-10 21:27 arcticc/__init__.py
--rw-rw-rw-  2.0 fat      583 b- defN 23-Jul-10 21:27 arcticc/pb2/__init__.py
--rw-rw-rw-  2.0 fat      424 b- defN 23-Jul-10 21:27 arcticdb/__init__.py
--rw-rw-rw-  2.0 fat      447 b- defN 23-Jul-10 21:27 arcticdb/_msgpack_compat.py
--rw-rw-rw-  2.0 fat    17934 b- defN 23-Jul-10 21:27 arcticdb/arctic.py
--rw-rw-rw-  2.0 fat     8617 b- defN 23-Jul-10 21:27 arcticdb/config.py
--rw-rw-rw-  2.0 fat      429 b- defN 23-Jul-10 21:27 arcticdb/encoding_version.py
--rw-rw-rw-  2.0 fat      765 b- defN 23-Jul-10 21:27 arcticdb/exceptions.py
--rw-rw-rw-  2.0 fat     9361 b- defN 23-Jul-10 21:27 arcticdb/flattener.py
--rw-rw-rw-  2.0 fat     1810 b- defN 23-Jul-10 21:27 arcticdb/log.py
--rw-rw-rw-  2.0 fat     6694 b- defN 23-Jul-10 21:27 arcticdb/options.py
--rw-rw-rw-  2.0 fat      519 b- defN 23-Jul-10 21:27 arcticdb/preconditions.py
--rw-rw-rw-  2.0 fat     1612 b- defN 23-Jul-10 21:27 arcticdb/supported_types.py
--rw-rw-rw-  2.0 fat     3150 b- defN 23-Jul-10 21:27 arcticdb/tools.py
--rw-rw-rw-  2.0 fat      211 b- defN 23-Jul-10 21:27 arcticdb/adapters/__init__.py
--rw-rw-rw-  2.0 fat     2507 b- defN 23-Jul-10 21:27 arcticdb/adapters/arctic_library_adapter.py
--rw-rw-rw-  2.0 fat     4935 b- defN 23-Jul-10 21:27 arcticdb/adapters/azure_library_adapter.py
--rw-rw-rw-  2.0 fat     2829 b- defN 23-Jul-10 21:27 arcticdb/adapters/lmdb_library_adapter.py
--rw-rw-rw-  2.0 fat     7845 b- defN 23-Jul-10 21:27 arcticdb/adapters/s3_library_adapter.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-10 21:27 arcticdb/authorization/__init__.py
--rw-rw-rw-  2.0 fat      969 b- defN 23-Jul-10 21:27 arcticdb/authorization/permissions.py
--rw-rw-rw-  2.0 fat     4188 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/azure_storage_pb2.py
--rw-rw-rw-  2.0 fat     8935 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/config_pb2.py
--rw-rw-rw-  2.0 fat    96954 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/descriptors_pb2.py
--rw-rw-rw-  2.0 fat    31651 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/encoding_pb2.py
--rw-rw-rw-  2.0 fat    13225 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/generation_pb2.py
--rw-rw-rw-  2.0 fat     1990 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/in_memory_storage_pb2.py
--rw-rw-rw-  2.0 fat     4634 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/lmdb_storage_pb2.py
--rw-rw-rw-  2.0 fat    24224 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/logger_pb2.py
--rw-rw-rw-  2.0 fat     2931 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/mongo_storage_pb2.py
--rw-rw-rw-  2.0 fat     6878 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/nfs_backed_storage_pb2.py
--rw-rw-rw-  2.0 fat     3821 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/processors_pb2.py
--rw-rw-rw-  2.0 fat    49227 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/request_pb2.py
--rw-rw-rw-  2.0 fat     6729 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/s3_storage_pb2.py
--rw-rw-rw-  2.0 fat    67741 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/storage_pb2.py
--rw-rw-rw-  2.0 fat    12621 b- defN 23-Jul-10 21:36 arcticdb/proto/3/arcticc/pb2/utils_pb2.py
--rw-rw-rw-  2.0 fat     1300 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/azure_storage_pb2.py
--rw-rw-rw-  2.0 fat     2413 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/config_pb2.py
--rw-rw-rw-  2.0 fat    15753 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/descriptors_pb2.py
--rw-rw-rw-  2.0 fat     5597 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/encoding_pb2.py
--rw-rw-rw-  2.0 fat     3113 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/generation_pb2.py
--rw-rw-rw-  2.0 fat     1081 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/in_memory_storage_pb2.py
--rw-rw-rw-  2.0 fat     1434 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/lmdb_storage_pb2.py
--rw-rw-rw-  2.0 fat     4397 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/logger_pb2.py
--rw-rw-rw-  2.0 fat     1262 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/mongo_storage_pb2.py
--rw-rw-rw-  2.0 fat     1560 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/nfs_backed_storage_pb2.py
--rw-rw-rw-  2.0 fat     1326 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/processors_pb2.py
--rw-rw-rw-  2.0 fat     7300 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/request_pb2.py
--rw-rw-rw-  2.0 fat     1539 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/s3_storage_pb2.py
--rw-rw-rw-  2.0 fat    10573 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/storage_pb2.py
--rw-rw-rw-  2.0 fat     2449 b- defN 23-Jul-10 21:36 arcticdb/proto/4/arcticc/pb2/utils_pb2.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-10 21:27 arcticdb/toolbox/__init__.py
--rw-rw-rw-  2.0 fat     6074 b- defN 23-Jul-10 21:27 arcticdb/toolbox/library_tool.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-10 21:27 arcticdb/util/__init__.py
--rw-rw-rw-  2.0 fat     2705 b- defN 23-Jul-10 21:27 arcticdb/util/errors.py
--rw-rw-rw-  2.0 fat     8775 b- defN 23-Jul-10 21:27 arcticdb/util/hypothesis.py
--rw-rw-rw-  2.0 fat      719 b- defN 23-Jul-10 21:27 arcticdb/util/memory.py
--rw-rw-rw-  2.0 fat     6013 b- defN 23-Jul-10 21:27 arcticdb/util/tasks.py
--rw-rw-rw-  2.0 fat    18249 b- defN 23-Jul-10 21:27 arcticdb/util/test.py
--rw-rw-rw-  2.0 fat      131 b- defN 23-Jul-10 21:27 arcticdb/version_store/__init__.py
--rw-rw-rw-  2.0 fat     7189 b- defN 23-Jul-10 21:27 arcticdb/version_store/_common.py
--rw-rw-rw-  2.0 fat     4193 b- defN 23-Jul-10 21:27 arcticdb/version_store/_custom_normalizers.py
--rw-rw-rw-  2.0 fat    52672 b- defN 23-Jul-10 21:27 arcticdb/version_store/_normalization.py
--rw-rw-rw-  2.0 fat   114434 b- defN 23-Jul-10 21:27 arcticdb/version_store/_store.py
--rw-rw-rw-  2.0 fat    12917 b- defN 23-Jul-10 21:27 arcticdb/version_store/helper.py
--rw-rw-rw-  2.0 fat    59901 b- defN 23-Jul-10 21:27 arcticdb/version_store/library.py
--rw-rw-rw-  2.0 fat    24370 b- defN 23-Jul-10 21:27 arcticdb/version_store/processing.py
--rw-rw-rw-  2.0 fat      603 b- defN 23-Jul-10 21:27 arcticdb/version_store/read_result.py
--rw-rw-rw-  2.0 fat     4851 b- defN 23-Jul-10 21:53 arcticdb-1.5.0.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat     9313 b- defN 23-Jul-10 21:53 arcticdb-1.5.0.dist-info/METADATA
--rw-rw-rw-  2.0 fat    18186 b- defN 23-Jul-10 21:53 arcticdb-1.5.0.dist-info/NOTICE.txt
--rw-rw-rw-  2.0 fat      100 b- defN 23-Jul-10 21:53 arcticdb-1.5.0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       30 b- defN 23-Jul-10 21:53 arcticdb-1.5.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     6926 b- defN 23-Jul-10 21:53 arcticdb-1.5.0.dist-info/RECORD
-75 files, 22914820 bytes uncompressed, 6469800 bytes compressed:  71.8%
+Zip file size: 6493676 bytes, number of entries: 75
+-rw-rw-rw-  2.0 fat 22130176 b- defN 23-Jul-25 09:22 arcticdb_ext.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat      302 b- defN 23-Jul-25 09:04 arcticc/__init__.py
+-rw-rw-rw-  2.0 fat      583 b- defN 23-Jul-25 09:04 arcticc/pb2/__init__.py
+-rw-rw-rw-  2.0 fat      424 b- defN 23-Jul-25 09:04 arcticdb/__init__.py
+-rw-rw-rw-  2.0 fat      447 b- defN 23-Jul-25 09:04 arcticdb/_msgpack_compat.py
+-rw-rw-rw-  2.0 fat    18531 b- defN 23-Jul-25 09:04 arcticdb/arctic.py
+-rw-rw-rw-  2.0 fat     8617 b- defN 23-Jul-25 09:04 arcticdb/config.py
+-rw-rw-rw-  2.0 fat      429 b- defN 23-Jul-25 09:04 arcticdb/encoding_version.py
+-rw-rw-rw-  2.0 fat      765 b- defN 23-Jul-25 09:04 arcticdb/exceptions.py
+-rw-rw-rw-  2.0 fat     9361 b- defN 23-Jul-25 09:04 arcticdb/flattener.py
+-rw-rw-rw-  2.0 fat     1810 b- defN 23-Jul-25 09:04 arcticdb/log.py
+-rw-rw-rw-  2.0 fat     6694 b- defN 23-Jul-25 09:04 arcticdb/options.py
+-rw-rw-rw-  2.0 fat      519 b- defN 23-Jul-25 09:04 arcticdb/preconditions.py
+-rw-rw-rw-  2.0 fat     1612 b- defN 23-Jul-25 09:04 arcticdb/supported_types.py
+-rw-rw-rw-  2.0 fat     3150 b- defN 23-Jul-25 09:04 arcticdb/tools.py
+-rw-rw-rw-  2.0 fat      211 b- defN 23-Jul-25 09:04 arcticdb/adapters/__init__.py
+-rw-rw-rw-  2.0 fat     2376 b- defN 23-Jul-25 09:04 arcticdb/adapters/arctic_library_adapter.py
+-rw-rw-rw-  2.0 fat     4806 b- defN 23-Jul-25 09:04 arcticdb/adapters/azure_library_adapter.py
+-rw-rw-rw-  2.0 fat     3240 b- defN 23-Jul-25 09:04 arcticdb/adapters/lmdb_library_adapter.py
+-rw-rw-rw-  2.0 fat     7716 b- defN 23-Jul-25 09:04 arcticdb/adapters/s3_library_adapter.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-25 09:04 arcticdb/authorization/__init__.py
+-rw-rw-rw-  2.0 fat      969 b- defN 23-Jul-25 09:04 arcticdb/authorization/permissions.py
+-rw-rw-rw-  2.0 fat     4188 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/azure_storage_pb2.py
+-rw-rw-rw-  2.0 fat     8935 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/config_pb2.py
+-rw-rw-rw-  2.0 fat    96954 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/descriptors_pb2.py
+-rw-rw-rw-  2.0 fat    31651 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/encoding_pb2.py
+-rw-rw-rw-  2.0 fat    13225 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/generation_pb2.py
+-rw-rw-rw-  2.0 fat     1990 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/in_memory_storage_pb2.py
+-rw-rw-rw-  2.0 fat     4634 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/lmdb_storage_pb2.py
+-rw-rw-rw-  2.0 fat    24224 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/logger_pb2.py
+-rw-rw-rw-  2.0 fat     2931 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/mongo_storage_pb2.py
+-rw-rw-rw-  2.0 fat     6878 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/nfs_backed_storage_pb2.py
+-rw-rw-rw-  2.0 fat     3821 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/processors_pb2.py
+-rw-rw-rw-  2.0 fat    49227 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/request_pb2.py
+-rw-rw-rw-  2.0 fat     6729 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/s3_storage_pb2.py
+-rw-rw-rw-  2.0 fat    67741 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/storage_pb2.py
+-rw-rw-rw-  2.0 fat    12621 b- defN 23-Jul-25 09:13 arcticdb/proto/3/arcticc/pb2/utils_pb2.py
+-rw-rw-rw-  2.0 fat     1300 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/azure_storage_pb2.py
+-rw-rw-rw-  2.0 fat     2413 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/config_pb2.py
+-rw-rw-rw-  2.0 fat    15753 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/descriptors_pb2.py
+-rw-rw-rw-  2.0 fat     5597 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/encoding_pb2.py
+-rw-rw-rw-  2.0 fat     3113 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/generation_pb2.py
+-rw-rw-rw-  2.0 fat     1081 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/in_memory_storage_pb2.py
+-rw-rw-rw-  2.0 fat     1434 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/lmdb_storage_pb2.py
+-rw-rw-rw-  2.0 fat     4397 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/logger_pb2.py
+-rw-rw-rw-  2.0 fat     1262 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/mongo_storage_pb2.py
+-rw-rw-rw-  2.0 fat     1560 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/nfs_backed_storage_pb2.py
+-rw-rw-rw-  2.0 fat     1326 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/processors_pb2.py
+-rw-rw-rw-  2.0 fat     7300 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/request_pb2.py
+-rw-rw-rw-  2.0 fat     1539 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/s3_storage_pb2.py
+-rw-rw-rw-  2.0 fat    10573 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/storage_pb2.py
+-rw-rw-rw-  2.0 fat     2449 b- defN 23-Jul-25 09:13 arcticdb/proto/4/arcticc/pb2/utils_pb2.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-25 09:04 arcticdb/toolbox/__init__.py
+-rw-rw-rw-  2.0 fat     6074 b- defN 23-Jul-25 09:04 arcticdb/toolbox/library_tool.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-25 09:04 arcticdb/util/__init__.py
+-rw-rw-rw-  2.0 fat     2705 b- defN 23-Jul-25 09:04 arcticdb/util/errors.py
+-rw-rw-rw-  2.0 fat     8775 b- defN 23-Jul-25 09:04 arcticdb/util/hypothesis.py
+-rw-rw-rw-  2.0 fat      719 b- defN 23-Jul-25 09:04 arcticdb/util/memory.py
+-rw-rw-rw-  2.0 fat     6013 b- defN 23-Jul-25 09:04 arcticdb/util/tasks.py
+-rw-rw-rw-  2.0 fat    18249 b- defN 23-Jul-25 09:04 arcticdb/util/test.py
+-rw-rw-rw-  2.0 fat      131 b- defN 23-Jul-25 09:04 arcticdb/version_store/__init__.py
+-rw-rw-rw-  2.0 fat     7189 b- defN 23-Jul-25 09:04 arcticdb/version_store/_common.py
+-rw-rw-rw-  2.0 fat     4193 b- defN 23-Jul-25 09:04 arcticdb/version_store/_custom_normalizers.py
+-rw-rw-rw-  2.0 fat    52672 b- defN 23-Jul-25 09:04 arcticdb/version_store/_normalization.py
+-rw-rw-rw-  2.0 fat   114274 b- defN 23-Jul-25 09:04 arcticdb/version_store/_store.py
+-rw-rw-rw-  2.0 fat    12917 b- defN 23-Jul-25 09:04 arcticdb/version_store/helper.py
+-rw-rw-rw-  2.0 fat    60721 b- defN 23-Jul-25 09:04 arcticdb/version_store/library.py
+-rw-rw-rw-  2.0 fat    24370 b- defN 23-Jul-25 09:04 arcticdb/version_store/processing.py
+-rw-rw-rw-  2.0 fat      603 b- defN 23-Jul-25 09:04 arcticdb/version_store/read_result.py
+-rw-rw-rw-  2.0 fat     4851 b- defN 23-Jul-25 09:22 arcticdb-1.6.0.dist-info/LICENSE.txt
+-rw-rw-rw-  2.0 fat     9311 b- defN 23-Jul-25 09:22 arcticdb-1.6.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat    18186 b- defN 23-Jul-25 09:22 arcticdb-1.6.0.dist-info/NOTICE.txt
+-rw-rw-rw-  2.0 fat      100 b- defN 23-Jul-25 09:22 arcticdb-1.6.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       30 b- defN 23-Jul-25 09:22 arcticdb-1.6.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     6926 b- defN 23-Jul-25 09:22 arcticdb-1.6.0.dist-info/RECORD
+75 files, 22958593 bytes uncompressed, 6482540 bytes compressed:  71.8%
```

## zipnote {}

```diff
@@ -201,26 +201,26 @@
 
 Filename: arcticdb/version_store/processing.py
 Comment: 
 
 Filename: arcticdb/version_store/read_result.py
 Comment: 
 
-Filename: arcticdb-1.5.0.dist-info/LICENSE.txt
+Filename: arcticdb-1.6.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: arcticdb-1.5.0.dist-info/METADATA
+Filename: arcticdb-1.6.0.dist-info/METADATA
 Comment: 
 
-Filename: arcticdb-1.5.0.dist-info/NOTICE.txt
+Filename: arcticdb-1.6.0.dist-info/NOTICE.txt
 Comment: 
 
-Filename: arcticdb-1.5.0.dist-info/WHEEL
+Filename: arcticdb-1.6.0.dist-info/WHEEL
 Comment: 
 
-Filename: arcticdb-1.5.0.dist-info/top_level.txt
+Filename: arcticdb-1.6.0.dist-info/top_level.txt
 Comment: 
 
-Filename: arcticdb-1.5.0.dist-info/RECORD
+Filename: arcticdb-1.6.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## arcticdb/__init__.py

```diff
@@ -7,8 +7,8 @@
 from arcticdb.version_store.processing import QueryBuilder
 import arcticdb.version_store.library as library
 from arcticdb.options import LibraryOptions
 from arcticdb.tools import set_config_from_env_vars
 
 set_config_from_env_vars(_os.environ)
 
-__version__ = "1.5.0"
+__version__ = "1.6.0"
```

## arcticdb/arctic.py

```diff
@@ -1,19 +1,19 @@
 """
 Copyright 2023 Man Group Operations Limited
 
 Use of this software is governed by the Business Source License 1.1 included in the file licenses/BSL.txt.
 
 As of the Change Date specified in that file, in accordance with the Business Source License, use of this software will be governed by the Apache License, version 2.0.
 """
-import enum
 from typing import List, Optional
 
 from arcticdb.options import LibraryOptions
 from arcticdb_ext.storage import LibraryManager, StorageOverride
+from arcticdb.exceptions import LibraryNotFound
 from arcticdb.version_store.library import Library
 from arcticdb.version_store._store import NativeVersionStore
 from arcticdb.adapters.s3_library_adapter import S3LibraryAdapter
 from arcticdb.adapters.lmdb_library_adapter import LMDBLibraryAdapter
 from arcticdb.encoding_version import EncodingVersion
 from arcticdb.adapters.azure_library_adapter import AzureLibraryAdapter
 
@@ -145,16 +145,24 @@
                 f"Invalid URI specified. Please see URI format specification for available formats. uri={uri}"
             )
 
         self._encoding_version = encoding_version
         self._library_adapter = _cls(uri, self._encoding_version)
         self._library_manager = LibraryManager(self._library_adapter.config_library)
         self._uri = uri
+        self._open_libraries = dict()
 
     def __getitem__(self, name: str) -> Library:
+        already_open = self._open_libraries.get(name)
+        if already_open:
+            return already_open
+
+        if not self._library_manager.has_library(name):
+            raise LibraryNotFound(name)
+
         storage_override = self._library_adapter.get_storage_override()
         lib = NativeVersionStore(
             self._library_manager.get_library(name, storage_override),
             repr(self._library_adapter),
             lib_cfg=self._library_manager.get_library_config(name, storage_override),
         )
         return Library(repr(self), lib)
@@ -204,42 +212,48 @@
 
         Examples
         --------
         >>> arctic = Arctic('s3://MY_ENDPOINT:MY_BUCKET')
         >>> arctic.create_library('test.library')
         >>> my_library = arctic['test.library']
         """
-        if self._library_manager.has_library(name):
-            raise ValueError(f"{name} already exists as a library. Please delete prior to re-creating.")
+        if name in self._open_libraries or self._library_manager.has_library(name):
+            raise ValueError(f"Library [{name}] already exists.")
 
         if library_options is None:
             library_options = LibraryOptions()
 
-        library_config = self._library_adapter.create_library_config(name, library_options)
-        self._library_adapter.initialize_library(name, library_config)
-        self._library_manager.write_library_config(library_config, name)
+        library = self._library_adapter.create_library(name, library_options)
+        library.env = repr(self._library_adapter)
+        lib = Library(repr(self), library)
+        self._open_libraries[name] = lib
+        self._library_manager.write_library_config(library._lib_cfg, name)
 
     def delete_library(self, name: str) -> None:
         """
         Removes the library called ``name``. This will remove the underlying data contained within the library and as
         such will take as much time as the underlying delete operations take.
 
         If no library with ``name`` exists then this is a no-op. In particular this method does not raise in this case.
 
         Parameters
         ----------
         name: `str`
             Name of the library to delete.
         """
-        if not self._library_manager.has_library(name):
+        already_open = self._open_libraries.pop(name, None)
+        if not already_open and not self._library_manager.has_library(name):
             return
-        self._library_adapter.delete_library(
-            self[name], self._library_manager.get_library_config(name, StorageOverride())
-        )
-        self._library_manager.remove_library_config(name)
+        config = self._library_manager.get_library_config(name, StorageOverride())
+        (already_open or self[name])._nvs.version_store.clear()
+        del already_open  # essential to free resources held by the library
+        try:
+            self._library_adapter.cleanup_library(name, config)
+        finally:
+            self._library_manager.remove_library_config(name)
 
     def list_libraries(self) -> List[str]:
         """
         Lists all libraries available.
 
         Examples
         --------
```

## arcticdb/adapters/arctic_library_adapter.py

```diff
@@ -5,16 +5,16 @@
 
 As of the Change Date specified in that file, in accordance with the Business Source License, use of this software will be governed by the Apache License, version 2.0.
 """
 from arcticdb.options import LibraryOptions
 from arcticc.pb2.storage_pb2 import LibraryConfig
 from arcticdb_ext.storage import Library, StorageOverride
 from arcticdb.encoding_version import EncodingVersion
+from arcticdb.version_store._store import NativeVersionStore
 from abc import ABC, abstractmethod
-from typing import Optional
 
 
 def set_library_options(lib_desc: "LibraryConfig", options: LibraryOptions):
     write_options = lib_desc.version.write_options
 
     write_options.dynamic_strings = True
     write_options.recursive_normalizers = True
@@ -53,19 +53,15 @@
 
     @property
     @abstractmethod
     def config_library(self) -> Library:
         raise NotImplementedError
 
     @abstractmethod
-    def create_library_config(self, name: str, library_options: LibraryOptions) -> LibraryConfig:
+    def create_library(self, name: str, library_options: LibraryOptions) -> NativeVersionStore:
         raise NotImplementedError
 
-    @abstractmethod
-    def initialize_library(self, name: str, config: LibraryConfig):
-        raise NotImplementedError
-
-    def delete_library(self, library: Library, library_config: LibraryConfig):
-        return library._nvs.version_store.clear()
+    def cleanup_library(self, library_name: str, library_config: LibraryConfig):
+        pass
 
     def get_storage_override(self) -> StorageOverride:
         return StorageOverride()
```

## arcticdb/adapters/azure_library_adapter.py

```diff
@@ -59,15 +59,15 @@
 
         super().__init__(uri, EncodingVersion.V1)
 
     def __repr__(self):
         return "azure(endpoint=%s, container=%s)" % (self._endpoint, self._container)
 
     @property
-    def config_library(self) -> Library:
+    def config_library(self):
         env_cfg = EnvironmentConfigsMap()
         with_prefix = (
             f"{self._query_params.Path_prefix}/{self.CONFIG_LIBRARY_NAME}" if self._query_params.Path_prefix else False
         )
 
         add_azure_library_to_env(
             cfg=env_cfg,
@@ -75,17 +75,17 @@
             env_name=_DEFAULT_ENV,
             container_name=self._container,
             endpoint=self._endpoint,
             with_prefix=with_prefix,
             ca_cert_path=self._ca_cert_path,
         )
 
-        lib = NativeVersionStore.create_store_from_config(env_cfg, _DEFAULT_ENV, self.CONFIG_LIBRARY_NAME)._library
+        lib = NativeVersionStore.create_store_from_config(env_cfg, _DEFAULT_ENV, self.CONFIG_LIBRARY_NAME)
 
-        return lib
+        return lib._library
 
     def _parse_query(self, query: str) -> ParsedQuery:
         if query and query.startswith("?"):
             query = query.strip("?")
         elif not query:
             raise ValueError(f"Invalid Azure URI. Missing query parameter")
 
@@ -96,15 +96,15 @@
 
         if parsed_query.get("Path_prefix"):
             parsed_query["Path_prefix"] = parsed_query["Path_prefix"].strip("/")
 
         _kwargs = {k: v for k, v in parsed_query.items() if k in field_dict.keys()}
         return _kwargs
 
-    def create_library_config(self, name, library_options: LibraryOptions) -> LibraryConfig:
+    def create_library(self, name, library_options: LibraryOptions):
         env_cfg = EnvironmentConfigsMap()
 
         if self._query_params.Path_prefix:
             # add time to prefix - so that the azure root folder is unique and we can delete and recreate fast
             with_prefix = f"{self._query_params.Path_prefix}/{name}{time.time() * 1e9:.0f}"
         else:
             with_prefix = True
@@ -119,15 +119,12 @@
             ca_cert_path=self._ca_cert_path,
         )
 
         set_library_options(env_cfg.env_by_id[_DEFAULT_ENV].lib_by_path[name], library_options)
 
         lib = NativeVersionStore.create_store_from_config(env_cfg, _DEFAULT_ENV, name)
 
-        return lib._lib_cfg
-
-    def initialize_library(self, name: str, config: LibraryConfig):
-        pass
+        return lib
 
     @property
     def path_prefix(self):
         return self._query_params.Path_prefix
```

## arcticdb/adapters/lmdb_library_adapter.py

```diff
@@ -3,27 +3,32 @@
 
 Use of this software is governed by the Business Source License 1.1 included in the file licenses/BSL.txt.
 
 As of the Change Date specified in that file, in accordance with the Business Source License, use of this software will be governed by the Apache License, version 2.0.
 """
 import re
 import os
-
-from typing import Optional
+import shutil
+from arcticdb.log import storage as log
 
 from arcticdb.options import LibraryOptions
 from arcticc.pb2.storage_pb2 import EnvironmentConfigsMap, LibraryConfig
+from arcticc.pb2.lmdb_storage_pb2 import Config as LmdbConfig
 from arcticdb.version_store.helper import add_lmdb_library_to_env
 from arcticdb.config import _DEFAULT_ENV
 from arcticdb.version_store._store import NativeVersionStore
 from arcticdb.adapters.arctic_library_adapter import ArcticLibraryAdapter, set_library_options
-from arcticdb_ext.storage import Library, StorageOverride
+from arcticdb_ext.storage import StorageOverride
 from arcticdb.encoding_version import EncodingVersion
 
 
+def _rmtree_errorhandler(func, path, exc_info):
+    log.warn("Error removing LMDB tree at path=[{}]", path, exc_info=exc_info)
+
+
 class LMDBLibraryAdapter(ArcticLibraryAdapter):
     """
     Use local LMDB library for storage.
 
     Supports any URI that begins with `lmdb://` - for example, `lmdb:///tmp/lmdb_db`.
     """
 
@@ -43,36 +48,39 @@
 
         super().__init__(uri, self._encoding_version)
 
     def __repr__(self):
         return "LMDB(path=%s)" % self._path
 
     @property
-    def config_library(self) -> Library:
+    def config_library(self):
         env_cfg = EnvironmentConfigsMap()
 
         add_lmdb_library_to_env(env_cfg, lib_name=self.CONFIG_LIBRARY_NAME, env_name=_DEFAULT_ENV, db_dir=self._path)
 
         lib = NativeVersionStore.create_store_from_config(
             env_cfg, _DEFAULT_ENV, self.CONFIG_LIBRARY_NAME, encoding_version=self._encoding_version
-        )._library
-
-        return lib
+        )
 
-    def get_storage_override(self) -> StorageOverride:
-        return StorageOverride()
+        return lib._library
 
-    def create_library_config(self, name, library_options: LibraryOptions) -> LibraryConfig:
+    def create_library(self, name, library_options: LibraryOptions):
         env_cfg = EnvironmentConfigsMap()
 
         add_lmdb_library_to_env(env_cfg, lib_name=name, env_name=_DEFAULT_ENV, db_dir=self._path)
 
         set_library_options(env_cfg.env_by_id[_DEFAULT_ENV].lib_by_path[name], library_options)
 
         lib = NativeVersionStore.create_store_from_config(
             env_cfg, _DEFAULT_ENV, name, encoding_version=self._encoding_version
         )
 
-        return lib._lib_cfg
+        return lib
+
+    def cleanup_library(self, library_name: str, library_config: LibraryConfig):
+        for k, v in library_config.storage_by_id.items():
+            lmdb_config = LmdbConfig()
+            v.config.Unpack(lmdb_config)
+            shutil.rmtree(os.path.join(lmdb_config.path, library_name), onerror=_rmtree_errorhandler)
 
-    def initialize_library(self, name: str, config: LibraryConfig):
-        pass
+    def get_storage_override(self) -> StorageOverride:
+        return StorageOverride()
```

## arcticdb/adapters/s3_library_adapter.py

```diff
@@ -68,15 +68,15 @@
 
         super().__init__(uri, self._encoding_version)
 
     def __repr__(self):
         return "S3(endpoint=%s, bucket=%s)" % (self._endpoint, self._bucket)
 
     @property
-    def config_library(self) -> Library:
+    def config_library(self):
         env_cfg = EnvironmentConfigsMap()
         _name = self._query_params.access if not self._query_params.aws_auth else USE_AWS_CRED_PROVIDERS_TOKEN
         _key = self._query_params.secret if not self._query_params.aws_auth else USE_AWS_CRED_PROVIDERS_TOKEN
         with_prefix = (
             f"{self._query_params.path_prefix}/{self.CONFIG_LIBRARY_NAME}" if self._query_params.path_prefix else False
         )
 
@@ -92,17 +92,17 @@
             with_prefix=with_prefix,
             region=self._query_params.region,
             use_virtual_addressing=self._query_params.use_virtual_addressing,
         )
 
         lib = NativeVersionStore.create_store_from_config(
             env_cfg, _DEFAULT_ENV, self.CONFIG_LIBRARY_NAME, encoding_version=self._encoding_version
-        )._library
+        )
 
-        return lib
+        return lib._library
 
     def _parse_query(self, query: str) -> ParsedQuery:
         if query and query.startswith("?"):
             query = query.strip("?")
         elif not query:
             return ParsedQuery(aws_auth=True)
 
@@ -146,15 +146,15 @@
             if self._bucket:
                 s3_override.bucket_name = self._bucket
             storage_override = StorageOverride()
             storage_override.set_override(s3_override)
 
         return storage_override
 
-    def create_library_config(self, name, library_options: LibraryOptions) -> LibraryConfig:
+    def create_library(self, name, library_options: LibraryOptions):
         env_cfg = EnvironmentConfigsMap()
 
         _name = self._query_params.access if not self._query_params.aws_auth else USE_AWS_CRED_PROVIDERS_TOKEN
         _key = self._query_params.secret if not self._query_params.aws_auth else USE_AWS_CRED_PROVIDERS_TOKEN
 
         if self._query_params.path_prefix:
             # add time to prefix - so that the s3 root folder is unique and we can delete and recreate fast
@@ -178,18 +178,15 @@
 
         set_library_options(env_cfg.env_by_id[_DEFAULT_ENV].lib_by_path[name], library_options)
 
         lib = NativeVersionStore.create_store_from_config(
             env_cfg, _DEFAULT_ENV, name, encoding_version=self._encoding_version
         )
 
-        return lib._lib_cfg
-
-    def initialize_library(self, name: str, config: LibraryConfig):
-        pass
+        return lib
 
     def _configure_aws(self):
         if not self._query_params.region:
             match = re.match(r"s3\.(?P<region>[a-z0-9-]+)\.amazonaws.*", self._endpoint)
             if match:
                 match_groups = match.groupdict()
                 self._query_params.region = match_groups["region"]
```

## arcticdb/version_store/_store.py

```diff
@@ -44,14 +44,15 @@
 from arcticdb_ext.version_store import PythonVersionStore as _PythonVersionStore
 from arcticdb_ext.version_store import PythonVersionStoreReadQuery as _PythonVersionStoreReadQuery
 from arcticdb_ext.version_store import PythonVersionStoreUpdateQuery as _PythonVersionStoreUpdateQuery
 from arcticdb_ext.version_store import PythonVersionStoreReadOptions as _PythonVersionStoreReadOptions
 from arcticdb_ext.version_store import PythonVersionStoreVersionQuery as _PythonVersionStoreVersionQuery
 from arcticdb_ext.version_store import ColumnStats as _ColumnStats
 from arcticdb_ext.version_store import StreamDescriptorMismatch
+from arcticdb_ext.version_store import DataError
 from arcticdb.authorization.permissions import OpenMode
 from arcticdb.exceptions import ArcticNativeNotYetImplemented, ArcticNativeException
 from arcticdb.flattener import Flattener
 from arcticdb.log import version as log
 from arcticdb.version_store._custom_normalizers import get_custom_normalizer, CompositeCustomNormalizer
 from arcticdb.version_store._normalization import (
     NPDDataFrame,
@@ -801,15 +802,15 @@
                 version=vit.version,
                 metadata=metadata,
                 data=None,
                 host=self.env,
             )
 
     def create_column_stats(
-        self, symbol: str, column_stats: Dict[str, Set[str]], as_of: VersionQueryInput = None
+        self, symbol: str, column_stats: Dict[str, Set[str]], as_of: Optional[VersionQueryInput] = None
     ) -> None:
         """
         Calculates the specified column statistics for each row-slice for the given symbol. In the future, these
         statistics will be used by `QueryBuilder` filtering operations to reduce the number of data segments read out
         of storage.
 
         Parameters
@@ -817,91 +818,81 @@
         symbol: `str`
             Symbol name.
         column_stats: `Dict[str, Set[str]]`
             The column stats to create.
             Keys are column names.
             Values are sets of statistic types to build for that column. Options are:
                 "MINMAX" : store the minimum and maximum value for the column in each row-slice
-        as_of : `str` or `int` or `datetime.datetime`
-            Create the column stats for the version as it was as_of the point in time.
-            `int` : specific version number
-            `str` : snapshot name which contains the version
-            `datetime.datetime` : the version of the data that existed as_of the requested point in time
+        as_of : `Optional[VersionQueryInput]`, default=None
+            See documentation of `read` method for more details.
 
         Returns
         -------
         None
         """
         column_stats = self._get_column_stats(column_stats)
         version_query = self._get_version_query(as_of)
         self.version_store.create_column_stats_version(symbol, column_stats, version_query)
 
     def drop_column_stats(
-        self, symbol: str, column_stats: Optional[Dict[str, Set[str]]] = None, as_of: VersionQueryInput = None
+        self, symbol: str, column_stats: Optional[Dict[str, Set[str]]] = None, as_of: Optional[VersionQueryInput] = None
     ) -> None:
         """
         Deletes the specified column statistics for the given symbol.
 
         Parameters
         ----------
         symbol: `str`
             Symbol name.
         column_stats: `Optional[Dict[str, Set[str]]], default=None`
             The column stats to drop. If not provided, all column stats will be dropped.
             See documentation of `create_column_stats` method for more details.
-        as_of : `str` or `int` or `datetime.datetime`
-            Create the column stats for the version as it was as_of the point in time.
-            `int` : specific version number
-            `str` : snapshot name which contains the version
-            `datetime.datetime` : the version of the data that existed as_of the requested point in time
+        as_of : `Optional[VersionQueryInput]`, default=None
+            See documentation of `read` method for more details.
 
         Returns
         -------
         None
         """
         column_stats = self._get_column_stats(column_stats)
         version_query = self._get_version_query(as_of)
         self.version_store.drop_column_stats_version(symbol, column_stats, version_query)
 
-    def read_column_stats(self, symbol: str, as_of: VersionQueryInput = None, **kwargs) -> pd.DataFrame:
+    def read_column_stats(self, symbol: str, as_of: Optional[VersionQueryInput] = None, **kwargs) -> pd.DataFrame:
         """
         Read all the column statistics data that has been generated for the given symbol.
 
         Parameters
         ----------
         symbol: `str`
             Symbol name.
-        as_of : `str` or `int` or `datetime.datetime`
-            Create the column stats for the version as it was as_of the point in time.
-            `int` : specific version number
-            `str` : snapshot name which contains the version
-            `datetime.datetime` : the version of the data that existed as_of the requested point in time
+        as_of : `Optional[VersionQueryInput]`, default=None
+            See documentation of `read` method for more details.
 
         Returns
         -------
         `pandas.DataFrame`
             DataFrame representing the stored column statistics for each row-slice in a human-readable format.
         """
         version_query = self._get_version_query(as_of, **kwargs)
         data = denormalize_dataframe(self.version_store.read_column_stats_version(symbol, version_query))
         return data
 
-    def get_column_stats_info(self, symbol: str, as_of: VersionQueryInput = None, **kwargs) -> Dict[str, Set[str]]:
+    def get_column_stats_info(
+        self, symbol: str, as_of: Optional[VersionQueryInput] = None, **kwargs
+    ) -> Dict[str, Set[str]]:
         """
         Read the column statistics dictionary for the given symbol.
 
         Parameters
         ----------
         symbol: `str`
             Symbol name.
-        as_of : `str` or `int` or `datetime.datetime`
-            Create the column stats for the version as it was as_of the point in time.
-            `int` : specific version number
-            `str` : snapshot name which contains the version
-            `datetime.datetime` : the version of the data that existed as_of the requested point in time
+        as_of : `Optional[VersionQueryInput]`, default=None
+            See documentation of `read` method for more details.
 
         Returns
         -------
         `Dict[str, Set[str]]`
             A dict from column names to sets of column stats that have been generated for that column.
             In the same format as the `column_stats` argument provided to `create_column_stats` and `drop_column_stats`.
         """
@@ -958,32 +949,43 @@
 
         Returns
         -------
         Dict
             Dictionary of symbol mapping with the versioned items
         """
         _check_batch_kwargs(NativeVersionStore.batch_read, NativeVersionStore.read, kwargs)
+        throw_on_missing_version = True
         versioned_items = self._batch_read_to_versioned_items(
-            symbols, as_ofs, date_ranges, columns, query_builder, kwargs
+            symbols, as_ofs, date_ranges, columns, query_builder, throw_on_missing_version, kwargs
+        )
+        check(
+            all(v is not None for v in versioned_items),
+            "Null value from _batch_read_to_versioned_items. NoDataFoundException should have been thrown instead.",
         )
         return {v.symbol: v for v in versioned_items}
 
-    def _batch_read_to_versioned_items(self, symbols, as_ofs, date_ranges, columns, query_builder, kwargs=None):
+    def _batch_read_to_versioned_items(
+        self, symbols, as_ofs, date_ranges, columns, query_builder, throw_on_missing_version, kwargs=None
+    ):
         if kwargs is None:
             kwargs = dict()
         version_queries = self._get_version_queries(len(symbols), as_ofs, **kwargs)
         read_queries = self._get_read_queries(len(symbols), date_ranges, columns, query_builder)
         read_options = self._get_read_options(**kwargs)
+        read_options.set_batch_throw_on_missing_version(throw_on_missing_version)
         read_results = self.version_store.batch_read(symbols, version_queries, read_queries, read_options)
         versioned_items = []
         for i in range(len(read_results)):
-            read_result = ReadResult(*read_results[i])
-            read_query = read_queries[i]
-            vitem = self._post_process_dataframe(read_result, read_query)
-            versioned_items.append(vitem)
+            if isinstance(read_results[i], DataError):
+                versioned_items.append(read_results[i])
+            else:
+                read_result = ReadResult(*read_results[i])
+                read_query = read_queries[i]
+                vitem = self._post_process_dataframe(read_result, read_query)
+                versioned_items.append(vitem)
         return versioned_items
 
     def batch_read_metadata(
         self, symbols: List[str], as_ofs: Optional[List[VersionQueryInput]] = None, **kwargs
     ) -> Dict[str, VersionedItem]:
         """
         Reads the metadata for multiple symbols in a batch fashion. This is more efficient than making multiple
@@ -1491,15 +1493,15 @@
 
         Parameters
         ----------
         symbol : `str`
             Symbol name.
         as_of : `Optional[VersionQueryInput]`, default=None
             Return the data as it was as_of the point in time. Defaults to getting the latest version.
-            `int` : specific version number
+            `int` : specific version number. Negative indexing is supported, with -1 representing the latest version, -2 the version before that, etc.
             `str` : snapshot name which contains the version
             `datetime.datetime` : the version of the data that existed as_of the requested point in time
         date_range: `Optional[DateRangeInput]`, default=None
             DateRange to read data for.  Applicable only for Pandas data with a DateTime index. Returns only the part
             of the data that falls within the given range.
         row_range: `Optional[Tuple[int, int]]`, default=None
             Row range to read data for. Inclusive of the lower bound, exclusive of the upper bound
```

## arcticdb/version_store/library.py

```diff
@@ -809,15 +809,15 @@
         ----------
         symbol : str
             Symbol name.
 
         as_of : AsOf, default=None
             Return the data as it was as of the point in time. ``None`` means that the latest version should be read. The
             various types of this parameter mean:
-           - ``int``: specific version number
+           - ``int``: specific version number. Negative indexing is supported, with -1 representing the latest version, -2 the version before that, etc.
            - ``str``: snapshot name which contains the version
            - ``datetime.datetime`` : the version of the data that existed ``as_of`` the requested point in time
 
         date_range: Tuple[Optional[Timestamp], Optional[Timestamp]], default=None
             DateRange to restrict read data to.
 
             Applicable only for time-indexed Pandas dataframes or series. Returns only the
@@ -872,34 +872,48 @@
 
         query_builder: Optional[QueryBuilder], default=None
             A single QueryBuilder to apply to all the dataframes before they are returned. If this argument is passed
             then none of the ``symbols`` may have their own query_builder specified in their request.
 
         Returns
         -------
-        List[VersionedItem]
+        List[Union[VersionedItem, DataError]]
             A list of the read results, whose i-th element corresponds to the i-th element of the ``symbols`` parameter.
+            If the specified version does not exist, a DataError object is returned, with symbol, version_request_type,
+            version_request_data properties, error_code, error_category, and exception_string properties.
 
         Raises
         ------
         ArcticInvalidApiUsageException
             If kwarg query_builder and per-symbol query builders both used.
 
         Examples
         --------
 
         >>> lib.write("s1", pd.DataFrame())
         >>> lib.write("s2", pd.DataFrame({"col": [1, 2, 3]}))
         >>> lib.write("s2", pd.DataFrame(), prune_previous_versions=False)
         >>> lib.write("s3", pd.DataFrame())
-        >>> batch = lib.read_batch(["s1", ReadRequest("s2", as_of=0), "s3"])
+        >>> batch = lib.read_batch(["s1", ReadRequest("s2", as_of=0), "s3", ReadRequest("s2", as_of=1000)])
         >>> batch[0].data.empty
         True
         >>> batch[1].data.empty
         False
+        >>> batch[2].data.empty
+        True
+        >>> batch[3].symbol
+        "s2"
+        >>> batch[3].version_request_type
+        VersionRequestType.SPECIFIC
+        >>> batch[3].version_request_data
+        1000
+        >>> batch[3].error_code
+        ErrorCode.E_NO_SUCH_VERSION
+        >>> batch[3].error_category
+        ErrorCategory.MISSING_DATA
 
         See Also
         --------
         read
         """
         symbol_strings = []
         as_ofs = []
@@ -931,17 +945,17 @@
             elif isinstance(s, ReadRequest):
                 handle_read_request(s)
             else:
                 raise ArcticInvalidApiUsageException(
                     f"Unsupported item in the symbols argument s=[{s}] type(s)=[{type(s)}]. Only [str] and"
                     " [ReadRequest] are supported."
                 )
-
+        throw_on_missing_version = False
         return self._nvs._batch_read_to_versioned_items(
-            symbol_strings, as_ofs, date_ranges, columns, query_builder or query_builders
+            symbol_strings, as_ofs, date_ranges, columns, query_builder or query_builders, throw_on_missing_version
         )
 
     def read_metadata(self, symbol: str, as_of: Optional[AsOf] = None) -> VersionedItem:
         """
         Return the metadata saved for a symbol.  This method is faster than read as it only loads the metadata, not the
         data itself.
```

## Comparing `arcticdb-1.5.0.dist-info/LICENSE.txt` & `arcticdb-1.6.0.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `arcticdb-1.5.0.dist-info/METADATA` & `arcticdb-1.6.0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: arcticdb
-Version: 1.5.0
+Version: 1.6.0
 Summary: ArcticDB DataFrame Database
 Home-page: https://github.com/man-group/arcticdb
 Author: Man Alpha Technology
 Author-email: arcticdb@man.com
 License: Business Source License 1.1 (See LICENSE.txt)
 Classifier: Programming Language :: Python :: 3
 Classifier: Operating System :: POSIX :: Linux
@@ -85,15 +85,15 @@
 ## Quickstart
 
 ### Prebuilt binary availability
 
 |                       | PyPI (Python 3.6 - 3.11) | conda-forge (Python 3.8 - 3.11) |
 | --------------------- | - | - |
 | Linux                 | ✔️ | ✔️ |
-| Windows               | ✔️ | ➖ |
+| Windows               | Beta | ➖ |
 | MacOS (Apple Silicon) | ➖ | ✔️ |
 
 ### Storage compatibility
 
 
 |                       | PyPI | conda-forge |
 | --------------------- | - | - |
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: arcticdb Version: 1.5.0 Summary: ArcticDB DataFrame
+Metadata-Version: 2.1 Name: arcticdb Version: 1.6.0 Summary: ArcticDB DataFrame
 Database Home-page: https://github.com/man-group/arcticdb Author: Man Alpha
 Technology Author-email: arcticdb@man.com License: Business Source License 1.1
 (See LICENSE.txt) Classifier: Programming Language :: Python :: 3 Classifier:
 Operating System :: POSIX :: Linux Classifier: Operating System :: Microsoft ::
 Windows Classifier: Topic :: Database Classifier: Topic :: Database :: Database
 Engines/Servers Description-Content-Type: text/markdown License-File:
 LICENSE.txt License-File: NOTICE.txt Requires-Dist: numpy Requires-Dist: pandas
@@ -50,15 +50,15 @@
 network. ArcticDB is designed from the outset to be resilient; there is no
 single point of failure, and persistent data structures in the storage mean
 that once a version of a *symbol* has been written, it can never be corrupted
 by subsequent updates. Pulling compressed data directly from storage to the
 client means that there is no server to overload, so your data is always
 available when you need it. ## Quickstart ### Prebuilt binary availability | |
 PyPI (Python 3.6 - 3.11) | conda-forge (Python 3.8 - 3.11) | | ----------------
------ | - | - | | Linux | âï¸ | âï¸ | | Windows | âï¸ | â | | MacOS
+----- | - | - | | Linux | âï¸ | âï¸ | | Windows | Beta | â | | MacOS
 (Apple Silicon) | â | âï¸ | ### Storage compatibility | | PyPI | conda-
 forge | | --------------------- | - | - | | S3 | âï¸ | âï¸ | | LMDB |
 âï¸ | âï¸ | | Azure Blob Storage | âï¸ | â | Support for Azure Blob
 Storage in conda-forge is tracked in [#519](https://github.com/man-group/
 ArcticDB/issues/519). ### Installation Install ArcticDB: ```bash $ pip install
 arcticdb ``` or using conda-forge ```bash $ conda install -c conda-forge
 arcticdb ``` Import ArcticDB: ```Python >>> from arcticdb import Arctic ```
```

## Comparing `arcticdb-1.5.0.dist-info/NOTICE.txt` & `arcticdb-1.6.0.dist-info/NOTICE.txt`

 * *Files identical despite different names*

## Comparing `arcticdb-1.5.0.dist-info/RECORD` & `arcticdb-1.6.0.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -1,27 +1,27 @@
-arcticdb_ext.cp39-win_amd64.pyd,sha256=Enbs9ZezDYzW5EH_FtK2o-QrNkOfKn1K4FnSXmcX76U,22087680
+arcticdb_ext.cp39-win_amd64.pyd,sha256=1EjD4j0SU_FhEKGUIOTUSqreSMr2_FyMawHza_CPOqU,22130176
 arcticc/__init__.py,sha256=TgMgqqJDwst6cvC4-whG_3DQOzyry3fRe8HxvE_jrPM,302
 arcticc/pb2/__init__.py,sha256=pfsson0mxPSudMCFd_HpaUTeFROIFD4yA_XQgqAYMiU,583
-arcticdb/__init__.py,sha256=LQnnoxv-duSag2iurWa-GyIsSQ2Ossb2467FWGrvnes,424
+arcticdb/__init__.py,sha256=dtZnmYZIoP8g8Smx_ZT9Kd83tqRokHKDO0oEP-Wifgs,424
 arcticdb/_msgpack_compat.py,sha256=i_3HluY89KVSXFnxC-UjcdK0zNsIcSBLmY3YpKFeLl8,447
-arcticdb/arctic.py,sha256=r0FOgsPYisd_kQhbJcnWkTTKcXZcE1F_DjJ4g5DHSKw,17934
+arcticdb/arctic.py,sha256=kf5WR7ZbHKUNekj4lhdKZdrJyfkgpBuqLEOB9p-lTsQ,18531
 arcticdb/config.py,sha256=IjUg-o-Dprb7N01kzf-o_RQj0Q4qfFpQ1frNZgJqmWA,8617
 arcticdb/encoding_version.py,sha256=vRHz5oyP06Wa_NFDxDBHrQaHMHx8QWN3RMAqenVgeS4,429
 arcticdb/exceptions.py,sha256=ArcFJwbH8PKD5CfC5Aq5LEKwcjIx-ftsocuGtwZjUrU,765
 arcticdb/flattener.py,sha256=u-rdlqaavqzcMUtyMycjaa9MjUdd-6xcVedkCjW8nJ8,9361
 arcticdb/log.py,sha256=-jhGsvGmwEyv7cvQMwEkVM9RMy2Ddm4JEGP7AcfxZOI,1810
 arcticdb/options.py,sha256=1T_MoK82FXZjSYQwduwafC2blCe20wAx5w6SZA-8HJk,6694
 arcticdb/preconditions.py,sha256=85PtbfJEUGvVeRethePECPEhwAY6ZTZ3oy8Fx-KePyY,519
 arcticdb/supported_types.py,sha256=FUr7Slxn5c1v_wQ20H3l5wlK1cwpDoQKJfwDEjtnhEI,1612
 arcticdb/tools.py,sha256=Ah-Dbr-7Tv-0zTg-fRpX9s0GzlHnPyYww9Ke7eaBUew,3150
 arcticdb/adapters/__init__.py,sha256=YgvA84MruMuPLIhy77ZV2QMlKbXwPLlFL2w-wiD4Yvo,211
-arcticdb/adapters/arctic_library_adapter.py,sha256=kAx4-HuXJ7USGlf6kSQcqPZX9PygBgbhpaHmCfEyNMA,2507
-arcticdb/adapters/azure_library_adapter.py,sha256=0_2uTFi7OBSe8hCputCXqtpaRy1xAP8lqKyi6aXuU3I,4935
-arcticdb/adapters/lmdb_library_adapter.py,sha256=2hiAm2iT-DTtAeDejmRuo_elm5xeD8N9jZO_e0_SZT4,2829
-arcticdb/adapters/s3_library_adapter.py,sha256=aMl0vpiAtgZYVoFvEc7vsBj7A1IlbWYbVd0ak0pk5vo,7845
+arcticdb/adapters/arctic_library_adapter.py,sha256=RS12Ps3wlZrLb2pYASxL57LHiGKzkQHvWTRy9McNLAc,2376
+arcticdb/adapters/azure_library_adapter.py,sha256=nHHlyl9lX-fGCcl8WRdfPrCmLeV02RtRCAtqLA2Kvao,4806
+arcticdb/adapters/lmdb_library_adapter.py,sha256=xxDdEj1zNekPQwCY1_L8KUALpVgFoJcd09eiQWh74tI,3240
+arcticdb/adapters/s3_library_adapter.py,sha256=YkV5FPMeerzrcd0lpiLbggjNQfN3gNDkeQcILXT4dso,7716
 arcticdb/authorization/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 arcticdb/authorization/permissions.py,sha256=3E91GMrL6xSEKloOWdIGdaKrHfHoqhkSEqJwjJZJ3HQ,969
 arcticdb/proto/3/arcticc/pb2/azure_storage_pb2.py,sha256=Ert6qv2iyawf92CwxsKJ6nLnckfaz_agS5clE9pxyaQ,4188
 arcticdb/proto/3/arcticc/pb2/config_pb2.py,sha256=W1pb3T1ArzmExVkjgF3xWn5WMWL5l9fR7rR0unnKhxE,8935
 arcticdb/proto/3/arcticc/pb2/descriptors_pb2.py,sha256=VmnoqTZkDtHRVxsPVWqOqoQF2W7lU03KHC6x4Lmk2ys,96954
 arcticdb/proto/3/arcticc/pb2/encoding_pb2.py,sha256=qT9YxRLKuFdjw0GPKtUEUhw8uDfGL2ve8A2ZZk-LlA4,31651
 arcticdb/proto/3/arcticc/pb2/generation_pb2.py,sha256=lnxrzzbxdZ9ooO6BvKwLcntubqOh87YHS-0nzcAJfoI,13225
@@ -58,18 +58,18 @@
 arcticdb/util/memory.py,sha256=-YYUz_ATxFGPov8mAOWsvwgulxZng1hgEB4xkAvUkPg,719
 arcticdb/util/tasks.py,sha256=aXNt_CDW9F0rtXCOwQaWIuoG69OMXajmy7NDUtwgJ2w,6013
 arcticdb/util/test.py,sha256=X0Vaz0kSoj585aaNTI9aj1d-iT2fgbAuoI2-vEknttI,18249
 arcticdb/version_store/__init__.py,sha256=uGAsgCsoyGmR-F7zvOx8GuMs1QdnVHdg5l7RSm6XiBY,131
 arcticdb/version_store/_common.py,sha256=V8eruObk6XhIabaGtFibt7jmzpf0V3nByNOdfb1ftGg,7189
 arcticdb/version_store/_custom_normalizers.py,sha256=EKqxg39qV8BJPjeSCZ9BEOnZkixCXJW796F91bR8wws,4193
 arcticdb/version_store/_normalization.py,sha256=ry2yM8r18YCaPL20acxIAEEthQmztjdb4Lx7lL3yWNs,52672
-arcticdb/version_store/_store.py,sha256=EBgjYie-9jz5qrxVLN3LWfBKTSH2vpHTXbH0sdxgiAA,114434
+arcticdb/version_store/_store.py,sha256=5GE6w1VwG3VOB3PorelvPIQFSpRHxpEKpxJAzirYrfw,114274
 arcticdb/version_store/helper.py,sha256=3dJR0R0far0_j7SAql-7HqYhvrijkAPdKHQpNZr4o0Q,12917
-arcticdb/version_store/library.py,sha256=0TJRHmTdrdmXzkpnLS3cEsJzf7xPFQPsFiQcQIA6NC4,59901
+arcticdb/version_store/library.py,sha256=cKJ8za7T7WojClgLoaD9YxkA2Qi6qmHI3xQ-OqRsMIs,60721
 arcticdb/version_store/processing.py,sha256=POVL_b4wwNgam5ETgyuTzlnt_wngZ29gFEUbGurXTDA,24370
 arcticdb/version_store/read_result.py,sha256=5HhAJ0Wh01f111qA5XvWqOXABO-2H0jZ78kx-iiQzOk,603
-arcticdb-1.5.0.dist-info/LICENSE.txt,sha256=ruvCXWZm0cgyb-XAEjFcfdJkJ_nGbv9gsYNeps514Ys,4851
-arcticdb-1.5.0.dist-info/METADATA,sha256=8Axjp34PohzgdWxTaYFVXWf2sjyaklBW0pGcePh9RY8,9313
-arcticdb-1.5.0.dist-info/NOTICE.txt,sha256=TsVpAVXueJjRq_zV86A3v_TqJRsXCQtYjrEvycwyaaY,18186
-arcticdb-1.5.0.dist-info/WHEEL,sha256=J_4V_gB-O6Y7Pn6lk91K27JaIhI-q07YM5J8Ufzqla4,100
-arcticdb-1.5.0.dist-info/top_level.txt,sha256=jDxz3uFaLYFuxxPf3h6-sqPQqEFbMkWGP-9vE8Dbi1w,30
-arcticdb-1.5.0.dist-info/RECORD,,
+arcticdb-1.6.0.dist-info/LICENSE.txt,sha256=ruvCXWZm0cgyb-XAEjFcfdJkJ_nGbv9gsYNeps514Ys,4851
+arcticdb-1.6.0.dist-info/METADATA,sha256=UEaSJOOLsbQMsACTXzaMD64ewH35rcuilmuMadnh4OM,9311
+arcticdb-1.6.0.dist-info/NOTICE.txt,sha256=TsVpAVXueJjRq_zV86A3v_TqJRsXCQtYjrEvycwyaaY,18186
+arcticdb-1.6.0.dist-info/WHEEL,sha256=J_4V_gB-O6Y7Pn6lk91K27JaIhI-q07YM5J8Ufzqla4,100
+arcticdb-1.6.0.dist-info/top_level.txt,sha256=jDxz3uFaLYFuxxPf3h6-sqPQqEFbMkWGP-9vE8Dbi1w,30
+arcticdb-1.6.0.dist-info/RECORD,,
```

